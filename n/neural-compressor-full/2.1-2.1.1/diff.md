# Comparing `tmp/neural_compressor_full-2.1.tar.gz` & `tmp/neural_compressor_full-2.1.1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "neural_compressor_full-2.1.tar", last modified: Wed Mar 29 09:29:05 2023, max compression
+gzip compressed data, was "neural_compressor_full-2.1.1.tar", last modified: Thu May 11 03:18:19 2023, max compression
```

## Comparing `neural_compressor_full-2.1.tar` & `neural_compressor_full-2.1.1.tar`

### file list

```diff
@@ -1,858 +1,859 @@
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.575706 neural_compressor_full-2.1/
--rw-r--r--   0 root         (0) root         (0)    11360 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/LICENSE
--rw-r--r--   0 root         (0) root         (0)    11296 2023-03-29 09:29:05.575706 neural_compressor_full-2.1/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)    10539 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/README.md
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.487699 neural_compressor_full-2.1/neural_coder/
--rw-r--r--   0 root         (0) root         (0)      748 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/__init__.py
--rw-r--r--   0 root         (0) root         (0)      668 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/__main__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.491699 neural_compressor_full-2.1/neural_coder/backends/
--rw-r--r--   0 root         (0) root         (0)      583 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1382 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/intel_extension_for_transformers.yaml
--rw-r--r--   0 root         (0) root         (0)     1114 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/keras_inc.yaml
--rw-r--r--   0 root         (0) root         (0)     1038 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_bf16.yaml
--rw-r--r--   0 root         (0) root         (0)     1058 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_bf16_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)     1053 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_bf16_ipex.yaml
--rw-r--r--   0 root         (0) root         (0)     1073 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_bf16_ipex_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)     1037 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_fp32_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)     1032 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_fp32_ipex.yaml
--rw-r--r--   0 root         (0) root         (0)     1052 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_fp32_ipex_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)      849 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_gpu_to_cpu.yaml
--rw-r--r--   0 root         (0) root         (0)     1038 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_int8.yaml
--rw-r--r--   0 root         (0) root         (0)     1057 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_jit_bf16.yaml
--rw-r--r--   0 root         (0) root         (0)     1077 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_jit_bf16_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)     1072 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_jit_bf16_ipex.yaml
--rw-r--r--   0 root         (0) root         (0)     1092 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_jit_bf16_ipex_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)     1038 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_jit_fp32.yaml
--rw-r--r--   0 root         (0) root         (0)     1056 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_jit_fp32_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)     1053 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_jit_fp32_ipex.yaml
--rw-r--r--   0 root         (0) root         (0)     1071 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_jit_fp32_ipex_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)     1044 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_onnxruntime_fp32.yaml
--rw-r--r--   0 root         (0) root         (0)     1065 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_onnxruntime_int8_qlinear.yaml
--rw-r--r--   0 root         (0) root         (0)     1041 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_openvino_fp32.yaml
--rw-r--r--   0 root         (0) root         (0)     1062 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/nano_openvino_int8.yaml
--rw-r--r--   0 root         (0) root         (0)     1138 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/onnx_inc_dynamic_quant.yaml
--rw-r--r--   0 root         (0) root         (0)     1188 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/onnx_inc_static_quant_qdq.yaml
--rw-r--r--   0 root         (0) root         (0)     1192 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/onnx_inc_static_quant_qlinear.yaml
--rw-r--r--   0 root         (0) root         (0)      922 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_aliblade.yaml
--rw-r--r--   0 root         (0) root         (0)     2655 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_benchmark.yaml
--rw-r--r--   0 root         (0) root         (0)     1246 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_channels_last.yaml
--rw-r--r--   0 root         (0) root         (0)     1363 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_bf16.yaml
--rw-r--r--   0 root         (0) root         (0)     1859 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_dynamic_quant.yaml
--rw-r--r--   0 root         (0) root         (0)     2033 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_dynamic_quant_fp8.yaml
--rw-r--r--   0 root         (0) root         (0)     1453 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_huggingface_optimum_dynamic.yaml
--rw-r--r--   0 root         (0) root         (0)     1486 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_huggingface_optimum_static.yaml
--rw-r--r--   0 root         (0) root         (0)     1886 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_static_quant_fx.yaml
--rw-r--r--   0 root         (0) root         (0)     1958 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_static_quant_fx_fp8.yaml
--rw-r--r--   0 root         (0) root         (0)     1510 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_static_quant_ipex.yaml
--rw-r--r--   0 root         (0) root         (0)     1306 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_ipex_bf16.yaml
--rw-r--r--   0 root         (0) root         (0)     1076 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_ipex_fp32.yaml
--rw-r--r--   0 root         (0) root         (0)     1540 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_ipex_int8_dynamic_quant.yaml
--rw-r--r--   0 root         (0) root         (0)     1539 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_ipex_int8_static_quant.yaml
--rw-r--r--   0 root         (0) root         (0)     1260 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_jit_script.yaml
--rw-r--r--   0 root         (0) root         (0)     1234 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_jit_script_ofi.yaml
--rw-r--r--   0 root         (0) root         (0)     1347 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_jit_trace.yaml
--rw-r--r--   0 root         (0) root         (0)     1321 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_jit_trace_ofi.yaml
--rw-r--r--   0 root         (0) root         (0)      860 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_mixed_precision_cpu.yaml
--rw-r--r--   0 root         (0) root         (0)      861 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_mixed_precision_cuda.yaml
--rw-r--r--   0 root         (0) root         (0)      843 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_mixed_precision_intel_gpu.yaml
--rw-r--r--   0 root         (0) root         (0)     1201 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_torchdynamo_jit_script.yaml
--rw-r--r--   0 root         (0) root         (0)     1235 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_torchdynamo_jit_script_ofi.yaml
--rw-r--r--   0 root         (0) root         (0)     1216 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_torchdynamo_jit_trace.yaml
--rw-r--r--   0 root         (0) root         (0)     1250 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/pytorch_torchdynamo_jit_trace_ofi.yaml
--rw-r--r--   0 root         (0) root         (0)     1118 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/backends/template.yaml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.491699 neural_compressor_full-2.1/neural_coder/coders/
--rw-r--r--   0 root         (0) root         (0)      583 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.491699 neural_compressor_full-2.1/neural_coder/coders/autoinc/
--rw-r--r--   0 root         (0) root         (0)      583 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/autoinc/__init__.py
--rw-r--r--   0 root         (0) root         (0)    26057 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/autoinc/autoinc_harness.py
--rw-r--r--   0 root         (0) root         (0)     1744 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/autoinc/calib_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     1335 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/autoinc/domain.py
--rw-r--r--   0 root         (0) root         (0)     4793 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/autoinc/eval_func.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.491699 neural_compressor_full-2.1/neural_coder/coders/pytorch/
--rw-r--r--   0 root         (0) root         (0)      583 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3204 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/batch_size.py
--rw-r--r--   0 root         (0) root         (0)     1457 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/change_trainer_to_nlptrainer.py
--rw-r--r--   0 root         (0) root         (0)     2992 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/cuda_to_cpu.py
--rw-r--r--   0 root         (0) root         (0)     6755 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/dummy_dataloader.py
--rw-r--r--   0 root         (0) root         (0)    23101 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/harness.py
--rw-r--r--   0 root         (0) root         (0)     2890 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/lightning.py
--rw-r--r--   0 root         (0) root         (0)     3667 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/reclaim_inference_transformers_trainer.py
--rw-r--r--   0 root         (0) root         (0)     5291 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/pytorch/reclaim_inputs.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.491699 neural_compressor_full-2.1/neural_coder/coders/tensorflow/
--rw-r--r--   0 root         (0) root         (0)      583 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/tensorflow/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2678 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/tensorflow/amp.py
--rw-r--r--   0 root         (0) root         (0)     2361 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/tensorflow/inc.py
--rw-r--r--   0 root         (0) root         (0)     3716 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/coders/transform.py
--rw-r--r--   0 root         (0) root         (0)     3401 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/globals.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.491699 neural_compressor_full-2.1/neural_coder/graphers/
--rw-r--r--   0 root         (0) root         (0)      583 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/graphers/__init__.py
--rw-r--r--   0 root         (0) root         (0)    11123 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/graphers/code_line.py
--rw-r--r--   0 root         (0) root         (0)     7296 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/graphers/function.py
--rw-r--r--   0 root         (0) root         (0)    12402 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/graphers/model.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.491699 neural_compressor_full-2.1/neural_coder/graphers/preloads/
--rw-r--r--   0 root         (0) root         (0)      583 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/graphers/preloads/__init__.py
--rw-r--r--   0 root         (0) root         (0)    58208 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/graphers/preloads/transformers.yaml
--rw-r--r--   0 root         (0) root         (0)    52440 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/interface.py
--rw-r--r--   0 root         (0) root         (0)     3722 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/launcher.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.495700 neural_compressor_full-2.1/neural_coder/utils/
--rw-r--r--   0 root         (0) root         (0)      583 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)      900 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/utils/common.py
--rw-r--r--   0 root         (0) root         (0)     1756 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/utils/cpu_info.py
--rw-r--r--   0 root         (0) root         (0)     3077 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/utils/device.py
--rw-r--r--   0 root         (0) root         (0)     7527 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/utils/handle_user_input.py
--rw-r--r--   0 root         (0) root         (0)     5116 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/utils/line_operation.py
--rw-r--r--   0 root         (0) root         (0)    38671 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/utils/numa_launcher.py
--rw-r--r--   0 root         (0) root         (0)    18664 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/utils/pdf_report.py
--rw-r--r--   0 root         (0) root         (0)      604 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_coder/version.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.495700 neural_compressor_full-2.1/neural_compressor/
--rw-r--r--   0 root         (0) root         (0)     1254 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.495700 neural_compressor_full-2.1/neural_compressor/adaptor/
--rw-r--r--   0 root         (0) root         (0)      973 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7730 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/adaptor.py
--rw-r--r--   0 root         (0) root         (0)    36382 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/keras.py
--rw-r--r--   0 root         (0) root         (0)     3590 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/keras.yaml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.495700 neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/
--rw-r--r--   0 root         (0) root         (0)      632 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3281 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/conv2d.py
--rw-r--r--   0 root         (0) root         (0)     2861 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/dense.py
--rw-r--r--   0 root         (0) root         (0)     4456 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/depthwise_conv2d.py
--rw-r--r--   0 root         (0) root         (0)     3950 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/quantizer.py
--rw-r--r--   0 root         (0) root         (0)     4248 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/separable_conv2d.py
--rw-r--r--   0 root         (0) root         (0)    22313 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/mxnet.py
--rw-r--r--   0 root         (0) root         (0)    10620 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/mxnet.yaml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.495700 neural_compressor_full-2.1/neural_compressor/adaptor/mxnet_utils/
--rw-r--r--   0 root         (0) root         (0)      655 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/mxnet_utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)    31176 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/mxnet_utils/util.py
--rw-r--r--   0 root         (0) root         (0)    72903 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/onnxrt.py
--rw-r--r--   0 root         (0) root         (0)    14506 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/onnxrt.yaml
--rw-r--r--   0 root         (0) root         (0)    15257 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/onnxrt_cuda.yaml
--rw-r--r--   0 root         (0) root         (0)     4832 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/onnxrt_trt.yaml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.499700 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/
--rw-r--r--   0 root         (0) root         (0)      656 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)    32644 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/calibration.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.499700 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/
--rw-r--r--   0 root         (0) root         (0)     1026 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5100 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/activation.py
--rw-r--r--   0 root         (0) root         (0)     1802 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/argmax.py
--rw-r--r--   0 root         (0) root         (0)     4737 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/attention.py
--rw-r--r--   0 root         (0) root         (0)     5054 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/binary_op.py
--rw-r--r--   0 root         (0) root         (0)     5946 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/concat.py
--rw-r--r--   0 root         (0) root         (0)    10775 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/conv.py
--rw-r--r--   0 root         (0) root         (0)     3671 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/direct_q8.py
--rw-r--r--   0 root         (0) root         (0)     4360 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/embed_layernorm.py
--rw-r--r--   0 root         (0) root         (0)     4390 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/gather.py
--rw-r--r--   0 root         (0) root         (0)     3662 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/gavgpool.py
--rw-r--r--   0 root         (0) root         (0)     6655 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/gemm.py
--rw-r--r--   0 root         (0) root         (0)     5776 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/lstm.py
--rw-r--r--   0 root         (0) root         (0)     7546 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/matmul.py
--rw-r--r--   0 root         (0) root         (0)     3319 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/maxpool.py
--rw-r--r--   0 root         (0) root         (0)     5577 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/ops.py
--rw-r--r--   0 root         (0) root         (0)     4996 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/pad.py
--rw-r--r--   0 root         (0) root         (0)     4726 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/pooling.py
--rw-r--r--   0 root         (0) root         (0)     3444 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/resize.py
--rw-r--r--   0 root         (0) root         (0)     6146 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/split.py
--rw-r--r--   0 root         (0) root         (0)    60047 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/quantizer.py
--rw-r--r--   0 root         (0) root         (0)    30132 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/util.py
--rw-r--r--   0 root         (0) root         (0)   186363 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/pytorch.py
--rw-r--r--   0 root         (0) root         (0)    15817 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/pytorch_cpu.yaml
--rw-r--r--   0 root         (0) root         (0)     2627 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/pytorch_gpu.yaml
--rw-r--r--   0 root         (0) root         (0)     4937 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/pytorch_ipex.yaml
--rw-r--r--   0 root         (0) root         (0)     2384 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/query.py
--rw-r--r--   0 root         (0) root         (0)   111661 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tensorflow.py
--rw-r--r--   0 root         (0) root         (0)     9844 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tensorflow.yaml
--rw-r--r--   0 root         (0) root         (0)     6941 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tensorflow_itex.yaml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.499700 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/
--rw-r--r--   0 root         (0) root         (0)      657 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)    41758 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_converter.py
--rw-r--r--   0 root         (0) root         (0)    16274 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_converter_without_calib.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.499700 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/
--rw-r--r--   0 root         (0) root         (0)      665 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.499700 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/
--rw-r--r--   0 root         (0) root         (0)      669 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/__init__.py
--rw-r--r--   0 root         (0) root         (0)    13692 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/bf16_convert.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.503700 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/
--rw-r--r--   0 root         (0) root         (0)      673 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3238 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_add_to_biasadd.py
--rw-r--r--   0 root         (0) root         (0)     3985 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_layout.py
--rw-r--r--   0 root         (0) root         (0)     3191 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_leakyrelu.py
--rw-r--r--   0 root         (0) root         (0)     1871 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_nan_to_random.py
--rw-r--r--   0 root         (0) root         (0)     4330 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_placeholder_to_const.py
--rw-r--r--   0 root         (0) root         (0)     3076 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dequantize_cast_optimizer.py
--rw-r--r--   0 root         (0) root         (0)     4157 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dilated_contraction.py
--rw-r--r--   0 root         (0) root         (0)     5522 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dummy_biasadd.py
--rw-r--r--   0 root         (0) root         (0)     3398 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/expanddims_optimizer.py
--rw-r--r--   0 root         (0) root         (0)     3912 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fetch_weight_from_reshape.py
--rw-r--r--   0 root         (0) root         (0)    13288 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_batch_norm.py
--rw-r--r--   0 root         (0) root         (0)     7500 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_constant.py
--rw-r--r--   0 root         (0) root         (0)     3011 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_biasadd_add.py
--rw-r--r--   0 root         (0) root         (0)     3813 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_column_wise_mul.py
--rw-r--r--   0 root         (0) root         (0)     5035 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_conv_with_math.py
--rw-r--r--   0 root         (0) root         (0)    17017 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_bn.py
--rw-r--r--   0 root         (0) root         (0)    16070 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_in.py
--rw-r--r--   0 root         (0) root         (0)     9500 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_gelu.py
--rw-r--r--   0 root         (0) root         (0)     9885 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_layer_norm.py
--rw-r--r--   0 root         (0) root         (0)     5473 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_conv.py
--rw-r--r--   0 root         (0) root         (0)     5588 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_fp32_conv.py
--rw-r--r--   0 root         (0) root         (0)     5941 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_reshape_transpose.py
--rw-r--r--   0 root         (0) root         (0)     5998 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/graph_cse_optimizer.py
--rw-r--r--   0 root         (0) root         (0)     3201 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/grappler_pass.py
--rw-r--r--   0 root         (0) root         (0)    12797 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/insert_print_node.py
--rw-r--r--   0 root         (0) root         (0)     5980 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/move_squeeze_after_relu.py
--rw-r--r--   0 root         (0) root         (0)    12422 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/pre_optimize.py
--rw-r--r--   0 root         (0) root         (0)     2843 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/remove_training_nodes.py
--rw-r--r--   0 root         (0) root         (0)     2346 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/rename_batch_norm.py
--rw-r--r--   0 root         (0) root         (0)     2674 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/split_shared_input.py
--rw-r--r--   0 root         (0) root         (0)     2219 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_equivalent_nodes.py
--rw-r--r--   0 root         (0) root         (0)     1631 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_unused_nodes.py
--rw-r--r--   0 root         (0) root         (0)     3420 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/switch_optimizer.py
--rw-r--r--   0 root         (0) root         (0)     1224 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/graph_base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.507701 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/
--rw-r--r--   0 root         (0) root         (0)      670 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7820 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_fake_quant.py
--rw-r--r--   0 root         (0) root         (0)    17182 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value.py
--rw-r--r--   0 root         (0) root         (0)     6116 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value_without_calib.py
--rw-r--r--   0 root         (0) root         (0)     7028 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_redundant_dequantize.py
--rw-r--r--   0 root         (0) root         (0)    39443 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_requantize.py
--rw-r--r--   0 root         (0) root         (0)     7817 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize.py
--rw-r--r--   0 root         (0) root         (0)    41642 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_requantize.py
--rw-r--r--   0 root         (0) root         (0)     5409 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/meta_op_optimizer.py
--rw-r--r--   0 root         (0) root         (0)     1736 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_hostconst_converter.py
--rw-r--r--   0 root         (0) root         (0)     5449 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_quantized_op_cse.py
--rw-r--r--   0 root         (0) root         (0)    17254 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/rnn_convert.py
--rw-r--r--   0 root         (0) root         (0)     4912 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/scale_propagation.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.507701 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/
--rw-r--r--   0 root         (0) root         (0)      692 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/__init__.py
--rw-r--r--   0 root         (0) root         (0)    55321 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_graph.py
--rw-r--r--   0 root         (0) root         (0)    13537 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_node.py
--rw-r--r--   0 root         (0) root         (0)     4606 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_schema.py
--rw-r--r--   0 root         (0) root         (0)    22286 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/tf2onnx_utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.507701 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/
--rw-r--r--   0 root         (0) root         (0)      669 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/__init__.py
--rw-r--r--   0 root         (0) root         (0)    36160 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/insert_qdq_pattern.py
--rw-r--r--   0 root         (0) root         (0)     4320 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/merge_duplicated_qdq.py
--rw-r--r--   0 root         (0) root         (0)     2506 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/share_qdq_y_pattern.py
--rw-r--r--   0 root         (0) root         (0)    40223 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_util.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.507701 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/
--rw-r--r--   0 root         (0) root         (0)      666 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.507701 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/
--rw-r--r--   0 root         (0) root         (0)      670 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8721 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/fake_quantize.py
--rw-r--r--   0 root         (0) root         (0)     4620 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_config.py
--rw-r--r--   0 root         (0) root         (0)     2973 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_helper.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.507701 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/
--rw-r--r--   0 root         (0) root         (0)      675 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1285 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/optimize_layer.py
--rw-r--r--   0 root         (0) root         (0)     3103 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_add.py
--rw-r--r--   0 root         (0) root         (0)     3134 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_base.py
--rw-r--r--   0 root         (0) root         (0)     2102 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_bn.py
--rw-r--r--   0 root         (0) root         (0)    10309 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_wrapper.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.507701 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/
--rw-r--r--   0 root         (0) root         (0)      670 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/__init__.py
--rw-r--r--   0 root         (0) root         (0)    13718 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_bn.py
--rw-r--r--   0 root         (0) root         (0)    12386 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_concatv2.py
--rw-r--r--   0 root         (0) root         (0)   112996 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_conv.py
--rw-r--r--   0 root         (0) root         (0)    27174 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_deconv.py
--rw-r--r--   0 root         (0) root         (0)     8266 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_in.py
--rw-r--r--   0 root         (0) root         (0)    55564 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_matmul.py
--rw-r--r--   0 root         (0) root         (0)     6075 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_pooling.py
--rw-r--r--   0 root         (0) root         (0)     7074 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/optimize_qdq.py
--rw-r--r--   0 root         (0) root         (0)    39207 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_base.py
--rw-r--r--   0 root         (0) root         (0)    13443 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_bn.py
--rw-r--r--   0 root         (0) root         (0)     4867 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_concatv2.py
--rw-r--r--   0 root         (0) root         (0)    21256 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_conv.py
--rw-r--r--   0 root         (0) root         (0)     5481 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_for_intel_cpu.py
--rw-r--r--   0 root         (0) root         (0)    17273 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_matmul.py
--rw-r--r--   0 root         (0) root         (0)     3261 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_pooling.py
--rw-r--r--   0 root         (0) root         (0)    19194 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph_common.py
--rw-r--r--   0 root         (0) root         (0)    14567 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/tf2onnx_converter.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/
--rw-r--r--   0 root         (0) root         (0)      662 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6270 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/bias_correction.py
--rw-r--r--   0 root         (0) root         (0)     3619 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base.py
--rw-r--r--   0 root         (0) root         (0)     9682 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/insert_logging.py
--rw-r--r--   0 root         (0) root         (0)    15143 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat.py
--rw-r--r--   0 root         (0) root         (0)    24096 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/util.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/
--rw-r--r--   0 root         (0) root         (0)      657 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3278 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/bf16_convert.py
--rw-r--r--   0 root         (0) root         (0)    25653 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/hawq_metric.py
--rw-r--r--   0 root         (0) root         (0)    33159 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/smooth_quant.py
--rw-r--r--   0 root         (0) root         (0)     2732 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/symbolic_trace.py
--rw-r--r--   0 root         (0) root         (0)    38269 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/util.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/algorithm/
--rw-r--r--   0 root         (0) root         (0)     1133 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/algorithm/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6577 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/algorithm/algorithm.py
--rw-r--r--   0 root         (0) root         (0)     6191 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/algorithm/fast_bias_correction.py
--rw-r--r--   0 root         (0) root         (0)     3362 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/algorithm/smooth_quant.py
--rw-r--r--   0 root         (0) root         (0)     6136 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/algorithm/weight_correction.py
--rw-r--r--   0 root         (0) root         (0)    26391 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/benchmark.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/compression/
--rw-r--r--   0 root         (0) root         (0)      820 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/__init__.py
--rw-r--r--   0 root         (0) root         (0)    32708 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/callbacks.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/compression/distillation/
--rw-r--r--   0 root         (0) root         (0)      656 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/distillation/__init__.py
--rw-r--r--   0 root         (0) root         (0)    65142 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/distillation/criterions.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/compression/pruner/
--rw-r--r--   0 root         (0) root         (0)      649 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/pruner/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7272 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/pruner/criteria.py
--rw-r--r--   0 root         (0) root         (0)    55148 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/pruner/patterns.py
--rw-r--r--   0 root         (0) root         (0)    24370 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/pruner/pruners.py
--rw-r--r--   0 root         (0) root         (0)     5094 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/pruner/regs.py
--rw-r--r--   0 root         (0) root         (0)     6369 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/pruner/schedulers.py
--rw-r--r--   0 root         (0) root         (0)    18398 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/compression/pruner/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/conf/
--rw-r--r--   0 root         (0) root         (0)      632 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/conf/__init__.py
--rw-r--r--   0 root         (0) root         (0)    73646 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/conf/config.py
--rw-r--r--   0 root         (0) root         (0)     3054 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/conf/dotdict.py
--rw-r--r--   0 root         (0) root         (0)     9784 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/conf/pythonic_config.py
--rw-r--r--   0 root         (0) root         (0)    75344 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/config.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/contrib/
--rw-r--r--   0 root         (0) root         (0)      712 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/contrib/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/contrib/strategy/
--rw-r--r--   0 root         (0) root         (0)      973 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/contrib/strategy/__init__.py
--rw-r--r--   0 root         (0) root         (0)    14037 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/contrib/strategy/sigopt.py
--rw-r--r--   0 root         (0) root         (0)    25688 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/contrib/strategy/tpe.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.511701 neural_compressor_full-2.1/neural_compressor/data/
--rw-r--r--   0 root         (0) root         (0)     2351 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.515701 neural_compressor_full-2.1/neural_compressor/data/dataloaders/
--rw-r--r--   0 root         (0) root         (0)      811 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4838 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/base_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     5843 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/dataloader.py
--rw-r--r--   0 root         (0) root         (0)     6119 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/default_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     4892 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/fetcher.py
--rw-r--r--   0 root         (0) root         (0)     1757 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/mxnet_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     3703 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/onnxrt_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     2559 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/pytorch_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     5097 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/sampler.py
--rw-r--r--   0 root         (0) root         (0)    14844 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/dataloaders/tensorflow_dataloader.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.515701 neural_compressor_full-2.1/neural_compressor/data/datasets/
--rw-r--r--   0 root         (0) root         (0)     1253 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/datasets/__init__.py
--rw-r--r--   0 root         (0) root         (0)    19629 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/datasets/bert_dataset.py
--rw-r--r--   0 root         (0) root         (0)    12251 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/datasets/coco_dataset.py
--rw-r--r--   0 root         (0) root         (0)    42946 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/datasets/dataset.py
--rw-r--r--   0 root         (0) root         (0)     6584 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/datasets/dummy_dataset.py
--rw-r--r--   0 root         (0) root         (0)    13461 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/datasets/dummy_dataset_v2.py
--rw-r--r--   0 root         (0) root         (0)     9400 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/datasets/imagenet_dataset.py
--rw-r--r--   0 root         (0) root         (0)     3650 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/datasets/style_transfer_dataset.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.515701 neural_compressor_full-2.1/neural_compressor/data/filters/
--rw-r--r--   0 root         (0) root         (0)     1131 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/filters/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1930 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/filters/coco_filter.py
--rw-r--r--   0 root         (0) root         (0)     6147 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/filters/filter.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.515701 neural_compressor_full-2.1/neural_compressor/data/transforms/
--rw-r--r--   0 root         (0) root         (0)     1929 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/transforms/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2031 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/transforms/coco_transform.py
--rw-r--r--   0 root         (0) root         (0)    17692 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/transforms/imagenet_transform.py
--rw-r--r--   0 root         (0) root         (0)      997 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/transforms/postprocess.py
--rw-r--r--   0 root         (0) root         (0)    12109 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/transforms/tokenization.py
--rw-r--r--   0 root         (0) root         (0)   106216 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/data/transforms/transform.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.515701 neural_compressor_full-2.1/neural_compressor/experimental/
--rw-r--r--   0 root         (0) root         (0)     1325 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/__init__.py
--rw-r--r--   0 root         (0) root         (0)    30416 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/benchmark.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.519702 neural_compressor_full-2.1/neural_compressor/experimental/common/
--rw-r--r--   0 root         (0) root         (0)     1034 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/common/__init__.py
--rw-r--r--   0 root         (0) root         (0)    68967 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/common/criterion.py
--rw-r--r--   0 root         (0) root         (0)     5122 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/common/dataloader.py
--rw-r--r--   0 root         (0) root         (0)     1535 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/common/metric.py
--rw-r--r--   0 root         (0) root         (0)     2500 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/common/model.py
--rw-r--r--   0 root         (0) root         (0)     7839 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/common/optimizer.py
--rw-r--r--   0 root         (0) root         (0)      997 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/common/postprocess.py
--rw-r--r--   0 root         (0) root         (0)     2182 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/common/torch_utils.py
--rw-r--r--   0 root         (0) root         (0)    25100 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/component.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.519702 neural_compressor_full-2.1/neural_compressor/experimental/compression/
--rw-r--r--   0 root         (0) root         (0)      700 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/compression/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5628 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/compression/pruning.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.519702 neural_compressor_full-2.1/neural_compressor/experimental/data/
--rw-r--r--   0 root         (0) root         (0)     1269 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.519702 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/
--rw-r--r--   0 root         (0) root         (0)      836 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4816 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/base_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     1582 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/dataloader.py
--rw-r--r--   0 root         (0) root         (0)     6075 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/default_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     4826 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/fetcher.py
--rw-r--r--   0 root         (0) root         (0)     1735 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/mxnet_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     3659 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/onnxrt_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     2537 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/pytorch_dataloader.py
--rw-r--r--   0 root         (0) root         (0)     5009 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/sampler.py
--rw-r--r--   0 root         (0) root         (0)    14814 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/tensorflow_dataloader.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.519702 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/
--rw-r--r--   0 root         (0) root         (0)     1128 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/__init__.py
--rw-r--r--   0 root         (0) root         (0)    19430 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/bert_dataset.py
--rw-r--r--   0 root         (0) root         (0)    12163 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/coco_dataset.py
--rw-r--r--   0 root         (0) root         (0)    42301 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/dataset.py
--rw-r--r--   0 root         (0) root         (0)     6561 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/dummy_dataset.py
--rw-r--r--   0 root         (0) root         (0)    13417 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/dummy_dataset_v2.py
--rw-r--r--   0 root         (0) root         (0)     9268 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/imagenet_dataset.py
--rw-r--r--   0 root         (0) root         (0)     3627 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/style_transfer_dataset.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.519702 neural_compressor_full-2.1/neural_compressor/experimental/data/filters/
--rw-r--r--   0 root         (0) root         (0)     1045 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/filters/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1884 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/filters/coco_filter.py
--rw-r--r--   0 root         (0) root         (0)     5962 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/filters/filter.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.519702 neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/
--rw-r--r--   0 root         (0) root         (0)     1208 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/__init__.py
--rw-r--r--   0 root         (0) root         (0)    17489 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/imagenet_transform.py
--rw-r--r--   0 root         (0) root         (0)    12109 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/tokenization.py
--rw-r--r--   0 root         (0) root         (0)   106216 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/transform.py
--rw-r--r--   0 root         (0) root         (0)    21921 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/distillation.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.519702 neural_compressor_full-2.1/neural_compressor/experimental/export/
--rw-r--r--   0 root         (0) root         (0)      834 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/export/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3079 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/export/qlinear2qdq.py
--rw-r--r--   0 root         (0) root         (0)     4687 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/export/tf2onnx.py
--rw-r--r--   0 root         (0) root         (0)    36419 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/export/torch2onnx.py
--rw-r--r--   0 root         (0) root         (0)     2289 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/export/utils.py
--rw-r--r--   0 root         (0) root         (0)    20016 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/graph_optimization.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.523702 neural_compressor_full-2.1/neural_compressor/experimental/metric/
--rw-r--r--   0 root         (0) root         (0)     1069 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/metric/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4874 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/metric/bleu.py
--rw-r--r--   0 root         (0) root         (0)     5230 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/metric/bleu_util.py
--rw-r--r--   0 root         (0) root         (0)     2188 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/metric/coco_label_map.py
--rw-r--r--   0 root         (0) root         (0)    32578 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/metric/coco_tools.py
--rw-r--r--   0 root         (0) root         (0)     4339 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/metric/evaluate_squad.py
--rw-r--r--   0 root         (0) root         (0)     5342 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/metric/f1.py
--rw-r--r--   0 root         (0) root         (0)    57890 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/metric/metric.py
--rw-r--r--   0 root         (0) root         (0)    10133 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/mixed_precision.py
--rw-r--r--   0 root         (0) root         (0)    15676 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/model_conversion.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.523702 neural_compressor_full-2.1/neural_compressor/experimental/nas/
--rw-r--r--   0 root         (0) root         (0)      728 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/nas/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6086 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/nas/basic_nas.py
--rw-r--r--   0 root         (0) root         (0)     4022 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/nas/dynas.py
--rw-r--r--   0 root         (0) root         (0)    15982 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/nas/nas.py
--rw-r--r--   0 root         (0) root         (0)     2797 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/nas/nas_utils.py
--rw-r--r--   0 root         (0) root         (0)     5893 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/nas/search_algorithms.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.523702 neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/
--rw-r--r--   0 root         (0) root         (0)      995 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/__init__.py
--rw-r--r--   0 root         (0) root         (0)    12216 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/gradient_sensitivity.py
--rw-r--r--   0 root         (0) root         (0)     2729 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/group_lasso.py
--rw-r--r--   0 root         (0) root         (0)     4565 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/magnitude.py
--rw-r--r--   0 root         (0) root         (0)     2158 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/pattern_lock.py
--rw-r--r--   0 root         (0) root         (0)     4724 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/pruner.py
--rw-r--r--   0 root         (0) root         (0)    22318 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruning.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.523702 neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/
--rw-r--r--   0 root         (0) root         (0)      736 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.523702 neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/patterns/
--rw-r--r--   0 root         (0) root         (0)     1017 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/patterns/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3735 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/patterns/pattern.py
--rw-r--r--   0 root         (0) root         (0)     2835 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py
--rw-r--r--   0 root         (0) root         (0)    23225 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pruning_v2.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.523702 neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/
--rw-r--r--   0 root         (0) root         (0)      660 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/__init__.py
--rw-r--r--   0 root         (0) root         (0)      681 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/logger.py
--rw-r--r--   0 root         (0) root         (0)    24675 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/patterns.py
--rw-r--r--   0 root         (0) root         (0)     9285 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/prune_utils.py
--rw-r--r--   0 root         (0) root         (0)    12505 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/pruner.py
--rw-r--r--   0 root         (0) root         (0)     6382 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/pruning.py
--rw-r--r--   0 root         (0) root         (0)     5421 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/scheduler.py
--rw-r--r--   0 root         (0) root         (0)    24028 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/quantization.py
--rw-r--r--   0 root         (0) root         (0)    18510 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/experimental/scheduler.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.523702 neural_compressor_full-2.1/neural_compressor/metric/
--rw-r--r--   0 root         (0) root         (0)     1204 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/metric/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4874 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/metric/bleu.py
--rw-r--r--   0 root         (0) root         (0)     5230 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/metric/bleu_util.py
--rw-r--r--   0 root         (0) root         (0)     2188 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/metric/coco_label_map.py
--rw-r--r--   0 root         (0) root         (0)    32578 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/metric/coco_tools.py
--rw-r--r--   0 root         (0) root         (0)     4339 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/metric/evaluate_squad.py
--rw-r--r--   0 root         (0) root         (0)     5342 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/metric/f1.py
--rw-r--r--   0 root         (0) root         (0)    58474 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/metric/metric.py
--rw-r--r--   0 root         (0) root         (0)    19915 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/mix_precision.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.527702 neural_compressor_full-2.1/neural_compressor/model/
--rw-r--r--   0 root         (0) root         (0)      800 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2098 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/base_model.py
--rw-r--r--   0 root         (0) root         (0)     4388 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/keras_model.py
--rw-r--r--   0 root         (0) root         (0)     7127 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/model.py
--rw-r--r--   0 root         (0) root         (0)     2471 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/mxnet_model.py
--rw-r--r--   0 root         (0) root         (0)     4945 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/nets_factory.py
--rw-r--r--   0 root         (0) root         (0)    25267 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/onnx_model.py
--rw-r--r--   0 root         (0) root         (0)    50828 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/tensorflow_model.py
--rw-r--r--   0 root         (0) root         (0)    16101 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/model/torch_model.py
--rw-r--r--   0 root         (0) root         (0)    21247 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/objective.py
--rw-r--r--   0 root         (0) root         (0)    23845 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/quantization.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.527702 neural_compressor_full-2.1/neural_compressor/strategy/
--rw-r--r--   0 root         (0) root         (0)     1015 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4847 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/auto.py
--rw-r--r--   0 root         (0) root         (0)     7623 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/auto_mixed_precision.py
--rw-r--r--   0 root         (0) root         (0)    17640 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/basic.py
--rw-r--r--   0 root         (0) root         (0)    15754 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/bayesian.py
--rw-r--r--   0 root         (0) root         (0)     9569 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/conservative.py
--rw-r--r--   0 root         (0) root         (0)     2297 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/exhaustive.py
--rw-r--r--   0 root         (0) root         (0)     5787 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/hawq_v2.py
--rw-r--r--   0 root         (0) root         (0)    10489 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/mse.py
--rw-r--r--   0 root         (0) root         (0)    11433 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/mse_v2.py
--rw-r--r--   0 root         (0) root         (0)     2550 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/random.py
--rw-r--r--   0 root         (0) root         (0)    78565 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/strategy.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.527702 neural_compressor_full-2.1/neural_compressor/strategy/utils/
--rw-r--r--   0 root         (0) root         (0)      905 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1427 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/utils/constant.py
--rw-r--r--   0 root         (0) root         (0)    21546 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/utils/tuning_sampler.py
--rw-r--r--   0 root         (0) root         (0)    31984 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/utils/tuning_space.py
--rw-r--r--   0 root         (0) root         (0)     3806 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/utils/tuning_structs.py
--rw-r--r--   0 root         (0) root         (0)     1760 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/strategy/utils/utility.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.527702 neural_compressor_full-2.1/neural_compressor/template/
--rw-r--r--   0 root         (0) root         (0)        0 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/template/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4411 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/template/api_doc_example.py
--rw-r--r--   0 root         (0) root         (0)     5001 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/template/graph_optimization.yaml
--rw-r--r--   0 root         (0) root         (0)     5133 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/template/pruning.yaml
--rw-r--r--   0 root         (0) root         (0)     7611 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/template/ptq.yaml
--rw-r--r--   0 root         (0) root         (0)     7003 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/template/qat.yaml
--rw-r--r--   0 root         (0) root         (0)    18689 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/training.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.527702 neural_compressor_full-2.1/neural_compressor/utils/
--rw-r--r--   0 root         (0) root         (0)     1034 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2869 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/collect_layer_histogram.py
--rw-r--r--   0 root         (0) root         (0)     3607 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/constant.py
--rw-r--r--   0 root         (0) root         (0)     9668 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/create_obj_from_config.py
--rw-r--r--   0 root         (0) root         (0)     6085 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/kl_divergence.py
--rw-r--r--   0 root         (0) root         (0)    11294 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/load_huggingface.py
--rw-r--r--   0 root         (0) root         (0)     4722 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/logger.py
--rw-r--r--   0 root         (0) root         (0)     1343 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/options.py
--rw-r--r--   0 root         (0) root         (0)    18173 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/pytorch.py
--rw-r--r--   0 root         (0) root         (0)    19279 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/utils/utility.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.527702 neural_compressor_full-2.1/neural_compressor/ux/
--rw-r--r--   0 root         (0) root         (0)      677 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.527702 neural_compressor_full-2.1/neural_compressor/ux/bin/
--rw-r--r--   0 root         (0) root         (0)      793 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/bin/inc_bench
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.531703 neural_compressor_full-2.1/neural_compressor/ux/components/
--rw-r--r--   0 root         (0) root         (0)      679 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.531703 neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/
--rw-r--r--   0 root         (0) root         (0)      783 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7037 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/benchmark.py
--rw-r--r--   0 root         (0) root         (0)     2580 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/benchmark_model.py
--rw-r--r--   0 root         (0) root         (0)    10329 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/execute_benchmark.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.531703 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/
--rw-r--r--   0 root         (0) root         (0)      706 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3242 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/benchmark_config_generator.py
--rw-r--r--   0 root         (0) root         (0)     3689 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/config_generator.py
--rw-r--r--   0 root         (0) root         (0)     2431 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/graph_optimization_config_generator.py
--rw-r--r--   0 root         (0) root         (0)     2407 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/mixed_precision_config_generator.py
--rw-r--r--   0 root         (0) root         (0)     1430 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/profiling_config_generator.py
--rw-r--r--   0 root         (0) root         (0)     2614 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/pruning_config_generator.py
--rw-r--r--   0 root         (0) root         (0)     4347 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/quantization_config_generator.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.531703 neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/
--rw-r--r--   0 root         (0) root         (0)      687 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/__init__.py
--rw-r--r--   0 root         (0) root         (0)    12749 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/configuration_parser.py
--rw-r--r--   0 root         (0) root         (0)     3230 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/get_boundary_nodes.py
--rw-r--r--   0 root         (0) root         (0)     2945 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/get_configuration.py
--rw-r--r--   0 root         (0) root         (0)     9088 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/params_feeder.py
--rw-r--r--   0 root         (0) root         (0)     1879 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/pruning_config_parser.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.531703 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/
--rw-r--r--   0 root         (0) root         (0)      799 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.531703 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/
--rw-r--r--   0 root         (0) root         (0)       38 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/README
--rw-r--r--   0 root         (0) root         (0)     4679 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/env.py
--rw-r--r--   0 root         (0) root         (0)      494 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/script.py.mako
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.531703 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/
--rw-r--r--   0 root         (0) root         (0)     5512 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/644ec953a7dc_pruning_support.py
--rw-r--r--   0 root         (0) root         (0)     6038 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/6ece06672ed3_v1_14.py
--rw-r--r--   0 root         (0) root         (0)     3060 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/6f0d0f71d92e_v1_13.py
--rw-r--r--   0 root         (0) root         (0)     6099 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/9e89549a08c8_v1_11.py
--rw-r--r--   0 root         (0) root         (0)     2921 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic.ini
--rw-r--r--   0 root         (0) root         (0)     3135 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.535703 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/
--rw-r--r--   0 root         (0) root         (0)      688 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/__init__.py
--rw-r--r--   0 root         (0) root         (0)    13822 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/benchmark.py
--rw-r--r--   0 root         (0) root         (0)     4232 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/benchmark_result.py
--rw-r--r--   0 root         (0) root         (0)     5589 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/dataloader.py
--rw-r--r--   0 root         (0) root         (0)     6642 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/dataset.py
--rw-r--r--   0 root         (0) root         (0)     3323 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/domain.py
--rw-r--r--   0 root         (0) root         (0)     3126 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/domain_flavour.py
--rw-r--r--   0 root         (0) root         (0)     1518 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/example.py
--rw-r--r--   0 root         (0) root         (0)     2558 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/framework.py
--rw-r--r--   0 root         (0) root         (0)     4376 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/metric.py
--rw-r--r--   0 root         (0) root         (0)     7249 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/model.py
--rw-r--r--   0 root         (0) root         (0)    27076 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/optimization.py
--rw-r--r--   0 root         (0) root         (0)     6657 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/optimization_type.py
--rw-r--r--   0 root         (0) root         (0)     4676 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/precision.py
--rw-r--r--   0 root         (0) root         (0)    10510 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/profiling.py
--rw-r--r--   0 root         (0) root         (0)     5790 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/profiling_result.py
--rw-r--r--   0 root         (0) root         (0)     6018 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/project.py
--rw-r--r--   0 root         (0) root         (0)     4585 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/pruning_details.py
--rw-r--r--   0 root         (0) root         (0)     5577 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/transform.py
--rw-r--r--   0 root         (0) root         (0)     5441 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/tuning_details.py
--rw-r--r--   0 root         (0) root         (0)     3702 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/tuning_history.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.535703 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/
--rw-r--r--   0 root         (0) root         (0)     2142 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/__init__.py
--rw-r--r--   0 root         (0) root         (0)    19009 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/benchmark_api_interface.py
--rw-r--r--   0 root         (0) root         (0)    18511 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/dataset_api_interface.py
--rw-r--r--   0 root         (0) root         (0)     5029 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/db_operations.py
--rw-r--r--   0 root         (0) root         (0)    12983 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/diagnosis_api_interface.py
--rw-r--r--   0 root         (0) root         (0)     5951 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/dictionaries_api_interface.py
--rw-r--r--   0 root         (0) root         (0)     9580 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/examples_api_interface.py
--rw-r--r--   0 root         (0) root         (0)     6174 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/model_api_interface.py
--rw-r--r--   0 root         (0) root         (0)    33061 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/optimization_api_interface.py
--rw-r--r--   0 root         (0) root         (0)    15716 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/profiling_api_interface.py
--rw-r--r--   0 root         (0) root         (0)     9808 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/project_api_interface.py
--rw-r--r--   0 root         (0) root         (0)     5872 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/params_interfaces.py
--rw-r--r--   0 root         (0) root         (0)     2803 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.535703 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/
--rw-r--r--   0 root         (0) root         (0)      711 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7624 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/diagnosis.py
--rw-r--r--   0 root         (0) root         (0)     2366 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/factory.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.535703 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/
--rw-r--r--   0 root         (0) root         (0)      718 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1733 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/onnxrt_diagnosis.py
--rw-r--r--   0 root         (0) root         (0)     2487 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/op_details.py
--rw-r--r--   0 root         (0) root         (0)     1495 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/op_entry.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.535703 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/
--rw-r--r--   0 root         (0) root         (0)      722 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1761 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/tensorflow_diagnosis.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.535703 neural_compressor_full-2.1/neural_compressor/ux/components/file_browser/
--rw-r--r--   0 root         (0) root         (0)      679 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/file_browser/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4851 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/file_browser/file_browser.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.535703 neural_compressor_full-2.1/neural_compressor/ux/components/graph/
--rw-r--r--   0 root         (0) root         (0)      682 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1026 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/attribute.py
--rw-r--r--   0 root         (0) root         (0)     5054 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/collapser.py
--rw-r--r--   0 root         (0) root         (0)     1215 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/edge.py
--rw-r--r--   0 root         (0) root         (0)     3114 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/graph.py
--rw-r--r--   0 root         (0) root         (0)     2326 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/graph_reader.py
--rw-r--r--   0 root         (0) root         (0)     1850 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/node.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/graph/reader/
--rw-r--r--   0 root         (0) root         (0)      645 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/reader/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8388 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/reader/onnxrt_reader.py
--rw-r--r--   0 root         (0) root         (0)     4946 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/graph/reader/tensorflow_reader.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/
--rw-r--r--   0 root         (0) root         (0)      996 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2995 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/jobs_control_queue.py
--rw-r--r--   0 root         (0) root         (0)     8397 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/jobs_manager.py
--rw-r--r--   0 root         (0) root         (0)     1486 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/request.py
--rw-r--r--   0 root         (0) root         (0)      942 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/manage_workspace.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/model/
--rw-r--r--   0 root         (0) root         (0)      682 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1097 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/domain.py
--rw-r--r--   0 root         (0) root         (0)     4984 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/model.py
--rw-r--r--   0 root         (0) root         (0)     1192 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/model_type_getter.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/model/onnxrt/
--rw-r--r--   0 root         (0) root         (0)      636 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/onnxrt/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8955 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/onnxrt/model.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/model/pytorch/
--rw-r--r--   0 root         (0) root         (0)      637 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/pytorch/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1907 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/pytorch/model.py
--rw-r--r--   0 root         (0) root         (0)     3194 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/repository.py
--rw-r--r--   0 root         (0) root         (0)     1390 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/shape.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/
--rw-r--r--   0 root         (0) root         (0)      640 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1185 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/frozen_pb.py
--rw-r--r--   0 root         (0) root         (0)     1298 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/keras.py
--rw-r--r--   0 root         (0) root         (0)     1528 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/meta_graph.py
--rw-r--r--   0 root         (0) root         (0)     4650 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/model.py
--rw-r--r--   0 root         (0) root         (0)     1055 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/saved_model.py
--rw-r--r--   0 root         (0) root         (0)     2416 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/
--rw-r--r--   0 root         (0) root         (0)      679 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/__init__.py
--rw-r--r--   0 root         (0) root         (0)      883 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/download_config.py
--rw-r--r--   0 root         (0) root         (0)      876 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/download_model.py
--rw-r--r--   0 root         (0) root         (0)    10674 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/downloader.py
--rw-r--r--   0 root         (0) root         (0)     4064 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/list_models.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/names_mapper/
--rw-r--r--   0 root         (0) root         (0)      650 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/names_mapper/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4121 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/names_mapper/names_mapper.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/
--rw-r--r--   0 root         (0) root         (0)      800 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/__init__.py
--rw-r--r--   0 root         (0) root         (0)    12567 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/execute_optimization.py
--rw-r--r--   0 root         (0) root         (0)     2455 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/factory.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/graph_optimizer/
--rw-r--r--   0 root         (0) root         (0)      693 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/graph_optimizer/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4511 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/graph_optimizer/graph_optimization.py
--rw-r--r--   0 root         (0) root         (0)     4556 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/graph_optimizer/optimize_model.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.539703 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/mixed_precision/
--rw-r--r--   0 root         (0) root         (0)      704 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/mixed_precision/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4361 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/mixed_precision/mixed_precision.py
--rw-r--r--   0 root         (0) root         (0)     4519 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/mixed_precision/optimize_model.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.543704 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/neural_coder_optimization/
--rw-r--r--   0 root         (0) root         (0)      693 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/neural_coder_optimization/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1873 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/neural_coder_optimization/optimize_model.py
--rw-r--r--   0 root         (0) root         (0)     8255 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/optimization.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.543704 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/pruning/
--rw-r--r--   0 root         (0) root         (0)      693 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/pruning/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2300 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/pruning/optimize_model.py
--rw-r--r--   0 root         (0) root         (0)     3451 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/pruning/pruning.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.543704 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tune/
--rw-r--r--   0 root         (0) root         (0)      672 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tune/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2673 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tune/tune_model.py
--rw-r--r--   0 root         (0) root         (0)     5403 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tune/tuning.py
--rw-r--r--   0 root         (0) root         (0)     6296 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tuning_history.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.543704 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/
--rw-r--r--   0 root         (0) root         (0)      695 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4826 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/execute_profiling.py
--rw-r--r--   0 root         (0) root         (0)     1440 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/factory.py
--rw-r--r--   0 root         (0) root         (0)     1751 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/profile_model.py
--rw-r--r--   0 root         (0) root         (0)      921 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/profiler.py
--rw-r--r--   0 root         (0) root         (0)     6098 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/profiling.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.543704 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/
--rw-r--r--   0 root         (0) root         (0)      717 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1023 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/factory.py
--rw-r--r--   0 root         (0) root         (0)     8101 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/profiler.py
--rw-r--r--   0 root         (0) root         (0)     1369 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/utils.py
--rw-r--r--   0 root         (0) root         (0)     2593 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/inc_bench.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.543704 neural_compressor_full-2.1/neural_compressor/ux/utils/
--rw-r--r--   0 root         (0) root         (0)      637 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.547704 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/
--rw-r--r--   0 root         (0) root         (0)    22723 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/dataloaders.json
--rw-r--r--   0 root         (0) root         (0)     2435 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/metrics.json
--rw-r--r--   0 root         (0) root         (0)      778 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/model_wise_params.json
--rw-r--r--   0 root         (0) root         (0)     8434 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/models.json
--rw-r--r--   0 root         (0) root         (0)       97 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/objectives.json
--rw-r--r--   0 root         (0) root         (0)      421 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/precisions.json
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.547704 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.547704 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/
--rw-r--r--   0 root         (0) root         (0)     3529 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/image_recognition.yaml
--rw-r--r--   0 root         (0) root         (0)     1533 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/nlp.yaml
--rw-r--r--   0 root         (0) root         (0)     4675 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/object_detection.yaml
--rw-r--r--   0 root         (0) root         (0)      576 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/pruning.yaml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.547704 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/
--rw-r--r--   0 root         (0) root         (0)     3519 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/default.yaml
--rw-r--r--   0 root         (0) root         (0)     3519 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/image_recognition.yaml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.547704 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/
--rw-r--r--   0 root         (0) root         (0)     3420 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/image_recognition.yaml
--rw-r--r--   0 root         (0) root         (0)     1689 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/nlp.yaml
--rw-r--r--   0 root         (0) root         (0)     3463 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/object_detection.yaml
--rw-r--r--   0 root         (0) root         (0)     3871 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/object_detection_ssd.yaml
--rw-r--r--   0 root         (0) root         (0)     2444 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/recommendation.yaml
--rw-r--r--   0 root         (0) root         (0)    85553 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/pruning_details.json
--rw-r--r--   0 root         (0) root         (0)      169 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/strategies.json
--rw-r--r--   0 root         (0) root         (0)    26030 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/transforms.json
--rw-r--r--   0 root         (0) root         (0)     1460 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/configs/transforms_filter.json
--rw-r--r--   0 root         (0) root         (0)     2662 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/consts.py
--rw-r--r--   0 root         (0) root         (0)     3177 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/environment.py
--rw-r--r--   0 root         (0) root         (0)      960 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/exceptions.py
--rw-r--r--   0 root         (0) root         (0)     8218 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/executor.py
--rw-r--r--   0 root         (0) root         (0)     2045 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/expiring_dict.py
--rw-r--r--   0 root         (0) root         (0)     1107 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/github_info.py
--rw-r--r--   0 root         (0) root         (0)     9590 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/hw_info.py
--rw-r--r--   0 root         (0) root         (0)     4861 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/json_serializer.py
--rw-r--r--   0 root         (0) root         (0)      943 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/logger.py
--rw-r--r--   0 root         (0) root         (0)    10312 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/parser.py
--rw-r--r--   0 root         (0) root         (0)     9732 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/proc.py
--rw-r--r--   0 root         (0) root         (0)     2271 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/processes.py
--rw-r--r--   0 root         (0) root         (0)     1029 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/singleton.py
--rw-r--r--   0 root         (0) root         (0)     1341 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/status_updates.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.547704 neural_compressor_full-2.1/neural_compressor/ux/utils/templates/
--rw-r--r--   0 root         (0) root         (0)      642 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/templates/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1353 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/templates/dataloader_and_metric_template.txt
--rw-r--r--   0 root         (0) root         (0)      935 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/templates/dataloader_template.txt
--rw-r--r--   0 root         (0) root         (0)     5589 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/templates/metric.py
--rw-r--r--   0 root         (0) root         (0)      641 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/templates/metric_template.txt
--rw-r--r--   0 root         (0) root         (0)     2510 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/templates/workdir.py
--rw-r--r--   0 root         (0) root         (0)    21428 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.547704 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/
--rw-r--r--   0 root         (0) root         (0)      630 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/__init__.py
--rw-r--r--   0 root         (0) root         (0)    17305 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/config.py
--rw-r--r--   0 root         (0) root         (0)     5361 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/dataloader.py
--rw-r--r--   0 root         (0) root         (0)     7836 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/evaluation.py
--rw-r--r--   0 root         (0) root         (0)     1934 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/graph_optimization.py
--rw-r--r--   0 root         (0) root         (0)     1978 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/mixed_precision.py
--rw-r--r--   0 root         (0) root         (0)     2436 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/model.py
--rw-r--r--   0 root         (0) root         (0)    16449 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/pruning.py
--rw-r--r--   0 root         (0) root         (0)     3944 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/quantization.py
--rw-r--r--   0 root         (0) root         (0)     8299 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/workload/tuning.py
--rw-r--r--   0 root         (0) root         (0)     1601 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/utils/yaml_utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.547704 neural_compressor_full-2.1/neural_compressor/ux/web/
--rw-r--r--   0 root         (0) root         (0)      670 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2711 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/communication.py
--rw-r--r--   0 root         (0) root         (0)     8904 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/configuration.py
--rw-r--r--   0 root         (0) root         (0)      799 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/exceptions.py
--rw-r--r--   0 root         (0) root         (0)    15066 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/router.py
--rw-r--r--   0 root         (0) root         (0)     7257 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/server.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.551704 neural_compressor_full-2.1/neural_compressor/ux/web/service/
--rw-r--r--   0 root         (0) root         (0)      628 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1329 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/benchmark.py
--rw-r--r--   0 root         (0) root         (0)     3995 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/history_snapshot_parser.py
--rw-r--r--   0 root         (0) root         (0)     1482 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/model.py
--rw-r--r--   0 root         (0) root         (0)     1359 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/optimization.py
--rw-r--r--   0 root         (0) root         (0)     3190 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/profiling.py
--rw-r--r--   0 root         (0) root         (0)     1073 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/request_data_processor.py
--rw-r--r--   0 root         (0) root         (0)     2363 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/response_generator.py
--rw-r--r--   0 root         (0) root         (0)     2838 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/service/workload.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.563705 neural_compressor_full-2.1/neural_compressor/ux/web/static/
--rw-r--r--   0 root         (0) root         (0)    57019 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/3rdpartylicenses.txt
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.571706 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/
--rw-r--r--   0 root         (0) root         (0)      769 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/004a-information-solid-gray.svg
--rw-r--r--   0 root         (0) root         (0)      769 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/004a-information-solid.svg
--rw-r--r--   0 root         (0) root         (0)     1201 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/005a-help-solid-blue.svg
--rw-r--r--   0 root         (0) root         (0)     1201 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/005a-help-solid-gray.svg
--rw-r--r--   0 root         (0) root         (0)     1186 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/005a-help-solid.svg
--rw-r--r--   0 root         (0) root         (0)      981 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/006a-alert-solid-orange.svg
--rw-r--r--   0 root         (0) root         (0)      981 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/006a-alert-solid-red.svg
--rw-r--r--   0 root         (0) root         (0)      662 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/007a-minus-solid.svg
--rw-r--r--   0 root         (0) root         (0)      781 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/008a-plus-solid-black.svg
--rw-r--r--   0 root         (0) root         (0)      781 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/008a-plus-solid-blue.svg
--rw-r--r--   0 root         (0) root         (0)      778 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/008a-plus-solid.svg
--rw-r--r--   0 root         (0) root         (0)      909 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/009a-close-solid.svg
--rw-r--r--   0 root         (0) root         (0)      817 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/010a-passed-completed-solid.svg
--rw-r--r--   0 root         (0) root         (0)      771 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/016-edit-blue.svg
--rw-r--r--   0 root         (0) root         (0)      762 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/016-edit-white.svg
--rw-r--r--   0 root         (0) root         (0)      771 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/016-edit.svg
--rw-r--r--   0 root         (0) root         (0)     2387 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/043-organize-disabled.svg
--rw-r--r--   0 root         (0) root         (0)     2394 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/043-organize.svg
--rw-r--r--   0 root         (0) root         (0)      654 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/050a-folder-solid-white.svg
--rw-r--r--   0 root         (0) root         (0)      657 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/050a-folder-solid.svg
--rw-r--r--   0 root         (0) root         (0)      973 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/052a-browse-preview-solid-gray.svg
--rw-r--r--   0 root         (0) root         (0)      970 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/052a-browse-preview-solid-white.svg
--rw-r--r--   0 root         (0) root         (0)     1031 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/056a-save-solid-white.svg
--rw-r--r--   0 root         (0) root         (0)     1294 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/057b-trash-outlined-gray.svg
--rw-r--r--   0 root         (0) root         (0)     1294 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/057b-trash-outlined.svg
--rw-r--r--   0 root         (0) root         (0)      878 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/073-menu.svg
--rw-r--r--   0 root         (0) root         (0)     1079 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/074-rewind-reverse.svg
--rw-r--r--   0 root         (0) root         (0)      825 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/077-arrow-up.svg
--rw-r--r--   0 root         (0) root         (0)      830 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/083-arrow-forward-right.svg
--rw-r--r--   0 root         (0) root         (0)      659 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/088a-start-solid-gray.svg
--rw-r--r--   0 root         (0) root         (0)      656 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/088a-start-solid-white.svg
--rw-r--r--   0 root         (0) root         (0)      659 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/088a-start-solid.svg
--rw-r--r--   0 root         (0) root         (0)      641 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/145b-document-outlined-white.svg
--rw-r--r--   0 root         (0) root         (0)      647 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/145b-document-outlined.svg
--rw-r--r--   0 root         (0) root         (0)      838 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/146a-copy-solid.svg
--rw-r--r--   0 root         (0) root         (0)      875 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/160a-download-solid-white.svg
--rw-r--r--   0 root         (0) root         (0)      881 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/160a-download-solid.svg
--rw-r--r--   0 root         (0) root         (0)     1465 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/174-gauge.svg
--rw-r--r--   0 root         (0) root         (0)     2006 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/221a-sunny-day-solid.svg
--rw-r--r--   0 root         (0) root         (0)     1324 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/222-night.svg
--rw-r--r--   0 root         (0) root         (0)     1602 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/234a-database-solid-disable.svg
--rw-r--r--   0 root         (0) root         (0)     1534 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/234a-database-solid.svg
--rw-r--r--   0 root         (0) root         (0)     1025 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/289a-checklist-solid.svg
--rw-r--r--   0 root         (0) root         (0)      937 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/291b-line-chart-outlined.svg
--rw-r--r--   0 root         (0) root         (0)     1366 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/292-growth-increase.svg
--rw-r--r--   0 root         (0) root         (0)     1121 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/298a-workflow-process-solid-white.svg
--rw-r--r--   0 root         (0) root         (0)     1109 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/298a-workflow-process-solid.svg
--rw-r--r--   0 root         (0) root         (0)     1169 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/307-org-chart-disabled.svg
--rw-r--r--   0 root         (0) root         (0)     1176 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/307-org-chart-white.svg
--rw-r--r--   0 root         (0) root         (0)     1164 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/307-org-chart.svg
--rw-r--r--   0 root         (0) root         (0)     1427 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/383-general-support.svg
--rw-r--r--   0 root         (0) root         (0)    49300 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/create-new.png
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.571706 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/
--rw-r--r--   0 root         (0) root         (0)     1198 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/005a-help-solid.svg
--rw-r--r--   0 root         (0) root         (0)     2385 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/043-organize-disabled.svg
--rw-r--r--   0 root         (0) root         (0)     2406 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/043-organize.svg
--rw-r--r--   0 root         (0) root         (0)     1501 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/174-gauge.svg
--rw-r--r--   0 root         (0) root         (0)     1594 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/234a-database-solid-disable.svg
--rw-r--r--   0 root         (0) root         (0)     1582 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/234a-database-solid.svg
--rw-r--r--   0 root         (0) root         (0)     1121 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/298a-workflow-process-solid.svg
--rw-r--r--   0 root         (0) root         (0)     1167 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/307-org-chart-disabled.svg
--rw-r--r--   0 root         (0) root         (0)     1176 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/307-org-chart.svg
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.571706 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/
--rw-r--r--   0 root         (0) root         (0)   312920 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Bd.ttf
--rw-r--r--   0 root         (0) root         (0)   314244 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Lt.ttf
--rw-r--r--   0 root         (0) root         (0)   316572 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Rg.ttf
--rw-r--r--   0 root         (0) root         (0)    96764 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-bold.ttf
--rw-r--r--   0 root         (0) root         (0)   100524 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-light.ttf
--rw-r--r--   0 root         (0) root         (0)    95288 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-regular.ttf
--rw-r--r--   0 root         (0) root         (0)     3373 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/logo-energyblue-72px.svg
--rw-r--r--   0 root         (0) root         (0)     3088 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/model-file.svg
--rw-r--r--   0 root         (0) root         (0)     2982 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/model-folder.svg
--rw-r--r--   0 root         (0) root         (0)    27661 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/nn.png
--rw-r--r--   0 root         (0) root         (0)    89817 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/performance.png
--rw-r--r--   0 root         (0) root         (0)     1255 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/index.html
--rw-r--r--   0 root         (0) root         (0)  5873343 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/main.15f64b4092974083.js
--rw-r--r--   0 root         (0) root         (0)  5658527 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/main.8f02ed35744647d6.js
--rw-r--r--   0 root         (0) root         (0)  5870150 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/main.b1d2e7ec4704abc2.js
--rw-r--r--   0 root         (0) root         (0)    37016 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/polyfills.05e532f1e1f2503a.js
--rw-r--r--   0 root         (0) root         (0)    37032 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/polyfills.20acf87fa4379d4f.js
--rw-r--r--   0 root         (0) root         (0)     1310 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/runtime.842b7f3162f7690e.js
--rw-r--r--   0 root         (0) root         (0)   159626 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/styles.00d3de8fab67a2a5.css
--rw-r--r--   0 root         (0) root         (0)   159889 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/styles.3c84233102d6c6b4.css
--rw-r--r--   0 root         (0) root         (0)   151495 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/ux/web/static/styles.a563d0a77a1990e6.css
--rw-r--r--   0 root         (0) root         (0)      764 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/neural_compressor/version.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-03-29 09:29:05.575706 neural_compressor_full-2.1/neural_compressor_full.egg-info/
--rw-r--r--   0 root         (0) root         (0)    11296 2023-03-29 09:29:05.000000 neural_compressor_full-2.1/neural_compressor_full.egg-info/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)    42248 2023-03-29 09:29:05.000000 neural_compressor_full-2.1/neural_compressor_full.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0) root         (0)        1 2023-03-29 09:29:05.000000 neural_compressor_full-2.1/neural_compressor_full.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0) root         (0)      226 2023-03-29 09:29:05.000000 neural_compressor_full-2.1/neural_compressor_full.egg-info/requires.txt
--rw-r--r--   0 root         (0) root         (0)       31 2023-03-29 09:29:05.000000 neural_compressor_full-2.1/neural_compressor_full.egg-info/top_level.txt
--rw-r--r--   0 root         (0) root         (0)       38 2023-03-29 09:29:05.575706 neural_compressor_full-2.1/setup.cfg
--rw-r--r--   0 root         (0) root         (0)     3109 2023-03-29 09:02:48.000000 neural_compressor_full-2.1/setup.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.402398 neural_compressor_full-2.1.1/
+-rw-r--r--   0 root         (0) root         (0)    11360 2023-05-11 02:51:06.000000 neural_compressor_full-2.1.1/LICENSE
+-rw-r--r--   0 root         (0) root         (0)    11463 2023-05-11 03:18:19.402398 neural_compressor_full-2.1.1/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    10704 2023-05-11 02:51:06.000000 neural_compressor_full-2.1.1/README.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.314390 neural_compressor_full-2.1.1/neural_coder/
+-rw-r--r--   0 root         (0) root         (0)      748 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      668 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/__main__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.318390 neural_compressor_full-2.1.1/neural_coder/backends/
+-rw-r--r--   0 root         (0) root         (0)      583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1382 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/intel_extension_for_transformers.yaml
+-rw-r--r--   0 root         (0) root         (0)     1114 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/keras_inc.yaml
+-rw-r--r--   0 root         (0) root         (0)     1038 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_bf16.yaml
+-rw-r--r--   0 root         (0) root         (0)     1058 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_bf16_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)     1053 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_bf16_ipex.yaml
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_bf16_ipex_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)     1037 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_fp32_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)     1032 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_fp32_ipex.yaml
+-rw-r--r--   0 root         (0) root         (0)     1052 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_fp32_ipex_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)      849 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_gpu_to_cpu.yaml
+-rw-r--r--   0 root         (0) root         (0)     1038 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_int8.yaml
+-rw-r--r--   0 root         (0) root         (0)     1057 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_bf16.yaml
+-rw-r--r--   0 root         (0) root         (0)     1077 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_bf16_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)     1072 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_bf16_ipex.yaml
+-rw-r--r--   0 root         (0) root         (0)     1092 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_bf16_ipex_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)     1038 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_fp32.yaml
+-rw-r--r--   0 root         (0) root         (0)     1056 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_fp32_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)     1053 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_fp32_ipex.yaml
+-rw-r--r--   0 root         (0) root         (0)     1071 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_fp32_ipex_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)     1044 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_onnxruntime_fp32.yaml
+-rw-r--r--   0 root         (0) root         (0)     1065 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_onnxruntime_int8_qlinear.yaml
+-rw-r--r--   0 root         (0) root         (0)     1041 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_openvino_fp32.yaml
+-rw-r--r--   0 root         (0) root         (0)     1062 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/nano_openvino_int8.yaml
+-rw-r--r--   0 root         (0) root         (0)     1138 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/onnx_inc_dynamic_quant.yaml
+-rw-r--r--   0 root         (0) root         (0)     1188 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/onnx_inc_static_quant_qdq.yaml
+-rw-r--r--   0 root         (0) root         (0)     1192 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/onnx_inc_static_quant_qlinear.yaml
+-rw-r--r--   0 root         (0) root         (0)      922 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_aliblade.yaml
+-rw-r--r--   0 root         (0) root         (0)     2655 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_benchmark.yaml
+-rw-r--r--   0 root         (0) root         (0)     1246 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_channels_last.yaml
+-rw-r--r--   0 root         (0) root         (0)     1363 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_bf16.yaml
+-rw-r--r--   0 root         (0) root         (0)     1859 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_dynamic_quant.yaml
+-rw-r--r--   0 root         (0) root         (0)     2033 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_dynamic_quant_fp8.yaml
+-rw-r--r--   0 root         (0) root         (0)     1453 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_huggingface_optimum_dynamic.yaml
+-rw-r--r--   0 root         (0) root         (0)     1486 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_huggingface_optimum_static.yaml
+-rw-r--r--   0 root         (0) root         (0)     1886 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_static_quant_fx.yaml
+-rw-r--r--   0 root         (0) root         (0)     1958 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_static_quant_fx_fp8.yaml
+-rw-r--r--   0 root         (0) root         (0)     1510 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_static_quant_ipex.yaml
+-rw-r--r--   0 root         (0) root         (0)     1306 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_ipex_bf16.yaml
+-rw-r--r--   0 root         (0) root         (0)     1076 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_ipex_fp32.yaml
+-rw-r--r--   0 root         (0) root         (0)     1540 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_ipex_int8_dynamic_quant.yaml
+-rw-r--r--   0 root         (0) root         (0)     1539 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_ipex_int8_static_quant.yaml
+-rw-r--r--   0 root         (0) root         (0)     1260 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_jit_script.yaml
+-rw-r--r--   0 root         (0) root         (0)     1234 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_jit_script_ofi.yaml
+-rw-r--r--   0 root         (0) root         (0)     1347 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_jit_trace.yaml
+-rw-r--r--   0 root         (0) root         (0)     1321 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_jit_trace_ofi.yaml
+-rw-r--r--   0 root         (0) root         (0)      860 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_mixed_precision_cpu.yaml
+-rw-r--r--   0 root         (0) root         (0)      861 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_mixed_precision_cuda.yaml
+-rw-r--r--   0 root         (0) root         (0)      843 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_mixed_precision_intel_gpu.yaml
+-rw-r--r--   0 root         (0) root         (0)     1201 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_torchdynamo_jit_script.yaml
+-rw-r--r--   0 root         (0) root         (0)     1235 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_torchdynamo_jit_script_ofi.yaml
+-rw-r--r--   0 root         (0) root         (0)     1216 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_torchdynamo_jit_trace.yaml
+-rw-r--r--   0 root         (0) root         (0)     1250 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/pytorch_torchdynamo_jit_trace_ofi.yaml
+-rw-r--r--   0 root         (0) root         (0)     1118 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/backends/template.yaml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.318390 neural_compressor_full-2.1.1/neural_coder/coders/
+-rw-r--r--   0 root         (0) root         (0)      583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.318390 neural_compressor_full-2.1.1/neural_coder/coders/autoinc/
+-rw-r--r--   0 root         (0) root         (0)      583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/autoinc/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26057 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/autoinc/autoinc_harness.py
+-rw-r--r--   0 root         (0) root         (0)     1744 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/autoinc/calib_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     1335 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/autoinc/domain.py
+-rw-r--r--   0 root         (0) root         (0)     4793 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/autoinc/eval_func.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.322391 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/
+-rw-r--r--   0 root         (0) root         (0)      583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3204 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/batch_size.py
+-rw-r--r--   0 root         (0) root         (0)     1457 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/change_trainer_to_nlptrainer.py
+-rw-r--r--   0 root         (0) root         (0)     2992 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/cuda_to_cpu.py
+-rw-r--r--   0 root         (0) root         (0)     6755 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/dummy_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)    23101 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/harness.py
+-rw-r--r--   0 root         (0) root         (0)     2890 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/lightning.py
+-rw-r--r--   0 root         (0) root         (0)     3667 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/reclaim_inference_transformers_trainer.py
+-rw-r--r--   0 root         (0) root         (0)     5291 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/pytorch/reclaim_inputs.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.322391 neural_compressor_full-2.1.1/neural_coder/coders/tensorflow/
+-rw-r--r--   0 root         (0) root         (0)      583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/tensorflow/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2678 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/tensorflow/amp.py
+-rw-r--r--   0 root         (0) root         (0)     2361 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/tensorflow/inc.py
+-rw-r--r--   0 root         (0) root         (0)     3716 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/coders/transform.py
+-rw-r--r--   0 root         (0) root         (0)     3401 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/globals.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.322391 neural_compressor_full-2.1.1/neural_coder/graphers/
+-rw-r--r--   0 root         (0) root         (0)      583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/graphers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    11123 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/graphers/code_line.py
+-rw-r--r--   0 root         (0) root         (0)     7296 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/graphers/function.py
+-rw-r--r--   0 root         (0) root         (0)    12402 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/graphers/model.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.322391 neural_compressor_full-2.1.1/neural_coder/graphers/preloads/
+-rw-r--r--   0 root         (0) root         (0)      583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/graphers/preloads/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    58208 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/graphers/preloads/transformers.yaml
+-rw-r--r--   0 root         (0) root         (0)    52440 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/interface.py
+-rw-r--r--   0 root         (0) root         (0)     3722 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/launcher.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.322391 neural_compressor_full-2.1.1/neural_coder/utils/
+-rw-r--r--   0 root         (0) root         (0)      583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      900 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/utils/common.py
+-rw-r--r--   0 root         (0) root         (0)     1756 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/utils/cpu_info.py
+-rw-r--r--   0 root         (0) root         (0)     3077 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/utils/device.py
+-rw-r--r--   0 root         (0) root         (0)     7527 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/utils/handle_user_input.py
+-rw-r--r--   0 root         (0) root         (0)     5116 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/utils/line_operation.py
+-rw-r--r--   0 root         (0) root         (0)    38671 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/utils/numa_launcher.py
+-rw-r--r--   0 root         (0) root         (0)    18664 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/utils/pdf_report.py
+-rw-r--r--   0 root         (0) root         (0)      604 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_coder/version.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.322391 neural_compressor_full-2.1.1/neural_compressor/
+-rw-r--r--   0 root         (0) root         (0)     1254 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.326391 neural_compressor_full-2.1.1/neural_compressor/adaptor/
+-rw-r--r--   0 root         (0) root         (0)      973 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7730 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/adaptor.py
+-rw-r--r--   0 root         (0) root         (0)    36382 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras.py
+-rw-r--r--   0 root         (0) root         (0)     3590 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras.yaml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.326391 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/
+-rw-r--r--   0 root         (0) root         (0)      632 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3281 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/conv2d.py
+-rw-r--r--   0 root         (0) root         (0)     2861 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/dense.py
+-rw-r--r--   0 root         (0) root         (0)     4456 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/depthwise_conv2d.py
+-rw-r--r--   0 root         (0) root         (0)     3950 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/quantizer.py
+-rw-r--r--   0 root         (0) root         (0)     4248 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/separable_conv2d.py
+-rw-r--r--   0 root         (0) root         (0)    22313 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet.py
+-rw-r--r--   0 root         (0) root         (0)    10620 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet.yaml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.326391 neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet_utils/
+-rw-r--r--   0 root         (0) root         (0)      655 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet_utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    31176 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet_utils/util.py
+-rw-r--r--   0 root         (0) root         (0)    73017 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/onnxrt.py
+-rw-r--r--   0 root         (0) root         (0)    14506 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/onnxrt.yaml
+-rw-r--r--   0 root         (0) root         (0)    15257 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/onnxrt_cuda.yaml
+-rw-r--r--   0 root         (0) root         (0)     4832 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/onnxrt_trt.yaml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.326391 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/
+-rw-r--r--   0 root         (0) root         (0)      656 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    32644 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/calibration.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.326391 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/
+-rw-r--r--   0 root         (0) root         (0)     1026 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5100 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/activation.py
+-rw-r--r--   0 root         (0) root         (0)     1802 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/argmax.py
+-rw-r--r--   0 root         (0) root         (0)     4737 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/attention.py
+-rw-r--r--   0 root         (0) root         (0)     5054 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/binary_op.py
+-rw-r--r--   0 root         (0) root         (0)     5946 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/concat.py
+-rw-r--r--   0 root         (0) root         (0)    10775 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/conv.py
+-rw-r--r--   0 root         (0) root         (0)     3671 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/direct_q8.py
+-rw-r--r--   0 root         (0) root         (0)     4360 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/embed_layernorm.py
+-rw-r--r--   0 root         (0) root         (0)     4390 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/gather.py
+-rw-r--r--   0 root         (0) root         (0)     3662 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/gavgpool.py
+-rw-r--r--   0 root         (0) root         (0)     6655 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/gemm.py
+-rw-r--r--   0 root         (0) root         (0)     5776 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/lstm.py
+-rw-r--r--   0 root         (0) root         (0)     7546 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/matmul.py
+-rw-r--r--   0 root         (0) root         (0)     3319 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/maxpool.py
+-rw-r--r--   0 root         (0) root         (0)     5577 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/ops.py
+-rw-r--r--   0 root         (0) root         (0)     4996 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/pad.py
+-rw-r--r--   0 root         (0) root         (0)     4726 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/pooling.py
+-rw-r--r--   0 root         (0) root         (0)     3444 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/resize.py
+-rw-r--r--   0 root         (0) root         (0)     6146 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/split.py
+-rw-r--r--   0 root         (0) root         (0)    60047 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/quantizer.py
+-rw-r--r--   0 root         (0) root         (0)    30132 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/util.py
+-rw-r--r--   0 root         (0) root         (0)   200728 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/pytorch.py
+-rw-r--r--   0 root         (0) root         (0)    15795 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/pytorch_cpu.yaml
+-rw-r--r--   0 root         (0) root         (0)     2627 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/pytorch_gpu.yaml
+-rw-r--r--   0 root         (0) root         (0)     4937 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/pytorch_ipex.yaml
+-rw-r--r--   0 root         (0) root         (0)     2384 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/query.py
+-rw-r--r--   0 root         (0) root         (0)   111831 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tensorflow.py
+-rw-r--r--   0 root         (0) root         (0)     9844 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tensorflow.yaml
+-rw-r--r--   0 root         (0) root         (0)     6941 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tensorflow_itex.yaml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.330392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/
+-rw-r--r--   0 root         (0) root         (0)      657 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    41758 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_converter.py
+-rw-r--r--   0 root         (0) root         (0)    16274 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_converter_without_calib.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.330392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/
+-rw-r--r--   0 root         (0) root         (0)      665 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.330392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/
+-rw-r--r--   0 root         (0) root         (0)      669 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    13692 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/bf16_convert.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.334392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/
+-rw-r--r--   0 root         (0) root         (0)      673 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3238 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_add_to_biasadd.py
+-rw-r--r--   0 root         (0) root         (0)     3985 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_layout.py
+-rw-r--r--   0 root         (0) root         (0)     3191 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_leakyrelu.py
+-rw-r--r--   0 root         (0) root         (0)     1871 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_nan_to_random.py
+-rw-r--r--   0 root         (0) root         (0)     4330 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_placeholder_to_const.py
+-rw-r--r--   0 root         (0) root         (0)     3076 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dequantize_cast_optimizer.py
+-rw-r--r--   0 root         (0) root         (0)     4157 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dilated_contraction.py
+-rw-r--r--   0 root         (0) root         (0)     5522 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dummy_biasadd.py
+-rw-r--r--   0 root         (0) root         (0)     3398 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/expanddims_optimizer.py
+-rw-r--r--   0 root         (0) root         (0)     3912 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fetch_weight_from_reshape.py
+-rw-r--r--   0 root         (0) root         (0)    13288 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_batch_norm.py
+-rw-r--r--   0 root         (0) root         (0)     7500 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_constant.py
+-rw-r--r--   0 root         (0) root         (0)     3011 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_biasadd_add.py
+-rw-r--r--   0 root         (0) root         (0)     3813 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_column_wise_mul.py
+-rw-r--r--   0 root         (0) root         (0)     5035 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_conv_with_math.py
+-rw-r--r--   0 root         (0) root         (0)    17017 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_bn.py
+-rw-r--r--   0 root         (0) root         (0)    16070 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_in.py
+-rw-r--r--   0 root         (0) root         (0)     9500 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_gelu.py
+-rw-r--r--   0 root         (0) root         (0)     9885 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_layer_norm.py
+-rw-r--r--   0 root         (0) root         (0)     5473 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_conv.py
+-rw-r--r--   0 root         (0) root         (0)     5588 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_fp32_conv.py
+-rw-r--r--   0 root         (0) root         (0)     5941 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_reshape_transpose.py
+-rw-r--r--   0 root         (0) root         (0)     5998 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/graph_cse_optimizer.py
+-rw-r--r--   0 root         (0) root         (0)     3201 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/grappler_pass.py
+-rw-r--r--   0 root         (0) root         (0)    12728 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/insert_print_node.py
+-rw-r--r--   0 root         (0) root         (0)     5980 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/move_squeeze_after_relu.py
+-rw-r--r--   0 root         (0) root         (0)    12441 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/pre_optimize.py
+-rw-r--r--   0 root         (0) root         (0)     2843 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/remove_training_nodes.py
+-rw-r--r--   0 root         (0) root         (0)     2346 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/rename_batch_norm.py
+-rw-r--r--   0 root         (0) root         (0)     2674 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/split_shared_input.py
+-rw-r--r--   0 root         (0) root         (0)     2219 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_equivalent_nodes.py
+-rw-r--r--   0 root         (0) root         (0)     1631 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_unused_nodes.py
+-rw-r--r--   0 root         (0) root         (0)     3420 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/switch_optimizer.py
+-rw-r--r--   0 root         (0) root         (0)     1224 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/graph_base.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.334392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/
+-rw-r--r--   0 root         (0) root         (0)      670 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7820 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_fake_quant.py
+-rw-r--r--   0 root         (0) root         (0)    18068 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value.py
+-rw-r--r--   0 root         (0) root         (0)     6116 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value_without_calib.py
+-rw-r--r--   0 root         (0) root         (0)     7028 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_redundant_dequantize.py
+-rw-r--r--   0 root         (0) root         (0)    39443 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_requantize.py
+-rw-r--r--   0 root         (0) root         (0)     7817 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize.py
+-rw-r--r--   0 root         (0) root         (0)    41642 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_requantize.py
+-rw-r--r--   0 root         (0) root         (0)     5409 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/meta_op_optimizer.py
+-rw-r--r--   0 root         (0) root         (0)     1736 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_hostconst_converter.py
+-rw-r--r--   0 root         (0) root         (0)     5449 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_quantized_op_cse.py
+-rw-r--r--   0 root         (0) root         (0)    17254 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/rnn_convert.py
+-rw-r--r--   0 root         (0) root         (0)     4912 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/scale_propagation.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.334392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/
+-rw-r--r--   0 root         (0) root         (0)      692 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    55321 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_graph.py
+-rw-r--r--   0 root         (0) root         (0)    13537 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_node.py
+-rw-r--r--   0 root         (0) root         (0)     4606 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_schema.py
+-rw-r--r--   0 root         (0) root         (0)    22286 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/tf2onnx_utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.334392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/
+-rw-r--r--   0 root         (0) root         (0)      669 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    36544 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/insert_qdq_pattern.py
+-rw-r--r--   0 root         (0) root         (0)     4320 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/merge_duplicated_qdq.py
+-rw-r--r--   0 root         (0) root         (0)     2506 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/share_qdq_y_pattern.py
+-rw-r--r--   0 root         (0) root         (0)    40223 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_util.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.334392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/
+-rw-r--r--   0 root         (0) root         (0)      666 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.334392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/
+-rw-r--r--   0 root         (0) root         (0)      670 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8721 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/fake_quantize.py
+-rw-r--r--   0 root         (0) root         (0)     4620 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_config.py
+-rw-r--r--   0 root         (0) root         (0)     2973 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_helper.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.338392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/
+-rw-r--r--   0 root         (0) root         (0)      675 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1285 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/optimize_layer.py
+-rw-r--r--   0 root         (0) root         (0)     3103 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_add.py
+-rw-r--r--   0 root         (0) root         (0)     3134 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_base.py
+-rw-r--r--   0 root         (0) root         (0)     2102 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_bn.py
+-rw-r--r--   0 root         (0) root         (0)    10309 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_wrapper.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.338392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/
+-rw-r--r--   0 root         (0) root         (0)      670 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    13718 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_bn.py
+-rw-r--r--   0 root         (0) root         (0)    12386 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_concatv2.py
+-rw-r--r--   0 root         (0) root         (0)   112996 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_conv.py
+-rw-r--r--   0 root         (0) root         (0)    27174 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_deconv.py
+-rw-r--r--   0 root         (0) root         (0)     8266 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_in.py
+-rw-r--r--   0 root         (0) root         (0)    55564 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_matmul.py
+-rw-r--r--   0 root         (0) root         (0)     6075 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_pooling.py
+-rw-r--r--   0 root         (0) root         (0)     7074 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/optimize_qdq.py
+-rw-r--r--   0 root         (0) root         (0)    39207 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_base.py
+-rw-r--r--   0 root         (0) root         (0)    13443 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_bn.py
+-rw-r--r--   0 root         (0) root         (0)     4867 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_concatv2.py
+-rw-r--r--   0 root         (0) root         (0)    21256 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_conv.py
+-rw-r--r--   0 root         (0) root         (0)     5481 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_for_intel_cpu.py
+-rw-r--r--   0 root         (0) root         (0)    17273 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_matmul.py
+-rw-r--r--   0 root         (0) root         (0)     3261 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_pooling.py
+-rw-r--r--   0 root         (0) root         (0)    19194 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph_common.py
+-rw-r--r--   0 root         (0) root         (0)    14567 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/tf2onnx_converter.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.338392 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/
+-rw-r--r--   0 root         (0) root         (0)      662 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6270 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/bias_correction.py
+-rw-r--r--   0 root         (0) root         (0)     3619 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base.py
+-rw-r--r--   0 root         (0) root         (0)     9682 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/insert_logging.py
+-rw-r--r--   0 root         (0) root         (0)    15143 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat.py
+-rw-r--r--   0 root         (0) root         (0)    24096 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/util.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.338392 neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/
+-rw-r--r--   0 root         (0) root         (0)      657 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3278 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/bf16_convert.py
+-rw-r--r--   0 root         (0) root         (0)    25653 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/hawq_metric.py
+-rw-r--r--   0 root         (0) root         (0)     4018 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/model_wrapper.py
+-rw-r--r--   0 root         (0) root         (0)    40384 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/smooth_quant.py
+-rw-r--r--   0 root         (0) root         (0)     2732 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/symbolic_trace.py
+-rw-r--r--   0 root         (0) root         (0)    39439 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/util.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.338392 neural_compressor_full-2.1.1/neural_compressor/algorithm/
+-rw-r--r--   0 root         (0) root         (0)     1133 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/algorithm/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6577 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/algorithm/algorithm.py
+-rw-r--r--   0 root         (0) root         (0)     6191 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/algorithm/fast_bias_correction.py
+-rw-r--r--   0 root         (0) root         (0)     3583 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/algorithm/smooth_quant.py
+-rw-r--r--   0 root         (0) root         (0)     6136 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/algorithm/weight_correction.py
+-rw-r--r--   0 root         (0) root         (0)    26398 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/benchmark.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.338392 neural_compressor_full-2.1.1/neural_compressor/compression/
+-rw-r--r--   0 root         (0) root         (0)      820 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    32708 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/callbacks.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.338392 neural_compressor_full-2.1.1/neural_compressor/compression/distillation/
+-rw-r--r--   0 root         (0) root         (0)      656 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/distillation/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    65142 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/distillation/criterions.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/compression/pruner/
+-rw-r--r--   0 root         (0) root         (0)      649 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/pruner/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7272 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/pruner/criteria.py
+-rw-r--r--   0 root         (0) root         (0)    55148 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/pruner/patterns.py
+-rw-r--r--   0 root         (0) root         (0)    24370 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/pruner/pruners.py
+-rw-r--r--   0 root         (0) root         (0)     5094 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/pruner/regs.py
+-rw-r--r--   0 root         (0) root         (0)     6369 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/pruner/schedulers.py
+-rw-r--r--   0 root         (0) root         (0)    18398 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/compression/pruner/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/conf/
+-rw-r--r--   0 root         (0) root         (0)      632 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/conf/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    73646 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/conf/config.py
+-rw-r--r--   0 root         (0) root         (0)     3054 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/conf/dotdict.py
+-rw-r--r--   0 root         (0) root         (0)     9784 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/conf/pythonic_config.py
+-rw-r--r--   0 root         (0) root         (0)    75392 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/config.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/contrib/
+-rw-r--r--   0 root         (0) root         (0)      712 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/contrib/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/contrib/strategy/
+-rw-r--r--   0 root         (0) root         (0)      973 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/contrib/strategy/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    14037 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/contrib/strategy/sigopt.py
+-rw-r--r--   0 root         (0) root         (0)    25688 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/contrib/strategy/tpe.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/data/
+-rw-r--r--   0 root         (0) root         (0)     2351 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/
+-rw-r--r--   0 root         (0) root         (0)      811 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4838 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/base_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     5843 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     6119 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/default_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     4892 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/fetcher.py
+-rw-r--r--   0 root         (0) root         (0)     1757 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/mxnet_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     3703 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/onnxrt_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     2559 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/pytorch_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     5097 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/sampler.py
+-rw-r--r--   0 root         (0) root         (0)    14844 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/tensorflow_dataloader.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/data/datasets/
+-rw-r--r--   0 root         (0) root         (0)     1253 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/datasets/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19629 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/datasets/bert_dataset.py
+-rw-r--r--   0 root         (0) root         (0)    12251 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/datasets/coco_dataset.py
+-rw-r--r--   0 root         (0) root         (0)    42946 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/datasets/dataset.py
+-rw-r--r--   0 root         (0) root         (0)     6584 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/datasets/dummy_dataset.py
+-rw-r--r--   0 root         (0) root         (0)    13461 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/datasets/dummy_dataset_v2.py
+-rw-r--r--   0 root         (0) root         (0)     9400 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/datasets/imagenet_dataset.py
+-rw-r--r--   0 root         (0) root         (0)     3650 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/datasets/style_transfer_dataset.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/data/filters/
+-rw-r--r--   0 root         (0) root         (0)     1131 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/filters/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1930 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/filters/coco_filter.py
+-rw-r--r--   0 root         (0) root         (0)     6147 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/filters/filter.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.342393 neural_compressor_full-2.1.1/neural_compressor/data/transforms/
+-rw-r--r--   0 root         (0) root         (0)     1929 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/transforms/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2031 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/transforms/coco_transform.py
+-rw-r--r--   0 root         (0) root         (0)    17692 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/transforms/imagenet_transform.py
+-rw-r--r--   0 root         (0) root         (0)      997 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/transforms/postprocess.py
+-rw-r--r--   0 root         (0) root         (0)    12109 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/transforms/tokenization.py
+-rw-r--r--   0 root         (0) root         (0)   106216 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/data/transforms/transform.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.346393 neural_compressor_full-2.1.1/neural_compressor/experimental/
+-rw-r--r--   0 root         (0) root         (0)     1325 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    30416 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/benchmark.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.346393 neural_compressor_full-2.1.1/neural_compressor/experimental/common/
+-rw-r--r--   0 root         (0) root         (0)     1034 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/common/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    68967 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/common/criterion.py
+-rw-r--r--   0 root         (0) root         (0)     5122 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/common/dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     1535 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/common/metric.py
+-rw-r--r--   0 root         (0) root         (0)     2500 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/common/model.py
+-rw-r--r--   0 root         (0) root         (0)     7839 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/common/optimizer.py
+-rw-r--r--   0 root         (0) root         (0)      997 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/common/postprocess.py
+-rw-r--r--   0 root         (0) root         (0)     2182 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/common/torch_utils.py
+-rw-r--r--   0 root         (0) root         (0)    25100 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/component.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.346393 neural_compressor_full-2.1.1/neural_compressor/experimental/compression/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/compression/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5628 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/compression/pruning.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.346393 neural_compressor_full-2.1.1/neural_compressor/experimental/data/
+-rw-r--r--   0 root         (0) root         (0)     1269 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.346393 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/
+-rw-r--r--   0 root         (0) root         (0)      836 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4816 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/base_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     1582 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     6075 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/default_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     4826 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/fetcher.py
+-rw-r--r--   0 root         (0) root         (0)     1735 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/mxnet_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     3659 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/onnxrt_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     2537 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/pytorch_dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     5009 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/sampler.py
+-rw-r--r--   0 root         (0) root         (0)    14814 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/tensorflow_dataloader.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.346393 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/
+-rw-r--r--   0 root         (0) root         (0)     1128 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19430 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/bert_dataset.py
+-rw-r--r--   0 root         (0) root         (0)    12163 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/coco_dataset.py
+-rw-r--r--   0 root         (0) root         (0)    42301 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/dataset.py
+-rw-r--r--   0 root         (0) root         (0)     6561 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/dummy_dataset.py
+-rw-r--r--   0 root         (0) root         (0)    13417 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/dummy_dataset_v2.py
+-rw-r--r--   0 root         (0) root         (0)     9268 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/imagenet_dataset.py
+-rw-r--r--   0 root         (0) root         (0)     3627 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/style_transfer_dataset.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/data/filters/
+-rw-r--r--   0 root         (0) root         (0)     1045 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/filters/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1884 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/filters/coco_filter.py
+-rw-r--r--   0 root         (0) root         (0)     5962 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/filters/filter.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/
+-rw-r--r--   0 root         (0) root         (0)     1208 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    17489 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/imagenet_transform.py
+-rw-r--r--   0 root         (0) root         (0)    12109 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/tokenization.py
+-rw-r--r--   0 root         (0) root         (0)   106216 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/transform.py
+-rw-r--r--   0 root         (0) root         (0)    21921 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/distillation.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/export/
+-rw-r--r--   0 root         (0) root         (0)      834 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/export/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3079 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/export/qlinear2qdq.py
+-rw-r--r--   0 root         (0) root         (0)     4687 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/export/tf2onnx.py
+-rw-r--r--   0 root         (0) root         (0)    36419 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/export/torch2onnx.py
+-rw-r--r--   0 root         (0) root         (0)     2289 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/export/utils.py
+-rw-r--r--   0 root         (0) root         (0)    20016 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/graph_optimization.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/
+-rw-r--r--   0 root         (0) root         (0)     1069 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4874 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/bleu.py
+-rw-r--r--   0 root         (0) root         (0)     5230 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/bleu_util.py
+-rw-r--r--   0 root         (0) root         (0)     2188 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/coco_label_map.py
+-rw-r--r--   0 root         (0) root         (0)    32578 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/coco_tools.py
+-rw-r--r--   0 root         (0) root         (0)     4339 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/evaluate_squad.py
+-rw-r--r--   0 root         (0) root         (0)     5342 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/f1.py
+-rw-r--r--   0 root         (0) root         (0)    57890 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/metric/metric.py
+-rw-r--r--   0 root         (0) root         (0)    10133 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/mixed_precision.py
+-rw-r--r--   0 root         (0) root         (0)    15676 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/model_conversion.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/nas/
+-rw-r--r--   0 root         (0) root         (0)      728 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/nas/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6086 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/nas/basic_nas.py
+-rw-r--r--   0 root         (0) root         (0)     4022 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/nas/dynas.py
+-rw-r--r--   0 root         (0) root         (0)    15982 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/nas/nas.py
+-rw-r--r--   0 root         (0) root         (0)     2797 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/nas/nas_utils.py
+-rw-r--r--   0 root         (0) root         (0)     5893 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/nas/search_algorithms.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/
+-rw-r--r--   0 root         (0) root         (0)      995 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    12216 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/gradient_sensitivity.py
+-rw-r--r--   0 root         (0) root         (0)     2729 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/group_lasso.py
+-rw-r--r--   0 root         (0) root         (0)     4565 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/magnitude.py
+-rw-r--r--   0 root         (0) root         (0)     2158 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/pattern_lock.py
+-rw-r--r--   0 root         (0) root         (0)     4724 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/pruner.py
+-rw-r--r--   0 root         (0) root         (0)    22318 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruning.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/
+-rw-r--r--   0 root         (0) root         (0)      736 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/patterns/
+-rw-r--r--   0 root         (0) root         (0)     1017 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/patterns/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3735 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/patterns/pattern.py
+-rw-r--r--   0 root         (0) root         (0)     2835 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py
+-rw-r--r--   0 root         (0) root         (0)    23225 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_v2.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.350393 neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/
+-rw-r--r--   0 root         (0) root         (0)      660 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      681 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/logger.py
+-rw-r--r--   0 root         (0) root         (0)    24675 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/patterns.py
+-rw-r--r--   0 root         (0) root         (0)     9285 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/prune_utils.py
+-rw-r--r--   0 root         (0) root         (0)    12505 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/pruner.py
+-rw-r--r--   0 root         (0) root         (0)     6382 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/pruning.py
+-rw-r--r--   0 root         (0) root         (0)     5421 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/scheduler.py
+-rw-r--r--   0 root         (0) root         (0)    24028 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/quantization.py
+-rw-r--r--   0 root         (0) root         (0)    18510 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/experimental/scheduler.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.354394 neural_compressor_full-2.1.1/neural_compressor/metric/
+-rw-r--r--   0 root         (0) root         (0)     1204 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/metric/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4874 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/metric/bleu.py
+-rw-r--r--   0 root         (0) root         (0)     5230 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/metric/bleu_util.py
+-rw-r--r--   0 root         (0) root         (0)     2188 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/metric/coco_label_map.py
+-rw-r--r--   0 root         (0) root         (0)    32578 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/metric/coco_tools.py
+-rw-r--r--   0 root         (0) root         (0)     4339 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/metric/evaluate_squad.py
+-rw-r--r--   0 root         (0) root         (0)     5342 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/metric/f1.py
+-rw-r--r--   0 root         (0) root         (0)    58474 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/metric/metric.py
+-rw-r--r--   0 root         (0) root         (0)    19915 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/mix_precision.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.354394 neural_compressor_full-2.1.1/neural_compressor/model/
+-rw-r--r--   0 root         (0) root         (0)      800 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2098 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/base_model.py
+-rw-r--r--   0 root         (0) root         (0)     4388 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/keras_model.py
+-rw-r--r--   0 root         (0) root         (0)     7172 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/model.py
+-rw-r--r--   0 root         (0) root         (0)     2471 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/mxnet_model.py
+-rw-r--r--   0 root         (0) root         (0)     4945 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/nets_factory.py
+-rw-r--r--   0 root         (0) root         (0)    25267 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/onnx_model.py
+-rw-r--r--   0 root         (0) root         (0)    50828 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/tensorflow_model.py
+-rw-r--r--   0 root         (0) root         (0)    16101 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/model/torch_model.py
+-rw-r--r--   0 root         (0) root         (0)    21247 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/objective.py
+-rw-r--r--   0 root         (0) root         (0)    24079 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/quantization.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.354394 neural_compressor_full-2.1.1/neural_compressor/strategy/
+-rw-r--r--   0 root         (0) root         (0)     1015 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4847 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/auto.py
+-rw-r--r--   0 root         (0) root         (0)     7623 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/auto_mixed_precision.py
+-rw-r--r--   0 root         (0) root         (0)    17640 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/basic.py
+-rw-r--r--   0 root         (0) root         (0)    15754 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/bayesian.py
+-rw-r--r--   0 root         (0) root         (0)     9569 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/conservative.py
+-rw-r--r--   0 root         (0) root         (0)     2297 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/exhaustive.py
+-rw-r--r--   0 root         (0) root         (0)     5787 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/hawq_v2.py
+-rw-r--r--   0 root         (0) root         (0)    10489 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/mse.py
+-rw-r--r--   0 root         (0) root         (0)    12459 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/mse_v2.py
+-rw-r--r--   0 root         (0) root         (0)     2550 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/random.py
+-rw-r--r--   0 root         (0) root         (0)    79180 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/strategy.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.354394 neural_compressor_full-2.1.1/neural_compressor/strategy/utils/
+-rw-r--r--   0 root         (0) root         (0)      905 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1427 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/utils/constant.py
+-rw-r--r--   0 root         (0) root         (0)    21546 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/utils/tuning_sampler.py
+-rw-r--r--   0 root         (0) root         (0)    31984 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/utils/tuning_space.py
+-rw-r--r--   0 root         (0) root         (0)     3808 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/utils/tuning_structs.py
+-rw-r--r--   0 root         (0) root         (0)     1760 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/strategy/utils/utility.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/template/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/template/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4411 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/template/api_doc_example.py
+-rw-r--r--   0 root         (0) root         (0)     5001 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/template/graph_optimization.yaml
+-rw-r--r--   0 root         (0) root         (0)     5133 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/template/pruning.yaml
+-rw-r--r--   0 root         (0) root         (0)     7611 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/template/ptq.yaml
+-rw-r--r--   0 root         (0) root         (0)     7003 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/template/qat.yaml
+-rw-r--r--   0 root         (0) root         (0)    18610 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/training.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/utils/
+-rw-r--r--   0 root         (0) root         (0)     1034 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2869 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/collect_layer_histogram.py
+-rw-r--r--   0 root         (0) root         (0)     3607 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/constant.py
+-rw-r--r--   0 root         (0) root         (0)     9668 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/create_obj_from_config.py
+-rw-r--r--   0 root         (0) root         (0)     6085 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/kl_divergence.py
+-rw-r--r--   0 root         (0) root         (0)    11294 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/load_huggingface.py
+-rw-r--r--   0 root         (0) root         (0)     4722 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/logger.py
+-rw-r--r--   0 root         (0) root         (0)     1343 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/options.py
+-rw-r--r--   0 root         (0) root         (0)    18173 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/pytorch.py
+-rw-r--r--   0 root         (0) root         (0)    19279 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/utils/utility.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/ux/
+-rw-r--r--   0 root         (0) root         (0)      677 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/ux/bin/
+-rw-r--r--   0 root         (0) root         (0)      793 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/bin/inc_bench
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/ux/components/
+-rw-r--r--   0 root         (0) root         (0)      679 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/
+-rw-r--r--   0 root         (0) root         (0)      783 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7037 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/benchmark.py
+-rw-r--r--   0 root         (0) root         (0)     2580 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/benchmark_model.py
+-rw-r--r--   0 root         (0) root         (0)    10329 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/execute_benchmark.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/
+-rw-r--r--   0 root         (0) root         (0)      706 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3242 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/benchmark_config_generator.py
+-rw-r--r--   0 root         (0) root         (0)     3689 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/config_generator.py
+-rw-r--r--   0 root         (0) root         (0)     2431 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/graph_optimization_config_generator.py
+-rw-r--r--   0 root         (0) root         (0)     2407 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/mixed_precision_config_generator.py
+-rw-r--r--   0 root         (0) root         (0)     1430 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/profiling_config_generator.py
+-rw-r--r--   0 root         (0) root         (0)     2614 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/pruning_config_generator.py
+-rw-r--r--   0 root         (0) root         (0)     4347 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/quantization_config_generator.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/
+-rw-r--r--   0 root         (0) root         (0)      687 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    12749 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/configuration_parser.py
+-rw-r--r--   0 root         (0) root         (0)     3230 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/get_boundary_nodes.py
+-rw-r--r--   0 root         (0) root         (0)     2945 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/get_configuration.py
+-rw-r--r--   0 root         (0) root         (0)     9088 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/params_feeder.py
+-rw-r--r--   0 root         (0) root         (0)     1879 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/pruning_config_parser.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/
+-rw-r--r--   0 root         (0) root         (0)      799 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.358394 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/
+-rw-r--r--   0 root         (0) root         (0)       38 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/README
+-rw-r--r--   0 root         (0) root         (0)     4679 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/env.py
+-rw-r--r--   0 root         (0) root         (0)      494 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/script.py.mako
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.362394 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/
+-rw-r--r--   0 root         (0) root         (0)     5512 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/644ec953a7dc_pruning_support.py
+-rw-r--r--   0 root         (0) root         (0)     6038 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/6ece06672ed3_v1_14.py
+-rw-r--r--   0 root         (0) root         (0)     3060 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/6f0d0f71d92e_v1_13.py
+-rw-r--r--   0 root         (0) root         (0)     6099 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/9e89549a08c8_v1_11.py
+-rw-r--r--   0 root         (0) root         (0)     2921 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic.ini
+-rw-r--r--   0 root         (0) root         (0)     3135 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.362394 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/
+-rw-r--r--   0 root         (0) root         (0)      688 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    13822 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/benchmark.py
+-rw-r--r--   0 root         (0) root         (0)     4232 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/benchmark_result.py
+-rw-r--r--   0 root         (0) root         (0)     5589 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     6642 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/dataset.py
+-rw-r--r--   0 root         (0) root         (0)     3323 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/domain.py
+-rw-r--r--   0 root         (0) root         (0)     3126 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/domain_flavour.py
+-rw-r--r--   0 root         (0) root         (0)     1518 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/example.py
+-rw-r--r--   0 root         (0) root         (0)     2558 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/framework.py
+-rw-r--r--   0 root         (0) root         (0)     4376 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/metric.py
+-rw-r--r--   0 root         (0) root         (0)     7249 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/model.py
+-rw-r--r--   0 root         (0) root         (0)    27076 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/optimization.py
+-rw-r--r--   0 root         (0) root         (0)     6657 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/optimization_type.py
+-rw-r--r--   0 root         (0) root         (0)     4676 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/precision.py
+-rw-r--r--   0 root         (0) root         (0)    10510 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/profiling.py
+-rw-r--r--   0 root         (0) root         (0)     5790 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/profiling_result.py
+-rw-r--r--   0 root         (0) root         (0)     6018 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/project.py
+-rw-r--r--   0 root         (0) root         (0)     4585 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/pruning_details.py
+-rw-r--r--   0 root         (0) root         (0)     5577 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/transform.py
+-rw-r--r--   0 root         (0) root         (0)     5441 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/tuning_details.py
+-rw-r--r--   0 root         (0) root         (0)     3702 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/tuning_history.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.362394 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/
+-rw-r--r--   0 root         (0) root         (0)     2142 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19009 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/benchmark_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)    18511 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/dataset_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)     5029 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/db_operations.py
+-rw-r--r--   0 root         (0) root         (0)    12983 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/diagnosis_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)     5951 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/dictionaries_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)     9580 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/examples_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)     6174 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/model_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)    33061 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/optimization_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)    15716 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/profiling_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)     9808 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/project_api_interface.py
+-rw-r--r--   0 root         (0) root         (0)     5872 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/params_interfaces.py
+-rw-r--r--   0 root         (0) root         (0)     2803 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/
+-rw-r--r--   0 root         (0) root         (0)      711 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7624 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/diagnosis.py
+-rw-r--r--   0 root         (0) root         (0)     2366 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/factory.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/
+-rw-r--r--   0 root         (0) root         (0)      718 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1733 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/onnxrt_diagnosis.py
+-rw-r--r--   0 root         (0) root         (0)     2487 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/op_details.py
+-rw-r--r--   0 root         (0) root         (0)     1495 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/op_entry.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/
+-rw-r--r--   0 root         (0) root         (0)      722 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1761 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/tensorflow_diagnosis.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/file_browser/
+-rw-r--r--   0 root         (0) root         (0)      679 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/file_browser/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4851 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/file_browser/file_browser.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/
+-rw-r--r--   0 root         (0) root         (0)      682 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1026 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/attribute.py
+-rw-r--r--   0 root         (0) root         (0)     5054 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/collapser.py
+-rw-r--r--   0 root         (0) root         (0)     1215 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/edge.py
+-rw-r--r--   0 root         (0) root         (0)     3114 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/graph.py
+-rw-r--r--   0 root         (0) root         (0)     2326 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/graph_reader.py
+-rw-r--r--   0 root         (0) root         (0)     1850 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/node.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/reader/
+-rw-r--r--   0 root         (0) root         (0)      645 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/reader/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8388 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/reader/onnxrt_reader.py
+-rw-r--r--   0 root         (0) root         (0)     4946 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/reader/tensorflow_reader.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/
+-rw-r--r--   0 root         (0) root         (0)      996 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2995 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/jobs_control_queue.py
+-rw-r--r--   0 root         (0) root         (0)     8397 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/jobs_manager.py
+-rw-r--r--   0 root         (0) root         (0)     1486 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/request.py
+-rw-r--r--   0 root         (0) root         (0)      942 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/manage_workspace.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/
+-rw-r--r--   0 root         (0) root         (0)      682 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1097 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/domain.py
+-rw-r--r--   0 root         (0) root         (0)     4984 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/model.py
+-rw-r--r--   0 root         (0) root         (0)     1192 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/model_type_getter.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/onnxrt/
+-rw-r--r--   0 root         (0) root         (0)      636 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/onnxrt/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8955 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/onnxrt/model.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/pytorch/
+-rw-r--r--   0 root         (0) root         (0)      637 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/pytorch/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1907 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/pytorch/model.py
+-rw-r--r--   0 root         (0) root         (0)     3194 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/repository.py
+-rw-r--r--   0 root         (0) root         (0)     1390 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/shape.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/
+-rw-r--r--   0 root         (0) root         (0)      640 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1185 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/frozen_pb.py
+-rw-r--r--   0 root         (0) root         (0)     1298 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/keras.py
+-rw-r--r--   0 root         (0) root         (0)     1528 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/meta_graph.py
+-rw-r--r--   0 root         (0) root         (0)     4650 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/model.py
+-rw-r--r--   0 root         (0) root         (0)     1055 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/saved_model.py
+-rw-r--r--   0 root         (0) root         (0)     2416 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.366395 neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/
+-rw-r--r--   0 root         (0) root         (0)      679 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      883 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/download_config.py
+-rw-r--r--   0 root         (0) root         (0)      876 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/download_model.py
+-rw-r--r--   0 root         (0) root         (0)    10674 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/downloader.py
+-rw-r--r--   0 root         (0) root         (0)     4064 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/list_models.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/names_mapper/
+-rw-r--r--   0 root         (0) root         (0)      650 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/names_mapper/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4121 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/names_mapper/names_mapper.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/
+-rw-r--r--   0 root         (0) root         (0)      800 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    12567 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/execute_optimization.py
+-rw-r--r--   0 root         (0) root         (0)     2455 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/factory.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/graph_optimizer/
+-rw-r--r--   0 root         (0) root         (0)      693 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/graph_optimizer/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4511 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/graph_optimizer/graph_optimization.py
+-rw-r--r--   0 root         (0) root         (0)     4556 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/graph_optimizer/optimize_model.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/mixed_precision/
+-rw-r--r--   0 root         (0) root         (0)      704 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/mixed_precision/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4361 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/mixed_precision/mixed_precision.py
+-rw-r--r--   0 root         (0) root         (0)     4519 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/mixed_precision/optimize_model.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/neural_coder_optimization/
+-rw-r--r--   0 root         (0) root         (0)      693 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/neural_coder_optimization/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1873 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/neural_coder_optimization/optimize_model.py
+-rw-r--r--   0 root         (0) root         (0)     8255 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/optimization.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/pruning/
+-rw-r--r--   0 root         (0) root         (0)      693 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/pruning/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2300 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/pruning/optimize_model.py
+-rw-r--r--   0 root         (0) root         (0)     3451 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/pruning/pruning.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tune/
+-rw-r--r--   0 root         (0) root         (0)      672 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tune/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2673 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tune/tune_model.py
+-rw-r--r--   0 root         (0) root         (0)     5403 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tune/tuning.py
+-rw-r--r--   0 root         (0) root         (0)     6296 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tuning_history.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/
+-rw-r--r--   0 root         (0) root         (0)      695 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4826 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/execute_profiling.py
+-rw-r--r--   0 root         (0) root         (0)     1440 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/factory.py
+-rw-r--r--   0 root         (0) root         (0)     1751 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/profile_model.py
+-rw-r--r--   0 root         (0) root         (0)      921 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/profiler.py
+-rw-r--r--   0 root         (0) root         (0)     6098 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/profiling.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.370395 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/
+-rw-r--r--   0 root         (0) root         (0)      717 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1023 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/factory.py
+-rw-r--r--   0 root         (0) root         (0)     8101 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/profiler.py
+-rw-r--r--   0 root         (0) root         (0)     1369 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/utils.py
+-rw-r--r--   0 root         (0) root         (0)     2593 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/inc_bench.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.374395 neural_compressor_full-2.1.1/neural_compressor/ux/utils/
+-rw-r--r--   0 root         (0) root         (0)      637 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.374395 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/
+-rw-r--r--   0 root         (0) root         (0)    22723 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/dataloaders.json
+-rw-r--r--   0 root         (0) root         (0)     2435 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/metrics.json
+-rw-r--r--   0 root         (0) root         (0)      778 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/model_wise_params.json
+-rw-r--r--   0 root         (0) root         (0)     8434 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/models.json
+-rw-r--r--   0 root         (0) root         (0)       97 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/objectives.json
+-rw-r--r--   0 root         (0) root         (0)      421 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/precisions.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.374395 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.374395 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/
+-rw-r--r--   0 root         (0) root         (0)     3529 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/image_recognition.yaml
+-rw-r--r--   0 root         (0) root         (0)     1533 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/nlp.yaml
+-rw-r--r--   0 root         (0) root         (0)     4675 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/object_detection.yaml
+-rw-r--r--   0 root         (0) root         (0)      576 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/pruning.yaml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.374395 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/
+-rw-r--r--   0 root         (0) root         (0)     3519 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/default.yaml
+-rw-r--r--   0 root         (0) root         (0)     3519 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/image_recognition.yaml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.374395 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/
+-rw-r--r--   0 root         (0) root         (0)     3420 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/image_recognition.yaml
+-rw-r--r--   0 root         (0) root         (0)     1689 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/nlp.yaml
+-rw-r--r--   0 root         (0) root         (0)     3463 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/object_detection.yaml
+-rw-r--r--   0 root         (0) root         (0)     3871 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/object_detection_ssd.yaml
+-rw-r--r--   0 root         (0) root         (0)     2444 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/recommendation.yaml
+-rw-r--r--   0 root         (0) root         (0)    85553 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/pruning_details.json
+-rw-r--r--   0 root         (0) root         (0)      169 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/strategies.json
+-rw-r--r--   0 root         (0) root         (0)    26030 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/transforms.json
+-rw-r--r--   0 root         (0) root         (0)     1460 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/transforms_filter.json
+-rw-r--r--   0 root         (0) root         (0)     2662 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/consts.py
+-rw-r--r--   0 root         (0) root         (0)     3177 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/environment.py
+-rw-r--r--   0 root         (0) root         (0)      960 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/exceptions.py
+-rw-r--r--   0 root         (0) root         (0)     8218 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/executor.py
+-rw-r--r--   0 root         (0) root         (0)     2045 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/expiring_dict.py
+-rw-r--r--   0 root         (0) root         (0)     1107 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/github_info.py
+-rw-r--r--   0 root         (0) root         (0)     9590 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/hw_info.py
+-rw-r--r--   0 root         (0) root         (0)     4861 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/json_serializer.py
+-rw-r--r--   0 root         (0) root         (0)      943 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/logger.py
+-rw-r--r--   0 root         (0) root         (0)    10312 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/parser.py
+-rw-r--r--   0 root         (0) root         (0)     9732 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/proc.py
+-rw-r--r--   0 root         (0) root         (0)     2271 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/processes.py
+-rw-r--r--   0 root         (0) root         (0)     1029 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/singleton.py
+-rw-r--r--   0 root         (0) root         (0)     1341 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/status_updates.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.374395 neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/
+-rw-r--r--   0 root         (0) root         (0)      642 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1353 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/dataloader_and_metric_template.txt
+-rw-r--r--   0 root         (0) root         (0)      935 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/dataloader_template.txt
+-rw-r--r--   0 root         (0) root         (0)     5589 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/metric.py
+-rw-r--r--   0 root         (0) root         (0)      641 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/metric_template.txt
+-rw-r--r--   0 root         (0) root         (0)     2510 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/workdir.py
+-rw-r--r--   0 root         (0) root         (0)    21428 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.378396 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/
+-rw-r--r--   0 root         (0) root         (0)      630 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    17305 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/config.py
+-rw-r--r--   0 root         (0) root         (0)     5361 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/dataloader.py
+-rw-r--r--   0 root         (0) root         (0)     7836 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/evaluation.py
+-rw-r--r--   0 root         (0) root         (0)     1934 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/graph_optimization.py
+-rw-r--r--   0 root         (0) root         (0)     1978 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/mixed_precision.py
+-rw-r--r--   0 root         (0) root         (0)     2436 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/model.py
+-rw-r--r--   0 root         (0) root         (0)    16449 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/pruning.py
+-rw-r--r--   0 root         (0) root         (0)     3944 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/quantization.py
+-rw-r--r--   0 root         (0) root         (0)     8299 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/tuning.py
+-rw-r--r--   0 root         (0) root         (0)     1601 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/utils/yaml_utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.378396 neural_compressor_full-2.1.1/neural_compressor/ux/web/
+-rw-r--r--   0 root         (0) root         (0)      670 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2711 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/communication.py
+-rw-r--r--   0 root         (0) root         (0)     8904 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/configuration.py
+-rw-r--r--   0 root         (0) root         (0)      799 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/exceptions.py
+-rw-r--r--   0 root         (0) root         (0)    15066 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/router.py
+-rw-r--r--   0 root         (0) root         (0)     7257 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/server.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.378396 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/
+-rw-r--r--   0 root         (0) root         (0)      628 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1329 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/benchmark.py
+-rw-r--r--   0 root         (0) root         (0)     3995 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/history_snapshot_parser.py
+-rw-r--r--   0 root         (0) root         (0)     1482 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/model.py
+-rw-r--r--   0 root         (0) root         (0)     1359 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/optimization.py
+-rw-r--r--   0 root         (0) root         (0)     3190 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/profiling.py
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/request_data_processor.py
+-rw-r--r--   0 root         (0) root         (0)     2363 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/response_generator.py
+-rw-r--r--   0 root         (0) root         (0)     2838 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/service/workload.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.394397 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/
+-rw-r--r--   0 root         (0) root         (0)    57019 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/3rdpartylicenses.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.398398 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/
+-rw-r--r--   0 root         (0) root         (0)      769 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/004a-information-solid-gray.svg
+-rw-r--r--   0 root         (0) root         (0)      769 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/004a-information-solid.svg
+-rw-r--r--   0 root         (0) root         (0)     1201 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/005a-help-solid-blue.svg
+-rw-r--r--   0 root         (0) root         (0)     1201 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/005a-help-solid-gray.svg
+-rw-r--r--   0 root         (0) root         (0)     1186 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/005a-help-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      981 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/006a-alert-solid-orange.svg
+-rw-r--r--   0 root         (0) root         (0)      981 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/006a-alert-solid-red.svg
+-rw-r--r--   0 root         (0) root         (0)      662 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/007a-minus-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      781 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/008a-plus-solid-black.svg
+-rw-r--r--   0 root         (0) root         (0)      781 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/008a-plus-solid-blue.svg
+-rw-r--r--   0 root         (0) root         (0)      778 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/008a-plus-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      909 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/009a-close-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      817 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/010a-passed-completed-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      771 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/016-edit-blue.svg
+-rw-r--r--   0 root         (0) root         (0)      762 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/016-edit-white.svg
+-rw-r--r--   0 root         (0) root         (0)      771 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/016-edit.svg
+-rw-r--r--   0 root         (0) root         (0)     2387 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/043-organize-disabled.svg
+-rw-r--r--   0 root         (0) root         (0)     2394 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/043-organize.svg
+-rw-r--r--   0 root         (0) root         (0)      654 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/050a-folder-solid-white.svg
+-rw-r--r--   0 root         (0) root         (0)      657 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/050a-folder-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      973 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/052a-browse-preview-solid-gray.svg
+-rw-r--r--   0 root         (0) root         (0)      970 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/052a-browse-preview-solid-white.svg
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/056a-save-solid-white.svg
+-rw-r--r--   0 root         (0) root         (0)     1294 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/057b-trash-outlined-gray.svg
+-rw-r--r--   0 root         (0) root         (0)     1294 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/057b-trash-outlined.svg
+-rw-r--r--   0 root         (0) root         (0)      878 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/073-menu.svg
+-rw-r--r--   0 root         (0) root         (0)     1079 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/074-rewind-reverse.svg
+-rw-r--r--   0 root         (0) root         (0)      825 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/077-arrow-up.svg
+-rw-r--r--   0 root         (0) root         (0)      830 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/083-arrow-forward-right.svg
+-rw-r--r--   0 root         (0) root         (0)      659 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/088a-start-solid-gray.svg
+-rw-r--r--   0 root         (0) root         (0)      656 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/088a-start-solid-white.svg
+-rw-r--r--   0 root         (0) root         (0)      659 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/088a-start-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      641 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/145b-document-outlined-white.svg
+-rw-r--r--   0 root         (0) root         (0)      647 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/145b-document-outlined.svg
+-rw-r--r--   0 root         (0) root         (0)      838 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/146a-copy-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      875 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/160a-download-solid-white.svg
+-rw-r--r--   0 root         (0) root         (0)      881 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/160a-download-solid.svg
+-rw-r--r--   0 root         (0) root         (0)     1465 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/174-gauge.svg
+-rw-r--r--   0 root         (0) root         (0)     2006 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/221a-sunny-day-solid.svg
+-rw-r--r--   0 root         (0) root         (0)     1324 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/222-night.svg
+-rw-r--r--   0 root         (0) root         (0)     1602 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/234a-database-solid-disable.svg
+-rw-r--r--   0 root         (0) root         (0)     1534 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/234a-database-solid.svg
+-rw-r--r--   0 root         (0) root         (0)     1025 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/289a-checklist-solid.svg
+-rw-r--r--   0 root         (0) root         (0)      937 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/291b-line-chart-outlined.svg
+-rw-r--r--   0 root         (0) root         (0)     1366 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/292-growth-increase.svg
+-rw-r--r--   0 root         (0) root         (0)     1121 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/298a-workflow-process-solid-white.svg
+-rw-r--r--   0 root         (0) root         (0)     1109 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/298a-workflow-process-solid.svg
+-rw-r--r--   0 root         (0) root         (0)     1169 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/307-org-chart-disabled.svg
+-rw-r--r--   0 root         (0) root         (0)     1176 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/307-org-chart-white.svg
+-rw-r--r--   0 root         (0) root         (0)     1164 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/307-org-chart.svg
+-rw-r--r--   0 root         (0) root         (0)     1427 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/383-general-support.svg
+-rw-r--r--   0 root         (0) root         (0)    49300 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/create-new.png
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.398398 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/
+-rw-r--r--   0 root         (0) root         (0)     1198 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/005a-help-solid.svg
+-rw-r--r--   0 root         (0) root         (0)     2385 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/043-organize-disabled.svg
+-rw-r--r--   0 root         (0) root         (0)     2406 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/043-organize.svg
+-rw-r--r--   0 root         (0) root         (0)     1501 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/174-gauge.svg
+-rw-r--r--   0 root         (0) root         (0)     1594 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/234a-database-solid-disable.svg
+-rw-r--r--   0 root         (0) root         (0)     1582 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/234a-database-solid.svg
+-rw-r--r--   0 root         (0) root         (0)     1121 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/298a-workflow-process-solid.svg
+-rw-r--r--   0 root         (0) root         (0)     1167 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/307-org-chart-disabled.svg
+-rw-r--r--   0 root         (0) root         (0)     1176 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/307-org-chart.svg
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.402398 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/
+-rw-r--r--   0 root         (0) root         (0)   312920 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Bd.ttf
+-rw-r--r--   0 root         (0) root         (0)   314244 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Lt.ttf
+-rw-r--r--   0 root         (0) root         (0)   316572 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Rg.ttf
+-rw-r--r--   0 root         (0) root         (0)    96764 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-bold.ttf
+-rw-r--r--   0 root         (0) root         (0)   100524 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-light.ttf
+-rw-r--r--   0 root         (0) root         (0)    95288 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-regular.ttf
+-rw-r--r--   0 root         (0) root         (0)     3373 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/logo-energyblue-72px.svg
+-rw-r--r--   0 root         (0) root         (0)     3088 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/model-file.svg
+-rw-r--r--   0 root         (0) root         (0)     2982 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/model-folder.svg
+-rw-r--r--   0 root         (0) root         (0)    27661 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/nn.png
+-rw-r--r--   0 root         (0) root         (0)    89817 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/performance.png
+-rw-r--r--   0 root         (0) root         (0)     1255 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/index.html
+-rw-r--r--   0 root         (0) root         (0)  5873343 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/main.15f64b4092974083.js
+-rw-r--r--   0 root         (0) root         (0)  5658527 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/main.8f02ed35744647d6.js
+-rw-r--r--   0 root         (0) root         (0)  5870150 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/main.b1d2e7ec4704abc2.js
+-rw-r--r--   0 root         (0) root         (0)    37016 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/polyfills.05e532f1e1f2503a.js
+-rw-r--r--   0 root         (0) root         (0)    37032 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/polyfills.20acf87fa4379d4f.js
+-rw-r--r--   0 root         (0) root         (0)     1310 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/runtime.842b7f3162f7690e.js
+-rw-r--r--   0 root         (0) root         (0)   159626 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/styles.00d3de8fab67a2a5.css
+-rw-r--r--   0 root         (0) root         (0)   159889 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/styles.3c84233102d6c6b4.css
+-rw-r--r--   0 root         (0) root         (0)   151495 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/ux/web/static/styles.a563d0a77a1990e6.css
+-rw-r--r--   0 root         (0) root         (0)      766 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/neural_compressor/version.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-11 03:18:19.402398 neural_compressor_full-2.1.1/neural_compressor_full.egg-info/
+-rw-r--r--   0 root         (0) root         (0)    11463 2023-05-11 03:18:19.000000 neural_compressor_full-2.1.1/neural_compressor_full.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    42303 2023-05-11 03:18:19.000000 neural_compressor_full-2.1.1/neural_compressor_full.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2023-05-11 03:18:19.000000 neural_compressor_full-2.1.1/neural_compressor_full.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)      226 2023-05-11 03:18:19.000000 neural_compressor_full-2.1.1/neural_compressor_full.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)       31 2023-05-11 03:18:19.000000 neural_compressor_full-2.1.1/neural_compressor_full.egg-info/top_level.txt
+-rw-r--r--   0 root         (0) root         (0)       38 2023-05-11 03:18:19.402398 neural_compressor_full-2.1.1/setup.cfg
+-rw-r--r--   0 root         (0) root         (0)     3109 2023-05-11 02:51:07.000000 neural_compressor_full-2.1.1/setup.py
```

### Comparing `neural_compressor_full-2.1/LICENSE` & `neural_compressor_full-2.1.1/LICENSE`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/PKG-INFO` & `neural_compressor_full-2.1.1/neural_compressor_full.egg-info/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
-Name: neural_compressor_full
-Version: 2.1
+Name: neural-compressor-full
+Version: 2.1.1
 Summary: Repository of Intel® Neural Compressor
 Home-page: https://github.com/intel/neural-compressor
 Author: Intel AIA Team
 Author-email: feng.tian@intel.com, haihao.shen@intel.com, suyue.chen@intel.com
 License: Apache 2.0
 Keywords: quantization,auto-tuning,post-training static quantization,post-training dynamic quantization,quantization-aware training,tuning strategy
 Classifier: Intended Audience :: Science/Research
@@ -35,15 +35,15 @@
 
 Intel® Neural Compressor aims to provide popular model compression techniques such as quantization, pruning (sparsity), distillation, and neural architecture search on mainstream frameworks such as [TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), [ONNX Runtime](https://onnxruntime.ai/), and [MXNet](https://mxnet.apache.org/),
 as well as Intel extensions such as [Intel Extension for TensorFlow](https://github.com/intel/intel-extension-for-tensorflow) and [Intel Extension for PyTorch](https://github.com/intel/intel-extension-for-pytorch).
 In particular, the tool provides the key features, typical examples, and open collaborations as below:
 
 * Support a wide range of Intel hardware such as [Intel Xeon Scalable processor](https://www.intel.com/content/www/us/en/products/details/processors/xeon/scalable.html), [Intel Xeon CPU Max Series](https://www.intel.com/content/www/us/en/products/details/processors/xeon/max-series.html), [Intel Data Center GPU Flex Series](https://www.intel.com/content/www/us/en/products/details/discrete-gpus/data-center-gpu/flex-series.html), and [Intel Data Center GPU Max Series](https://www.intel.com/content/www/us/en/products/details/discrete-gpus/data-center-gpu/max-series.html) with extensive testing; support AMD CPU, ARM CPU, and NVidia GPU through ONNX Runtime with limited testing
 
-* Validate more than 10,000 models such as [Bloom-176B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [OPT-30B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [Stable Diffusion](/examples/pytorch/nlp/huggingface_models/text-to-image/quantization), [GPT-J](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/fx), [BERT-Large](/examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx), and [ResNet50](/examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx) from popular model hubs such as [Hugging Face](https://huggingface.co/), [Torch Vision](https://pytorch.org/vision/stable/index.html), and [ONNX Model Zoo](https://github.com/onnx/models#models), by leveraging zero-code optimization solution [Neural Coder](/neural_coder#what-do-we-offer) and automatic [accuracy-driven](/docs/source/design.md#workflow) quantization strategies
+* Validate more than 10,000 models such as [Bloom-176B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [OPT-6.7B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [Stable Diffusion](/examples/pytorch/nlp/huggingface_models/text-to-image/quantization), [GPT-J](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/fx), [BERT-Large](/examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx), and [ResNet50](/examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx) from popular model hubs such as [Hugging Face](https://huggingface.co/), [Torch Vision](https://pytorch.org/vision/stable/index.html), and [ONNX Model Zoo](https://github.com/onnx/models#models), by leveraging zero-code optimization solution [Neural Coder](/neural_coder#what-do-we-offer) and automatic [accuracy-driven](/docs/source/design.md#workflow) quantization strategies
 
 * Collaborate with cloud marketplace such as [Google Cloud Platform](https://console.cloud.google.com/marketplace/product/bitnami-launchpad/inc-tensorflow-intel?project=verdant-sensor-286207), [Amazon Web Services](https://aws.amazon.com/marketplace/pp/prodview-yjyh2xmggbmga#pdp-support), and [Azure](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/bitnami.inc-tensorflow-intel), software platforms such as [Alibaba Cloud](https://www.intel.com/content/www/us/en/developer/articles/technical/quantize-ai-by-oneapi-analytics-on-alibaba-cloud.html) and [Tencent TACO](https://new.qq.com/rain/a/20221202A00B9S00), and open AI ecosystem such as [Hugging Face](https://huggingface.co/blog/intel), [PyTorch](https://pytorch.org/tutorials/recipes/intel_neural_compressor_for_pytorch.html), [ONNX](https://github.com/onnx/models#models), and [Lightning AI](https://github.com/Lightning-AI/lightning/blob/master/docs/source-pytorch/advanced/post_training_quantization.rst)
 
 ## Installation
 
 ### Install from pypi
 ```Shell
@@ -79,82 +79,82 @@
 > More quick samples can be found in [Get Started Page](./docs/source/get_started.md).
 
 ## Documentation
 
 <table class="docutils">
   <thead>
   <tr>
-    <th colspan="9">Overview</th>
+    <th colspan="8">Overview</th>
   </tr>
   </thead>
   <tbody>
     <tr>
-      <td colspan="3" align="center"><a href="./docs/source/design.md#architecture">Architecture</a></td>
+      <td colspan="2" align="center"><a href="./docs/source/design.md#architecture">Architecture</a></td>
       <td colspan="2" align="center"><a href="./docs/source/design.md#workflow">Workflow</a></td>
       <td colspan="2" align="center"><a href="https://intel.github.io/neural-compressor/latest/docs/source/api-doc/apis.html">APIs</a></td>
       <td colspan="2" align="center"><a href="./docs/source/bench.md">GUI</a></td>
     </tr>
     <tr>
       <td colspan="2" align="center"><a href="examples/README.md#notebook-examples">Notebook</a></td>
       <td colspan="2" align="center"><a href="examples/README.md">Examples</a></td>
-      <td colspan="5" align="center"><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit</a></td>
+      <td colspan="4" align="center"><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit</a></td>
     </tr>
   </tbody>
   <thead>
     <tr>
-      <th colspan="9">Python-based APIs</th>
+      <th colspan="8">Python-based APIs</th>
     </tr>
   </thead>
   <tbody>
     <tr>
         <td colspan="2" align="center"><a href="./docs/source/quantization.md">Quantization</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/mixed_precision.md">Advanced Mixed Precision</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/mixed_precision.md">Advanced Mixed Precision</a></td>
         <td colspan="2" align="center"><a href="./docs/source/pruning.md">Pruning (Sparsity)</a></td> 
         <td colspan="2" align="center"><a href="./docs/source/distillation.md">Distillation</a></td>
     </tr>
     <tr>
         <td colspan="2" align="center"><a href="./docs/source/orchestration.md">Orchestration</a></td>        
         <td colspan="2" align="center"><a href="./docs/source/benchmark.md">Benchmarking</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/distributed.md">Distributed Compression</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/export.md">Model Export</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/distributed.md">Distributed Compression</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/export.md">Model Export</a></td>
     </tr>
   </tbody>
   <thead>
     <tr>
-      <th colspan="9">Neural Coder (Zero-code Optimization)</th>
+      <th colspan="8">Neural Coder (Zero-code Optimization)</th>
     </tr>
   </thead>
   <tbody>
     <tr>
-        <td colspan="1" align="center"><a href="./neural_coder/docs/PythonLauncher.md">Launcher</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/docs/PythonLauncher.md">Launcher</a></td>
         <td colspan="2" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_lab/README.md">JupyterLab Extension</a></td>
-        <td colspan="3" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_vscode/README.md">Visual Studio Code Extension</a></td>
-        <td colspan="3" align="center"><a href="./neural_coder/docs/SupportMatrix.md">Supported Matrix</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_vscode/README.md">Visual Studio Code Extension</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/docs/SupportMatrix.md">Supported Matrix</a></td>
     </tr>    
   </tbody>
   <thead>
       <tr>
-        <th colspan="9">Advanced Topics</th>
+        <th colspan="8">Advanced Topics</th>
       </tr>
   </thead>
   <tbody>
       <tr>
-          <td colspan="1" align="center"><a href="./docs/source/adaptor.md">Adaptor</a></td>
+          <td colspan="2" align="center"><a href="./docs/source/adaptor.md">Adaptor</a></td>
           <td colspan="2" align="center"><a href="./docs/source/tuning_strategies.md">Strategy</a></td>
-          <td colspan="3" align="center"><a href="./docs/source/distillation_quantization.md">Distillation for Quantization</a></td>
-          <td colspan="3" align="center"><a href="./docs/source/smooth_quant.md">SmoothQuant</td>
+          <td colspan="2" align="center"><a href="./docs/source/distillation_quantization.md">Distillation for Quantization</a></td>
+          <td colspan="2" align="center"><a href="./docs/source/smooth_quant.md">SmoothQuant</td>
       </tr>
   </tbody>
 </table>
 
 ## Selected Publications/Events
+* Blog on Medium: [Effective Post-training Quantization for Large Language Models with Enhanced SmoothQuant Approach](https://medium.com/@NeuralCompressor/effective-post-training-quantization-for-large-language-models-with-enhanced-smoothquant-approach-93e9d104fb98) (Apr 2023)
+* Blog by Intel: [Intel® Xeon® Processors Are Still the Only CPU With MLPerf Results, Raising the Bar By 5x](https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Xeon-Processors-Are-Still-the-Only-CPU-With-MLPerf-Results/post/1472750) (Apr 2023)
 * Post on Social Media: [Adopt with Tencent TACO: Heterogeneous optimization is also key to improving AI computing power](https://mp.weixin.qq.com/s/I-FQqOuW7HTnwXegLGNAtw) (Mar 2023)
 * Post on Social Media: [Training and Inference for Stable Diffusion | Intel Business](https://www.youtube.com/watch?v=emCgSTlJaAg) (Jan 2023)
-* Blog by Intel: [Intel® AMX Enhances AI Inference Performance](https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/advanced-matrix-extensions/alibaba-solution-brief.html) (Jan 2023)
-* Blog by TensorFlow: [Optimizing TensorFlow for 4th Gen Intel Xeon Processors](https://blog.tensorflow.org/2023/01/optimizing-tensorflow-for-4th-gen-intel-xeon-processors.html) (Jan 2023)
 * NeurIPS'2022: [Fast Distilbert on CPUs](https://arxiv.org/abs/2211.07715) (Oct 2022)
 * NeurIPS'2022: [QuaLA-MiniLM: a Quantized Length Adaptive MiniLM](https://arxiv.org/abs/2210.17114) (Oct 2022)
 
 > View our [Full Publication List](./docs/source/publication_list.md).
 
 ## Additional Content
```

### Comparing `neural_compressor_full-2.1/README.md` & `neural_compressor_full-2.1.1/README.md`

 * *Files 6% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 
 Intel® Neural Compressor aims to provide popular model compression techniques such as quantization, pruning (sparsity), distillation, and neural architecture search on mainstream frameworks such as [TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), [ONNX Runtime](https://onnxruntime.ai/), and [MXNet](https://mxnet.apache.org/),
 as well as Intel extensions such as [Intel Extension for TensorFlow](https://github.com/intel/intel-extension-for-tensorflow) and [Intel Extension for PyTorch](https://github.com/intel/intel-extension-for-pytorch).
 In particular, the tool provides the key features, typical examples, and open collaborations as below:
 
 * Support a wide range of Intel hardware such as [Intel Xeon Scalable processor](https://www.intel.com/content/www/us/en/products/details/processors/xeon/scalable.html), [Intel Xeon CPU Max Series](https://www.intel.com/content/www/us/en/products/details/processors/xeon/max-series.html), [Intel Data Center GPU Flex Series](https://www.intel.com/content/www/us/en/products/details/discrete-gpus/data-center-gpu/flex-series.html), and [Intel Data Center GPU Max Series](https://www.intel.com/content/www/us/en/products/details/discrete-gpus/data-center-gpu/max-series.html) with extensive testing; support AMD CPU, ARM CPU, and NVidia GPU through ONNX Runtime with limited testing
 
-* Validate more than 10,000 models such as [Bloom-176B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [OPT-30B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [Stable Diffusion](/examples/pytorch/nlp/huggingface_models/text-to-image/quantization), [GPT-J](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/fx), [BERT-Large](/examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx), and [ResNet50](/examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx) from popular model hubs such as [Hugging Face](https://huggingface.co/), [Torch Vision](https://pytorch.org/vision/stable/index.html), and [ONNX Model Zoo](https://github.com/onnx/models#models), by leveraging zero-code optimization solution [Neural Coder](/neural_coder#what-do-we-offer) and automatic [accuracy-driven](/docs/source/design.md#workflow) quantization strategies
+* Validate more than 10,000 models such as [Bloom-176B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [OPT-6.7B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [Stable Diffusion](/examples/pytorch/nlp/huggingface_models/text-to-image/quantization), [GPT-J](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/fx), [BERT-Large](/examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx), and [ResNet50](/examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx) from popular model hubs such as [Hugging Face](https://huggingface.co/), [Torch Vision](https://pytorch.org/vision/stable/index.html), and [ONNX Model Zoo](https://github.com/onnx/models#models), by leveraging zero-code optimization solution [Neural Coder](/neural_coder#what-do-we-offer) and automatic [accuracy-driven](/docs/source/design.md#workflow) quantization strategies
 
 * Collaborate with cloud marketplace such as [Google Cloud Platform](https://console.cloud.google.com/marketplace/product/bitnami-launchpad/inc-tensorflow-intel?project=verdant-sensor-286207), [Amazon Web Services](https://aws.amazon.com/marketplace/pp/prodview-yjyh2xmggbmga#pdp-support), and [Azure](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/bitnami.inc-tensorflow-intel), software platforms such as [Alibaba Cloud](https://www.intel.com/content/www/us/en/developer/articles/technical/quantize-ai-by-oneapi-analytics-on-alibaba-cloud.html) and [Tencent TACO](https://new.qq.com/rain/a/20221202A00B9S00), and open AI ecosystem such as [Hugging Face](https://huggingface.co/blog/intel), [PyTorch](https://pytorch.org/tutorials/recipes/intel_neural_compressor_for_pytorch.html), [ONNX](https://github.com/onnx/models#models), and [Lightning AI](https://github.com/Lightning-AI/lightning/blob/master/docs/source-pytorch/advanced/post_training_quantization.rst)
 
 ## Installation
 
 ### Install from pypi
 ```Shell
@@ -62,82 +62,82 @@
 > More quick samples can be found in [Get Started Page](./docs/source/get_started.md).
 
 ## Documentation
 
 <table class="docutils">
   <thead>
   <tr>
-    <th colspan="9">Overview</th>
+    <th colspan="8">Overview</th>
   </tr>
   </thead>
   <tbody>
     <tr>
-      <td colspan="3" align="center"><a href="./docs/source/design.md#architecture">Architecture</a></td>
+      <td colspan="2" align="center"><a href="./docs/source/design.md#architecture">Architecture</a></td>
       <td colspan="2" align="center"><a href="./docs/source/design.md#workflow">Workflow</a></td>
       <td colspan="2" align="center"><a href="https://intel.github.io/neural-compressor/latest/docs/source/api-doc/apis.html">APIs</a></td>
       <td colspan="2" align="center"><a href="./docs/source/bench.md">GUI</a></td>
     </tr>
     <tr>
       <td colspan="2" align="center"><a href="examples/README.md#notebook-examples">Notebook</a></td>
       <td colspan="2" align="center"><a href="examples/README.md">Examples</a></td>
-      <td colspan="5" align="center"><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit</a></td>
+      <td colspan="4" align="center"><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit</a></td>
     </tr>
   </tbody>
   <thead>
     <tr>
-      <th colspan="9">Python-based APIs</th>
+      <th colspan="8">Python-based APIs</th>
     </tr>
   </thead>
   <tbody>
     <tr>
         <td colspan="2" align="center"><a href="./docs/source/quantization.md">Quantization</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/mixed_precision.md">Advanced Mixed Precision</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/mixed_precision.md">Advanced Mixed Precision</a></td>
         <td colspan="2" align="center"><a href="./docs/source/pruning.md">Pruning (Sparsity)</a></td> 
         <td colspan="2" align="center"><a href="./docs/source/distillation.md">Distillation</a></td>
     </tr>
     <tr>
         <td colspan="2" align="center"><a href="./docs/source/orchestration.md">Orchestration</a></td>        
         <td colspan="2" align="center"><a href="./docs/source/benchmark.md">Benchmarking</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/distributed.md">Distributed Compression</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/export.md">Model Export</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/distributed.md">Distributed Compression</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/export.md">Model Export</a></td>
     </tr>
   </tbody>
   <thead>
     <tr>
-      <th colspan="9">Neural Coder (Zero-code Optimization)</th>
+      <th colspan="8">Neural Coder (Zero-code Optimization)</th>
     </tr>
   </thead>
   <tbody>
     <tr>
-        <td colspan="1" align="center"><a href="./neural_coder/docs/PythonLauncher.md">Launcher</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/docs/PythonLauncher.md">Launcher</a></td>
         <td colspan="2" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_lab/README.md">JupyterLab Extension</a></td>
-        <td colspan="3" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_vscode/README.md">Visual Studio Code Extension</a></td>
-        <td colspan="3" align="center"><a href="./neural_coder/docs/SupportMatrix.md">Supported Matrix</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_vscode/README.md">Visual Studio Code Extension</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/docs/SupportMatrix.md">Supported Matrix</a></td>
     </tr>    
   </tbody>
   <thead>
       <tr>
-        <th colspan="9">Advanced Topics</th>
+        <th colspan="8">Advanced Topics</th>
       </tr>
   </thead>
   <tbody>
       <tr>
-          <td colspan="1" align="center"><a href="./docs/source/adaptor.md">Adaptor</a></td>
+          <td colspan="2" align="center"><a href="./docs/source/adaptor.md">Adaptor</a></td>
           <td colspan="2" align="center"><a href="./docs/source/tuning_strategies.md">Strategy</a></td>
-          <td colspan="3" align="center"><a href="./docs/source/distillation_quantization.md">Distillation for Quantization</a></td>
-          <td colspan="3" align="center"><a href="./docs/source/smooth_quant.md">SmoothQuant</td>
+          <td colspan="2" align="center"><a href="./docs/source/distillation_quantization.md">Distillation for Quantization</a></td>
+          <td colspan="2" align="center"><a href="./docs/source/smooth_quant.md">SmoothQuant</td>
       </tr>
   </tbody>
 </table>
 
 ## Selected Publications/Events
+* Blog on Medium: [Effective Post-training Quantization for Large Language Models with Enhanced SmoothQuant Approach](https://medium.com/@NeuralCompressor/effective-post-training-quantization-for-large-language-models-with-enhanced-smoothquant-approach-93e9d104fb98) (Apr 2023)
+* Blog by Intel: [Intel® Xeon® Processors Are Still the Only CPU With MLPerf Results, Raising the Bar By 5x](https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Xeon-Processors-Are-Still-the-Only-CPU-With-MLPerf-Results/post/1472750) (Apr 2023)
 * Post on Social Media: [Adopt with Tencent TACO: Heterogeneous optimization is also key to improving AI computing power](https://mp.weixin.qq.com/s/I-FQqOuW7HTnwXegLGNAtw) (Mar 2023)
 * Post on Social Media: [Training and Inference for Stable Diffusion | Intel Business](https://www.youtube.com/watch?v=emCgSTlJaAg) (Jan 2023)
-* Blog by Intel: [Intel® AMX Enhances AI Inference Performance](https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/advanced-matrix-extensions/alibaba-solution-brief.html) (Jan 2023)
-* Blog by TensorFlow: [Optimizing TensorFlow for 4th Gen Intel Xeon Processors](https://blog.tensorflow.org/2023/01/optimizing-tensorflow-for-4th-gen-intel-xeon-processors.html) (Jan 2023)
 * NeurIPS'2022: [Fast Distilbert on CPUs](https://arxiv.org/abs/2211.07715) (Oct 2022)
 * NeurIPS'2022: [QuaLA-MiniLM: a Quantized Length Adaptive MiniLM](https://arxiv.org/abs/2210.17114) (Oct 2022)
 
 > View our [Full Publication List](./docs/source/publication_list.md).
 
 ## Additional Content
```

### Comparing `neural_compressor_full-2.1/neural_coder/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/__main__.py` & `neural_compressor_full-2.1.1/neural_coder/__main__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/backends/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/intel_extension_for_transformers.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/intel_extension_for_transformers.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/keras_inc.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/keras_inc.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_bf16.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_bf16.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_bf16_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_bf16_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_bf16_ipex.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_bf16_ipex.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_bf16_ipex_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_bf16_ipex_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_fp32_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_fp32_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_fp32_ipex.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_fp32_ipex.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_fp32_ipex_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_fp32_ipex_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_gpu_to_cpu.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_gpu_to_cpu.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_int8.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_int8.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_jit_bf16.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_bf16.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_jit_bf16_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_bf16_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_jit_bf16_ipex.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_bf16_ipex.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_jit_bf16_ipex_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_bf16_ipex_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_jit_fp32.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_fp32.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_jit_fp32_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_fp32_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_jit_fp32_ipex.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_fp32_ipex.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_jit_fp32_ipex_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_jit_fp32_ipex_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_onnxruntime_fp32.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_onnxruntime_fp32.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_onnxruntime_int8_qlinear.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_onnxruntime_int8_qlinear.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_openvino_fp32.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_openvino_fp32.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/nano_openvino_int8.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/nano_openvino_int8.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/onnx_inc_dynamic_quant.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/onnx_inc_dynamic_quant.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/onnx_inc_static_quant_qdq.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/onnx_inc_static_quant_qdq.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/onnx_inc_static_quant_qlinear.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/onnx_inc_static_quant_qlinear.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_aliblade.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_aliblade.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_benchmark.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_benchmark.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_channels_last.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_channels_last.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_bf16.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_bf16.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_dynamic_quant.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_dynamic_quant.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_dynamic_quant_fp8.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_dynamic_quant_fp8.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_huggingface_optimum_dynamic.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_huggingface_optimum_dynamic.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_huggingface_optimum_static.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_huggingface_optimum_static.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_static_quant_fx.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_static_quant_fx.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_static_quant_fx_fp8.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_static_quant_fx_fp8.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_inc_static_quant_ipex.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_inc_static_quant_ipex.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_ipex_bf16.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_ipex_bf16.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_ipex_fp32.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_ipex_fp32.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_ipex_int8_dynamic_quant.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_ipex_int8_dynamic_quant.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_ipex_int8_static_quant.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_ipex_int8_static_quant.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_jit_script.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_jit_script.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_jit_script_ofi.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_jit_script_ofi.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_jit_trace.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_jit_trace.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_jit_trace_ofi.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_jit_trace_ofi.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_mixed_precision_cpu.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_mixed_precision_cpu.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_mixed_precision_cuda.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_mixed_precision_cuda.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_mixed_precision_intel_gpu.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_mixed_precision_intel_gpu.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_torchdynamo_jit_script.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_torchdynamo_jit_script.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_torchdynamo_jit_script_ofi.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_torchdynamo_jit_script_ofi.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_torchdynamo_jit_trace.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_torchdynamo_jit_trace.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/pytorch_torchdynamo_jit_trace_ofi.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/pytorch_torchdynamo_jit_trace_ofi.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/backends/template.yaml` & `neural_compressor_full-2.1.1/neural_coder/backends/template.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/coders/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/autoinc/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/coders/autoinc/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/autoinc/autoinc_harness.py` & `neural_compressor_full-2.1.1/neural_coder/coders/autoinc/autoinc_harness.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/autoinc/calib_dataloader.py` & `neural_compressor_full-2.1.1/neural_coder/coders/autoinc/calib_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/autoinc/domain.py` & `neural_compressor_full-2.1.1/neural_coder/coders/autoinc/domain.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/autoinc/eval_func.py` & `neural_compressor_full-2.1.1/neural_coder/coders/autoinc/eval_func.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/batch_size.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/batch_size.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/change_trainer_to_nlptrainer.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/change_trainer_to_nlptrainer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/cuda_to_cpu.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/cuda_to_cpu.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/dummy_dataloader.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/dummy_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/harness.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/harness.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/lightning.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/lightning.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/reclaim_inference_transformers_trainer.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/reclaim_inference_transformers_trainer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/pytorch/reclaim_inputs.py` & `neural_compressor_full-2.1.1/neural_coder/coders/pytorch/reclaim_inputs.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/tensorflow/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/coders/tensorflow/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/tensorflow/amp.py` & `neural_compressor_full-2.1.1/neural_coder/coders/tensorflow/amp.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/tensorflow/inc.py` & `neural_compressor_full-2.1.1/neural_coder/coders/tensorflow/inc.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/coders/transform.py` & `neural_compressor_full-2.1.1/neural_coder/coders/transform.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/globals.py` & `neural_compressor_full-2.1.1/neural_coder/globals.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/graphers/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/graphers/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/graphers/code_line.py` & `neural_compressor_full-2.1.1/neural_coder/graphers/code_line.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/graphers/function.py` & `neural_compressor_full-2.1.1/neural_coder/graphers/function.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/graphers/model.py` & `neural_compressor_full-2.1.1/neural_coder/graphers/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/graphers/preloads/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/graphers/preloads/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/graphers/preloads/transformers.yaml` & `neural_compressor_full-2.1.1/neural_coder/graphers/preloads/transformers.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/interface.py` & `neural_compressor_full-2.1.1/neural_coder/interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/launcher.py` & `neural_compressor_full-2.1.1/neural_coder/launcher.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/utils/__init__.py` & `neural_compressor_full-2.1.1/neural_coder/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/utils/common.py` & `neural_compressor_full-2.1.1/neural_coder/utils/common.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/utils/cpu_info.py` & `neural_compressor_full-2.1.1/neural_coder/utils/cpu_info.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/utils/device.py` & `neural_compressor_full-2.1.1/neural_coder/utils/device.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/utils/handle_user_input.py` & `neural_compressor_full-2.1.1/neural_coder/utils/handle_user_input.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/utils/line_operation.py` & `neural_compressor_full-2.1.1/neural_coder/utils/line_operation.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/utils/numa_launcher.py` & `neural_compressor_full-2.1.1/neural_coder/utils/numa_launcher.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/utils/pdf_report.py` & `neural_compressor_full-2.1.1/neural_coder/utils/pdf_report.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_coder/version.py` & `neural_compressor_full-2.1.1/neural_coder/version.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/adaptor.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/adaptor.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/keras.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/keras.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/keras.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/keras.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/conv2d.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/conv2d.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/dense.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/dense.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/depthwise_conv2d.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/depthwise_conv2d.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/quantizer.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/quantizer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/keras_utils/separable_conv2d.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/keras_utils/separable_conv2d.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/mxnet.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/mxnet.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/mxnet_utils/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/mxnet_utils/util.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/mxnet_utils/util.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/onnxrt.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/onnxrt.py`

 * *Files 1% similar despite different names*

```diff
@@ -148,24 +148,25 @@
         self.fp32_preds_as_label = False
         self.quantize_config = {} # adaptor should know current configs at any time
         self.quantize_params = {} # adaptor should know current params at any time
         self.min_max = None
 
         self.optype_statistics = None
 
-    def smooth_quant(self, model, dataloader, iterations, tune_cfg, alpha=0.5,
+    def smooth_quant(self, model, dataloader, iterations, tune_cfg, alpha=0.5, folding=False,
                                     percentile=99.999, op_types=['MatMul', 'Linear', 'Conv'], scales_per_op=True):
         """Get augmented model with smooth quant.
 
         Args:
             model_wrapper: origin_model
             dataloader: dataloader
             iterations: iterations
             tune_cfg: quantization config
             alpha: smooth alpha in SmoothQuant, 1.0 will fallback to SPIQ
+            folding: whether insert mul(False) or just allow foldable layers(True) for SmoothQuant
             percentile:Percentile of calibration to remove outliers
             op_types: The op types whose input tensor will be dumped
             scales_per_op: True, each op will have an individual scale, mainly for accuracy
                            False, ops with the same input will share a scale, mainly for performance
 
         Returns:
             model: A modified onnx model
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/onnxrt.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/onnxrt.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/onnxrt_cuda.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/onnxrt_cuda.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/onnxrt_trt.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/onnxrt_trt.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/calibration.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/calibration.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/activation.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/activation.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/argmax.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/argmax.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/attention.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/attention.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/binary_op.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/binary_op.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/concat.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/concat.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/conv.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/conv.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/direct_q8.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/direct_q8.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/embed_layernorm.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/embed_layernorm.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/gather.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/gather.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/gavgpool.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/gavgpool.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/gemm.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/gemm.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/lstm.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/lstm.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/matmul.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/matmul.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/maxpool.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/maxpool.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/ops.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/ops.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/pad.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/pad.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/pooling.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/pooling.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/resize.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/resize.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/operators/split.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/operators/split.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/quantizer.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/quantizer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/ox_utils/util.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/ox_utils/util.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/pytorch.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/pytorch.py`

 * *Files 2% similar despite different names*

```diff
@@ -1268,10381 +1268,11279 @@
 00004f30: 7970 6520 2873 7472 696e 6729 3a20 4f62  ype (string): Ob
 00004f40: 7365 7276 6572 2074 7970 652c 2064 6566  server type, def
 00004f50: 6175 6c74 2069 7320 2770 6f73 745f 7472  ault is 'post_tr
 00004f60: 6169 6e69 6e67 5f73 7461 7469 635f 7175  aining_static_qu
 00004f70: 616e 7427 2e0a 0a20 2020 2052 6574 7572  ant'...    Retur
 00004f80: 6e73 3a0a 2020 2020 2020 2020 6f62 6572  ns:.        ober
 00004f90: 7365 7220 286f 626a 6563 7429 0a20 2020  ser (object).   
-00004fa0: 2022 2222 0a20 2020 2069 6620 6f62 7365   """.    if obse
-00004fb0: 7276 6572 5f74 7970 6520 3d3d 2027 706f  rver_type == 'po
-00004fc0: 7374 5f74 7261 696e 696e 675f 6479 6e61  st_training_dyna
-00004fd0: 6d69 635f 7175 616e 7427 2061 6e64 205c  mic_quant' and \
-00004fe0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00004ff0: 2067 6574 5f74 6f72 6368 5f76 6572 7369   get_torch_versi
-00005000: 6f6e 2829 2e72 656c 6561 7365 203e 3d20  on().release >= 
-00005010: 5665 7273 696f 6e28 2231 2e36 2e30 2229  Version("1.6.0")
-00005020: 2e72 656c 6561 7365 3a0a 2020 2020 2020  .release:.      
-00005030: 2020 7265 7475 726e 2074 6f72 6368 2e71    return torch.q
-00005040: 7561 6e74 697a 6174 696f 6e2e 6465 6661  uantization.defa
-00005050: 756c 745f 6479 6e61 6d69 635f 7175 616e  ult_dynamic_quan
-00005060: 745f 6f62 7365 7276 6572 0a0a 2020 2020  t_observer..    
-00005070: 636f 6d70 7574 655f 6474 7970 655f 6469  compute_dtype_di
-00005080: 6374 203d 207b 2769 6e74 3827 3a20 746f  ct = {'int8': to
-00005090: 7263 682e 7169 6e74 382c 2027 7569 6e74  rch.qint8, 'uint
-000050a0: 3827 3a20 746f 7263 682e 7175 696e 7438  8': torch.quint8
-000050b0: 2c20 274e 6f6e 6527 3a20 4e6f 6e65 7d0a  , 'None': None}.
-000050c0: 2020 2020 6966 2063 6f6d 7075 7465 5f64      if compute_d
-000050d0: 7479 7065 2069 6e20 636f 6d70 7574 655f  type in compute_
-000050e0: 6474 7970 655f 6469 6374 3a0a 2020 2020  dtype_dict:.    
-000050f0: 2020 2020 636f 6d70 7574 655f 6474 7970      compute_dtyp
-00005100: 6520 3d20 636f 6d70 7574 655f 6474 7970  e = compute_dtyp
-00005110: 655f 6469 6374 5b63 6f6d 7075 7465 5f64  e_dict[compute_d
-00005120: 7479 7065 5d0a 2020 2020 656c 7365 3a20  type].    else: 
-00005130: 2023 2070 7261 676d 613a 206e 6f20 636f   # pragma: no co
-00005140: 7665 720a 2020 2020 2020 2020 6173 7365  ver.        asse
-00005150: 7274 2046 616c 7365 2c20 2255 6e73 7570  rt False, "Unsup
-00005160: 706f 7274 2063 6f6d 7075 7465 5f64 7479  port compute_dty
-00005170: 7065 2077 6974 6820 7b7d 222e 666f 726d  pe with {}".form
-00005180: 6174 2863 6f6d 7075 7465 5f64 7479 7065  at(compute_dtype
-00005190: 290a 0a20 2020 2064 7479 7065 5f64 6963  )..    dtype_dic
-000051a0: 7420 3d20 7b27 696e 7438 273a 2074 6f72  t = {'int8': tor
-000051b0: 6368 2e71 696e 7438 2c20 2775 696e 7438  ch.qint8, 'uint8
-000051c0: 273a 2074 6f72 6368 2e71 7569 6e74 382c  ': torch.quint8,
-000051d0: 2027 6670 3332 273a 2074 6f72 6368 2e66   'fp32': torch.f
-000051e0: 6c6f 6174 7d0a 2020 2020 6966 2064 7479  loat}.    if dty
-000051f0: 7065 2069 6e20 6474 7970 655f 6469 6374  pe in dtype_dict
-00005200: 3a0a 2020 2020 2020 2020 6474 7970 6520  :.        dtype 
-00005210: 3d20 6474 7970 655f 6469 6374 5b64 7479  = dtype_dict[dty
-00005220: 7065 5d0a 2020 2020 656c 7365 3a20 2023  pe].    else:  #
-00005230: 2070 7261 676d 613a 206e 6f20 636f 7665   pragma: no cove
-00005240: 720a 2020 2020 2020 2020 6173 7365 7274  r.        assert
-00005250: 2046 616c 7365 2c20 2255 6e73 7570 706f   False, "Unsuppo
-00005260: 7274 2064 7479 7065 2077 6974 6820 7b7d  rt dtype with {}
-00005270: 222e 666f 726d 6174 2864 7479 7065 290a  ".format(dtype).
-00005280: 0a20 2020 2069 6620 616c 676f 7269 7468  .    if algorith
-00005290: 6d20 3d3d 2027 706c 6163 6568 6f6c 6465  m == 'placeholde
-000052a0: 7227 206f 7220 6474 7970 6520 3d3d 2074  r' or dtype == t
-000052b0: 6f72 6368 2e66 6c6f 6174 3a20 2023 2070  orch.float:  # p
-000052c0: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
-000052d0: 2020 2020 2020 2020 7265 7475 726e 2074          return t
-000052e0: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
-000052f0: 6e2e 506c 6163 6568 6f6c 6465 724f 6273  n.PlaceholderObs
-00005300: 6572 7665 7220 5c0a 2020 2020 2020 2020  erver \.        
-00005310: 2020 2020 6966 2067 6574 5f74 6f72 6368      if get_torch
-00005320: 5f76 6572 7369 6f6e 2829 2e72 656c 6561  _version().relea
-00005330: 7365 203c 2056 6572 7369 6f6e 2822 312e  se < Version("1.
-00005340: 382e 3022 292e 7265 6c65 6173 6520 5c0a  8.0").release \.
-00005350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005360: 656c 7365 2074 6f72 6368 2e71 7561 6e74  else torch.quant
-00005370: 697a 6174 696f 6e2e 506c 6163 6568 6f6c  ization.Placehol
-00005380: 6465 724f 6273 6572 7665 722e 7769 7468  derObserver.with
-00005390: 5f61 7267 7328 6474 7970 653d 6474 7970  _args(dtype=dtyp
-000053a0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-000053b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000053c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000053d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000053e0: 2020 2020 2020 2020 2063 6f6d 7075 7465           compute
-000053f0: 5f64 7479 7065 3d63 6f6d 7075 7465 5f64  _dtype=compute_d
-00005400: 7479 7065 290a 2020 2020 6966 2061 6c67  type).    if alg
-00005410: 6f72 6974 686d 203d 3d20 276d 696e 6d61  orithm == 'minma
-00005420: 7827 3a0a 2020 2020 2020 2020 6966 2067  x':.        if g
-00005430: 7261 6e75 6c61 7269 7479 203d 3d20 2770  ranularity == 'p
-00005440: 6572 5f63 6861 6e6e 656c 273a 0a20 2020  er_channel':.   
-00005450: 2020 2020 2020 2020 206f 6273 6572 7665           observe
-00005460: 7220 3d20 746f 7263 682e 7175 616e 7469  r = torch.quanti
-00005470: 7a61 7469 6f6e 2e50 6572 4368 616e 6e65  zation.PerChanne
-00005480: 6c4d 696e 4d61 784f 6273 6572 7665 720a  lMinMaxObserver.
-00005490: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-000054a0: 6368 656d 6520 3d3d 2027 7379 6d27 3a0a  cheme == 'sym':.
-000054b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000054c0: 7173 6368 656d 6520 3d20 746f 7263 682e  qscheme = torch.
-000054d0: 7065 725f 6368 616e 6e65 6c5f 7379 6d6d  per_channel_symm
-000054e0: 6574 7269 630a 2020 2020 2020 2020 2020  etric.          
-000054f0: 2020 656c 6966 2073 6368 656d 6520 3d3d    elif scheme ==
-00005500: 2027 6173 796d 5f66 6c6f 6174 273a 0a20   'asym_float':. 
-00005510: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-00005520: 7363 6865 6d65 203d 2074 6f72 6368 2e70  scheme = torch.p
-00005530: 6572 5f63 6861 6e6e 656c 5f61 6666 696e  er_channel_affin
-00005540: 655f 666c 6f61 745f 7170 6172 616d 730a  e_float_qparams.
-00005550: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00005560: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00005570: 2020 7173 6368 656d 6520 3d20 746f 7263    qscheme = torc
-00005580: 682e 7065 725f 6368 616e 6e65 6c5f 6166  h.per_channel_af
-00005590: 6669 6e65 0a20 2020 2020 2020 2065 6c73  fine.        els
-000055a0: 653a 0a20 2020 2020 2020 2020 2020 2061  e:.            a
-000055b0: 7373 6572 7420 6772 616e 756c 6172 6974  ssert granularit
-000055c0: 7920 3d3d 2027 7065 725f 7465 6e73 6f72  y == 'per_tensor
-000055d0: 270a 2020 2020 2020 2020 2020 2020 6f62  '.            ob
-000055e0: 7365 7276 6572 203d 2074 6f72 6368 2e71  server = torch.q
-000055f0: 7561 6e74 697a 6174 696f 6e2e 4d69 6e4d  uantization.MinM
-00005600: 6178 4f62 7365 7276 6572 0a20 2020 2020  axObserver.     
-00005610: 2020 2020 2020 2069 6620 7363 6865 6d65         if scheme
-00005620: 203d 3d20 2773 796d 273a 0a20 2020 2020   == 'sym':.     
-00005630: 2020 2020 2020 2020 2020 2071 7363 6865             qsche
-00005640: 6d65 203d 2074 6f72 6368 2e70 6572 5f74  me = torch.per_t
-00005650: 656e 736f 725f 7379 6d6d 6574 7269 630a  ensor_symmetric.
-00005660: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00005670: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00005680: 2020 6173 7365 7274 2073 6368 656d 6520    assert scheme 
-00005690: 3d3d 2027 6173 796d 270a 2020 2020 2020  == 'asym'.      
-000056a0: 2020 2020 2020 2020 2020 7173 6368 656d            qschem
-000056b0: 6520 3d20 746f 7263 682e 7065 725f 7465  e = torch.per_te
-000056c0: 6e73 6f72 5f61 6666 696e 650a 2020 2020  nsor_affine.    
-000056d0: 656c 7365 3a0a 2020 2020 2020 2020 6173  else:.        as
-000056e0: 7365 7274 2061 6c67 6f72 6974 686d 203d  sert algorithm =
-000056f0: 3d20 276b 6c27 0a20 2020 2020 2020 206f  = 'kl'.        o
-00005700: 6273 6572 7665 7220 3d20 746f 7263 682e  bserver = torch.
-00005710: 7175 616e 7469 7a61 7469 6f6e 2e48 6973  quantization.His
-00005720: 746f 6772 616d 4f62 7365 7276 6572 0a20  togramObserver. 
-00005730: 2020 2020 2020 2061 7373 6572 7420 6772         assert gr
-00005740: 616e 756c 6172 6974 7920 3d3d 2027 7065  anularity == 'pe
-00005750: 725f 7465 6e73 6f72 270a 2020 2020 2020  r_tensor'.      
-00005760: 2020 6966 2073 6368 656d 6520 3d3d 2027    if scheme == '
-00005770: 7379 6d27 3a0a 2020 2020 2020 2020 2020  sym':.          
-00005780: 2020 7173 6368 656d 6520 3d20 746f 7263    qscheme = torc
-00005790: 682e 7065 725f 7465 6e73 6f72 5f73 796d  h.per_tensor_sym
-000057a0: 6d65 7472 6963 0a20 2020 2020 2020 2065  metric.        e
-000057b0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-000057c0: 2061 7373 6572 7420 7363 6865 6d65 203d   assert scheme =
-000057d0: 3d20 2761 7379 6d27 0a20 2020 2020 2020  = 'asym'.       
-000057e0: 2020 2020 2071 7363 6865 6d65 203d 2074       qscheme = t
-000057f0: 6f72 6368 2e70 6572 5f74 656e 736f 725f  orch.per_tensor_
-00005800: 6166 6669 6e65 0a0a 2020 2020 7265 7475  affine..    retu
-00005810: 726e 206f 6273 6572 7665 722e 7769 7468  rn observer.with
-00005820: 5f61 7267 7328 7173 6368 656d 653d 7173  _args(qscheme=qs
-00005830: 6368 656d 652c 0a20 2020 2020 2020 2020  cheme,.         
-00005840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005850: 2020 2020 2064 7479 7065 3d64 7479 7065       dtype=dtype
-00005860: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00005870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005880: 7265 6475 6365 5f72 616e 6765 3d28 5245  reduce_range=(RE
-00005890: 4455 4345 5f52 414e 4745 2061 6e64 2073  DUCE_RANGE and s
-000058a0: 6368 656d 6520 3d3d 2027 6173 796d 2729  cheme == 'asym')
-000058b0: 290a 0a0a 6465 6620 5f66 616b 655f 7175  )...def _fake_qu
-000058c0: 616e 7469 7a65 2861 6c67 6f72 6974 686d  antize(algorithm
-000058d0: 2c20 7363 6865 6d65 2c20 6772 616e 756c  , scheme, granul
-000058e0: 6172 6974 792c 2064 7479 7065 2c20 636f  arity, dtype, co
-000058f0: 6d70 7574 655f 6474 7970 653d 2775 696e  mpute_dtype='uin
-00005900: 7438 2729 3a0a 2020 2020 2222 2243 6f6e  t8'):.    """Con
-00005910: 7374 7275 6374 2061 2066 616b 6520 7175  struct a fake qu
-00005920: 616e 7469 7a65 206d 6f64 756c 652c 2049  antize module, I
-00005930: 6e20 666f 7277 6172 642c 2066 616b 6520  n forward, fake 
-00005940: 7175 616e 7469 7a65 206d 6f64 756c 6520  quantize module 
-00005950: 7769 6c6c 2075 7064 6174 650a 2020 2020  will update.    
-00005960: 2020 2074 6865 2073 7461 7469 7374 6963     the statistic
-00005970: 7320 6f66 2074 6865 206f 6273 6572 7665  s of the observe
-00005980: 6420 5465 6e73 6f72 2061 6e64 2066 616b  d Tensor and fak
-00005990: 6520 7175 616e 7469 7a65 2074 6865 2069  e quantize the i
-000059a0: 6e70 7574 2e0a 2020 2020 2020 2054 6865  nput..       The
-000059b0: 7920 7368 6f75 6c64 2061 6c73 6f20 7072  y should also pr
-000059c0: 6f76 6964 6520 6120 6063 616c 6375 6c61  ovide a `calcula
-000059d0: 7465 5f71 7061 7261 6d73 6020 6675 6e63  te_qparams` func
-000059e0: 7469 6f6e 0a20 2020 2020 2020 7468 6174  tion.       that
-000059f0: 2063 6f6d 7075 7465 7320 7468 6520 7175   computes the qu
-00005a00: 616e 7469 7a61 7469 6f6e 2070 6172 616d  antization param
-00005a10: 6574 6572 7320 6769 7665 6e20 7468 6520  eters given the 
-00005a20: 636f 6c6c 6563 7465 6420 7374 6174 6973  collected statis
-00005a30: 7469 6373 2e0a 0a20 2020 2041 7267 733a  tics...    Args:
-00005a40: 0a20 2020 2020 2020 2061 6c67 6f72 6974  .        algorit
-00005a50: 686d 2028 7374 7269 6e67 293a 2057 6861  hm (string): Wha
-00005a60: 7420 616c 676f 7269 7468 6d20 666f 7220  t algorithm for 
-00005a70: 636f 6d70 7574 696e 6720 7468 6520 7175  computing the qu
-00005a80: 616e 7469 7a61 7469 6f6e 2070 6172 616d  antization param
-00005a90: 6574 6572 7320 6261 7365 6420 6f6e 2e0a  eters based on..
-00005aa0: 2020 2020 2020 2020 7363 6865 6d65 2028          scheme (
-00005ab0: 7374 7269 6e67 293a 2051 7561 6e74 697a  string): Quantiz
-00005ac0: 6174 696f 6e20 7363 6865 6d65 2074 6f20  ation scheme to 
-00005ad0: 6265 2075 7365 642e 0a20 2020 2020 2020  be used..       
-00005ae0: 2067 7261 6e75 6c61 7269 7479 2028 7374   granularity (st
-00005af0: 7269 6e67 293a 2057 6861 7420 6772 616e  ring): What gran
-00005b00: 756c 6172 6974 7920 746f 2063 6f6d 7075  ularity to compu
-00005b10: 7469 6e67 2074 6865 2071 7561 6e74 697a  ting the quantiz
-00005b20: 6174 696f 6e20 7061 7261 6d65 7465 7273  ation parameters
-00005b30: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00005b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005b50: 7065 7220 6368 616e 6e65 6c20 6f72 2070  per channel or p
-00005b60: 6572 2074 656e 736f 722e 0a20 2020 2020  er tensor..     
-00005b70: 2020 2064 7479 7065 2028 7374 696e 6729     dtype (sting)
-00005b80: 3a20 5175 616e 7469 7a65 6420 6461 7461  : Quantized data
-00005b90: 2074 7970 650a 0a20 2020 2052 6574 7572   type..    Retur
-00005ba0: 6e3a 0a20 2020 2020 2020 2066 616b 6520  n:.        fake 
-00005bb0: 7175 616e 7469 7a61 7469 6f6e 2028 6f62  quantization (ob
-00005bc0: 6a65 6374 290a 2020 2020 2222 220a 2020  ject).    """.  
-00005bd0: 2020 7665 7273 696f 6e20 3d20 6765 745f    version = get_
-00005be0: 746f 7263 685f 7665 7273 696f 6e28 290a  torch_version().
-00005bf0: 2020 2020 6966 2073 6368 656d 6520 3d3d      if scheme ==
-00005c00: 2027 6173 796d 5f66 6c6f 6174 2720 5c0a   'asym_float' \.
-00005c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005c20: 2061 6e64 2076 6572 7369 6f6e 2e72 656c   and version.rel
-00005c30: 6561 7365 203e 3d20 5665 7273 696f 6e28  ease >= Version(
-00005c40: 2231 2e37 2e30 2229 2e72 656c 6561 7365  "1.7.0").release
-00005c50: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
-00005c60: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
-00005c70: 696f 6e2e 6465 6661 756c 745f 666c 6f61  ion.default_floa
-00005c80: 745f 7170 6172 616d 735f 6f62 7365 7276  t_qparams_observ
-00005c90: 6572 0a20 2020 2069 6620 616c 676f 7269  er.    if algori
-00005ca0: 7468 6d20 3d3d 2027 706c 6163 6568 6f6c  thm == 'placehol
-00005cb0: 6465 7227 206f 7220 6474 7970 6520 3d3d  der' or dtype ==
-00005cc0: 2027 6670 3332 273a 2020 2320 7072 6167   'fp32':  # prag
-00005cd0: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
-00005ce0: 2020 2020 2072 6574 7572 6e20 5f6f 6273       return _obs
-00005cf0: 6572 7665 7228 616c 676f 7269 7468 6d2c  erver(algorithm,
-00005d00: 2073 6368 656d 652c 2067 7261 6e75 6c61   scheme, granula
-00005d10: 7269 7479 2c20 6474 7970 652c 2063 6f6d  rity, dtype, com
-00005d20: 7075 7465 5f64 7479 7065 3d63 6f6d 7075  pute_dtype=compu
-00005d30: 7465 5f64 7479 7065 290a 2020 2020 6661  te_dtype).    fa
-00005d40: 6b65 5f71 7561 6e74 203d 2074 6f72 6368  ke_quant = torch
-00005d50: 2e71 7561 6e74 697a 6174 696f 6e2e 4661  .quantization.Fa
-00005d60: 6b65 5175 616e 7469 7a65 205c 0a20 2020  keQuantize \.   
-00005d70: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00005d80: 2076 6572 7369 6f6e 2e72 656c 6561 7365   version.release
-00005d90: 203c 2056 6572 7369 6f6e 2822 312e 3130   < Version("1.10
-00005da0: 2e30 2229 2e72 656c 6561 7365 2065 6c73  .0").release els
-00005db0: 6520 5c0a 2020 2020 2020 2020 2020 2020  e \.            
-00005dc0: 2020 2020 2020 2020 2074 6f72 6368 2e71           torch.q
-00005dd0: 7561 6e74 697a 6174 696f 6e2e 4675 7365  uantization.Fuse
-00005de0: 644d 6f76 696e 6741 7667 4f62 7346 616b  dMovingAvgObsFak
-00005df0: 6551 7561 6e74 697a 650a 2020 2020 6966  eQuantize.    if
-00005e00: 2061 6c67 6f72 6974 686d 203d 3d20 276d   algorithm == 'm
-00005e10: 696e 6d61 7827 3a0a 2020 2020 2020 2020  inmax':.        
-00005e20: 6966 2067 7261 6e75 6c61 7269 7479 203d  if granularity =
-00005e30: 3d20 2770 6572 5f63 6861 6e6e 656c 273a  = 'per_channel':
-00005e40: 0a20 2020 2020 2020 2020 2020 206f 6273  .            obs
-00005e50: 6572 7665 7220 3d20 746f 7263 682e 7175  erver = torch.qu
-00005e60: 616e 7469 7a61 7469 6f6e 2e4d 6f76 696e  antization.Movin
-00005e70: 6741 7665 7261 6765 5065 7243 6861 6e6e  gAveragePerChann
-00005e80: 656c 4d69 6e4d 6178 4f62 7365 7276 6572  elMinMaxObserver
-00005e90: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00005ea0: 7363 6865 6d65 203d 3d20 2773 796d 273a  scheme == 'sym':
-00005eb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005ec0: 2071 7363 6865 6d65 203d 2074 6f72 6368   qscheme = torch
-00005ed0: 2e70 6572 5f63 6861 6e6e 656c 5f73 796d  .per_channel_sym
-00005ee0: 6d65 7472 6963 0a20 2020 2020 2020 2020  metric.         
-00005ef0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00005f00: 2020 2020 2020 2020 2061 7373 6572 7420           assert 
-00005f10: 7363 6865 6d65 203d 3d20 2761 7379 6d27  scheme == 'asym'
-00005f20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005f30: 2071 7363 6865 6d65 203d 2074 6f72 6368   qscheme = torch
-00005f40: 2e70 6572 5f63 6861 6e6e 656c 5f61 6666  .per_channel_aff
-00005f50: 696e 650a 2020 2020 2020 2020 656c 7365  ine.        else
-00005f60: 3a0a 2020 2020 2020 2020 2020 2020 6173  :.            as
-00005f70: 7365 7274 2067 7261 6e75 6c61 7269 7479  sert granularity
-00005f80: 203d 3d20 2770 6572 5f74 656e 736f 7227   == 'per_tensor'
-00005f90: 0a20 2020 2020 2020 2020 2020 206f 6273  .            obs
-00005fa0: 6572 7665 7220 3d20 746f 7263 682e 7175  erver = torch.qu
-00005fb0: 616e 7469 7a61 7469 6f6e 2e4d 6f76 696e  antization.Movin
-00005fc0: 6741 7665 7261 6765 4d69 6e4d 6178 4f62  gAverageMinMaxOb
-00005fd0: 7365 7276 6572 0a20 2020 2020 2020 2020  server.         
-00005fe0: 2020 2069 6620 7363 6865 6d65 203d 3d20     if scheme == 
-00005ff0: 2773 796d 273a 0a20 2020 2020 2020 2020  'sym':.         
-00006000: 2020 2020 2020 2071 7363 6865 6d65 203d         qscheme =
-00006010: 2074 6f72 6368 2e70 6572 5f74 656e 736f   torch.per_tenso
-00006020: 725f 7379 6d6d 6574 7269 630a 2020 2020  r_symmetric.    
-00006030: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00006040: 2020 2020 2020 2020 2020 2020 2020 6173                as
-00006050: 7365 7274 2073 6368 656d 6520 3d3d 2027  sert scheme == '
-00006060: 6173 796d 270a 2020 2020 2020 2020 2020  asym'.          
-00006070: 2020 2020 2020 7173 6368 656d 6520 3d20        qscheme = 
-00006080: 746f 7263 682e 7065 725f 7465 6e73 6f72  torch.per_tensor
-00006090: 5f61 6666 696e 650a 2020 2020 656c 7365  _affine.    else
-000060a0: 3a20 2023 2070 7261 676d 613a 206e 6f20  :  # pragma: no 
-000060b0: 636f 7665 720a 2020 2020 2020 2020 2320  cover.        # 
-000060c0: 4869 7374 6f67 7261 6d20 6f62 7365 7276  Histogram observ
-000060d0: 6572 2069 7320 746f 6f20 736c 6f77 2066  er is too slow f
-000060e0: 6f72 2071 7561 6e74 697a 6174 696f 6e20  or quantization 
-000060f0: 6177 6172 6520 7472 6169 6e69 6e67 0a20  aware training. 
-00006100: 2020 2020 2020 2061 7373 6572 7420 616c         assert al
-00006110: 676f 7269 7468 6d20 3d3d 2027 6b6c 270a  gorithm == 'kl'.
-00006120: 2020 2020 2020 2020 6f62 7365 7276 6572          observer
-00006130: 203d 2074 6f72 6368 2e71 7561 6e74 697a   = torch.quantiz
-00006140: 6174 696f 6e2e 4869 7374 6f67 7261 6d4f  ation.HistogramO
-00006150: 6273 6572 7665 720a 2020 2020 2020 2020  bserver.        
-00006160: 6173 7365 7274 2067 7261 6e75 6c61 7269  assert granulari
-00006170: 7479 203d 3d20 2770 6572 5f74 656e 736f  ty == 'per_tenso
-00006180: 7227 0a20 2020 2020 2020 2069 6620 7363  r'.        if sc
-00006190: 6865 6d65 203d 3d20 2773 796d 273a 0a20  heme == 'sym':. 
-000061a0: 2020 2020 2020 2020 2020 2071 7363 6865             qsche
-000061b0: 6d65 203d 2074 6f72 6368 2e70 6572 5f74  me = torch.per_t
-000061c0: 656e 736f 725f 7379 6d6d 6574 7269 630a  ensor_symmetric.
-000061d0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-000061e0: 2020 2020 2020 2020 2020 6173 7365 7274            assert
-000061f0: 2073 6368 656d 6520 3d3d 2027 6173 796d   scheme == 'asym
-00006200: 270a 2020 2020 2020 2020 2020 2020 7173  '.            qs
-00006210: 6368 656d 6520 3d20 746f 7263 682e 7065  cheme = torch.pe
-00006220: 725f 7465 6e73 6f72 5f61 6666 696e 650a  r_tensor_affine.
-00006230: 0a20 2020 2069 6620 6474 7970 6520 3d3d  .    if dtype ==
-00006240: 2027 696e 7438 273a 0a20 2020 2020 2020   'int8':.       
-00006250: 2071 6d69 6e20 3d20 2d31 3238 0a20 2020   qmin = -128.   
-00006260: 2020 2020 2071 6d61 7820 3d20 3132 370a       qmax = 127.
-00006270: 2020 2020 2020 2020 6474 7970 6520 3d20          dtype = 
-00006280: 746f 7263 682e 7169 6e74 380a 2020 2020  torch.qint8.    
-00006290: 656c 7365 3a0a 2020 2020 2020 2020 6173  else:.        as
-000062a0: 7365 7274 2064 7479 7065 203d 3d20 2775  sert dtype == 'u
-000062b0: 696e 7438 270a 2020 2020 2020 2020 716d  int8'.        qm
-000062c0: 696e 203d 2030 0a20 2020 2020 2020 2071  in = 0.        q
-000062d0: 6d61 7820 3d20 3235 350a 2020 2020 2020  max = 255.      
-000062e0: 2020 6474 7970 6520 3d20 746f 7263 682e    dtype = torch.
-000062f0: 7175 696e 7438 0a0a 2020 2020 7265 7475  quint8..    retu
-00006300: 726e 2066 616b 655f 7175 616e 742e 7769  rn fake_quant.wi
-00006310: 7468 5f61 7267 7328 6f62 7365 7276 6572  th_args(observer
-00006320: 3d6f 6273 6572 7665 722c 0a20 2020 2020  =observer,.     
-00006330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006340: 2020 2020 2020 2020 2020 2071 7561 6e74             quant
-00006350: 5f6d 696e 3d71 6d69 6e2c 0a20 2020 2020  _min=qmin,.     
-00006360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006370: 2020 2020 2020 2020 2020 2071 7561 6e74             quant
-00006380: 5f6d 6178 3d71 6d61 782c 0a20 2020 2020  _max=qmax,.     
-00006390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000063a0: 2020 2020 2020 2020 2020 2064 7479 7065             dtype
-000063b0: 3d64 7479 7065 2c0a 2020 2020 2020 2020  =dtype,.        
-000063c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000063d0: 2020 2020 2020 2020 7173 6368 656d 653d          qscheme=
-000063e0: 7173 6368 656d 652c 0a20 2020 2020 2020  qscheme,.       
-000063f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006400: 2020 2020 2020 2020 2072 6564 7563 655f           reduce_
-00006410: 7261 6e67 653d 2852 4544 5543 455f 5241  range=(REDUCE_RA
-00006420: 4e47 4520 616e 6420 7363 6865 6d65 203d  NGE and scheme =
-00006430: 3d20 2761 7379 6d27 2929 0a0a 0a64 6566  = 'asym'))...def
-00006440: 205f 7072 6f70 6167 6174 655f 7163 6f6e   _propagate_qcon
-00006450: 6669 6728 6d6f 6465 6c2c 0a20 2020 2020  fig(model,.     
-00006460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006470: 2020 6f70 5f71 6366 6773 2c0a 2020 2020    op_qcfgs,.    
-00006480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006490: 2020 2069 735f 7161 745f 636f 6e76 6572     is_qat_conver
-000064a0: 743d 4661 6c73 652c 0a20 2020 2020 2020  t=False,.       
-000064b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000064c0: 6170 7072 6f61 6368 3d27 706f 7374 5f74  approach='post_t
-000064d0: 7261 696e 696e 675f 7374 6174 6963 5f71  raining_static_q
-000064e0: 7561 6e74 2729 3a0a 2020 2020 2222 2250  uant'):.    """P
-000064f0: 726f 7061 6761 7465 2071 636f 6e66 6967  ropagate qconfig
-00006500: 2074 6872 6f75 6768 2074 6865 206d 6f64   through the mod
-00006510: 756c 6520 6869 6572 6172 6368 7920 616e  ule hierarchy an
-00006520: 6420 6173 7369 676e 2060 7163 6f6e 6669  d assign `qconfi
-00006530: 6760 0a20 2020 2020 2020 6174 7472 6962  g`.       attrib
-00006540: 7574 6520 6f6e 2065 6163 6820 6c65 6166  ute on each leaf
-00006550: 206d 6f64 756c 650a 0a20 2020 2041 7267   module..    Arg
-00006560: 733a 0a20 2020 2020 2020 206d 6f64 656c  s:.        model
-00006570: 2028 6f62 6a65 6374 293a 2069 6e70 7574   (object): input
-00006580: 206d 6f64 656c 0a20 2020 2020 2020 206f   model.        o
-00006590: 705f 7163 6667 7320 2864 6963 7429 3a20  p_qcfgs (dict): 
-000065a0: 6469 6374 696f 6e61 7279 2074 6861 7420  dictionary that 
-000065b0: 6d61 7073 2066 726f 6d20 6e61 6d65 206f  maps from name o
-000065c0: 7220 7479 7065 206f 6620 7375 626d 6f64  r type of submod
-000065d0: 756c 6520 746f 0a20 2020 2020 2020 2020  ule to.         
-000065e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000065f0: 7175 616e 7469 7a61 7469 6f6e 2063 6f6e  quantization con
-00006600: 6669 6775 7261 7469 6f6e 2c20 7163 6f6e  figuration, qcon
-00006610: 6669 6720 6170 706c 6965 7320 746f 2061  fig applies to a
-00006620: 6c6c 2073 7562 6d6f 6475 6c65 7320 6f66  ll submodules of
-00006630: 2061 0a20 2020 2020 2020 2020 2020 2020   a.             
-00006640: 2020 2020 2020 2020 2020 2020 6769 7665              give
-00006650: 6e20 6d6f 6475 6c65 2075 6e6c 6573 7320  n module unless 
-00006660: 7163 6f6e 6669 6720 666f 7220 7468 6520  qconfig for the 
-00006670: 7375 626d 6f64 756c 6573 2061 7265 2073  submodules are s
-00006680: 7065 6369 6669 6564 2028 7768 656e 0a20  pecified (when. 
+00004fa0: 2022 2222 0a20 2020 2066 726f 6d20 2e74   """.    from .t
+00004fb0: 6f72 6368 5f75 7469 6c73 2e75 7469 6c20  orch_utils.util 
+00004fc0: 696d 706f 7274 206d 6174 6368 5f64 6174  import match_dat
+00004fd0: 6174 7970 655f 7061 7474 6572 6e2c 2063  atype_pattern, c
+00004fe0: 616c 6375 6c61 7465 5f71 7561 6e74 5f6d  alculate_quant_m
+00004ff0: 696e 5f6d 6178 2c20 5f67 6574 5f73 6967  in_max, _get_sig
+00005000: 6e65 645f 616e 645f 6269 7473 0a20 2020  ned_and_bits.   
+00005010: 2069 6620 6f62 7365 7276 6572 5f74 7970   if observer_typ
+00005020: 6520 3d3d 2027 706f 7374 5f74 7261 696e  e == 'post_train
+00005030: 696e 675f 6479 6e61 6d69 635f 7175 616e  ing_dynamic_quan
+00005040: 7427 2061 6e64 205c 0a20 2020 2020 2020  t' and \.       
+00005050: 2020 2020 2020 2020 2067 6574 5f74 6f72           get_tor
+00005060: 6368 5f76 6572 7369 6f6e 2829 2e72 656c  ch_version().rel
+00005070: 6561 7365 203e 3d20 5665 7273 696f 6e28  ease >= Version(
+00005080: 2231 2e36 2e30 2229 2e72 656c 6561 7365  "1.6.0").release
+00005090: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
+000050a0: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
+000050b0: 696f 6e2e 6465 6661 756c 745f 6479 6e61  ion.default_dyna
+000050c0: 6d69 635f 7175 616e 745f 6f62 7365 7276  mic_quant_observ
+000050d0: 6572 0a0a 2020 2020 636f 6d70 7574 655f  er..    compute_
+000050e0: 6474 7970 655f 6469 6374 203d 207b 2769  dtype_dict = {'i
+000050f0: 6e74 3827 3a20 746f 7263 682e 7169 6e74  nt8': torch.qint
+00005100: 382c 2027 7569 6e74 3827 3a20 746f 7263  8, 'uint8': torc
+00005110: 682e 7175 696e 7438 2c20 274e 6f6e 6527  h.quint8, 'None'
+00005120: 3a20 4e6f 6e65 7d0a 2020 2020 6966 2063  : None}.    if c
+00005130: 6f6d 7075 7465 5f64 7479 7065 2069 6e20  ompute_dtype in 
+00005140: 636f 6d70 7574 655f 6474 7970 655f 6469  compute_dtype_di
+00005150: 6374 3a0a 2020 2020 2020 2020 636f 6d70  ct:.        comp
+00005160: 7574 655f 6474 7970 6520 3d20 636f 6d70  ute_dtype = comp
+00005170: 7574 655f 6474 7970 655f 6469 6374 5b63  ute_dtype_dict[c
+00005180: 6f6d 7075 7465 5f64 7479 7065 5d0a 2020  ompute_dtype].  
+00005190: 2020 656c 7365 3a20 2023 2070 7261 676d    else:  # pragm
+000051a0: 613a 206e 6f20 636f 7665 720a 2020 2020  a: no cover.    
+000051b0: 2020 2020 6173 7365 7274 2046 616c 7365      assert False
+000051c0: 2c20 2255 6e73 7570 706f 7274 2063 6f6d  , "Unsupport com
+000051d0: 7075 7465 5f64 7479 7065 2077 6974 6820  pute_dtype with 
+000051e0: 7b7d 222e 666f 726d 6174 2863 6f6d 7075  {}".format(compu
+000051f0: 7465 5f64 7479 7065 290a 0a20 2020 2071  te_dtype)..    q
+00005200: 7561 6e74 5f6d 696e 2c20 7175 616e 745f  uant_min, quant_
+00005210: 6d61 7820 3d20 4e6f 6e65 2c20 4e6f 6e65  max = None, None
+00005220: 200a 2020 2020 6474 7970 655f 6469 6374   .    dtype_dict
+00005230: 203d 207b 2769 6e74 3827 3a20 746f 7263   = {'int8': torc
+00005240: 682e 7169 6e74 382c 2027 7569 6e74 3827  h.qint8, 'uint8'
+00005250: 3a20 746f 7263 682e 7175 696e 7438 2c20  : torch.quint8, 
+00005260: 2766 7033 3227 3a20 746f 7263 682e 666c  'fp32': torch.fl
+00005270: 6f61 747d 0a20 2020 2069 6620 6474 7970  oat}.    if dtyp
+00005280: 6520 696e 2064 7479 7065 5f64 6963 743a  e in dtype_dict:
+00005290: 0a20 2020 2020 2020 2074 6f72 6368 5f64  .        torch_d
+000052a0: 7479 7065 203d 2064 7479 7065 5f64 6963  type = dtype_dic
+000052b0: 745b 6474 7970 655d 0a20 2020 2065 6c73  t[dtype].    els
+000052c0: 653a 2020 2320 7072 6167 6d61 3a20 6e6f  e:  # pragma: no
+000052d0: 2063 6f76 6572 0a20 2020 2020 2020 2023   cover.        #
+000052e0: 544f 444f 2074 6f20 6861 6e64 6c65 2069  TODO to handle i
+000052f0: 6e74 340a 2020 2020 2020 2020 6966 206d  nt4.        if m
+00005300: 6174 6368 5f64 6174 6174 7970 655f 7061  atch_datatype_pa
+00005310: 7474 6572 6e28 6474 7970 6529 3a0a 2020  ttern(dtype):.  
+00005320: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
+00005330: 2e69 6e66 6f28 2866 2243 7572 7265 6e74  .info((f"Current
+00005340: 6c79 2c20 5079 546f 7263 6820 646f 6573  ly, PyTorch does
+00005350: 206e 6f74 206e 6174 6976 656c 7920 7375   not natively su
+00005360: 7070 6f72 7420 7b64 7479 7065 7d2c 222b  pport {dtype},"+
+00005370: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+00005380: 2020 2066 2269 7420 7769 6c6c 2073 696d     f"it will sim
+00005390: 756c 6174 6520 6974 7320 6e75 6d65 7269  ulate its numeri
+000053a0: 6373 2069 6e73 7465 6164 2e22 2929 0a20  cs instead.")). 
+000053b0: 2020 2020 2020 2020 2020 2075 6e73 6967             unsig
+000053c0: 6e65 642c 206e 756d 5f62 6974 7320 3d20  ned, num_bits = 
+000053d0: 5f67 6574 5f73 6967 6e65 645f 616e 645f  _get_signed_and_
+000053e0: 6269 7473 2864 7479 7065 290a 2020 2020  bits(dtype).    
+000053f0: 2020 2020 2020 2020 746f 7263 685f 6474          torch_dt
+00005400: 7970 6520 3d20 746f 7263 682e 7175 696e  ype = torch.quin
+00005410: 7438 2069 6620 756e 7369 676e 6564 2065  t8 if unsigned e
+00005420: 6c73 6520 746f 7263 682e 7169 6e74 380a  lse torch.qint8.
+00005430: 2020 2020 2020 2020 2020 2020 7175 616e              quan
+00005440: 745f 6d69 6e2c 2071 7561 6e74 5f6d 6178  t_min, quant_max
+00005450: 203d 2063 616c 6375 6c61 7465 5f71 7561   = calculate_qua
+00005460: 6e74 5f6d 696e 5f6d 6178 2875 6e73 6967  nt_min_max(unsig
+00005470: 6e65 642c 206e 756d 5f62 6974 7329 0a20  ned, num_bits). 
+00005480: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
+00005490: 722e 696e 666f 2828 6622 466f 7220 7b64  r.info((f"For {d
+000054a0: 7479 7065 7d2c 2072 6570 6c61 6365 2069  type}, replace i
+000054b0: 7420 7769 7468 207b 746f 7263 685f 6474  t with {torch_dt
+000054c0: 7970 657d 2061 6e64 2022 202b 205c 0a20  ype} and " + \. 
+000054d0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+000054e0: 2273 6574 2071 7561 6e74 5f6d 696e 3a20  "set quant_min: 
+000054f0: 7b71 7561 6e74 5f6d 696e 7d2c 2071 7561  {quant_min}, qua
+00005500: 6e74 5f6d 6178 3a20 7b71 7561 6e74 5f6d  nt_max: {quant_m
+00005510: 6178 7d22 2929 0a20 2020 2020 2020 2065  ax}")).        e
+00005520: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00005530: 2061 7373 6572 7420 4661 6c73 652c 2022   assert False, "
+00005540: 556e 7375 7070 6f72 7420 6474 7970 6520  Unsupport dtype 
+00005550: 7769 7468 207b 7d22 2e66 6f72 6d61 7428  with {}".format(
+00005560: 6474 7970 6529 0a0a 2020 2020 6966 2061  dtype)..    if a
+00005570: 6c67 6f72 6974 686d 203d 3d20 2770 6c61  lgorithm == 'pla
+00005580: 6365 686f 6c64 6572 2720 6f72 2074 6f72  ceholder' or tor
+00005590: 6368 5f64 7479 7065 203d 3d20 746f 7263  ch_dtype == torc
+000055a0: 682e 666c 6f61 743a 2020 2320 7072 6167  h.float:  # prag
+000055b0: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
+000055c0: 2020 2020 2072 6574 7572 6e20 746f 7263       return torc
+000055d0: 682e 7175 616e 7469 7a61 7469 6f6e 2e50  h.quantization.P
+000055e0: 6c61 6365 686f 6c64 6572 4f62 7365 7276  laceholderObserv
+000055f0: 6572 205c 0a20 2020 2020 2020 2020 2020  er \.           
+00005600: 2069 6620 6765 745f 746f 7263 685f 7665   if get_torch_ve
+00005610: 7273 696f 6e28 292e 7265 6c65 6173 6520  rsion().release 
+00005620: 3c20 5665 7273 696f 6e28 2231 2e38 2e30  < Version("1.8.0
+00005630: 2229 2e72 656c 6561 7365 205c 0a20 2020  ").release \.   
+00005640: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+00005650: 6520 746f 7263 682e 7175 616e 7469 7a61  e torch.quantiza
+00005660: 7469 6f6e 2e50 6c61 6365 686f 6c64 6572  tion.Placeholder
+00005670: 4f62 7365 7276 6572 2e77 6974 685f 6172  Observer.with_ar
+00005680: 6773 2864 7479 7065 3d74 6f72 6368 5f64  gs(dtype=torch_d
+00005690: 7479 7065 2c0a 2020 2020 2020 2020 2020  type,.          
+000056a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000056b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000056c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000056d0: 2020 2020 2020 2020 2020 2020 636f 6d70              comp
+000056e0: 7574 655f 6474 7970 653d 636f 6d70 7574  ute_dtype=comput
+000056f0: 655f 6474 7970 6529 0a20 2020 2069 6620  e_dtype).    if 
+00005700: 616c 676f 7269 7468 6d20 3d3d 2027 6d69  algorithm == 'mi
+00005710: 6e6d 6178 273a 0a20 2020 2020 2020 2069  nmax':.        i
+00005720: 6620 6772 616e 756c 6172 6974 7920 3d3d  f granularity ==
+00005730: 2027 7065 725f 6368 616e 6e65 6c27 3a0a   'per_channel':.
+00005740: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+00005750: 7276 6572 203d 2074 6f72 6368 2e71 7561  rver = torch.qua
+00005760: 6e74 697a 6174 696f 6e2e 5065 7243 6861  ntization.PerCha
+00005770: 6e6e 656c 4d69 6e4d 6178 4f62 7365 7276  nnelMinMaxObserv
+00005780: 6572 0a20 2020 2020 2020 2020 2020 2069  er.            i
+00005790: 6620 7363 6865 6d65 203d 3d20 2773 796d  f scheme == 'sym
+000057a0: 273a 0a20 2020 2020 2020 2020 2020 2020  ':.             
+000057b0: 2020 2071 7363 6865 6d65 203d 2074 6f72     qscheme = tor
+000057c0: 6368 2e70 6572 5f63 6861 6e6e 656c 5f73  ch.per_channel_s
+000057d0: 796d 6d65 7472 6963 0a20 2020 2020 2020  ymmetric.       
+000057e0: 2020 2020 2065 6c69 6620 7363 6865 6d65       elif scheme
+000057f0: 203d 3d20 2761 7379 6d5f 666c 6f61 7427   == 'asym_float'
+00005800: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00005810: 2020 7173 6368 656d 6520 3d20 746f 7263    qscheme = torc
+00005820: 682e 7065 725f 6368 616e 6e65 6c5f 6166  h.per_channel_af
+00005830: 6669 6e65 5f66 6c6f 6174 5f71 7061 7261  fine_float_qpara
+00005840: 6d73 0a20 2020 2020 2020 2020 2020 2065  ms.            e
+00005850: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00005860: 2020 2020 2071 7363 6865 6d65 203d 2074       qscheme = t
+00005870: 6f72 6368 2e70 6572 5f63 6861 6e6e 656c  orch.per_channel
+00005880: 5f61 6666 696e 650a 2020 2020 2020 2020  _affine.        
+00005890: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+000058a0: 2020 6173 7365 7274 2067 7261 6e75 6c61    assert granula
+000058b0: 7269 7479 203d 3d20 2770 6572 5f74 656e  rity == 'per_ten
+000058c0: 736f 7227 0a20 2020 2020 2020 2020 2020  sor'.           
+000058d0: 206f 6273 6572 7665 7220 3d20 746f 7263   observer = torc
+000058e0: 682e 7175 616e 7469 7a61 7469 6f6e 2e4d  h.quantization.M
+000058f0: 696e 4d61 784f 6273 6572 7665 720a 2020  inMaxObserver.  
+00005900: 2020 2020 2020 2020 2020 6966 2073 6368            if sch
+00005910: 656d 6520 3d3d 2027 7379 6d27 3a0a 2020  eme == 'sym':.  
+00005920: 2020 2020 2020 2020 2020 2020 2020 7173                qs
+00005930: 6368 656d 6520 3d20 746f 7263 682e 7065  cheme = torch.pe
+00005940: 725f 7465 6e73 6f72 5f73 796d 6d65 7472  r_tensor_symmetr
+00005950: 6963 0a20 2020 2020 2020 2020 2020 2065  ic.            e
+00005960: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00005970: 2020 2020 2061 7373 6572 7420 7363 6865       assert sche
+00005980: 6d65 203d 3d20 2761 7379 6d27 0a20 2020  me == 'asym'.   
+00005990: 2020 2020 2020 2020 2020 2020 2071 7363               qsc
+000059a0: 6865 6d65 203d 2074 6f72 6368 2e70 6572  heme = torch.per
+000059b0: 5f74 656e 736f 725f 6166 6669 6e65 0a20  _tensor_affine. 
+000059c0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+000059d0: 2061 7373 6572 7420 616c 676f 7269 7468   assert algorith
+000059e0: 6d20 3d3d 2027 6b6c 270a 2020 2020 2020  m == 'kl'.      
+000059f0: 2020 6f62 7365 7276 6572 203d 2074 6f72    observer = tor
+00005a00: 6368 2e71 7561 6e74 697a 6174 696f 6e2e  ch.quantization.
+00005a10: 4869 7374 6f67 7261 6d4f 6273 6572 7665  HistogramObserve
+00005a20: 720a 2020 2020 2020 2020 6173 7365 7274  r.        assert
+00005a30: 2067 7261 6e75 6c61 7269 7479 203d 3d20   granularity == 
+00005a40: 2770 6572 5f74 656e 736f 7227 0a20 2020  'per_tensor'.   
+00005a50: 2020 2020 2069 6620 7363 6865 6d65 203d       if scheme =
+00005a60: 3d20 2773 796d 273a 0a20 2020 2020 2020  = 'sym':.       
+00005a70: 2020 2020 2071 7363 6865 6d65 203d 2074       qscheme = t
+00005a80: 6f72 6368 2e70 6572 5f74 656e 736f 725f  orch.per_tensor_
+00005a90: 7379 6d6d 6574 7269 630a 2020 2020 2020  symmetric.      
+00005aa0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00005ab0: 2020 2020 6173 7365 7274 2073 6368 656d      assert schem
+00005ac0: 6520 3d3d 2027 6173 796d 270a 2020 2020  e == 'asym'.    
+00005ad0: 2020 2020 2020 2020 7173 6368 656d 6520          qscheme 
+00005ae0: 3d20 746f 7263 682e 7065 725f 7465 6e73  = torch.per_tens
+00005af0: 6f72 5f61 6666 696e 650a 0a20 2020 2072  or_affine..    r
+00005b00: 6574 7572 6e20 6f62 7365 7276 6572 2e77  eturn observer.w
+00005b10: 6974 685f 6172 6773 2871 7363 6865 6d65  ith_args(qscheme
+00005b20: 3d71 7363 6865 6d65 2c0a 2020 2020 2020  =qscheme,.      
+00005b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005b40: 2020 2020 2020 2020 6474 7970 653d 746f          dtype=to
+00005b50: 7263 685f 6474 7970 652c 0a20 2020 2020  rch_dtype,.     
+00005b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005b70: 2020 2020 2020 2020 2072 6564 7563 655f           reduce_
+00005b80: 7261 6e67 653d 2852 4544 5543 455f 5241  range=(REDUCE_RA
+00005b90: 4e47 4520 616e 6420 7363 6865 6d65 203d  NGE and scheme =
+00005ba0: 3d20 2761 7379 6d27 292c 0a20 2020 2020  = 'asym'),.     
+00005bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005bc0: 2020 2020 2020 2020 2071 7561 6e74 5f6d           quant_m
+00005bd0: 696e 3d71 7561 6e74 5f6d 696e 2c0a 2020  in=quant_min,.  
+00005be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005bf0: 2020 2020 2020 2020 2020 2020 7175 616e              quan
+00005c00: 745f 6d61 783d 7175 616e 745f 6d61 7829  t_max=quant_max)
+00005c10: 0a0a 0a64 6566 205f 6661 6b65 5f71 7561  ...def _fake_qua
+00005c20: 6e74 697a 6528 616c 676f 7269 7468 6d2c  ntize(algorithm,
+00005c30: 2073 6368 656d 652c 2067 7261 6e75 6c61   scheme, granula
+00005c40: 7269 7479 2c20 6474 7970 652c 2063 6f6d  rity, dtype, com
+00005c50: 7075 7465 5f64 7479 7065 3d27 7569 6e74  pute_dtype='uint
+00005c60: 3827 293a 0a20 2020 2022 2222 436f 6e73  8'):.    """Cons
+00005c70: 7472 7563 7420 6120 6661 6b65 2071 7561  truct a fake qua
+00005c80: 6e74 697a 6520 6d6f 6475 6c65 2c20 496e  ntize module, In
+00005c90: 2066 6f72 7761 7264 2c20 6661 6b65 2071   forward, fake q
+00005ca0: 7561 6e74 697a 6520 6d6f 6475 6c65 2077  uantize module w
+00005cb0: 696c 6c20 7570 6461 7465 0a20 2020 2020  ill update.     
+00005cc0: 2020 7468 6520 7374 6174 6973 7469 6373    the statistics
+00005cd0: 206f 6620 7468 6520 6f62 7365 7276 6564   of the observed
+00005ce0: 2054 656e 736f 7220 616e 6420 6661 6b65   Tensor and fake
+00005cf0: 2071 7561 6e74 697a 6520 7468 6520 696e   quantize the in
+00005d00: 7075 742e 0a20 2020 2020 2020 5468 6579  put..       They
+00005d10: 2073 686f 756c 6420 616c 736f 2070 726f   should also pro
+00005d20: 7669 6465 2061 2060 6361 6c63 756c 6174  vide a `calculat
+00005d30: 655f 7170 6172 616d 7360 2066 756e 6374  e_qparams` funct
+00005d40: 696f 6e0a 2020 2020 2020 2074 6861 7420  ion.       that 
+00005d50: 636f 6d70 7574 6573 2074 6865 2071 7561  computes the qua
+00005d60: 6e74 697a 6174 696f 6e20 7061 7261 6d65  ntization parame
+00005d70: 7465 7273 2067 6976 656e 2074 6865 2063  ters given the c
+00005d80: 6f6c 6c65 6374 6564 2073 7461 7469 7374  ollected statist
+00005d90: 6963 732e 0a0a 2020 2020 4172 6773 3a0a  ics...    Args:.
+00005da0: 2020 2020 2020 2020 616c 676f 7269 7468          algorith
+00005db0: 6d20 2873 7472 696e 6729 3a20 5768 6174  m (string): What
+00005dc0: 2061 6c67 6f72 6974 686d 2066 6f72 2063   algorithm for c
+00005dd0: 6f6d 7075 7469 6e67 2074 6865 2071 7561  omputing the qua
+00005de0: 6e74 697a 6174 696f 6e20 7061 7261 6d65  ntization parame
+00005df0: 7465 7273 2062 6173 6564 206f 6e2e 0a20  ters based on.. 
+00005e00: 2020 2020 2020 2073 6368 656d 6520 2873         scheme (s
+00005e10: 7472 696e 6729 3a20 5175 616e 7469 7a61  tring): Quantiza
+00005e20: 7469 6f6e 2073 6368 656d 6520 746f 2062  tion scheme to b
+00005e30: 6520 7573 6564 2e0a 2020 2020 2020 2020  e used..        
+00005e40: 6772 616e 756c 6172 6974 7920 2873 7472  granularity (str
+00005e50: 696e 6729 3a20 5768 6174 2067 7261 6e75  ing): What granu
+00005e60: 6c61 7269 7479 2074 6f20 636f 6d70 7574  larity to comput
+00005e70: 696e 6720 7468 6520 7175 616e 7469 7a61  ing the quantiza
+00005e80: 7469 6f6e 2070 6172 616d 6574 6572 732c  tion parameters,
+00005e90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005ea0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00005eb0: 6572 2063 6861 6e6e 656c 206f 7220 7065  er channel or pe
+00005ec0: 7220 7465 6e73 6f72 2e0a 2020 2020 2020  r tensor..      
+00005ed0: 2020 6474 7970 6520 2873 7469 6e67 293a    dtype (sting):
+00005ee0: 2051 7561 6e74 697a 6564 2064 6174 6120   Quantized data 
+00005ef0: 7479 7065 0a0a 2020 2020 5265 7475 726e  type..    Return
+00005f00: 3a0a 2020 2020 2020 2020 6661 6b65 2071  :.        fake q
+00005f10: 7561 6e74 697a 6174 696f 6e20 286f 626a  uantization (obj
+00005f20: 6563 7429 0a20 2020 2022 2222 0a20 2020  ect).    """.   
+00005f30: 2076 6572 7369 6f6e 203d 2067 6574 5f74   version = get_t
+00005f40: 6f72 6368 5f76 6572 7369 6f6e 2829 0a20  orch_version(). 
+00005f50: 2020 2069 6620 7363 6865 6d65 203d 3d20     if scheme == 
+00005f60: 2761 7379 6d5f 666c 6f61 7427 205c 0a20  'asym_float' \. 
+00005f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005f80: 616e 6420 7665 7273 696f 6e2e 7265 6c65  and version.rele
+00005f90: 6173 6520 3e3d 2056 6572 7369 6f6e 2822  ase >= Version("
+00005fa0: 312e 372e 3022 292e 7265 6c65 6173 653a  1.7.0").release:
+00005fb0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00005fc0: 746f 7263 682e 7175 616e 7469 7a61 7469  torch.quantizati
+00005fd0: 6f6e 2e64 6566 6175 6c74 5f66 6c6f 6174  on.default_float
+00005fe0: 5f71 7061 7261 6d73 5f6f 6273 6572 7665  _qparams_observe
+00005ff0: 720a 2020 2020 6966 2061 6c67 6f72 6974  r.    if algorit
+00006000: 686d 203d 3d20 2770 6c61 6365 686f 6c64  hm == 'placehold
+00006010: 6572 2720 6f72 2064 7479 7065 203d 3d20  er' or dtype == 
+00006020: 2766 7033 3227 3a20 2023 2070 7261 676d  'fp32':  # pragm
+00006030: 613a 206e 6f20 636f 7665 720a 2020 2020  a: no cover.    
+00006040: 2020 2020 7265 7475 726e 205f 6f62 7365      return _obse
+00006050: 7276 6572 2861 6c67 6f72 6974 686d 2c20  rver(algorithm, 
+00006060: 7363 6865 6d65 2c20 6772 616e 756c 6172  scheme, granular
+00006070: 6974 792c 2064 7479 7065 2c20 636f 6d70  ity, dtype, comp
+00006080: 7574 655f 6474 7970 653d 636f 6d70 7574  ute_dtype=comput
+00006090: 655f 6474 7970 6529 0a20 2020 2066 616b  e_dtype).    fak
+000060a0: 655f 7175 616e 7420 3d20 746f 7263 682e  e_quant = torch.
+000060b0: 7175 616e 7469 7a61 7469 6f6e 2e46 616b  quantization.Fak
+000060c0: 6551 7561 6e74 697a 6520 5c0a 2020 2020  eQuantize \.    
+000060d0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000060e0: 7665 7273 696f 6e2e 7265 6c65 6173 6520  version.release 
+000060f0: 3c20 5665 7273 696f 6e28 2231 2e31 302e  < Version("1.10.
+00006100: 3022 292e 7265 6c65 6173 6520 656c 7365  0").release else
+00006110: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+00006120: 2020 2020 2020 2020 746f 7263 682e 7175          torch.qu
+00006130: 616e 7469 7a61 7469 6f6e 2e46 7573 6564  antization.Fused
+00006140: 4d6f 7669 6e67 4176 674f 6273 4661 6b65  MovingAvgObsFake
+00006150: 5175 616e 7469 7a65 0a20 2020 2069 6620  Quantize.    if 
+00006160: 616c 676f 7269 7468 6d20 3d3d 2027 6d69  algorithm == 'mi
+00006170: 6e6d 6178 273a 0a20 2020 2020 2020 2069  nmax':.        i
+00006180: 6620 6772 616e 756c 6172 6974 7920 3d3d  f granularity ==
+00006190: 2027 7065 725f 6368 616e 6e65 6c27 3a0a   'per_channel':.
+000061a0: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+000061b0: 7276 6572 203d 2074 6f72 6368 2e71 7561  rver = torch.qua
+000061c0: 6e74 697a 6174 696f 6e2e 4d6f 7669 6e67  ntization.Moving
+000061d0: 4176 6572 6167 6550 6572 4368 616e 6e65  AveragePerChanne
+000061e0: 6c4d 696e 4d61 784f 6273 6572 7665 720a  lMinMaxObserver.
+000061f0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00006200: 6368 656d 6520 3d3d 2027 7379 6d27 3a0a  cheme == 'sym':.
+00006210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006220: 7173 6368 656d 6520 3d20 746f 7263 682e  qscheme = torch.
+00006230: 7065 725f 6368 616e 6e65 6c5f 7379 6d6d  per_channel_symm
+00006240: 6574 7269 630a 2020 2020 2020 2020 2020  etric.          
+00006250: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00006260: 2020 2020 2020 2020 6173 7365 7274 2073          assert s
+00006270: 6368 656d 6520 3d3d 2027 6173 796d 270a  cheme == 'asym'.
+00006280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006290: 7173 6368 656d 6520 3d20 746f 7263 682e  qscheme = torch.
+000062a0: 7065 725f 6368 616e 6e65 6c5f 6166 6669  per_channel_affi
+000062b0: 6e65 0a20 2020 2020 2020 2065 6c73 653a  ne.        else:
+000062c0: 0a20 2020 2020 2020 2020 2020 2061 7373  .            ass
+000062d0: 6572 7420 6772 616e 756c 6172 6974 7920  ert granularity 
+000062e0: 3d3d 2027 7065 725f 7465 6e73 6f72 270a  == 'per_tensor'.
+000062f0: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+00006300: 7276 6572 203d 2074 6f72 6368 2e71 7561  rver = torch.qua
+00006310: 6e74 697a 6174 696f 6e2e 4d6f 7669 6e67  ntization.Moving
+00006320: 4176 6572 6167 654d 696e 4d61 784f 6273  AverageMinMaxObs
+00006330: 6572 7665 720a 2020 2020 2020 2020 2020  erver.          
+00006340: 2020 6966 2073 6368 656d 6520 3d3d 2027    if scheme == '
+00006350: 7379 6d27 3a0a 2020 2020 2020 2020 2020  sym':.          
+00006360: 2020 2020 2020 7173 6368 656d 6520 3d20        qscheme = 
+00006370: 746f 7263 682e 7065 725f 7465 6e73 6f72  torch.per_tensor
+00006380: 5f73 796d 6d65 7472 6963 0a20 2020 2020  _symmetric.     
+00006390: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+000063a0: 2020 2020 2020 2020 2020 2020 2061 7373               ass
+000063b0: 6572 7420 7363 6865 6d65 203d 3d20 2761  ert scheme == 'a
+000063c0: 7379 6d27 0a20 2020 2020 2020 2020 2020  sym'.           
+000063d0: 2020 2020 2071 7363 6865 6d65 203d 2074       qscheme = t
+000063e0: 6f72 6368 2e70 6572 5f74 656e 736f 725f  orch.per_tensor_
+000063f0: 6166 6669 6e65 0a20 2020 2065 6c73 653a  affine.    else:
+00006400: 2020 2320 7072 6167 6d61 3a20 6e6f 2063    # pragma: no c
+00006410: 6f76 6572 0a20 2020 2020 2020 2023 2048  over.        # H
+00006420: 6973 746f 6772 616d 206f 6273 6572 7665  istogram observe
+00006430: 7220 6973 2074 6f6f 2073 6c6f 7720 666f  r is too slow fo
+00006440: 7220 7175 616e 7469 7a61 7469 6f6e 2061  r quantization a
+00006450: 7761 7265 2074 7261 696e 696e 670a 2020  ware training.  
+00006460: 2020 2020 2020 6173 7365 7274 2061 6c67        assert alg
+00006470: 6f72 6974 686d 203d 3d20 276b 6c27 0a20  orithm == 'kl'. 
+00006480: 2020 2020 2020 206f 6273 6572 7665 7220         observer 
+00006490: 3d20 746f 7263 682e 7175 616e 7469 7a61  = torch.quantiza
+000064a0: 7469 6f6e 2e48 6973 746f 6772 616d 4f62  tion.HistogramOb
+000064b0: 7365 7276 6572 0a20 2020 2020 2020 2061  server.        a
+000064c0: 7373 6572 7420 6772 616e 756c 6172 6974  ssert granularit
+000064d0: 7920 3d3d 2027 7065 725f 7465 6e73 6f72  y == 'per_tensor
+000064e0: 270a 2020 2020 2020 2020 6966 2073 6368  '.        if sch
+000064f0: 656d 6520 3d3d 2027 7379 6d27 3a0a 2020  eme == 'sym':.  
+00006500: 2020 2020 2020 2020 2020 7173 6368 656d            qschem
+00006510: 6520 3d20 746f 7263 682e 7065 725f 7465  e = torch.per_te
+00006520: 6e73 6f72 5f73 796d 6d65 7472 6963 0a20  nsor_symmetric. 
+00006530: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00006540: 2020 2020 2020 2020 2061 7373 6572 7420           assert 
+00006550: 7363 6865 6d65 203d 3d20 2761 7379 6d27  scheme == 'asym'
+00006560: 0a20 2020 2020 2020 2020 2020 2071 7363  .            qsc
+00006570: 6865 6d65 203d 2074 6f72 6368 2e70 6572  heme = torch.per
+00006580: 5f74 656e 736f 725f 6166 6669 6e65 0a0a  _tensor_affine..
+00006590: 2020 2020 6966 2064 7479 7065 203d 3d20      if dtype == 
+000065a0: 2769 6e74 3827 3a0a 2020 2020 2020 2020  'int8':.        
+000065b0: 716d 696e 203d 202d 3132 380a 2020 2020  qmin = -128.    
+000065c0: 2020 2020 716d 6178 203d 2031 3237 0a20      qmax = 127. 
+000065d0: 2020 2020 2020 2064 7479 7065 203d 2074         dtype = t
+000065e0: 6f72 6368 2e71 696e 7438 0a20 2020 2065  orch.qint8.    e
+000065f0: 6c73 653a 0a20 2020 2020 2020 2061 7373  lse:.        ass
+00006600: 6572 7420 6474 7970 6520 3d3d 2027 7569  ert dtype == 'ui
+00006610: 6e74 3827 0a20 2020 2020 2020 2071 6d69  nt8'.        qmi
+00006620: 6e20 3d20 300a 2020 2020 2020 2020 716d  n = 0.        qm
+00006630: 6178 203d 2032 3535 0a20 2020 2020 2020  ax = 255.       
+00006640: 2064 7479 7065 203d 2074 6f72 6368 2e71   dtype = torch.q
+00006650: 7569 6e74 380a 0a20 2020 2072 6574 7572  uint8..    retur
+00006660: 6e20 6661 6b65 5f71 7561 6e74 2e77 6974  n fake_quant.wit
+00006670: 685f 6172 6773 286f 6273 6572 7665 723d  h_args(observer=
+00006680: 6f62 7365 7276 6572 2c0a 2020 2020 2020  observer,.      
 00006690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000066a0: 2020 2020 2020 2020 7468 6520 7375 626d          the subm
-000066b0: 6f64 756c 6520 616c 7265 6164 7920 6861  odule already ha
-000066c0: 7320 7163 6f6e 6669 6720 6174 7472 6962  s qconfig attrib
-000066d0: 7574 6529 0a20 2020 2020 2020 2069 735f  ute).        is_
-000066e0: 7161 745f 636f 6e76 6572 7420 2862 6f6f  qat_convert (boo
-000066f0: 6c29 3a20 666c 6167 2074 6861 7420 7370  l): flag that sp
-00006700: 6563 6966 6965 6420 7468 6973 2066 756e  ecified this fun
-00006710: 6374 696f 6e20 6973 2075 7365 6420 746f  ction is used to
-00006720: 2051 4154 2070 7265 7061 7265 0a20 2020   QAT prepare.   
-00006730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006740: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00006750: 7079 746f 7263 6820 312e 3720 6f72 2061  pytorch 1.7 or a
-00006760: 626f 7665 2e0a 2020 2020 2020 2020 6170  bove..        ap
-00006770: 7072 6f61 6368 2028 7374 7229 3a20 7175  proach (str): qu
-00006780: 616e 7469 7a61 7469 6f6e 2061 7070 726f  antization appro
-00006790: 6163 680a 2020 2020 5265 7475 726e 3a0a  ach.    Return:.
-000067a0: 2020 2020 2020 2020 4e6f 6e65 2c20 6d6f          None, mo
-000067b0: 6475 6c65 2069 7320 6d6f 6469 6669 6564  dule is modified
-000067c0: 2069 6e70 6c61 6365 2077 6974 6820 7163   inplace with qc
-000067d0: 6f6e 6669 6720 6174 7461 6368 6564 0a20  onfig attached. 
-000067e0: 2020 2022 2222 0a20 2020 2066 616c 6c62     """.    fallb
-000067f0: 6163 6b5f 6f70 7320 3d20 5b5d 0a20 2020  ack_ops = [].   
-00006800: 205f 7072 6f70 6167 6174 655f 7163 6f6e   _propagate_qcon
-00006810: 6669 675f 7265 6375 7273 6976 656c 7928  fig_recursively(
-00006820: 6d6f 6465 6c2c 2027 272c 206f 705f 7163  model, '', op_qc
-00006830: 6667 7329 0a0a 2020 2020 6966 2061 7070  fgs)..    if app
-00006840: 726f 6163 6820 213d 2027 706f 7374 5f74  roach != 'post_t
-00006850: 7261 696e 696e 675f 6479 6e61 6d69 635f  raining_dynamic_
-00006860: 7175 616e 7427 3a0a 2020 2020 2020 2020  quant':.        
-00006870: 666f 7220 6b2c 2076 2069 6e20 6f70 5f71  for k, v in op_q
-00006880: 6366 6773 2e69 7465 6d73 2829 3a0a 2020  cfgs.items():.  
-00006890: 2020 2020 2020 2020 2020 6966 2076 2069            if v i
-000068a0: 7320 4e6f 6e65 2061 6e64 206e 6f74 2069  s None and not i
-000068b0: 735f 7161 745f 636f 6e76 6572 743a 0a20  s_qat_convert:. 
-000068c0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-000068d0: 616c 6c62 6163 6b5f 6f70 732e 6170 7065  allback_ops.appe
-000068e0: 6e64 286b 290a 0a20 2020 2020 2020 2069  nd(k)..        i
-000068f0: 6620 6661 6c6c 6261 636b 5f6f 7073 2061  f fallback_ops a
-00006900: 6e64 206e 6f74 2069 735f 7161 745f 636f  nd not is_qat_co
-00006910: 6e76 6572 743a 0a20 2020 2020 2020 2020  nvert:.         
-00006920: 2020 205f 6661 6c6c 6261 636b 5f71 7561     _fallback_qua
-00006930: 6e74 697a 6162 6c65 5f6f 7073 5f72 6563  ntizable_ops_rec
-00006940: 7572 7369 7665 6c79 286d 6f64 656c 2c20  ursively(model, 
-00006950: 2727 2c20 6661 6c6c 6261 636b 5f6f 7073  '', fallback_ops
-00006960: 2c20 6f70 5f71 6366 6773 290a 0a0a 6465  , op_qcfgs)...de
-00006970: 6620 5f70 726f 7061 6761 7465 5f71 636f  f _propagate_qco
-00006980: 6e66 6967 5f72 6563 7572 7369 7665 6c79  nfig_recursively
-00006990: 286d 6f64 656c 2c20 7072 6566 6978 2c20  (model, prefix, 
-000069a0: 6f70 5f71 6366 6773 2c20 7163 6f6e 6669  op_qcfgs, qconfi
-000069b0: 675f 7061 7265 6e74 3d4e 6f6e 6529 3a0a  g_parent=None):.
-000069c0: 2020 2020 2222 2254 6869 7320 6973 2061      """This is a
-000069d0: 2068 656c 7065 7220 6675 6e63 7469 6f6e   helper function
-000069e0: 2066 6f72 2060 7072 6f70 6167 6174 655f   for `propagate_
-000069f0: 7163 6f6e 6669 6760 0a0a 2020 2020 4172  qconfig`..    Ar
-00006a00: 6773 3a0a 2020 2020 2020 2020 6d6f 6465  gs:.        mode
-00006a10: 6c20 286f 626a 6563 7429 3a20 696e 7075  l (object): inpu
-00006a20: 7420 6d6f 6465 6c0a 2020 2020 2020 2020  t model.        
-00006a30: 7072 6566 6978 2028 7374 7269 6e67 293a  prefix (string):
-00006a40: 2070 7265 6669 7820 6f66 206f 7020 6e61   prefix of op na
-00006a50: 6d65 0a20 2020 2020 2020 206f 705f 7163  me.        op_qc
-00006a60: 6667 7320 2864 6963 7429 3a20 6469 6374  fgs (dict): dict
-00006a70: 696f 6e61 7279 2074 6861 7420 6d61 7073  ionary that maps
-00006a80: 2066 726f 6d20 6e61 6d65 206f 7220 7479   from name or ty
-00006a90: 7065 206f 6620 7375 626d 6f64 756c 6520  pe of submodule 
-00006aa0: 746f 0a20 2020 2020 2020 2020 2020 2020  to.             
-00006ab0: 2020 2020 2020 2020 2020 2071 7561 6e74             quant
-00006ac0: 697a 6174 696f 6e20 636f 6e66 6967 7572  ization configur
-00006ad0: 6174 696f 6e0a 2020 2020 2020 2020 7163  ation.        qc
-00006ae0: 6f6e 6669 675f 7061 7265 6e74 2028 6f62  onfig_parent (ob
-00006af0: 6a65 6374 2c20 6f70 7469 6f6e 616c 293a  ject, optional):
-00006b00: 2071 636f 6e66 6967 206f 6620 7061 7265   qconfig of pare
-00006b10: 6e74 206d 6f64 756c 650a 0a20 2020 2052  nt module..    R
-00006b20: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
-00006b30: 4e6f 6e65 0a20 2020 2022 2222 0a20 2020  None.    """.   
-00006b40: 2066 6f72 206e 616d 652c 2063 6869 6c64   for name, child
-00006b50: 2069 6e20 6d6f 6465 6c2e 6e61 6d65 645f   in model.named_
-00006b60: 6368 696c 6472 656e 2829 3a0a 2020 2020  children():.    
-00006b70: 2020 2020 6f70 5f6e 616d 6520 3d20 7072      op_name = pr
-00006b80: 6566 6978 202b 206e 616d 650a 2020 2020  efix + name.    
-00006b90: 2020 2020 6368 696c 642e 7163 6f6e 6669      child.qconfi
-00006ba0: 6720 3d20 7163 6f6e 6669 675f 7061 7265  g = qconfig_pare
-00006bb0: 6e74 0a20 2020 2020 2020 2071 636f 6e66  nt.        qconf
-00006bc0: 6967 5f73 6f6e 203d 204e 6f6e 650a 2020  ig_son = None.  
-00006bd0: 2020 2020 2020 6966 206f 705f 6e61 6d65        if op_name
-00006be0: 2069 6e20 6f70 5f71 6366 6773 3a0a 2020   in op_qcfgs:.  
-00006bf0: 2020 2020 2020 2020 2020 6368 696c 642e            child.
-00006c00: 7163 6f6e 6669 6720 3d20 6f70 5f71 6366  qconfig = op_qcf
-00006c10: 6773 5b6f 705f 6e61 6d65 5d0a 2020 2020  gs[op_name].    
-00006c20: 2020 2020 2020 2020 2320 666f 7220 7375          # for su
-00006c30: 626d 6f64 756c 6573 206f 6620 6675 7365  bmodules of fuse
-00006c40: 6420 6d6f 6475 6c65 2c20 6c69 6b65 206e  d module, like n
-00006c50: 6e2e 436f 6e76 426e 5265 6c75 3264 2e0a  n.ConvBnRelu2d..
-00006c60: 2020 2020 2020 2020 2020 2020 7163 6f6e              qcon
-00006c70: 6669 675f 736f 6e20 3d20 6368 696c 642e  fig_son = child.
-00006c80: 7163 6f6e 6669 670a 2020 2020 2020 2020  qconfig.        
-00006c90: 656c 6966 2074 7970 6528 6368 696c 6429  elif type(child)
-00006ca0: 203d 3d20 746f 7263 682e 7175 616e 7469   == torch.quanti
-00006cb0: 7a61 7469 6f6e 2e44 6551 7561 6e74 5374  zation.DeQuantSt
-00006cc0: 7562 3a0a 2020 2020 2020 2020 2020 2020  ub:.            
-00006cd0: 7665 7273 696f 6e20 3d20 6765 745f 746f  version = get_to
-00006ce0: 7263 685f 7665 7273 696f 6e28 290a 2020  rch_version().  
-00006cf0: 2020 2020 2020 2020 2020 6966 2076 6572            if ver
-00006d00: 7369 6f6e 2e72 656c 6561 7365 203e 3d20  sion.release >= 
-00006d10: 5665 7273 696f 6e28 2231 2e38 2e30 2229  Version("1.8.0")
-00006d20: 2e72 656c 6561 7365 3a0a 2020 2020 2020  .release:.      
-00006d30: 2020 2020 2020 2020 2020 6368 696c 642e            child.
-00006d40: 7163 6f6e 6669 6720 3d20 746f 7263 682e  qconfig = torch.
-00006d50: 7175 616e 7469 7a61 7469 6f6e 2e51 436f  quantization.QCo
-00006d60: 6e66 6967 280a 2020 2020 2020 2020 2020  nfig(.          
-00006d70: 2020 2020 2020 2020 2020 6163 7469 7661            activa
-00006d80: 7469 6f6e 3d74 6f72 6368 2e71 7561 6e74  tion=torch.quant
-00006d90: 697a 6174 696f 6e2e 4d69 6e4d 6178 4f62  ization.MinMaxOb
-00006da0: 7365 7276 6572 2e77 6974 685f 6172 6773  server.with_args
-00006db0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00006dc0: 2020 2020 2020 2020 2020 7265 6475 6365            reduce
-00006dd0: 5f72 616e 6765 3d52 4544 5543 455f 5241  _range=REDUCE_RA
-00006de0: 4e47 4529 2c0a 2020 2020 2020 2020 2020  NGE),.          
-00006df0: 2020 2020 2020 2020 2020 7765 6967 6874            weight
-00006e00: 3d74 6f72 6368 2e71 7561 6e74 697a 6174  =torch.quantizat
-00006e10: 696f 6e2e 6465 6661 756c 745f 7065 725f  ion.default_per_
-00006e20: 6368 616e 6e65 6c5f 7765 6967 6874 5f6f  channel_weight_o
-00006e30: 6273 6572 7665 7229 0a20 2020 2020 2020  bserver).       
-00006e40: 205f 7072 6f70 6167 6174 655f 7163 6f6e   _propagate_qcon
-00006e50: 6669 675f 7265 6375 7273 6976 656c 7928  fig_recursively(
-00006e60: 6368 696c 642c 206f 705f 6e61 6d65 202b  child, op_name +
-00006e70: 2027 2e27 2c20 6f70 5f71 6366 6773 2c20   '.', op_qcfgs, 
-00006e80: 7163 6f6e 6669 675f 736f 6e29 0a0a 0a64  qconfig_son)...d
-00006e90: 6566 205f 6669 6e64 5f71 7561 6e74 697a  ef _find_quantiz
-00006ea0: 6564 5f6f 705f 6e75 6d28 6d6f 6475 6c65  ed_op_num(module
-00006eb0: 2c20 6f70 5f71 6366 6773 2c20 7072 6566  , op_qcfgs, pref
-00006ec0: 6978 3d27 272c 206f 705f 636f 756e 743d  ix='', op_count=
-00006ed0: 3029 3a0a 2020 2020 2222 2254 6869 7320  0):.    """This 
-00006ee0: 6973 2061 2068 656c 7065 7220 6675 6e63  is a helper func
-00006ef0: 7469 6f6e 2066 6f72 2060 5f66 616c 6c62  tion for `_fallb
-00006f00: 6163 6b5f 7175 616e 7469 7a61 626c 655f  ack_quantizable_
-00006f10: 6f70 735f 7265 6375 7273 6976 656c 7960  ops_recursively`
-00006f20: 0a0a 2020 2020 4172 6773 3a0a 2020 2020  ..    Args:.    
-00006f30: 2020 2020 6d6f 6465 6c20 286f 626a 6563      model (objec
-00006f40: 7429 3a20 696e 7075 7420 6d6f 6465 6c0a  t): input model.
-00006f50: 2020 2020 2020 2020 6f70 5f63 6667 7320          op_cfgs 
-00006f60: 2864 6963 7429 3a20 6469 6374 696f 6e61  (dict): dictiona
-00006f70: 7279 206f 6620 7175 616e 7469 7a61 7469  ry of quantizati
-00006f80: 6f6e 2063 6f6e 6669 6775 7265 2066 6f72  on configure for
-00006f90: 2065 6163 6820 6f70 0a20 2020 2020 2020   each op.       
-00006fa0: 2070 7265 6669 7820 2873 7472 293a 2070   prefix (str): p
-00006fb0: 7265 6669 7820 6f66 206f 7020 6e61 6d65  refix of op name
-00006fc0: 0a20 2020 2020 2020 206f 705f 636f 756e  .        op_coun
-00006fd0: 7420 2869 6e74 2c20 6f70 7469 6f6e 616c  t (int, optional
-00006fe0: 293a 2063 6f75 6e74 2074 6865 2071 7561  ): count the qua
-00006ff0: 6e74 697a 6162 6c65 206f 7020 7175 616e  ntizable op quan
-00007000: 7469 7479 2069 6e20 7468 6973 206d 6f64  tity in this mod
-00007010: 756c 650a 0a20 2020 2052 6574 7572 6e73  ule..    Returns
-00007020: 3a0a 2020 2020 2020 2020 7468 6520 7175  :.        the qu
-00007030: 616e 7469 7a61 626c 6520 6f70 2071 7561  antizable op qua
-00007040: 6e74 6974 7920 696e 2074 6869 7320 6d6f  ntity in this mo
-00007050: 6475 6c65 0a20 2020 2022 2222 0a20 2020  dule.    """.   
-00007060: 2066 6f72 206e 616d 655f 746d 702c 2063   for name_tmp, c
-00007070: 6869 6c64 5f74 6d70 2069 6e20 6d6f 6475  hild_tmp in modu
-00007080: 6c65 2e6e 616d 6564 5f63 6869 6c64 7265  le.named_childre
-00007090: 6e28 293a 0a20 2020 2020 2020 206f 705f  n():.        op_
-000070a0: 6e61 6d65 203d 2070 7265 6669 7820 2b20  name = prefix + 
-000070b0: 272e 2720 2b20 6e61 6d65 5f74 6d70 2069  '.' + name_tmp i
-000070c0: 6620 7072 6566 6978 2021 3d20 2727 2065  f prefix != '' e
-000070d0: 6c73 6520 6e61 6d65 5f74 6d70 0a20 2020  lse name_tmp.   
-000070e0: 2020 2020 2069 6620 6f70 5f6e 616d 6520       if op_name 
-000070f0: 696e 206f 705f 7163 6667 732e 6b65 7973  in op_qcfgs.keys
-00007100: 2829 2061 6e64 205c 0a20 2020 2020 2020  () and \.       
-00007110: 2020 2074 7970 6528 6368 696c 645f 746d     type(child_tm
-00007120: 7029 2021 3d20 746f 7263 682e 7175 616e  p) != torch.quan
-00007130: 7469 7a61 7469 6f6e 2e51 7561 6e74 5374  tization.QuantSt
-00007140: 7562 3a0a 2020 2020 2020 2020 2020 2020  ub:.            
-00007150: 6f70 5f63 6f75 6e74 202b 3d20 310a 2020  op_count += 1.  
-00007160: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00007170: 2020 2020 2020 2020 6f70 5f63 6f75 6e74          op_count
-00007180: 203d 205f 6669 6e64 5f71 7561 6e74 697a   = _find_quantiz
-00007190: 6564 5f6f 705f 6e75 6d28 6368 696c 645f  ed_op_num(child_
-000071a0: 746d 702c 206f 705f 7163 6667 732c 206f  tmp, op_qcfgs, o
-000071b0: 705f 6e61 6d65 2c20 6f70 5f63 6f75 6e74  p_name, op_count
-000071c0: 290a 2020 2020 7265 7475 726e 206f 705f  ).    return op_
-000071d0: 636f 756e 740a 0a0a 6465 6620 5f66 616c  count...def _fal
-000071e0: 6c62 6163 6b5f 7175 616e 7469 7a61 626c  lback_quantizabl
-000071f0: 655f 6f70 735f 7265 6375 7273 6976 656c  e_ops_recursivel
-00007200: 7928 6d6f 6465 6c2c 2070 7265 6669 782c  y(model, prefix,
-00007210: 2066 616c 6c62 6163 6b5f 6f70 732c 206f   fallback_ops, o
-00007220: 705f 7163 6667 7329 3a0a 2020 2020 2222  p_qcfgs):.    ""
-00007230: 2248 616e 646c 6520 616c 6c20 6661 6c6c  "Handle all fall
-00007240: 6261 636b 206f 7073 2866 7033 3220 6f70  back ops(fp32 op
-00007250: 7329 0a0a 2020 2020 4172 6773 3a0a 2020  s)..    Args:.  
-00007260: 2020 2020 2020 6d6f 6465 6c20 286f 626a        model (obj
-00007270: 6563 7429 3a20 696e 7075 7420 6d6f 6465  ect): input mode
-00007280: 6c0a 2020 2020 2020 2020 7072 6566 6978  l.        prefix
-00007290: 2028 7374 7269 6e67 293a 2074 6865 2070   (string): the p
-000072a0: 7265 6669 7820 6f66 206f 7020 6e61 6d65  refix of op name
-000072b0: 0a20 2020 2020 2020 2066 616c 6c62 6163  .        fallbac
-000072c0: 6b5f 6f70 7320 286c 6973 7429 3a20 6c69  k_ops (list): li
-000072d0: 7374 206f 6620 6661 6c6c 6261 636b 206f  st of fallback o
-000072e0: 7073 2866 7033 3220 6f70 7329 0a20 2020  ps(fp32 ops).   
-000072f0: 2020 2020 206f 705f 6366 6773 2028 6469       op_cfgs (di
-00007300: 6374 293a 2064 6963 7469 6f6e 6172 7920  ct): dictionary 
-00007310: 6f66 2071 7561 6e74 697a 6174 696f 6e20  of quantization 
-00007320: 636f 6e66 6967 7572 6520 666f 7220 6561  configure for ea
-00007330: 6368 206f 700a 0a20 2020 2052 6574 7572  ch op..    Retur
-00007340: 6e73 3a0a 2020 2020 2020 2020 4e6f 6e65  ns:.        None
-00007350: 0a20 2020 2022 2222 0a20 2020 2063 6c61  .    """.    cla
-00007360: 7373 2044 6571 7561 6e74 5175 616e 7457  ss DequantQuantW
-00007370: 7261 7070 6572 2874 6f72 6368 2e6e 6e2e  rapper(torch.nn.
-00007380: 4d6f 6475 6c65 293a 0a20 2020 2020 2020  Module):.       
-00007390: 2022 2222 4120 7772 6170 7065 7220 636c   """A wrapper cl
-000073a0: 6173 7320 7468 6174 2077 7261 7073 2074  ass that wraps t
-000073b0: 6865 2069 6e70 7574 206d 6f64 756c 652c  he input module,
-000073c0: 2061 6464 7320 4465 5175 616e 7453 7475   adds DeQuantStu
-000073d0: 6220 616e 640a 2020 2020 2020 2020 2020  b and.          
-000073e0: 2073 7572 726f 756e 6420 7468 6520 6361   surround the ca
-000073f0: 6c6c 2074 6f20 6d6f 6475 6c65 2077 6974  ll to module wit
-00007400: 6820 6361 6c6c 2074 6f20 6465 7175 616e  h call to dequan
-00007410: 742e 0a20 2020 2020 2020 2020 2020 7468  t..           th
-00007420: 6973 2069 7320 7573 6564 2062 7920 6661  is is used by fa
-00007430: 6c6c 6261 636b 206c 6179 6572 2077 6865  llback layer whe
-00007440: 6e20 7468 6520 6461 7461 2074 7970 6520  n the data type 
-00007450: 6f66 2071 7561 6e74 697a 6564 206f 700a  of quantized op.
-00007460: 2020 2020 2020 2020 2020 2069 7320 2069             is  i
-00007470: 6e70 7574 3a69 6e74 382f 6f75 7470 7574  nput:int8/output
-00007480: 3a69 6e74 382e 0a0a 2020 2020 2020 2020  :int8...        
-00007490: 2020 2054 6869 7320 6973 2075 7365 6420     This is used 
-000074a0: 6279 2074 6865 2066 616c 6c62 6163 6b20  by the fallback 
-000074b0: 7574 696c 6974 7920 6675 6e63 7469 6f6e  utility function
-000074c0: 7320 746f 2061 6464 2074 6865 2064 6571  s to add the deq
-000074d0: 7561 6e74 2061 6e64 0a20 2020 2020 2020  uant and.       
-000074e0: 2020 2020 7175 616e 7420 6d6f 6475 6c65      quant module
-000074f0: 732c 2062 6566 6f72 6520 6063 6f6e 7665  s, before `conve
-00007500: 7274 6020 6675 6e63 7469 6f6e 2060 5175  rt` function `Qu
-00007510: 616e 7453 7475 6260 2077 696c 6c20 6a75  antStub` will ju
-00007520: 7374 2062 6520 6f62 7365 7276 6572 2c0a  st be observer,.
-00007530: 2020 2020 2020 2020 2020 2069 7420 6f62             it ob
-00007540: 7365 7276 6573 2074 6865 2069 6e70 7574  serves the input
-00007550: 2074 656e 736f 722c 2061 6674 6572 2060   tensor, after `
-00007560: 636f 6e76 6572 7460 2c20 6051 7561 6e74  convert`, `Quant
-00007570: 5374 7562 600a 2020 2020 2020 2020 2020  Stub`.          
-00007580: 2077 696c 6c20 6265 2073 7761 7070 6564   will be swapped
-00007590: 2074 6f20 606e 6e71 2e51 7561 6e74 697a   to `nnq.Quantiz
-000075a0: 6560 2077 6869 6368 2064 6f65 7320 6163  e` which does ac
-000075b0: 7475 616c 2071 7561 6e74 697a 6174 696f  tual quantizatio
-000075c0: 6e2e 2053 696d 696c 6172 6c79 0a20 2020  n. Similarly.   
-000075d0: 2020 2020 2020 2020 666f 7220 6044 6551          for `DeQ
-000075e0: 7561 6e74 5374 7562 602e 0a20 2020 2020  uantStub`..     
-000075f0: 2020 2022 2222 0a20 2020 2020 2020 2064     """.        d
-00007600: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-00007610: 2c20 6d6f 6475 6c65 2c20 6f62 7365 7276  , module, observ
-00007620: 6572 3d4e 6f6e 6529 3a0a 2020 2020 2020  er=None):.      
-00007630: 2020 2020 2020 7375 7065 7228 4465 7175        super(Dequ
-00007640: 616e 7451 7561 6e74 5772 6170 7065 722c  antQuantWrapper,
-00007650: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
-00007660: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-00007670: 206e 6f74 206d 6f64 756c 652e 7163 6f6e   not module.qcon
-00007680: 6669 6720 616e 6420 6f62 7365 7276 6572  fig and observer
-00007690: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000076a0: 2020 7765 6967 6874 735f 6f62 7365 7276    weights_observ
-000076b0: 6572 203d 206f 6273 6572 7665 7228 276d  er = observer('m
-000076c0: 696e 6d61 7827 2c20 2761 7379 6d27 2c20  inmax', 'asym', 
-000076d0: 2770 6572 5f63 6861 6e6e 656c 272c 2027  'per_channel', '
-000076e0: 696e 7438 2729 0a20 2020 2020 2020 2020  int8').         
-000076f0: 2020 2020 2020 2061 6374 6976 6174 696f         activatio
-00007700: 6e5f 6f62 7365 7276 6572 203d 206f 6273  n_observer = obs
-00007710: 6572 7665 7228 276d 696e 6d61 7827 2c20  erver('minmax', 
-00007720: 2773 796d 272c 2027 7065 725f 7465 6e73  'sym', 'per_tens
-00007730: 6f72 272c 2027 7569 6e74 3827 290a 2020  or', 'uint8').  
-00007740: 2020 2020 2020 2020 2020 2020 2020 6d6f                mo
-00007750: 6475 6c65 2e71 636f 6e66 6967 203d 2074  dule.qconfig = t
-00007760: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
-00007770: 6e2e 5143 6f6e 6669 6728 6163 7469 7661  n.QConfig(activa
-00007780: 7469 6f6e 3d61 6374 6976 6174 696f 6e5f  tion=activation_
-00007790: 6f62 7365 7276 6572 2c0a 2020 2020 2020  observer,.      
-000077a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000077b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000077c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000077d0: 2020 2020 2020 7765 6967 6874 3d77 6569        weight=wei
-000077e0: 6768 7473 5f6f 6273 6572 7665 7229 0a20  ghts_observer). 
-000077f0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00007800: 6164 645f 6d6f 6475 6c65 2827 7175 616e  add_module('quan
-00007810: 7427 2c20 746f 7263 682e 7175 616e 7469  t', torch.quanti
-00007820: 7a61 7469 6f6e 2e51 7561 6e74 5374 7562  zation.QuantStub
-00007830: 286d 6f64 756c 652e 7163 6f6e 6669 6729  (module.qconfig)
-00007840: 290a 2020 2020 2020 2020 2020 2020 7365  ).            se
-00007850: 6c66 2e61 6464 5f6d 6f64 756c 6528 2764  lf.add_module('d
-00007860: 6571 7561 6e74 272c 2074 6f72 6368 2e71  equant', torch.q
-00007870: 7561 6e74 697a 6174 696f 6e2e 4465 5175  uantization.DeQu
-00007880: 616e 7453 7475 6228 2929 0a20 2020 2020  antStub()).     
-00007890: 2020 2020 2020 2073 656c 662e 6164 645f         self.add_
-000078a0: 6d6f 6475 6c65 2827 6d6f 6475 6c65 272c  module('module',
-000078b0: 206d 6f64 756c 6529 0a20 2020 2020 2020   module).       
-000078c0: 2020 2020 2076 6572 7369 6f6e 203d 2067       version = g
-000078d0: 6574 5f74 6f72 6368 5f76 6572 7369 6f6e  et_torch_version
-000078e0: 2829 0a20 2020 2020 2020 2020 2020 2069  ().            i
-000078f0: 6620 7665 7273 696f 6e2e 7265 6c65 6173  f version.releas
-00007900: 6520 3e3d 2056 6572 7369 6f6e 2822 312e  e >= Version("1.
-00007910: 382e 3022 292e 7265 6c65 6173 653a 0a20  8.0").release:. 
-00007920: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00007930: 656c 662e 6465 7175 616e 742e 7163 6f6e  elf.dequant.qcon
-00007940: 6669 6720 3d20 6d6f 6475 6c65 2e71 636f  fig = module.qco
-00007950: 6e66 6967 0a20 2020 2020 2020 2020 2020  nfig.           
-00007960: 206d 6f64 756c 652e 7163 6f6e 6669 6720   module.qconfig 
-00007970: 3d20 4e6f 6e65 0a20 2020 2020 2020 2020  = None.         
-00007980: 2020 2073 656c 662e 7472 6169 6e28 6d6f     self.train(mo
-00007990: 6475 6c65 2e74 7261 696e 696e 6729 0a0a  dule.training)..
-000079a0: 2020 2020 2020 2020 6465 6620 666f 7277          def forw
-000079b0: 6172 6428 7365 6c66 2c20 5829 3a0a 2020  ard(self, X):.  
-000079c0: 2020 2020 2020 2020 2020 5820 3d20 7365            X = se
-000079d0: 6c66 2e64 6571 7561 6e74 2858 290a 2020  lf.dequant(X).  
-000079e0: 2020 2020 2020 2020 2020 5820 3d20 7365            X = se
-000079f0: 6c66 2e6d 6f64 756c 6528 5829 0a20 2020  lf.module(X).   
-00007a00: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00007a10: 7365 6c66 2e71 7561 6e74 2858 290a 0a20  self.quant(X).. 
-00007a20: 2020 2020 2020 2064 6566 2061 6464 2873         def add(s
-00007a30: 656c 662c 2078 2c20 7929 3a0a 2020 2020  elf, x, y):.    
-00007a40: 2020 2020 2020 2020 2320 7479 7065 3a20          # type: 
-00007a50: 2854 656e 736f 722c 2054 656e 736f 7229  (Tensor, Tensor)
-00007a60: 202d 3e20 5465 6e73 6f72 0a20 2020 2020   -> Tensor.     
-00007a70: 2020 2020 2020 2078 203d 2073 656c 662e         x = self.
-00007a80: 6465 7175 616e 7428 7829 0a20 2020 2020  dequant(x).     
-00007a90: 2020 2020 2020 2079 203d 2073 656c 662e         y = self.
-00007aa0: 6465 7175 616e 7428 7929 0a20 2020 2020  dequant(y).     
-00007ab0: 2020 2020 2020 2072 203d 2073 656c 662e         r = self.
-00007ac0: 6d6f 6475 6c65 2e61 6464 2878 2c20 7929  module.add(x, y)
-00007ad0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00007ae0: 7572 6e20 7365 6c66 2e71 7561 6e74 2872  urn self.quant(r
-00007af0: 290a 0a20 2020 2020 2020 2064 6566 2061  )..        def a
-00007b00: 6464 5f73 6361 6c61 7228 7365 6c66 2c20  dd_scalar(self, 
-00007b10: 782c 2079 293a 0a20 2020 2020 2020 2020  x, y):.         
-00007b20: 2020 2023 2074 7970 653a 2028 5465 6e73     # type: (Tens
-00007b30: 6f72 2c20 666c 6f61 7429 202d 3e20 5465  or, float) -> Te
-00007b40: 6e73 6f72 0a20 2020 2020 2020 2020 2020  nsor.           
-00007b50: 2078 203d 2073 656c 662e 6465 7175 616e   x = self.dequan
-00007b60: 7428 7829 0a20 2020 2020 2020 2020 2020  t(x).           
-00007b70: 2072 203d 2073 656c 662e 6d6f 6475 6c65   r = self.module
-00007b80: 2e61 6464 5f73 6361 6c61 7228 782c 2079  .add_scalar(x, y
-00007b90: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
-00007ba0: 7475 726e 2073 656c 662e 7175 616e 7428  turn self.quant(
-00007bb0: 7229 0a0a 2020 2020 2020 2020 6465 6620  r)..        def 
-00007bc0: 6d75 6c28 7365 6c66 2c20 782c 2079 293a  mul(self, x, y):
-00007bd0: 0a20 2020 2020 2020 2020 2020 2023 2074  .            # t
-00007be0: 7970 653a 2028 5465 6e73 6f72 2c20 5465  ype: (Tensor, Te
-00007bf0: 6e73 6f72 2920 2d3e 2054 656e 736f 720a  nsor) -> Tensor.
-00007c00: 2020 2020 2020 2020 2020 2020 7820 3d20              x = 
-00007c10: 7365 6c66 2e64 6571 7561 6e74 2878 290a  self.dequant(x).
-00007c20: 2020 2020 2020 2020 2020 2020 7920 3d20              y = 
-00007c30: 7365 6c66 2e64 6571 7561 6e74 2879 290a  self.dequant(y).
-00007c40: 2020 2020 2020 2020 2020 2020 7220 3d20              r = 
-00007c50: 7365 6c66 2e6d 6f64 756c 652e 6d75 6c28  self.module.mul(
-00007c60: 782c 2079 290a 2020 2020 2020 2020 2020  x, y).          
-00007c70: 2020 7265 7475 726e 2073 656c 662e 7175    return self.qu
-00007c80: 616e 7428 7229 0a0a 2020 2020 2020 2020  ant(r)..        
-00007c90: 6465 6620 6d75 6c5f 7363 616c 6172 2873  def mul_scalar(s
-00007ca0: 656c 662c 2078 2c20 7929 3a0a 2020 2020  elf, x, y):.    
-00007cb0: 2020 2020 2020 2020 2320 7479 7065 3a20          # type: 
-00007cc0: 2854 656e 736f 722c 2066 6c6f 6174 2920  (Tensor, float) 
-00007cd0: 2d3e 2054 656e 736f 720a 2020 2020 2020  -> Tensor.      
-00007ce0: 2020 2020 2020 7820 3d20 7365 6c66 2e64        x = self.d
-00007cf0: 6571 7561 6e74 2878 290a 2020 2020 2020  equant(x).      
-00007d00: 2020 2020 2020 7220 3d20 7365 6c66 2e6d        r = self.m
-00007d10: 6f64 756c 652e 6d75 6c5f 7363 616c 6172  odule.mul_scalar
-00007d20: 2878 2c20 7929 0a20 2020 2020 2020 2020  (x, y).         
-00007d30: 2020 2072 6574 7572 6e20 7365 6c66 2e71     return self.q
-00007d40: 7561 6e74 2872 290a 0a20 2020 2020 2020  uant(r)..       
-00007d50: 2064 6566 2063 6174 2873 656c 662c 2078   def cat(self, x
-00007d60: 2c20 6469 6d3d 3029 3a0a 2020 2020 2020  , dim=0):.      
-00007d70: 2020 2020 2020 2320 7479 7065 3a20 284c        # type: (L
-00007d80: 6973 745b 5465 6e73 6f72 5d2c 2069 6e74  ist[Tensor], int
-00007d90: 2920 2d3e 2054 656e 736f 720a 2020 2020  ) -> Tensor.    
-00007da0: 2020 2020 2020 2020 5820 3d20 5b73 656c          X = [sel
-00007db0: 662e 6465 7175 616e 7428 785f 2920 666f  f.dequant(x_) fo
-00007dc0: 7220 785f 2069 6e20 785d 0a20 2020 2020  r x_ in x].     
-00007dd0: 2020 2020 2020 2072 203d 2073 656c 662e         r = self.
-00007de0: 6d6f 6475 6c65 2e63 6174 2858 2c20 6469  module.cat(X, di
-00007df0: 6d29 0a20 2020 2020 2020 2020 2020 2072  m).            r
-00007e00: 6574 7572 6e20 7365 6c66 2e71 7561 6e74  eturn self.quant
-00007e10: 2872 290a 0a20 2020 2020 2020 2064 6566  (r)..        def
-00007e20: 2061 6464 5f72 656c 7528 7365 6c66 2c20   add_relu(self, 
-00007e30: 782c 2079 293a 0a20 2020 2020 2020 2020  x, y):.         
-00007e40: 2020 2023 2074 7970 653a 2028 5465 6e73     # type: (Tens
-00007e50: 6f72 2c20 5465 6e73 6f72 2920 2d3e 2054  or, Tensor) -> T
-00007e60: 656e 736f 720a 2020 2020 2020 2020 2020  ensor.          
-00007e70: 2020 7820 3d20 7365 6c66 2e64 6571 7561    x = self.dequa
-00007e80: 6e74 2878 290a 2020 2020 2020 2020 2020  nt(x).          
-00007e90: 2020 7920 3d20 7365 6c66 2e64 6571 7561    y = self.dequa
-00007ea0: 6e74 2879 290a 2020 2020 2020 2020 2020  nt(y).          
-00007eb0: 2020 7220 3d20 7365 6c66 2e6d 6f64 756c    r = self.modul
-00007ec0: 652e 6164 645f 7265 6c75 2878 2c20 7929  e.add_relu(x, y)
-00007ed0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00007ee0: 7572 6e20 7365 6c66 2e71 7561 6e74 2872  urn self.quant(r
-00007ef0: 290a 0a20 2020 2066 6f72 206e 616d 652c  )..    for name,
-00007f00: 2063 6869 6c64 2069 6e20 6d6f 6465 6c2e   child in model.
-00007f10: 6e61 6d65 645f 6368 696c 6472 656e 2829  named_children()
-00007f20: 3a0a 2020 2020 2020 2020 6f70 5f6e 616d  :.        op_nam
-00007f30: 6520 3d20 7072 6566 6978 202b 2027 2e27  e = prefix + '.'
-00007f40: 202b 206e 616d 6520 6966 2070 7265 6669   + name if prefi
-00007f50: 7820 213d 2027 2720 656c 7365 206e 616d  x != '' else nam
-00007f60: 650a 2020 2020 2020 2020 6966 206f 705f  e.        if op_
-00007f70: 6e61 6d65 2069 6e20 6661 6c6c 6261 636b  name in fallback
-00007f80: 5f6f 7073 3a0a 2020 2020 2020 2020 2020  _ops:.          
-00007f90: 2020 6368 696c 642e 7163 6f6e 6669 6720    child.qconfig 
-00007fa0: 3d20 4e6f 6e65 0a20 2020 2020 2020 2020  = None.         
-00007fb0: 2020 2071 7561 6e74 697a 655f 6f70 5f6e     quantize_op_n
-00007fc0: 756d 203d 205f 6669 6e64 5f71 7561 6e74  um = _find_quant
-00007fd0: 697a 6564 5f6f 705f 6e75 6d28 6d6f 6465  ized_op_num(mode
-00007fe0: 6c2c 206f 705f 7163 6667 732c 2070 7265  l, op_qcfgs, pre
-00007ff0: 6669 783d 7072 6566 6978 290a 2020 2020  fix=prefix).    
-00008000: 2020 2020 2020 2020 6966 2071 7561 6e74          if quant
-00008010: 697a 655f 6f70 5f6e 756d 203d 3d20 313a  ize_op_num == 1:
-00008020: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008030: 2066 6f75 6e64 203d 2046 616c 7365 0a20   found = False. 
-00008040: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00008050: 6f72 206e 616d 655f 746d 702c 2063 6869  or name_tmp, chi
-00008060: 6c64 5f74 6d70 2069 6e20 6d6f 6465 6c2e  ld_tmp in model.
-00008070: 6e61 6d65 645f 6368 696c 6472 656e 2829  named_children()
-00008080: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00008090: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
-000080a0: 6e63 6528 6368 696c 645f 746d 702c 2074  nce(child_tmp, t
-000080b0: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
-000080c0: 6e2e 5175 616e 7453 7475 6229 206f 7220  n.QuantStub) or 
-000080d0: 6973 696e 7374 616e 6365 280a 2020 2020  isinstance(.    
-000080e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000080f0: 2020 2020 2020 2020 6368 696c 645f 746d          child_tm
-00008100: 702c 2074 6f72 6368 2e71 7561 6e74 697a  p, torch.quantiz
-00008110: 6174 696f 6e2e 4465 5175 616e 7453 7475  ation.DeQuantStu
-00008120: 6229 3a0a 2020 2020 2020 2020 2020 2020  b):.            
-00008130: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
-00008140: 6c2e 5f6d 6f64 756c 6573 5b6e 616d 655f  l._modules[name_
-00008150: 746d 705d 203d 2074 6f72 6368 2e6e 6e2e  tmp] = torch.nn.
-00008160: 4964 656e 7469 7479 2829 0a20 2020 2020  Identity().     
-00008170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008180: 2020 2066 6f75 6e64 203d 2054 7275 650a     found = True.
-00008190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000081a0: 6966 206e 6f74 2066 6f75 6e64 3a0a 2020  if not found:.  
-000081b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000081c0: 2020 6d6f 6465 6c2e 5f6d 6f64 756c 6573    model._modules
-000081d0: 5b6e 616d 655d 203d 2044 6571 7561 6e74  [name] = Dequant
-000081e0: 5175 616e 7457 7261 7070 6572 2863 6869  QuantWrapper(chi
-000081f0: 6c64 2c20 6f62 7365 7276 6572 3d5f 6f62  ld, observer=_ob
-00008200: 7365 7276 6572 290a 2020 2020 2020 2020  server).        
-00008210: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00008220: 2020 2020 2020 2020 2020 6d6f 6465 6c2e            model.
-00008230: 5f6d 6f64 756c 6573 5b6e 616d 655d 203d  _modules[name] =
-00008240: 2044 6571 7561 6e74 5175 616e 7457 7261   DequantQuantWra
-00008250: 7070 6572 2863 6869 6c64 2c20 6f62 7365  pper(child, obse
-00008260: 7276 6572 3d5f 6f62 7365 7276 6572 290a  rver=_observer).
-00008270: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00008280: 2020 2020 2020 2020 2020 5f66 616c 6c62            _fallb
-00008290: 6163 6b5f 7175 616e 7469 7a61 626c 655f  ack_quantizable_
-000082a0: 6f70 735f 7265 6375 7273 6976 656c 7928  ops_recursively(
-000082b0: 6368 696c 642c 206f 705f 6e61 6d65 2c20  child, op_name, 
-000082c0: 6661 6c6c 6261 636b 5f6f 7073 2c20 6f70  fallback_ops, op
-000082d0: 5f71 6366 6773 290a 0a0a 4061 6461 7074  _qcfgs)...@adapt
-000082e0: 6f72 5f72 6567 6973 7472 790a 636c 6173  or_registry.clas
-000082f0: 7320 5465 6d70 6c61 7465 4164 6170 746f  s TemplateAdapto
-00008300: 7228 4164 6170 746f 7229 3a0a 2020 2020  r(Adaptor):.    
-00008310: 2222 2254 616d 706c 6520 6164 6170 746f  """Tample adapto
-00008320: 7220 6f66 2050 7954 6f72 6368 2066 7261  r of PyTorch fra
-00008330: 6d65 776f 726b 2e0a 0a20 2020 2041 7267  mework...    Arg
-00008340: 733a 0a20 2020 2020 2020 2066 7261 6d65  s:.        frame
-00008350: 776f 726b 5f73 7065 6369 6669 635f 696e  work_specific_in
-00008360: 666f 2028 6469 6374 293a 2064 6963 7469  fo (dict): dicti
-00008370: 6f6e 6172 7920 6f66 2074 756e 696e 6720  onary of tuning 
-00008380: 636f 6e66 6967 7572 6520 6672 6f6d 2079  configure from y
-00008390: 616d 6c20 6669 6c65 2e0a 2020 2020 2222  aml file..    ""
-000083a0: 220a 2020 2020 6465 6620 5f5f 696e 6974  ".    def __init
-000083b0: 5f5f 2873 656c 662c 2066 7261 6d65 776f  __(self, framewo
-000083c0: 726b 5f73 7065 6369 6669 635f 696e 666f  rk_specific_info
-000083d0: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
-000083e0: 2854 656d 706c 6174 6541 6461 7074 6f72  (TemplateAdaptor
-000083f0: 2c20 7365 6c66 292e 5f5f 696e 6974 5f5f  , self).__init__
-00008400: 2866 7261 6d65 776f 726b 5f73 7065 6369  (framework_speci
-00008410: 6669 635f 696e 666f 290a 2020 2020 2020  fic_info).      
-00008420: 2020 696d 706f 7274 2074 6f72 6368 2e71    import torch.q
-00008430: 7561 6e74 697a 6174 696f 6e20 6173 2074  uantization as t
-00008440: 710a 2020 2020 2020 2020 7365 6c66 2e76  q.        self.v
-00008450: 6572 7369 6f6e 203d 2067 6574 5f74 6f72  ersion = get_tor
-00008460: 6368 5f76 6572 7369 6f6e 2829 0a20 2020  ch_version().   
-00008470: 2020 2020 2023 2073 6574 2074 6f72 6368       # set torch
-00008480: 2072 616e 646f 6d20 7365 6564 0a20 2020   random seed.   
-00008490: 2020 2020 2072 616e 646f 6d5f 7365 6564       random_seed
-000084a0: 203d 2066 7261 6d65 776f 726b 5f73 7065   = framework_spe
-000084b0: 6369 6669 635f 696e 666f 5b27 7261 6e64  cific_info['rand
-000084c0: 6f6d 5f73 6565 6427 5d0a 2020 2020 2020  om_seed'].      
-000084d0: 2020 746f 7263 682e 6d61 6e75 616c 5f73    torch.manual_s
-000084e0: 6565 6428 7261 6e64 6f6d 5f73 6565 6429  eed(random_seed)
-000084f0: 0a0a 2020 2020 2020 2020 7365 6c66 2e62  ..        self.b
-00008500: 6631 365f 6f70 7320 3d20 5b5d 0a20 2020  f16_ops = [].   
-00008510: 2020 2020 2073 656c 662e 7573 655f 6266       self.use_bf
-00008520: 3136 203d 2066 7261 6d65 776f 726b 5f73  16 = framework_s
-00008530: 7065 6369 6669 635f 696e 666f 2e67 6574  pecific_info.get
-00008540: 2827 7573 655f 6266 3136 272c 2054 7275  ('use_bf16', Tru
-00008550: 6529 0a20 2020 2020 2020 2073 656c 662e  e).        self.
-00008560: 6465 7669 6365 203d 2066 7261 6d65 776f  device = framewo
-00008570: 726b 5f73 7065 6369 6669 635f 696e 666f  rk_specific_info
-00008580: 5b27 6465 7669 6365 275d 0a20 2020 2020  ['device'].     
-00008590: 2020 2073 656c 662e 715f 6461 7461 6c6f     self.q_datalo
-000085a0: 6164 6572 203d 2066 7261 6d65 776f 726b  ader = framework
-000085b0: 5f73 7065 6369 6669 635f 696e 666f 5b27  _specific_info['
-000085c0: 715f 6461 7461 6c6f 6164 6572 275d 0a20  q_dataloader']. 
-000085d0: 2020 2020 2020 2073 656c 662e 715f 6675         self.q_fu
-000085e0: 6e63 203d 2066 7261 6d65 776f 726b 5f73  nc = framework_s
-000085f0: 7065 6369 6669 635f 696e 666f 2e67 6574  pecific_info.get
-00008600: 2827 715f 6675 6e63 272c 204e 6f6e 6529  ('q_func', None)
-00008610: 0a20 2020 2020 2020 2073 656c 662e 6265  .        self.be
-00008620: 6e63 686d 6172 6b20 3d20 2847 4c4f 4241  nchmark = (GLOBA
-00008630: 4c5f 5354 4154 452e 5354 4154 4520 3d3d  L_STATE.STATE ==
-00008640: 204d 4f44 452e 4245 4e43 484d 4152 4b29   MODE.BENCHMARK)
-00008650: 0a20 2020 2020 2020 2073 656c 662e 776f  .        self.wo
-00008660: 726b 7370 6163 655f 7061 7468 203d 2066  rkspace_path = f
-00008670: 7261 6d65 776f 726b 5f73 7065 6369 6669  ramework_specifi
-00008680: 635f 696e 666f 5b27 776f 726b 7370 6163  c_info['workspac
-00008690: 655f 7061 7468 275d 0a20 2020 2020 2020  e_path'].       
-000086a0: 2073 656c 662e 6973 5f62 6173 656c 696e   self.is_baselin
-000086b0: 6520 3d20 4661 6c73 6520 6966 2047 4c4f  e = False if GLO
-000086c0: 4241 4c5f 5354 4154 452e 5354 4154 4520  BAL_STATE.STATE 
-000086d0: 3d3d 204d 4f44 452e 4245 4e43 484d 4152  == MODE.BENCHMAR
-000086e0: 4b20 656c 7365 2054 7275 650a 2020 2020  K else True.    
-000086f0: 2020 2020 7365 6c66 2e71 7565 7279 5f68      self.query_h
-00008700: 616e 646c 6572 203d 204e 6f6e 650a 2020  andler = None.  
-00008710: 2020 2020 2020 7365 6c66 2e61 7070 726f        self.appro
-00008720: 6163 6820 3d20 2727 0a20 2020 2020 2020  ach = ''.       
-00008730: 2073 656c 662e 7072 655f 6f70 7469 6d69   self.pre_optimi
-00008740: 7a65 645f 6d6f 6465 6c20 3d20 4e6f 6e65  zed_model = None
-00008750: 0a20 2020 2020 2020 2073 656c 662e 7375  .        self.su
-00008760: 625f 6d6f 6475 6c65 5f6c 6973 7420 3d20  b_module_list = 
-00008770: 4e6f 6e65 0a20 2020 2020 2020 2073 656c  None.        sel
-00008780: 662e 6465 6661 756c 745f 7163 6f6e 6669  f.default_qconfi
-00008790: 6720 3d20 6672 616d 6577 6f72 6b5f 7370  g = framework_sp
-000087a0: 6563 6966 6963 5f69 6e66 6f2e 6765 7428  ecific_info.get(
-000087b0: 2764 6566 6175 6c74 5f71 636f 6e66 6967  'default_qconfig
-000087c0: 272c 204e 6f6e 6529 0a20 2020 2020 2020  ', None).       
-000087d0: 2073 656c 662e 7065 7266 6f72 6d61 6e63   self.performanc
-000087e0: 655f 6f6e 6c79 203d 2066 7261 6d65 776f  e_only = framewo
-000087f0: 726b 5f73 7065 6369 6669 635f 696e 666f  rk_specific_info
-00008800: 2e67 6574 2822 7065 7266 6f72 6d61 6e63  .get("performanc
-00008810: 655f 6f6e 6c79 222c 2046 616c 7365 290a  e_only", False).
-00008820: 2020 2020 2020 2020 7365 6c66 2e65 7861          self.exa
-00008830: 6d70 6c65 5f69 6e70 7574 7320 3d20 6672  mple_inputs = fr
-00008840: 616d 6577 6f72 6b5f 7370 6563 6966 6963  amework_specific
-00008850: 5f69 6e66 6f2e 6765 7428 2265 7861 6d70  _info.get("examp
-00008860: 6c65 5f69 6e70 7574 7322 2c20 4e6f 6e65  le_inputs", None
-00008870: 290a 0a20 2020 2020 2020 2069 6620 2761  )..        if 'a
-00008880: 7070 726f 6163 6827 2069 6e20 6672 616d  pproach' in fram
-00008890: 6577 6f72 6b5f 7370 6563 6966 6963 5f69  ework_specific_i
-000088a0: 6e66 6f3a 2020 2320 7072 6167 6d61 3a20  nfo:  # pragma: 
-000088b0: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
-000088c0: 2020 2020 2073 656c 662e 6170 7072 6f61       self.approa
-000088d0: 6368 203d 2066 7261 6d65 776f 726b 5f73  ch = framework_s
-000088e0: 7065 6369 6669 635f 696e 666f 5b27 6170  pecific_info['ap
-000088f0: 7072 6f61 6368 275d 0a20 2020 2020 2020  proach'].       
-00008900: 2020 2020 2069 6620 6672 616d 6577 6f72       if framewor
-00008910: 6b5f 7370 6563 6966 6963 5f69 6e66 6f5b  k_specific_info[
-00008920: 2761 7070 726f 6163 6827 5d20 696e 205b  'approach'] in [
-00008930: 2270 6f73 745f 7472 6169 6e69 6e67 5f73  "post_training_s
-00008940: 7461 7469 635f 7175 616e 7422 2c0a 2020  tatic_quant",.  
-00008950: 2020 2020 2020 2020 2020 2020 2020 2270                "p
-00008960: 6f73 745f 7472 6169 6e69 6e67 5f61 7574  ost_training_aut
-00008970: 6f5f 7175 616e 7422 5d3a 0a20 2020 2020  o_quant"]:.     
-00008980: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-00008990: 6c66 2e76 6572 7369 6f6e 2e72 656c 6561  lf.version.relea
-000089a0: 7365 203c 2056 6572 7369 6f6e 2822 312e  se < Version("1.
-000089b0: 372e 3022 292e 7265 6c65 6173 653a 0a20  7.0").release:. 
-000089c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000089d0: 2020 2073 656c 662e 715f 6d61 7070 696e     self.q_mappin
-000089e0: 6720 3d20 7471 2e64 6566 6175 6c74 5f6d  g = tq.default_m
-000089f0: 6170 7069 6e67 732e 4445 4641 554c 545f  appings.DEFAULT_
-00008a00: 4d4f 4455 4c45 5f4d 4150 5049 4e47 0a20  MODULE_MAPPING. 
-00008a10: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00008a20: 6c69 6620 7365 6c66 2e76 6572 7369 6f6e  lif self.version
-00008a30: 2e72 656c 6561 7365 203c 2056 6572 7369  .release < Versi
-00008a40: 6f6e 2822 312e 382e 3022 292e 7265 6c65  on("1.8.0").rele
-00008a50: 6173 653a 0a20 2020 2020 2020 2020 2020  ase:.           
-00008a60: 2020 2020 2020 2020 2073 656c 662e 715f           self.q_
-00008a70: 6d61 7070 696e 6720 3d20 5c0a 2020 2020  mapping = \.    
-00008a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008a90: 2020 2020 7471 2e71 7561 6e74 697a 6174      tq.quantizat
-00008aa0: 696f 6e5f 6d61 7070 696e 6773 2e67 6574  ion_mappings.get
-00008ab0: 5f73 7461 7469 635f 7175 616e 745f 6d6f  _static_quant_mo
-00008ac0: 6475 6c65 5f6d 6170 7069 6e67 7328 290a  dule_mappings().
-00008ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008ae0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00008af0: 2020 2020 2020 2020 2020 7365 6c66 2e71            self.q
-00008b00: 5f6d 6170 7069 6e67 203d 205c 0a20 2020  _mapping = \.   
-00008b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008b20: 2020 2020 2074 712e 7175 616e 7469 7a61       tq.quantiza
-00008b30: 7469 6f6e 5f6d 6170 7069 6e67 732e 6765  tion_mappings.ge
-00008b40: 745f 6465 6661 756c 745f 7374 6174 6963  t_default_static
-00008b50: 5f71 7561 6e74 5f6d 6f64 756c 655f 6d61  _quant_module_ma
-00008b60: 7070 696e 6773 2829 0a20 2020 2020 2020  ppings().       
-00008b70: 2020 2020 2065 6c69 6620 6672 616d 6577       elif framew
-00008b80: 6f72 6b5f 7370 6563 6966 6963 5f69 6e66  ork_specific_inf
-00008b90: 6f5b 2761 7070 726f 6163 6827 5d20 3d3d  o['approach'] ==
-00008ba0: 2022 7175 616e 745f 6177 6172 655f 7472   "quant_aware_tr
-00008bb0: 6169 6e69 6e67 223a 0a20 2020 2020 2020  aining":.       
-00008bc0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00008bd0: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
-00008be0: 203c 2056 6572 7369 6f6e 2822 312e 372e   < Version("1.7.
-00008bf0: 3022 292e 7265 6c65 6173 653a 0a20 2020  0").release:.   
-00008c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c10: 2073 656c 662e 715f 6d61 7070 696e 6720   self.q_mapping 
-00008c20: 3d20 7471 2e64 6566 6175 6c74 5f6d 6170  = tq.default_map
-00008c30: 7069 6e67 732e 4445 4641 554c 545f 5141  pings.DEFAULT_QA
-00008c40: 545f 4d4f 4455 4c45 5f4d 4150 5049 4e47  T_MODULE_MAPPING
-00008c50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008c60: 2065 6c69 6620 7365 6c66 2e76 6572 7369   elif self.versi
-00008c70: 6f6e 2e72 656c 6561 7365 203c 2056 6572  on.release < Ver
-00008c80: 7369 6f6e 2822 312e 382e 3022 292e 7265  sion("1.8.0").re
-00008c90: 6c65 6173 653a 0a20 2020 2020 2020 2020  lease:.         
-00008ca0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00008cb0: 715f 6d61 7070 696e 6720 3d20 5c0a 2020  q_mapping = \.  
-00008cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008cd0: 2020 2020 2020 7471 2e71 7561 6e74 697a        tq.quantiz
-00008ce0: 6174 696f 6e5f 6d61 7070 696e 6773 2e67  ation_mappings.g
-00008cf0: 6574 5f71 6174 5f6d 6f64 756c 655f 6d61  et_qat_module_ma
-00008d00: 7070 696e 6773 2829 0a20 2020 2020 2020  ppings().       
-00008d10: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00008d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008d30: 2020 2073 656c 662e 715f 6d61 7070 696e     self.q_mappin
-00008d40: 6720 3d20 5c0a 2020 2020 2020 2020 2020  g = \.          
-00008d50: 2020 2020 2020 2020 2020 2020 2020 7471                tq
-00008d60: 2e71 7561 6e74 697a 6174 696f 6e5f 6d61  .quantization_ma
-00008d70: 7070 696e 6773 2e67 6574 5f64 6566 6175  ppings.get_defau
-00008d80: 6c74 5f71 6174 5f6d 6f64 756c 655f 6d61  lt_qat_module_ma
-00008d90: 7070 696e 6773 2829 0a20 2020 2020 2020  ppings().       
-00008da0: 2020 2020 2065 6c69 6620 6672 616d 6577       elif framew
-00008db0: 6f72 6b5f 7370 6563 6966 6963 5f69 6e66  ork_specific_inf
-00008dc0: 6f5b 2761 7070 726f 6163 6827 5d20 3d3d  o['approach'] ==
-00008dd0: 2022 706f 7374 5f74 7261 696e 696e 675f   "post_training_
-00008de0: 6479 6e61 6d69 635f 7175 616e 7422 3a0a  dynamic_quant":.
-00008df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e00: 6966 2073 656c 662e 7665 7273 696f 6e2e  if self.version.
-00008e10: 7265 6c65 6173 6520 3c20 5665 7273 696f  release < Versio
-00008e20: 6e28 2231 2e37 2e30 2229 2e72 656c 6561  n("1.7.0").relea
-00008e30: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00008e40: 2020 2020 2020 2020 7365 6c66 2e71 5f6d          self.q_m
-00008e50: 6170 7069 6e67 203d 205c 0a20 2020 2020  apping = \.     
-00008e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e70: 2020 2074 712e 6465 6661 756c 745f 6d61     tq.default_ma
-00008e80: 7070 696e 6773 2e44 4546 4155 4c54 5f44  ppings.DEFAULT_D
-00008e90: 594e 414d 4943 5f4d 4f44 554c 455f 4d41  YNAMIC_MODULE_MA
-00008ea0: 5050 494e 470a 2020 2020 2020 2020 2020  PPING.          
-00008eb0: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
-00008ec0: 7665 7273 696f 6e2e 7265 6c65 6173 6520  version.release 
-00008ed0: 3c20 5665 7273 696f 6e28 2231 2e38 2e30  < Version("1.8.0
-00008ee0: 2229 2e72 656c 6561 7365 3a0a 2020 2020  ").release:.    
-00008ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008f00: 7365 6c66 2e71 5f6d 6170 7069 6e67 203d  self.q_mapping =
-00008f10: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00008f20: 2020 2020 2020 2020 2020 2074 712e 7175             tq.qu
-00008f30: 616e 7469 7a61 7469 6f6e 5f6d 6170 7069  antization_mappi
-00008f40: 6e67 732e 6765 745f 6479 6e61 6d69 635f  ngs.get_dynamic_
-00008f50: 7175 616e 745f 6d6f 6475 6c65 5f6d 6170  quant_module_map
-00008f60: 7069 6e67 7328 290a 2020 2020 2020 2020  pings().        
-00008f70: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00008f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008f90: 2020 7365 6c66 2e71 5f6d 6170 7069 6e67    self.q_mapping
-00008fa0: 203d 205c 0a20 2020 2020 2020 2020 2020   = \.           
-00008fb0: 2020 2020 2020 2020 2020 2020 2074 712e               tq.
-00008fc0: 7175 616e 7469 7a61 7469 6f6e 5f6d 6170  quantization_map
-00008fd0: 7069 6e67 732e 6765 745f 6465 6661 756c  pings.get_defaul
-00008fe0: 745f 6479 6e61 6d69 635f 7175 616e 745f  t_dynamic_quant_
-00008ff0: 6d6f 6475 6c65 5f6d 6170 7069 6e67 7328  module_mappings(
-00009000: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-00009010: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00009020: 2020 2020 6173 7365 7274 2046 616c 7365      assert False
-00009030: 2c20 2255 6e73 7570 706f 7274 2061 7070  , "Unsupport app
-00009040: 726f 6163 683a 207b 7d22 2e66 6f72 6d61  roach: {}".forma
-00009050: 7428 7365 6c66 2e61 7070 726f 6163 6829  t(self.approach)
-00009060: 0a0a 2020 2020 2020 2020 7365 6c66 2e66  ..        self.f
-00009070: 7033 325f 7265 7375 6c74 7320 3d20 5b5d  p32_results = []
-00009080: 0a20 2020 2020 2020 2073 656c 662e 6670  .        self.fp
-00009090: 3332 5f70 7265 6473 5f61 735f 6c61 6265  32_preds_as_labe
-000090a0: 6c20 3d20 4661 6c73 650a 0a20 2020 2064  l = False..    d
-000090b0: 6566 2063 616c 6962 5f66 756e 6328 7365  ef calib_func(se
-000090c0: 6c66 2c20 6d6f 6465 6c2c 2064 6174 616c  lf, model, datal
-000090d0: 6f61 6465 722c 2074 6d70 5f69 7465 7261  oader, tmp_itera
-000090e0: 7469 6f6e 732c 2063 6f6e 663d 4e6f 6e65  tions, conf=None
-000090f0: 293a 0a20 2020 2020 2020 2074 7279 3a0a  ):.        try:.
-00009100: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00009110: 6964 782c 2028 696e 7075 742c 206c 6162  idx, (input, lab
-00009120: 656c 2920 696e 2065 6e75 6d65 7261 7465  el) in enumerate
-00009130: 2864 6174 616c 6f61 6465 7229 3a0a 2020  (dataloader):.  
-00009140: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-00009150: 7470 7574 203d 2070 7974 6f72 6368 5f66  tput = pytorch_f
-00009160: 6f72 7761 7264 5f77 7261 7070 6572 286d  orward_wrapper(m
-00009170: 6f64 656c 2c0a 2020 2020 2020 2020 2020  odel,.          
-00009180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000091a0: 2020 2020 2020 2069 6e70 7574 2c0a 2020         input,.  
-000091b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000091c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000091d0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-000091e0: 6576 6963 653d 7365 6c66 2e64 6576 6963  evice=self.devic
-000091f0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-00009200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009220: 2020 2020 636f 6e66 3d63 6f6e 662c 0a20      conf=conf,. 
+000066a0: 2020 2020 2020 2020 2020 7175 616e 745f            quant_
+000066b0: 6d69 6e3d 716d 696e 2c0a 2020 2020 2020  min=qmin,.      
+000066c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000066d0: 2020 2020 2020 2020 2020 7175 616e 745f            quant_
+000066e0: 6d61 783d 716d 6178 2c0a 2020 2020 2020  max=qmax,.      
+000066f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006700: 2020 2020 2020 2020 2020 6474 7970 653d            dtype=
+00006710: 6474 7970 652c 0a20 2020 2020 2020 2020  dtype,.         
+00006720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006730: 2020 2020 2020 2071 7363 6865 6d65 3d71         qscheme=q
+00006740: 7363 6865 6d65 2c0a 2020 2020 2020 2020  scheme,.        
+00006750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006760: 2020 2020 2020 2020 7265 6475 6365 5f72          reduce_r
+00006770: 616e 6765 3d28 5245 4455 4345 5f52 414e  ange=(REDUCE_RAN
+00006780: 4745 2061 6e64 2073 6368 656d 6520 3d3d  GE and scheme ==
+00006790: 2027 6173 796d 2729 290a 0a0a 6465 6620   'asym'))...def 
+000067a0: 5f70 726f 7061 6761 7465 5f71 636f 6e66  _propagate_qconf
+000067b0: 6967 286d 6f64 656c 2c0a 2020 2020 2020  ig(model,.      
+000067c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000067d0: 206f 705f 7163 6667 732c 0a20 2020 2020   op_qcfgs,.     
+000067e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000067f0: 2020 6973 5f71 6174 5f63 6f6e 7665 7274    is_qat_convert
+00006800: 3d46 616c 7365 2c0a 2020 2020 2020 2020  =False,.        
+00006810: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+00006820: 7070 726f 6163 683d 2770 6f73 745f 7472  pproach='post_tr
+00006830: 6169 6e69 6e67 5f73 7461 7469 635f 7175  aining_static_qu
+00006840: 616e 7427 293a 0a20 2020 2022 2222 5072  ant'):.    """Pr
+00006850: 6f70 6167 6174 6520 7163 6f6e 6669 6720  opagate qconfig 
+00006860: 7468 726f 7567 6820 7468 6520 6d6f 6475  through the modu
+00006870: 6c65 2068 6965 7261 7263 6879 2061 6e64  le hierarchy and
+00006880: 2061 7373 6967 6e20 6071 636f 6e66 6967   assign `qconfig
+00006890: 600a 2020 2020 2020 2061 7474 7269 6275  `.       attribu
+000068a0: 7465 206f 6e20 6561 6368 206c 6561 6620  te on each leaf 
+000068b0: 6d6f 6475 6c65 0a0a 2020 2020 4172 6773  module..    Args
+000068c0: 3a0a 2020 2020 2020 2020 6d6f 6465 6c20  :.        model 
+000068d0: 286f 626a 6563 7429 3a20 696e 7075 7420  (object): input 
+000068e0: 6d6f 6465 6c0a 2020 2020 2020 2020 6f70  model.        op
+000068f0: 5f71 6366 6773 2028 6469 6374 293a 2064  _qcfgs (dict): d
+00006900: 6963 7469 6f6e 6172 7920 7468 6174 206d  ictionary that m
+00006910: 6170 7320 6672 6f6d 206e 616d 6520 6f72  aps from name or
+00006920: 2074 7970 6520 6f66 2073 7562 6d6f 6475   type of submodu
+00006930: 6c65 2074 6f0a 2020 2020 2020 2020 2020  le to.          
+00006940: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+00006950: 7561 6e74 697a 6174 696f 6e20 636f 6e66  uantization conf
+00006960: 6967 7572 6174 696f 6e2c 2071 636f 6e66  iguration, qconf
+00006970: 6967 2061 7070 6c69 6573 2074 6f20 616c  ig applies to al
+00006980: 6c20 7375 626d 6f64 756c 6573 206f 6620  l submodules of 
+00006990: 610a 2020 2020 2020 2020 2020 2020 2020  a.              
+000069a0: 2020 2020 2020 2020 2020 2067 6976 656e             given
+000069b0: 206d 6f64 756c 6520 756e 6c65 7373 2071   module unless q
+000069c0: 636f 6e66 6967 2066 6f72 2074 6865 2073  config for the s
+000069d0: 7562 6d6f 6475 6c65 7320 6172 6520 7370  ubmodules are sp
+000069e0: 6563 6966 6965 6420 2877 6865 6e0a 2020  ecified (when.  
+000069f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006a00: 2020 2020 2020 2074 6865 2073 7562 6d6f         the submo
+00006a10: 6475 6c65 2061 6c72 6561 6479 2068 6173  dule already has
+00006a20: 2071 636f 6e66 6967 2061 7474 7269 6275   qconfig attribu
+00006a30: 7465 290a 2020 2020 2020 2020 6973 5f71  te).        is_q
+00006a40: 6174 5f63 6f6e 7665 7274 2028 626f 6f6c  at_convert (bool
+00006a50: 293a 2066 6c61 6720 7468 6174 2073 7065  ): flag that spe
+00006a60: 6369 6669 6564 2074 6869 7320 6675 6e63  cified this func
+00006a70: 7469 6f6e 2069 7320 7573 6564 2074 6f20  tion is used to 
+00006a80: 5141 5420 7072 6570 6172 650a 2020 2020  QAT prepare.    
+00006a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006aa0: 2020 2020 2020 2020 2020 2066 6f72 2070             for p
+00006ab0: 7974 6f72 6368 2031 2e37 206f 7220 6162  ytorch 1.7 or ab
+00006ac0: 6f76 652e 0a20 2020 2020 2020 2061 7070  ove..        app
+00006ad0: 726f 6163 6820 2873 7472 293a 2071 7561  roach (str): qua
+00006ae0: 6e74 697a 6174 696f 6e20 6170 7072 6f61  ntization approa
+00006af0: 6368 0a20 2020 2052 6574 7572 6e3a 0a20  ch.    Return:. 
+00006b00: 2020 2020 2020 204e 6f6e 652c 206d 6f64         None, mod
+00006b10: 756c 6520 6973 206d 6f64 6966 6965 6420  ule is modified 
+00006b20: 696e 706c 6163 6520 7769 7468 2071 636f  inplace with qco
+00006b30: 6e66 6967 2061 7474 6163 6865 640a 2020  nfig attached.  
+00006b40: 2020 2222 220a 2020 2020 6661 6c6c 6261    """.    fallba
+00006b50: 636b 5f6f 7073 203d 205b 5d0a 2020 2020  ck_ops = [].    
+00006b60: 5f70 726f 7061 6761 7465 5f71 636f 6e66  _propagate_qconf
+00006b70: 6967 5f72 6563 7572 7369 7665 6c79 286d  ig_recursively(m
+00006b80: 6f64 656c 2c20 2727 2c20 6f70 5f71 6366  odel, '', op_qcf
+00006b90: 6773 290a 0a20 2020 2069 6620 6170 7072  gs)..    if appr
+00006ba0: 6f61 6368 2021 3d20 2770 6f73 745f 7472  oach != 'post_tr
+00006bb0: 6169 6e69 6e67 5f64 796e 616d 6963 5f71  aining_dynamic_q
+00006bc0: 7561 6e74 273a 0a20 2020 2020 2020 2066  uant':.        f
+00006bd0: 6f72 206b 2c20 7620 696e 206f 705f 7163  or k, v in op_qc
+00006be0: 6667 732e 6974 656d 7328 293a 0a20 2020  fgs.items():.   
+00006bf0: 2020 2020 2020 2020 2069 6620 7620 6973           if v is
+00006c00: 204e 6f6e 6520 616e 6420 6e6f 7420 6973   None and not is
+00006c10: 5f71 6174 5f63 6f6e 7665 7274 3a0a 2020  _qat_convert:.  
+00006c20: 2020 2020 2020 2020 2020 2020 2020 6661                fa
+00006c30: 6c6c 6261 636b 5f6f 7073 2e61 7070 656e  llback_ops.appen
+00006c40: 6428 6b29 0a0a 2020 2020 2020 2020 6966  d(k)..        if
+00006c50: 2066 616c 6c62 6163 6b5f 6f70 7320 616e   fallback_ops an
+00006c60: 6420 6e6f 7420 6973 5f71 6174 5f63 6f6e  d not is_qat_con
+00006c70: 7665 7274 3a0a 2020 2020 2020 2020 2020  vert:.          
+00006c80: 2020 5f66 616c 6c62 6163 6b5f 7175 616e    _fallback_quan
+00006c90: 7469 7a61 626c 655f 6f70 735f 7265 6375  tizable_ops_recu
+00006ca0: 7273 6976 656c 7928 6d6f 6465 6c2c 2027  rsively(model, '
+00006cb0: 272c 2066 616c 6c62 6163 6b5f 6f70 732c  ', fallback_ops,
+00006cc0: 206f 705f 7163 6667 7329 0a0a 0a64 6566   op_qcfgs)...def
+00006cd0: 205f 7072 6f70 6167 6174 655f 7163 6f6e   _propagate_qcon
+00006ce0: 6669 675f 7265 6375 7273 6976 656c 7928  fig_recursively(
+00006cf0: 6d6f 6465 6c2c 2070 7265 6669 782c 206f  model, prefix, o
+00006d00: 705f 7163 6667 732c 2071 636f 6e66 6967  p_qcfgs, qconfig
+00006d10: 5f70 6172 656e 743d 4e6f 6e65 293a 0a20  _parent=None):. 
+00006d20: 2020 2022 2222 5468 6973 2069 7320 6120     """This is a 
+00006d30: 6865 6c70 6572 2066 756e 6374 696f 6e20  helper function 
+00006d40: 666f 7220 6070 726f 7061 6761 7465 5f71  for `propagate_q
+00006d50: 636f 6e66 6967 600a 0a20 2020 2041 7267  config`..    Arg
+00006d60: 733a 0a20 2020 2020 2020 206d 6f64 656c  s:.        model
+00006d70: 2028 6f62 6a65 6374 293a 2069 6e70 7574   (object): input
+00006d80: 206d 6f64 656c 0a20 2020 2020 2020 2070   model.        p
+00006d90: 7265 6669 7820 2873 7472 696e 6729 3a20  refix (string): 
+00006da0: 7072 6566 6978 206f 6620 6f70 206e 616d  prefix of op nam
+00006db0: 650a 2020 2020 2020 2020 6f70 5f71 6366  e.        op_qcf
+00006dc0: 6773 2028 6469 6374 293a 2064 6963 7469  gs (dict): dicti
+00006dd0: 6f6e 6172 7920 7468 6174 206d 6170 7320  onary that maps 
+00006de0: 6672 6f6d 206e 616d 6520 6f72 2074 7970  from name or typ
+00006df0: 6520 6f66 2073 7562 6d6f 6475 6c65 2074  e of submodule t
+00006e00: 6f0a 2020 2020 2020 2020 2020 2020 2020  o.              
+00006e10: 2020 2020 2020 2020 2020 7175 616e 7469            quanti
+00006e20: 7a61 7469 6f6e 2063 6f6e 6669 6775 7261  zation configura
+00006e30: 7469 6f6e 0a20 2020 2020 2020 2071 636f  tion.        qco
+00006e40: 6e66 6967 5f70 6172 656e 7420 286f 626a  nfig_parent (obj
+00006e50: 6563 742c 206f 7074 696f 6e61 6c29 3a20  ect, optional): 
+00006e60: 7163 6f6e 6669 6720 6f66 2070 6172 656e  qconfig of paren
+00006e70: 7420 6d6f 6475 6c65 0a0a 2020 2020 5265  t module..    Re
+00006e80: 7475 726e 733a 0a20 2020 2020 2020 204e  turns:.        N
+00006e90: 6f6e 650a 2020 2020 2222 220a 2020 2020  one.    """.    
+00006ea0: 666f 7220 6e61 6d65 2c20 6368 696c 6420  for name, child 
+00006eb0: 696e 206d 6f64 656c 2e6e 616d 6564 5f63  in model.named_c
+00006ec0: 6869 6c64 7265 6e28 293a 0a20 2020 2020  hildren():.     
+00006ed0: 2020 206f 705f 6e61 6d65 203d 2070 7265     op_name = pre
+00006ee0: 6669 7820 2b20 6e61 6d65 0a20 2020 2020  fix + name.     
+00006ef0: 2020 2063 6869 6c64 2e71 636f 6e66 6967     child.qconfig
+00006f00: 203d 2071 636f 6e66 6967 5f70 6172 656e   = qconfig_paren
+00006f10: 740a 2020 2020 2020 2020 7163 6f6e 6669  t.        qconfi
+00006f20: 675f 736f 6e20 3d20 4e6f 6e65 0a20 2020  g_son = None.   
+00006f30: 2020 2020 2069 6620 6f70 5f6e 616d 6520       if op_name 
+00006f40: 696e 206f 705f 7163 6667 733a 0a20 2020  in op_qcfgs:.   
+00006f50: 2020 2020 2020 2020 2063 6869 6c64 2e71           child.q
+00006f60: 636f 6e66 6967 203d 206f 705f 7163 6667  config = op_qcfg
+00006f70: 735b 6f70 5f6e 616d 655d 0a20 2020 2020  s[op_name].     
+00006f80: 2020 2020 2020 2023 2066 6f72 2073 7562         # for sub
+00006f90: 6d6f 6475 6c65 7320 6f66 2066 7573 6564  modules of fused
+00006fa0: 206d 6f64 756c 652c 206c 696b 6520 6e6e   module, like nn
+00006fb0: 2e43 6f6e 7642 6e52 656c 7532 642e 0a20  .ConvBnRelu2d.. 
+00006fc0: 2020 2020 2020 2020 2020 2071 636f 6e66             qconf
+00006fd0: 6967 5f73 6f6e 203d 2063 6869 6c64 2e71  ig_son = child.q
+00006fe0: 636f 6e66 6967 0a20 2020 2020 2020 2065  config.        e
+00006ff0: 6c69 6620 7479 7065 2863 6869 6c64 2920  lif type(child) 
+00007000: 3d3d 2074 6f72 6368 2e71 7561 6e74 697a  == torch.quantiz
+00007010: 6174 696f 6e2e 4465 5175 616e 7453 7475  ation.DeQuantStu
+00007020: 623a 0a20 2020 2020 2020 2020 2020 2076  b:.            v
+00007030: 6572 7369 6f6e 203d 2067 6574 5f74 6f72  ersion = get_tor
+00007040: 6368 5f76 6572 7369 6f6e 2829 0a20 2020  ch_version().   
+00007050: 2020 2020 2020 2020 2069 6620 7665 7273           if vers
+00007060: 696f 6e2e 7265 6c65 6173 6520 3e3d 2056  ion.release >= V
+00007070: 6572 7369 6f6e 2822 312e 382e 3022 292e  ersion("1.8.0").
+00007080: 7265 6c65 6173 653a 0a20 2020 2020 2020  release:.       
+00007090: 2020 2020 2020 2020 2063 6869 6c64 2e71           child.q
+000070a0: 636f 6e66 6967 203d 2074 6f72 6368 2e71  config = torch.q
+000070b0: 7561 6e74 697a 6174 696f 6e2e 5143 6f6e  uantization.QCon
+000070c0: 6669 6728 0a20 2020 2020 2020 2020 2020  fig(.           
+000070d0: 2020 2020 2020 2020 2061 6374 6976 6174           activat
+000070e0: 696f 6e3d 746f 7263 682e 7175 616e 7469  ion=torch.quanti
+000070f0: 7a61 7469 6f6e 2e4d 696e 4d61 784f 6273  zation.MinMaxObs
+00007100: 6572 7665 722e 7769 7468 5f61 7267 7328  erver.with_args(
+00007110: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007120: 2020 2020 2020 2020 2072 6564 7563 655f           reduce_
+00007130: 7261 6e67 653d 5245 4455 4345 5f52 414e  range=REDUCE_RAN
+00007140: 4745 292c 0a20 2020 2020 2020 2020 2020  GE),.           
+00007150: 2020 2020 2020 2020 2077 6569 6768 743d           weight=
+00007160: 746f 7263 682e 7175 616e 7469 7a61 7469  torch.quantizati
+00007170: 6f6e 2e64 6566 6175 6c74 5f70 6572 5f63  on.default_per_c
+00007180: 6861 6e6e 656c 5f77 6569 6768 745f 6f62  hannel_weight_ob
+00007190: 7365 7276 6572 290a 2020 2020 2020 2020  server).        
+000071a0: 5f70 726f 7061 6761 7465 5f71 636f 6e66  _propagate_qconf
+000071b0: 6967 5f72 6563 7572 7369 7665 6c79 2863  ig_recursively(c
+000071c0: 6869 6c64 2c20 6f70 5f6e 616d 6520 2b20  hild, op_name + 
+000071d0: 272e 272c 206f 705f 7163 6667 732c 2071  '.', op_qcfgs, q
+000071e0: 636f 6e66 6967 5f73 6f6e 290a 0a0a 6465  config_son)...de
+000071f0: 6620 5f66 696e 645f 7175 616e 7469 7a65  f _find_quantize
+00007200: 645f 6f70 5f6e 756d 286d 6f64 756c 652c  d_op_num(module,
+00007210: 206f 705f 7163 6667 732c 2070 7265 6669   op_qcfgs, prefi
+00007220: 783d 2727 2c20 6f70 5f63 6f75 6e74 3d30  x='', op_count=0
+00007230: 293a 0a20 2020 2022 2222 5468 6973 2069  ):.    """This i
+00007240: 7320 6120 6865 6c70 6572 2066 756e 6374  s a helper funct
+00007250: 696f 6e20 666f 7220 605f 6661 6c6c 6261  ion for `_fallba
+00007260: 636b 5f71 7561 6e74 697a 6162 6c65 5f6f  ck_quantizable_o
+00007270: 7073 5f72 6563 7572 7369 7665 6c79 600a  ps_recursively`.
+00007280: 0a20 2020 2041 7267 733a 0a20 2020 2020  .    Args:.     
+00007290: 2020 206d 6f64 656c 2028 6f62 6a65 6374     model (object
+000072a0: 293a 2069 6e70 7574 206d 6f64 656c 0a20  ): input model. 
+000072b0: 2020 2020 2020 206f 705f 6366 6773 2028         op_cfgs (
+000072c0: 6469 6374 293a 2064 6963 7469 6f6e 6172  dict): dictionar
+000072d0: 7920 6f66 2071 7561 6e74 697a 6174 696f  y of quantizatio
+000072e0: 6e20 636f 6e66 6967 7572 6520 666f 7220  n configure for 
+000072f0: 6561 6368 206f 700a 2020 2020 2020 2020  each op.        
+00007300: 7072 6566 6978 2028 7374 7229 3a20 7072  prefix (str): pr
+00007310: 6566 6978 206f 6620 6f70 206e 616d 650a  efix of op name.
+00007320: 2020 2020 2020 2020 6f70 5f63 6f75 6e74          op_count
+00007330: 2028 696e 742c 206f 7074 696f 6e61 6c29   (int, optional)
+00007340: 3a20 636f 756e 7420 7468 6520 7175 616e  : count the quan
+00007350: 7469 7a61 626c 6520 6f70 2071 7561 6e74  tizable op quant
+00007360: 6974 7920 696e 2074 6869 7320 6d6f 6475  ity in this modu
+00007370: 6c65 0a0a 2020 2020 5265 7475 726e 733a  le..    Returns:
+00007380: 0a20 2020 2020 2020 2074 6865 2071 7561  .        the qua
+00007390: 6e74 697a 6162 6c65 206f 7020 7175 616e  ntizable op quan
+000073a0: 7469 7479 2069 6e20 7468 6973 206d 6f64  tity in this mod
+000073b0: 756c 650a 2020 2020 2222 220a 2020 2020  ule.    """.    
+000073c0: 666f 7220 6e61 6d65 5f74 6d70 2c20 6368  for name_tmp, ch
+000073d0: 696c 645f 746d 7020 696e 206d 6f64 756c  ild_tmp in modul
+000073e0: 652e 6e61 6d65 645f 6368 696c 6472 656e  e.named_children
+000073f0: 2829 3a0a 2020 2020 2020 2020 6f70 5f6e  ():.        op_n
+00007400: 616d 6520 3d20 7072 6566 6978 202b 2027  ame = prefix + '
+00007410: 2e27 202b 206e 616d 655f 746d 7020 6966  .' + name_tmp if
+00007420: 2070 7265 6669 7820 213d 2027 2720 656c   prefix != '' el
+00007430: 7365 206e 616d 655f 746d 700a 2020 2020  se name_tmp.    
+00007440: 2020 2020 6966 206f 705f 6e61 6d65 2069      if op_name i
+00007450: 6e20 6f70 5f71 6366 6773 2e6b 6579 7328  n op_qcfgs.keys(
+00007460: 2920 616e 6420 5c0a 2020 2020 2020 2020  ) and \.        
+00007470: 2020 7479 7065 2863 6869 6c64 5f74 6d70    type(child_tmp
+00007480: 2920 213d 2074 6f72 6368 2e71 7561 6e74  ) != torch.quant
+00007490: 697a 6174 696f 6e2e 5175 616e 7453 7475  ization.QuantStu
+000074a0: 623a 0a20 2020 2020 2020 2020 2020 206f  b:.            o
+000074b0: 705f 636f 756e 7420 2b3d 2031 0a20 2020  p_count += 1.   
+000074c0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+000074d0: 2020 2020 2020 206f 705f 636f 756e 7420         op_count 
+000074e0: 3d20 5f66 696e 645f 7175 616e 7469 7a65  = _find_quantize
+000074f0: 645f 6f70 5f6e 756d 2863 6869 6c64 5f74  d_op_num(child_t
+00007500: 6d70 2c20 6f70 5f71 6366 6773 2c20 6f70  mp, op_qcfgs, op
+00007510: 5f6e 616d 652c 206f 705f 636f 756e 7429  _name, op_count)
+00007520: 0a20 2020 2072 6574 7572 6e20 6f70 5f63  .    return op_c
+00007530: 6f75 6e74 0a0a 0a64 6566 205f 6661 6c6c  ount...def _fall
+00007540: 6261 636b 5f71 7561 6e74 697a 6162 6c65  back_quantizable
+00007550: 5f6f 7073 5f72 6563 7572 7369 7665 6c79  _ops_recursively
+00007560: 286d 6f64 656c 2c20 7072 6566 6978 2c20  (model, prefix, 
+00007570: 6661 6c6c 6261 636b 5f6f 7073 2c20 6f70  fallback_ops, op
+00007580: 5f71 6366 6773 293a 0a20 2020 2022 2222  _qcfgs):.    """
+00007590: 4861 6e64 6c65 2061 6c6c 2066 616c 6c62  Handle all fallb
+000075a0: 6163 6b20 6f70 7328 6670 3332 206f 7073  ack ops(fp32 ops
+000075b0: 290a 0a20 2020 2041 7267 733a 0a20 2020  )..    Args:.   
+000075c0: 2020 2020 206d 6f64 656c 2028 6f62 6a65       model (obje
+000075d0: 6374 293a 2069 6e70 7574 206d 6f64 656c  ct): input model
+000075e0: 0a20 2020 2020 2020 2070 7265 6669 7820  .        prefix 
+000075f0: 2873 7472 696e 6729 3a20 7468 6520 7072  (string): the pr
+00007600: 6566 6978 206f 6620 6f70 206e 616d 650a  efix of op name.
+00007610: 2020 2020 2020 2020 6661 6c6c 6261 636b          fallback
+00007620: 5f6f 7073 2028 6c69 7374 293a 206c 6973  _ops (list): lis
+00007630: 7420 6f66 2066 616c 6c62 6163 6b20 6f70  t of fallback op
+00007640: 7328 6670 3332 206f 7073 290a 2020 2020  s(fp32 ops).    
+00007650: 2020 2020 6f70 5f63 6667 7320 2864 6963      op_cfgs (dic
+00007660: 7429 3a20 6469 6374 696f 6e61 7279 206f  t): dictionary o
+00007670: 6620 7175 616e 7469 7a61 7469 6f6e 2063  f quantization c
+00007680: 6f6e 6669 6775 7265 2066 6f72 2065 6163  onfigure for eac
+00007690: 6820 6f70 0a0a 2020 2020 5265 7475 726e  h op..    Return
+000076a0: 733a 0a20 2020 2020 2020 204e 6f6e 650a  s:.        None.
+000076b0: 2020 2020 2222 220a 2020 2020 636c 6173      """.    clas
+000076c0: 7320 4465 7175 616e 7451 7561 6e74 5772  s DequantQuantWr
+000076d0: 6170 7065 7228 746f 7263 682e 6e6e 2e4d  apper(torch.nn.M
+000076e0: 6f64 756c 6529 3a0a 2020 2020 2020 2020  odule):.        
+000076f0: 2222 2241 2077 7261 7070 6572 2063 6c61  """A wrapper cla
+00007700: 7373 2074 6861 7420 7772 6170 7320 7468  ss that wraps th
+00007710: 6520 696e 7075 7420 6d6f 6475 6c65 2c20  e input module, 
+00007720: 6164 6473 2044 6551 7561 6e74 5374 7562  adds DeQuantStub
+00007730: 2061 6e64 0a20 2020 2020 2020 2020 2020   and.           
+00007740: 7375 7272 6f75 6e64 2074 6865 2063 616c  surround the cal
+00007750: 6c20 746f 206d 6f64 756c 6520 7769 7468  l to module with
+00007760: 2063 616c 6c20 746f 2064 6571 7561 6e74   call to dequant
+00007770: 2e0a 2020 2020 2020 2020 2020 2074 6869  ..           thi
+00007780: 7320 6973 2075 7365 6420 6279 2066 616c  s is used by fal
+00007790: 6c62 6163 6b20 6c61 7965 7220 7768 656e  lback layer when
+000077a0: 2074 6865 2064 6174 6120 7479 7065 206f   the data type o
+000077b0: 6620 7175 616e 7469 7a65 6420 6f70 0a20  f quantized op. 
+000077c0: 2020 2020 2020 2020 2020 6973 2020 696e            is  in
+000077d0: 7075 743a 696e 7438 2f6f 7574 7075 743a  put:int8/output:
+000077e0: 696e 7438 2e0a 0a20 2020 2020 2020 2020  int8...         
+000077f0: 2020 5468 6973 2069 7320 7573 6564 2062    This is used b
+00007800: 7920 7468 6520 6661 6c6c 6261 636b 2075  y the fallback u
+00007810: 7469 6c69 7479 2066 756e 6374 696f 6e73  tility functions
+00007820: 2074 6f20 6164 6420 7468 6520 6465 7175   to add the dequ
+00007830: 616e 7420 616e 640a 2020 2020 2020 2020  ant and.        
+00007840: 2020 2071 7561 6e74 206d 6f64 756c 6573     quant modules
+00007850: 2c20 6265 666f 7265 2060 636f 6e76 6572  , before `conver
+00007860: 7460 2066 756e 6374 696f 6e20 6051 7561  t` function `Qua
+00007870: 6e74 5374 7562 6020 7769 6c6c 206a 7573  ntStub` will jus
+00007880: 7420 6265 206f 6273 6572 7665 722c 0a20  t be observer,. 
+00007890: 2020 2020 2020 2020 2020 6974 206f 6273            it obs
+000078a0: 6572 7665 7320 7468 6520 696e 7075 7420  erves the input 
+000078b0: 7465 6e73 6f72 2c20 6166 7465 7220 6063  tensor, after `c
+000078c0: 6f6e 7665 7274 602c 2060 5175 616e 7453  onvert`, `QuantS
+000078d0: 7475 6260 0a20 2020 2020 2020 2020 2020  tub`.           
+000078e0: 7769 6c6c 2062 6520 7377 6170 7065 6420  will be swapped 
+000078f0: 746f 2060 6e6e 712e 5175 616e 7469 7a65  to `nnq.Quantize
+00007900: 6020 7768 6963 6820 646f 6573 2061 6374  ` which does act
+00007910: 7561 6c20 7175 616e 7469 7a61 7469 6f6e  ual quantization
+00007920: 2e20 5369 6d69 6c61 726c 790a 2020 2020  . Similarly.    
+00007930: 2020 2020 2020 2066 6f72 2060 4465 5175         for `DeQu
+00007940: 616e 7453 7475 6260 2e0a 2020 2020 2020  antStub`..      
+00007950: 2020 2222 220a 2020 2020 2020 2020 6465    """.        de
+00007960: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
+00007970: 206d 6f64 756c 652c 206f 6273 6572 7665   module, observe
+00007980: 723d 4e6f 6e65 293a 0a20 2020 2020 2020  r=None):.       
+00007990: 2020 2020 2073 7570 6572 2844 6571 7561       super(Dequa
+000079a0: 6e74 5175 616e 7457 7261 7070 6572 2c20  ntQuantWrapper, 
+000079b0: 7365 6c66 292e 5f5f 696e 6974 5f5f 2829  self).__init__()
+000079c0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+000079d0: 6e6f 7420 6d6f 6475 6c65 2e71 636f 6e66  not module.qconf
+000079e0: 6967 2061 6e64 206f 6273 6572 7665 723a  ig and observer:
+000079f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007a00: 2077 6569 6768 7473 5f6f 6273 6572 7665   weights_observe
+00007a10: 7220 3d20 6f62 7365 7276 6572 2827 6d69  r = observer('mi
+00007a20: 6e6d 6178 272c 2027 6173 796d 272c 2027  nmax', 'asym', '
+00007a30: 7065 725f 6368 616e 6e65 6c27 2c20 2769  per_channel', 'i
+00007a40: 6e74 3827 290a 2020 2020 2020 2020 2020  nt8').          
+00007a50: 2020 2020 2020 6163 7469 7661 7469 6f6e        activation
+00007a60: 5f6f 6273 6572 7665 7220 3d20 6f62 7365  _observer = obse
+00007a70: 7276 6572 2827 6d69 6e6d 6178 272c 2027  rver('minmax', '
+00007a80: 7379 6d27 2c20 2770 6572 5f74 656e 736f  sym', 'per_tenso
+00007a90: 7227 2c20 2775 696e 7438 2729 0a20 2020  r', 'uint8').   
+00007aa0: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
+00007ab0: 756c 652e 7163 6f6e 6669 6720 3d20 746f  ule.qconfig = to
+00007ac0: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+00007ad0: 2e51 436f 6e66 6967 2861 6374 6976 6174  .QConfig(activat
+00007ae0: 696f 6e3d 6163 7469 7661 7469 6f6e 5f6f  ion=activation_o
+00007af0: 6273 6572 7665 722c 0a20 2020 2020 2020  bserver,.       
+00007b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007b30: 2020 2020 2077 6569 6768 743d 7765 6967       weight=weig
+00007b40: 6874 735f 6f62 7365 7276 6572 290a 2020  hts_observer).  
+00007b50: 2020 2020 2020 2020 2020 7365 6c66 2e61            self.a
+00007b60: 6464 5f6d 6f64 756c 6528 2771 7561 6e74  dd_module('quant
+00007b70: 272c 2074 6f72 6368 2e71 7561 6e74 697a  ', torch.quantiz
+00007b80: 6174 696f 6e2e 5175 616e 7453 7475 6228  ation.QuantStub(
+00007b90: 6d6f 6475 6c65 2e71 636f 6e66 6967 2929  module.qconfig))
+00007ba0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00007bb0: 662e 6164 645f 6d6f 6475 6c65 2827 6465  f.add_module('de
+00007bc0: 7175 616e 7427 2c20 746f 7263 682e 7175  quant', torch.qu
+00007bd0: 616e 7469 7a61 7469 6f6e 2e44 6551 7561  antization.DeQua
+00007be0: 6e74 5374 7562 2829 290a 2020 2020 2020  ntStub()).      
+00007bf0: 2020 2020 2020 7365 6c66 2e61 6464 5f6d        self.add_m
+00007c00: 6f64 756c 6528 276d 6f64 756c 6527 2c20  odule('module', 
+00007c10: 6d6f 6475 6c65 290a 2020 2020 2020 2020  module).        
+00007c20: 2020 2020 7665 7273 696f 6e20 3d20 6765      version = ge
+00007c30: 745f 746f 7263 685f 7665 7273 696f 6e28  t_torch_version(
+00007c40: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
+00007c50: 2076 6572 7369 6f6e 2e72 656c 6561 7365   version.release
+00007c60: 203e 3d20 5665 7273 696f 6e28 2231 2e38   >= Version("1.8
+00007c70: 2e30 2229 2e72 656c 6561 7365 3a0a 2020  .0").release:.  
+00007c80: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00007c90: 6c66 2e64 6571 7561 6e74 2e71 636f 6e66  lf.dequant.qconf
+00007ca0: 6967 203d 206d 6f64 756c 652e 7163 6f6e  ig = module.qcon
+00007cb0: 6669 670a 2020 2020 2020 2020 2020 2020  fig.            
+00007cc0: 6d6f 6475 6c65 2e71 636f 6e66 6967 203d  module.qconfig =
+00007cd0: 204e 6f6e 650a 2020 2020 2020 2020 2020   None.          
+00007ce0: 2020 7365 6c66 2e74 7261 696e 286d 6f64    self.train(mod
+00007cf0: 756c 652e 7472 6169 6e69 6e67 290a 0a20  ule.training).. 
+00007d00: 2020 2020 2020 2064 6566 2066 6f72 7761         def forwa
+00007d10: 7264 2873 656c 662c 2058 293a 0a20 2020  rd(self, X):.   
+00007d20: 2020 2020 2020 2020 2058 203d 2073 656c           X = sel
+00007d30: 662e 6465 7175 616e 7428 5829 0a20 2020  f.dequant(X).   
+00007d40: 2020 2020 2020 2020 2058 203d 2073 656c           X = sel
+00007d50: 662e 6d6f 6475 6c65 2858 290a 2020 2020  f.module(X).    
+00007d60: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00007d70: 656c 662e 7175 616e 7428 5829 0a0a 2020  elf.quant(X)..  
+00007d80: 2020 2020 2020 6465 6620 6164 6428 7365        def add(se
+00007d90: 6c66 2c20 782c 2079 293a 0a20 2020 2020  lf, x, y):.     
+00007da0: 2020 2020 2020 2023 2074 7970 653a 2028         # type: (
+00007db0: 5465 6e73 6f72 2c20 5465 6e73 6f72 2920  Tensor, Tensor) 
+00007dc0: 2d3e 2054 656e 736f 720a 2020 2020 2020  -> Tensor.      
+00007dd0: 2020 2020 2020 7820 3d20 7365 6c66 2e64        x = self.d
+00007de0: 6571 7561 6e74 2878 290a 2020 2020 2020  equant(x).      
+00007df0: 2020 2020 2020 7920 3d20 7365 6c66 2e64        y = self.d
+00007e00: 6571 7561 6e74 2879 290a 2020 2020 2020  equant(y).      
+00007e10: 2020 2020 2020 7220 3d20 7365 6c66 2e6d        r = self.m
+00007e20: 6f64 756c 652e 6164 6428 782c 2079 290a  odule.add(x, y).
+00007e30: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00007e40: 726e 2073 656c 662e 7175 616e 7428 7229  rn self.quant(r)
+00007e50: 0a0a 2020 2020 2020 2020 6465 6620 6164  ..        def ad
+00007e60: 645f 7363 616c 6172 2873 656c 662c 2078  d_scalar(self, x
+00007e70: 2c20 7929 3a0a 2020 2020 2020 2020 2020  , y):.          
+00007e80: 2020 2320 7479 7065 3a20 2854 656e 736f    # type: (Tenso
+00007e90: 722c 2066 6c6f 6174 2920 2d3e 2054 656e  r, float) -> Ten
+00007ea0: 736f 720a 2020 2020 2020 2020 2020 2020  sor.            
+00007eb0: 7820 3d20 7365 6c66 2e64 6571 7561 6e74  x = self.dequant
+00007ec0: 2878 290a 2020 2020 2020 2020 2020 2020  (x).            
+00007ed0: 7220 3d20 7365 6c66 2e6d 6f64 756c 652e  r = self.module.
+00007ee0: 6164 645f 7363 616c 6172 2878 2c20 7929  add_scalar(x, y)
+00007ef0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00007f00: 7572 6e20 7365 6c66 2e71 7561 6e74 2872  urn self.quant(r
+00007f10: 290a 0a20 2020 2020 2020 2064 6566 206d  )..        def m
+00007f20: 756c 2873 656c 662c 2078 2c20 7929 3a0a  ul(self, x, y):.
+00007f30: 2020 2020 2020 2020 2020 2020 2320 7479              # ty
+00007f40: 7065 3a20 2854 656e 736f 722c 2054 656e  pe: (Tensor, Ten
+00007f50: 736f 7229 202d 3e20 5465 6e73 6f72 0a20  sor) -> Tensor. 
+00007f60: 2020 2020 2020 2020 2020 2078 203d 2073             x = s
+00007f70: 656c 662e 6465 7175 616e 7428 7829 0a20  elf.dequant(x). 
+00007f80: 2020 2020 2020 2020 2020 2079 203d 2073             y = s
+00007f90: 656c 662e 6465 7175 616e 7428 7929 0a20  elf.dequant(y). 
+00007fa0: 2020 2020 2020 2020 2020 2072 203d 2073             r = s
+00007fb0: 656c 662e 6d6f 6475 6c65 2e6d 756c 2878  elf.module.mul(x
+00007fc0: 2c20 7929 0a20 2020 2020 2020 2020 2020  , y).           
+00007fd0: 2072 6574 7572 6e20 7365 6c66 2e71 7561   return self.qua
+00007fe0: 6e74 2872 290a 0a20 2020 2020 2020 2064  nt(r)..        d
+00007ff0: 6566 206d 756c 5f73 6361 6c61 7228 7365  ef mul_scalar(se
+00008000: 6c66 2c20 782c 2079 293a 0a20 2020 2020  lf, x, y):.     
+00008010: 2020 2020 2020 2023 2074 7970 653a 2028         # type: (
+00008020: 5465 6e73 6f72 2c20 666c 6f61 7429 202d  Tensor, float) -
+00008030: 3e20 5465 6e73 6f72 0a20 2020 2020 2020  > Tensor.       
+00008040: 2020 2020 2078 203d 2073 656c 662e 6465       x = self.de
+00008050: 7175 616e 7428 7829 0a20 2020 2020 2020  quant(x).       
+00008060: 2020 2020 2072 203d 2073 656c 662e 6d6f       r = self.mo
+00008070: 6475 6c65 2e6d 756c 5f73 6361 6c61 7228  dule.mul_scalar(
+00008080: 782c 2079 290a 2020 2020 2020 2020 2020  x, y).          
+00008090: 2020 7265 7475 726e 2073 656c 662e 7175    return self.qu
+000080a0: 616e 7428 7229 0a0a 2020 2020 2020 2020  ant(r)..        
+000080b0: 6465 6620 6361 7428 7365 6c66 2c20 782c  def cat(self, x,
+000080c0: 2064 696d 3d30 293a 0a20 2020 2020 2020   dim=0):.       
+000080d0: 2020 2020 2023 2074 7970 653a 2028 4c69       # type: (Li
+000080e0: 7374 5b54 656e 736f 725d 2c20 696e 7429  st[Tensor], int)
+000080f0: 202d 3e20 5465 6e73 6f72 0a20 2020 2020   -> Tensor.     
+00008100: 2020 2020 2020 2058 203d 205b 7365 6c66         X = [self
+00008110: 2e64 6571 7561 6e74 2878 5f29 2066 6f72  .dequant(x_) for
+00008120: 2078 5f20 696e 2078 5d0a 2020 2020 2020   x_ in x].      
+00008130: 2020 2020 2020 7220 3d20 7365 6c66 2e6d        r = self.m
+00008140: 6f64 756c 652e 6361 7428 582c 2064 696d  odule.cat(X, dim
+00008150: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
+00008160: 7475 726e 2073 656c 662e 7175 616e 7428  turn self.quant(
+00008170: 7229 0a0a 2020 2020 2020 2020 6465 6620  r)..        def 
+00008180: 6164 645f 7265 6c75 2873 656c 662c 2078  add_relu(self, x
+00008190: 2c20 7929 3a0a 2020 2020 2020 2020 2020  , y):.          
+000081a0: 2020 2320 7479 7065 3a20 2854 656e 736f    # type: (Tenso
+000081b0: 722c 2054 656e 736f 7229 202d 3e20 5465  r, Tensor) -> Te
+000081c0: 6e73 6f72 0a20 2020 2020 2020 2020 2020  nsor.           
+000081d0: 2078 203d 2073 656c 662e 6465 7175 616e   x = self.dequan
+000081e0: 7428 7829 0a20 2020 2020 2020 2020 2020  t(x).           
+000081f0: 2079 203d 2073 656c 662e 6465 7175 616e   y = self.dequan
+00008200: 7428 7929 0a20 2020 2020 2020 2020 2020  t(y).           
+00008210: 2072 203d 2073 656c 662e 6d6f 6475 6c65   r = self.module
+00008220: 2e61 6464 5f72 656c 7528 782c 2079 290a  .add_relu(x, y).
+00008230: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00008240: 726e 2073 656c 662e 7175 616e 7428 7229  rn self.quant(r)
+00008250: 0a0a 2020 2020 666f 7220 6e61 6d65 2c20  ..    for name, 
+00008260: 6368 696c 6420 696e 206d 6f64 656c 2e6e  child in model.n
+00008270: 616d 6564 5f63 6869 6c64 7265 6e28 293a  amed_children():
+00008280: 0a20 2020 2020 2020 206f 705f 6e61 6d65  .        op_name
+00008290: 203d 2070 7265 6669 7820 2b20 272e 2720   = prefix + '.' 
+000082a0: 2b20 6e61 6d65 2069 6620 7072 6566 6978  + name if prefix
+000082b0: 2021 3d20 2727 2065 6c73 6520 6e61 6d65   != '' else name
+000082c0: 0a20 2020 2020 2020 2069 6620 6f70 5f6e  .        if op_n
+000082d0: 616d 6520 696e 2066 616c 6c62 6163 6b5f  ame in fallback_
+000082e0: 6f70 733a 0a20 2020 2020 2020 2020 2020  ops:.           
+000082f0: 2063 6869 6c64 2e71 636f 6e66 6967 203d   child.qconfig =
+00008300: 204e 6f6e 650a 2020 2020 2020 2020 2020   None.          
+00008310: 2020 7175 616e 7469 7a65 5f6f 705f 6e75    quantize_op_nu
+00008320: 6d20 3d20 5f66 696e 645f 7175 616e 7469  m = _find_quanti
+00008330: 7a65 645f 6f70 5f6e 756d 286d 6f64 656c  zed_op_num(model
+00008340: 2c20 6f70 5f71 6366 6773 2c20 7072 6566  , op_qcfgs, pref
+00008350: 6978 3d70 7265 6669 7829 0a20 2020 2020  ix=prefix).     
+00008360: 2020 2020 2020 2069 6620 7175 616e 7469         if quanti
+00008370: 7a65 5f6f 705f 6e75 6d20 3d3d 2031 3a0a  ze_op_num == 1:.
+00008380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008390: 666f 756e 6420 3d20 4661 6c73 650a 2020  found = False.  
+000083a0: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+000083b0: 7220 6e61 6d65 5f74 6d70 2c20 6368 696c  r name_tmp, chil
+000083c0: 645f 746d 7020 696e 206d 6f64 656c 2e6e  d_tmp in model.n
+000083d0: 616d 6564 5f63 6869 6c64 7265 6e28 293a  amed_children():
+000083e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000083f0: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
+00008400: 6365 2863 6869 6c64 5f74 6d70 2c20 746f  ce(child_tmp, to
+00008410: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+00008420: 2e51 7561 6e74 5374 7562 2920 6f72 2069  .QuantStub) or i
+00008430: 7369 6e73 7461 6e63 6528 0a20 2020 2020  sinstance(.     
+00008440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008450: 2020 2020 2020 2063 6869 6c64 5f74 6d70         child_tmp
+00008460: 2c20 746f 7263 682e 7175 616e 7469 7a61  , torch.quantiza
+00008470: 7469 6f6e 2e44 6551 7561 6e74 5374 7562  tion.DeQuantStub
+00008480: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+00008490: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+000084a0: 2e5f 6d6f 6475 6c65 735b 6e61 6d65 5f74  ._modules[name_t
+000084b0: 6d70 5d20 3d20 746f 7263 682e 6e6e 2e49  mp] = torch.nn.I
+000084c0: 6465 6e74 6974 7928 290a 2020 2020 2020  dentity().      
+000084d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000084e0: 2020 666f 756e 6420 3d20 5472 7565 0a20    found = True. 
+000084f0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00008500: 6620 6e6f 7420 666f 756e 643a 0a20 2020  f not found:.   
+00008510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008520: 206d 6f64 656c 2e5f 6d6f 6475 6c65 735b   model._modules[
+00008530: 6e61 6d65 5d20 3d20 4465 7175 616e 7451  name] = DequantQ
+00008540: 7561 6e74 5772 6170 7065 7228 6368 696c  uantWrapper(chil
+00008550: 642c 206f 6273 6572 7665 723d 5f6f 6273  d, observer=_obs
+00008560: 6572 7665 7229 0a20 2020 2020 2020 2020  erver).         
+00008570: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00008580: 2020 2020 2020 2020 206d 6f64 656c 2e5f           model._
+00008590: 6d6f 6475 6c65 735b 6e61 6d65 5d20 3d20  modules[name] = 
+000085a0: 4465 7175 616e 7451 7561 6e74 5772 6170  DequantQuantWrap
+000085b0: 7065 7228 6368 696c 642c 206f 6273 6572  per(child, obser
+000085c0: 7665 723d 5f6f 6273 6572 7665 7229 0a20  ver=_observer). 
+000085d0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+000085e0: 2020 2020 2020 2020 205f 6661 6c6c 6261           _fallba
+000085f0: 636b 5f71 7561 6e74 697a 6162 6c65 5f6f  ck_quantizable_o
+00008600: 7073 5f72 6563 7572 7369 7665 6c79 2863  ps_recursively(c
+00008610: 6869 6c64 2c20 6f70 5f6e 616d 652c 2066  hild, op_name, f
+00008620: 616c 6c62 6163 6b5f 6f70 732c 206f 705f  allback_ops, op_
+00008630: 7163 6667 7329 0a0a 0a40 6164 6170 746f  qcfgs)...@adapto
+00008640: 725f 7265 6769 7374 7279 0a63 6c61 7373  r_registry.class
+00008650: 2054 656d 706c 6174 6541 6461 7074 6f72   TemplateAdaptor
+00008660: 2841 6461 7074 6f72 293a 0a20 2020 2022  (Adaptor):.    "
+00008670: 2222 5461 6d70 6c65 2061 6461 7074 6f72  ""Tample adaptor
+00008680: 206f 6620 5079 546f 7263 6820 6672 616d   of PyTorch fram
+00008690: 6577 6f72 6b2e 0a0a 2020 2020 4172 6773  ework...    Args
+000086a0: 3a0a 2020 2020 2020 2020 6672 616d 6577  :.        framew
+000086b0: 6f72 6b5f 7370 6563 6966 6963 5f69 6e66  ork_specific_inf
+000086c0: 6f20 2864 6963 7429 3a20 6469 6374 696f  o (dict): dictio
+000086d0: 6e61 7279 206f 6620 7475 6e69 6e67 2063  nary of tuning c
+000086e0: 6f6e 6669 6775 7265 2066 726f 6d20 7961  onfigure from ya
+000086f0: 6d6c 2066 696c 652e 0a20 2020 2022 2222  ml file..    """
+00008700: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+00008710: 5f28 7365 6c66 2c20 6672 616d 6577 6f72  _(self, framewor
+00008720: 6b5f 7370 6563 6966 6963 5f69 6e66 6f29  k_specific_info)
+00008730: 3a0a 2020 2020 2020 2020 7375 7065 7228  :.        super(
+00008740: 5465 6d70 6c61 7465 4164 6170 746f 722c  TemplateAdaptor,
+00008750: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
+00008760: 6672 616d 6577 6f72 6b5f 7370 6563 6966  framework_specif
+00008770: 6963 5f69 6e66 6f29 0a20 2020 2020 2020  ic_info).       
+00008780: 2069 6d70 6f72 7420 746f 7263 682e 7175   import torch.qu
+00008790: 616e 7469 7a61 7469 6f6e 2061 7320 7471  antization as tq
+000087a0: 0a20 2020 2020 2020 2073 656c 662e 7665  .        self.ve
+000087b0: 7273 696f 6e20 3d20 6765 745f 746f 7263  rsion = get_torc
+000087c0: 685f 7665 7273 696f 6e28 290a 2020 2020  h_version().    
+000087d0: 2020 2020 2320 7365 7420 746f 7263 6820      # set torch 
+000087e0: 7261 6e64 6f6d 2073 6565 640a 2020 2020  random seed.    
+000087f0: 2020 2020 7261 6e64 6f6d 5f73 6565 6420      random_seed 
+00008800: 3d20 6672 616d 6577 6f72 6b5f 7370 6563  = framework_spec
+00008810: 6966 6963 5f69 6e66 6f5b 2772 616e 646f  ific_info['rando
+00008820: 6d5f 7365 6564 275d 0a20 2020 2020 2020  m_seed'].       
+00008830: 2074 6f72 6368 2e6d 616e 7561 6c5f 7365   torch.manual_se
+00008840: 6564 2872 616e 646f 6d5f 7365 6564 290a  ed(random_seed).
+00008850: 0a20 2020 2020 2020 2073 656c 662e 6266  .        self.bf
+00008860: 3136 5f6f 7073 203d 205b 5d0a 2020 2020  16_ops = [].    
+00008870: 2020 2020 7365 6c66 2e75 7365 5f62 6631      self.use_bf1
+00008880: 3620 3d20 6672 616d 6577 6f72 6b5f 7370  6 = framework_sp
+00008890: 6563 6966 6963 5f69 6e66 6f2e 6765 7428  ecific_info.get(
+000088a0: 2775 7365 5f62 6631 3627 2c20 5472 7565  'use_bf16', True
+000088b0: 290a 2020 2020 2020 2020 7365 6c66 2e64  ).        self.d
+000088c0: 6576 6963 6520 3d20 6672 616d 6577 6f72  evice = framewor
+000088d0: 6b5f 7370 6563 6966 6963 5f69 6e66 6f5b  k_specific_info[
+000088e0: 2764 6576 6963 6527 5d0a 2020 2020 2020  'device'].      
+000088f0: 2020 7365 6c66 2e71 5f64 6174 616c 6f61    self.q_dataloa
+00008900: 6465 7220 3d20 6672 616d 6577 6f72 6b5f  der = framework_
+00008910: 7370 6563 6966 6963 5f69 6e66 6f5b 2771  specific_info['q
+00008920: 5f64 6174 616c 6f61 6465 7227 5d0a 2020  _dataloader'].  
+00008930: 2020 2020 2020 7365 6c66 2e71 5f66 756e        self.q_fun
+00008940: 6320 3d20 6672 616d 6577 6f72 6b5f 7370  c = framework_sp
+00008950: 6563 6966 6963 5f69 6e66 6f2e 6765 7428  ecific_info.get(
+00008960: 2771 5f66 756e 6327 2c20 4e6f 6e65 290a  'q_func', None).
+00008970: 2020 2020 2020 2020 7365 6c66 2e62 656e          self.ben
+00008980: 6368 6d61 726b 203d 2028 474c 4f42 414c  chmark = (GLOBAL
+00008990: 5f53 5441 5445 2e53 5441 5445 203d 3d20  _STATE.STATE == 
+000089a0: 4d4f 4445 2e42 454e 4348 4d41 524b 290a  MODE.BENCHMARK).
+000089b0: 2020 2020 2020 2020 7365 6c66 2e77 6f72          self.wor
+000089c0: 6b73 7061 6365 5f70 6174 6820 3d20 6672  kspace_path = fr
+000089d0: 616d 6577 6f72 6b5f 7370 6563 6966 6963  amework_specific
+000089e0: 5f69 6e66 6f5b 2777 6f72 6b73 7061 6365  _info['workspace
+000089f0: 5f70 6174 6827 5d0a 2020 2020 2020 2020  _path'].        
+00008a00: 7365 6c66 2e69 735f 6261 7365 6c69 6e65  self.is_baseline
+00008a10: 203d 2046 616c 7365 2069 6620 474c 4f42   = False if GLOB
+00008a20: 414c 5f53 5441 5445 2e53 5441 5445 203d  AL_STATE.STATE =
+00008a30: 3d20 4d4f 4445 2e42 454e 4348 4d41 524b  = MODE.BENCHMARK
+00008a40: 2065 6c73 6520 5472 7565 0a20 2020 2020   else True.     
+00008a50: 2020 2073 656c 662e 7175 6572 795f 6861     self.query_ha
+00008a60: 6e64 6c65 7220 3d20 4e6f 6e65 0a20 2020  ndler = None.   
+00008a70: 2020 2020 2073 656c 662e 6170 7072 6f61       self.approa
+00008a80: 6368 203d 2027 270a 2020 2020 2020 2020  ch = ''.        
+00008a90: 7365 6c66 2e70 7265 5f6f 7074 696d 697a  self.pre_optimiz
+00008aa0: 6564 5f6d 6f64 656c 203d 204e 6f6e 650a  ed_model = None.
+00008ab0: 2020 2020 2020 2020 7365 6c66 2e73 7562          self.sub
+00008ac0: 5f6d 6f64 756c 655f 6c69 7374 203d 204e  _module_list = N
+00008ad0: 6f6e 650a 2020 2020 2020 2020 7365 6c66  one.        self
+00008ae0: 2e64 6566 6175 6c74 5f71 636f 6e66 6967  .default_qconfig
+00008af0: 203d 2066 7261 6d65 776f 726b 5f73 7065   = framework_spe
+00008b00: 6369 6669 635f 696e 666f 2e67 6574 2827  cific_info.get('
+00008b10: 6465 6661 756c 745f 7163 6f6e 6669 6727  default_qconfig'
+00008b20: 2c20 4e6f 6e65 290a 2020 2020 2020 2020  , None).        
+00008b30: 7365 6c66 2e70 6572 666f 726d 616e 6365  self.performance
+00008b40: 5f6f 6e6c 7920 3d20 6672 616d 6577 6f72  _only = framewor
+00008b50: 6b5f 7370 6563 6966 6963 5f69 6e66 6f2e  k_specific_info.
+00008b60: 6765 7428 2270 6572 666f 726d 616e 6365  get("performance
+00008b70: 5f6f 6e6c 7922 2c20 4661 6c73 6529 0a20  _only", False). 
+00008b80: 2020 2020 2020 2073 656c 662e 6578 616d         self.exam
+00008b90: 706c 655f 696e 7075 7473 203d 2066 7261  ple_inputs = fra
+00008ba0: 6d65 776f 726b 5f73 7065 6369 6669 635f  mework_specific_
+00008bb0: 696e 666f 2e67 6574 2822 6578 616d 706c  info.get("exampl
+00008bc0: 655f 696e 7075 7473 222c 204e 6f6e 6529  e_inputs", None)
+00008bd0: 0a20 2020 2020 2020 2069 6620 2772 6563  .        if 'rec
+00008be0: 6970 6573 2720 696e 2066 7261 6d65 776f  ipes' in framewo
+00008bf0: 726b 5f73 7065 6369 6669 635f 696e 666f  rk_specific_info
+00008c00: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
+00008c10: 6c66 2e72 6563 6970 6573 203d 2066 7261  lf.recipes = fra
+00008c20: 6d65 776f 726b 5f73 7065 6369 6669 635f  mework_specific_
+00008c30: 696e 666f 5b27 7265 6369 7065 7327 5d0a  info['recipes'].
+00008c40: 0a20 2020 2020 2020 2069 6620 2761 7070  .        if 'app
+00008c50: 726f 6163 6827 2069 6e20 6672 616d 6577  roach' in framew
+00008c60: 6f72 6b5f 7370 6563 6966 6963 5f69 6e66  ork_specific_inf
+00008c70: 6f3a 2020 2320 7072 6167 6d61 3a20 6e6f  o:  # pragma: no
+00008c80: 2063 6f76 6572 0a20 2020 2020 2020 2020   cover.         
+00008c90: 2020 2073 656c 662e 6170 7072 6f61 6368     self.approach
+00008ca0: 203d 2066 7261 6d65 776f 726b 5f73 7065   = framework_spe
+00008cb0: 6369 6669 635f 696e 666f 5b27 6170 7072  cific_info['appr
+00008cc0: 6f61 6368 275d 0a20 2020 2020 2020 2020  oach'].         
+00008cd0: 2020 2069 6620 6672 616d 6577 6f72 6b5f     if framework_
+00008ce0: 7370 6563 6966 6963 5f69 6e66 6f5b 2761  specific_info['a
+00008cf0: 7070 726f 6163 6827 5d20 696e 205b 2270  pproach'] in ["p
+00008d00: 6f73 745f 7472 6169 6e69 6e67 5f73 7461  ost_training_sta
+00008d10: 7469 635f 7175 616e 7422 2c0a 2020 2020  tic_quant",.    
+00008d20: 2020 2020 2020 2020 2020 2020 2270 6f73              "pos
+00008d30: 745f 7472 6169 6e69 6e67 5f61 7574 6f5f  t_training_auto_
+00008d40: 7175 616e 7422 5d3a 0a20 2020 2020 2020  quant"]:.       
+00008d50: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+00008d60: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
+00008d70: 203c 2056 6572 7369 6f6e 2822 312e 372e   < Version("1.7.
+00008d80: 3022 292e 7265 6c65 6173 653a 0a20 2020  0").release:.   
+00008d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008da0: 2073 656c 662e 715f 6d61 7070 696e 6720   self.q_mapping 
+00008db0: 3d20 7471 2e64 6566 6175 6c74 5f6d 6170  = tq.default_map
+00008dc0: 7069 6e67 732e 4445 4641 554c 545f 4d4f  pings.DEFAULT_MO
+00008dd0: 4455 4c45 5f4d 4150 5049 4e47 0a20 2020  DULE_MAPPING.   
+00008de0: 2020 2020 2020 2020 2020 2020 2065 6c69               eli
+00008df0: 6620 7365 6c66 2e76 6572 7369 6f6e 2e72  f self.version.r
+00008e00: 656c 6561 7365 203c 2056 6572 7369 6f6e  elease < Version
+00008e10: 2822 312e 382e 3022 292e 7265 6c65 6173  ("1.8.0").releas
+00008e20: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00008e30: 2020 2020 2020 2073 656c 662e 715f 6d61         self.q_ma
+00008e40: 7070 696e 6720 3d20 5c0a 2020 2020 2020  pping = \.      
+00008e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008e60: 2020 7471 2e71 7561 6e74 697a 6174 696f    tq.quantizatio
+00008e70: 6e5f 6d61 7070 696e 6773 2e67 6574 5f73  n_mappings.get_s
+00008e80: 7461 7469 635f 7175 616e 745f 6d6f 6475  tatic_quant_modu
+00008e90: 6c65 5f6d 6170 7069 6e67 7328 290a 2020  le_mappings().  
+00008ea0: 2020 2020 2020 2020 2020 2020 2020 656c                el
+00008eb0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00008ec0: 2020 2020 2020 2020 7365 6c66 2e71 5f6d          self.q_m
+00008ed0: 6170 7069 6e67 203d 205c 0a20 2020 2020  apping = \.     
+00008ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008ef0: 2020 2074 712e 7175 616e 7469 7a61 7469     tq.quantizati
+00008f00: 6f6e 5f6d 6170 7069 6e67 732e 6765 745f  on_mappings.get_
+00008f10: 6465 6661 756c 745f 7374 6174 6963 5f71  default_static_q
+00008f20: 7561 6e74 5f6d 6f64 756c 655f 6d61 7070  uant_module_mapp
+00008f30: 696e 6773 2829 0a20 2020 2020 2020 2020  ings().         
+00008f40: 2020 2065 6c69 6620 6672 616d 6577 6f72     elif framewor
+00008f50: 6b5f 7370 6563 6966 6963 5f69 6e66 6f5b  k_specific_info[
+00008f60: 2761 7070 726f 6163 6827 5d20 3d3d 2022  'approach'] == "
+00008f70: 7175 616e 745f 6177 6172 655f 7472 6169  quant_aware_trai
+00008f80: 6e69 6e67 223a 0a20 2020 2020 2020 2020  ning":.         
+00008f90: 2020 2020 2020 2069 6620 7365 6c66 2e76         if self.v
+00008fa0: 6572 7369 6f6e 2e72 656c 6561 7365 203c  ersion.release <
+00008fb0: 2056 6572 7369 6f6e 2822 312e 372e 3022   Version("1.7.0"
+00008fc0: 292e 7265 6c65 6173 653a 0a20 2020 2020  ).release:.     
+00008fd0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00008fe0: 656c 662e 715f 6d61 7070 696e 6720 3d20  elf.q_mapping = 
+00008ff0: 7471 2e64 6566 6175 6c74 5f6d 6170 7069  tq.default_mappi
+00009000: 6e67 732e 4445 4641 554c 545f 5141 545f  ngs.DEFAULT_QAT_
+00009010: 4d4f 4455 4c45 5f4d 4150 5049 4e47 0a20  MODULE_MAPPING. 
+00009020: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+00009030: 6c69 6620 7365 6c66 2e76 6572 7369 6f6e  lif self.version
+00009040: 2e72 656c 6561 7365 203c 2056 6572 7369  .release < Versi
+00009050: 6f6e 2822 312e 382e 3022 292e 7265 6c65  on("1.8.0").rele
+00009060: 6173 653a 0a20 2020 2020 2020 2020 2020  ase:.           
+00009070: 2020 2020 2020 2020 2073 656c 662e 715f           self.q_
+00009080: 6d61 7070 696e 6720 3d20 5c0a 2020 2020  mapping = \.    
+00009090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000090a0: 2020 2020 7471 2e71 7561 6e74 697a 6174      tq.quantizat
+000090b0: 696f 6e5f 6d61 7070 696e 6773 2e67 6574  ion_mappings.get
+000090c0: 5f71 6174 5f6d 6f64 756c 655f 6d61 7070  _qat_module_mapp
+000090d0: 696e 6773 2829 0a20 2020 2020 2020 2020  ings().         
+000090e0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+000090f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009100: 2073 656c 662e 715f 6d61 7070 696e 6720   self.q_mapping 
+00009110: 3d20 5c0a 2020 2020 2020 2020 2020 2020  = \.            
+00009120: 2020 2020 2020 2020 2020 2020 7471 2e71              tq.q
+00009130: 7561 6e74 697a 6174 696f 6e5f 6d61 7070  uantization_mapp
+00009140: 696e 6773 2e67 6574 5f64 6566 6175 6c74  ings.get_default
+00009150: 5f71 6174 5f6d 6f64 756c 655f 6d61 7070  _qat_module_mapp
+00009160: 696e 6773 2829 0a20 2020 2020 2020 2020  ings().         
+00009170: 2020 2065 6c69 6620 6672 616d 6577 6f72     elif framewor
+00009180: 6b5f 7370 6563 6966 6963 5f69 6e66 6f5b  k_specific_info[
+00009190: 2761 7070 726f 6163 6827 5d20 3d3d 2022  'approach'] == "
+000091a0: 706f 7374 5f74 7261 696e 696e 675f 6479  post_training_dy
+000091b0: 6e61 6d69 635f 7175 616e 7422 3a0a 2020  namic_quant":.  
+000091c0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+000091d0: 2073 656c 662e 7665 7273 696f 6e2e 7265   self.version.re
+000091e0: 6c65 6173 6520 3c20 5665 7273 696f 6e28  lease < Version(
+000091f0: 2231 2e37 2e30 2229 2e72 656c 6561 7365  "1.7.0").release
+00009200: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00009210: 2020 2020 2020 7365 6c66 2e71 5f6d 6170        self.q_map
+00009220: 7069 6e67 203d 205c 0a20 2020 2020 2020  ping = \.       
 00009230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009260: 7275 6e6e 696e 675f 6d6f 6465 3d27 6361  running_mode='ca
-00009270: 6c69 6272 6174 696f 6e27 290a 2020 2020  libration').    
-00009280: 2020 2020 2020 2020 2020 2020 6966 2069              if i
-00009290: 6478 203e 3d20 746d 705f 6974 6572 6174  dx >= tmp_iterat
-000092a0: 696f 6e73 202d 2031 3a0a 2020 2020 2020  ions - 1:.      
-000092b0: 2020 2020 2020 2020 2020 2020 2020 6272                br
-000092c0: 6561 6b0a 2020 2020 2020 2020 6578 6365  eak.        exce
-000092d0: 7074 2045 7863 6570 7469 6f6e 2061 7320  pt Exception as 
-000092e0: 653a 0a20 2020 2020 2020 2020 2020 2066  e:.            f
-000092f0: 6f72 2069 6478 2c20 696e 7075 7420 696e  or idx, input in
-00009300: 2065 6e75 6d65 7261 7465 2864 6174 616c   enumerate(datal
-00009310: 6f61 6465 7229 3a0a 2020 2020 2020 2020  oader):.        
-00009320: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00009330: 2070 7974 6f72 6368 5f66 6f72 7761 7264   pytorch_forward
-00009340: 5f77 7261 7070 6572 286d 6f64 656c 2c0a  _wrapper(model,.
+00009240: 2074 712e 6465 6661 756c 745f 6d61 7070   tq.default_mapp
+00009250: 696e 6773 2e44 4546 4155 4c54 5f44 594e  ings.DEFAULT_DYN
+00009260: 414d 4943 5f4d 4f44 554c 455f 4d41 5050  AMIC_MODULE_MAPP
+00009270: 494e 470a 2020 2020 2020 2020 2020 2020  ING.            
+00009280: 2020 2020 656c 6966 2073 656c 662e 7665      elif self.ve
+00009290: 7273 696f 6e2e 7265 6c65 6173 6520 3c20  rsion.release < 
+000092a0: 5665 7273 696f 6e28 2231 2e38 2e30 2229  Version("1.8.0")
+000092b0: 2e72 656c 6561 7365 3a0a 2020 2020 2020  .release:.      
+000092c0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+000092d0: 6c66 2e71 5f6d 6170 7069 6e67 203d 205c  lf.q_mapping = \
+000092e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000092f0: 2020 2020 2020 2020 2074 712e 7175 616e           tq.quan
+00009300: 7469 7a61 7469 6f6e 5f6d 6170 7069 6e67  tization_mapping
+00009310: 732e 6765 745f 6479 6e61 6d69 635f 7175  s.get_dynamic_qu
+00009320: 616e 745f 6d6f 6475 6c65 5f6d 6170 7069  ant_module_mappi
+00009330: 6e67 7328 290a 2020 2020 2020 2020 2020  ngs().          
+00009340: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
 00009350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009380: 2069 6e70 7574 2c0a 2020 2020 2020 2020   input,.        
-00009390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000093a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000093b0: 2020 2020 2020 2020 2064 6576 6963 653d           device=
-000093c0: 7365 6c66 2e64 6576 6963 652c 0a20 2020  self.device,.   
-000093d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000093e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000093f0: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00009400: 6e66 3d63 6f6e 662c 0a20 2020 2020 2020  nf=conf,.       
-00009410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009430: 2020 2020 2020 2020 2020 7275 6e6e 696e            runnin
-00009440: 675f 6d6f 6465 3d27 6361 6c69 6272 6174  g_mode='calibrat
-00009450: 696f 6e27 290a 2020 2020 2020 2020 2020  ion').          
-00009460: 2020 2020 2020 6966 2069 6478 203e 3d20        if idx >= 
-00009470: 746d 705f 6974 6572 6174 696f 6e73 202d  tmp_iterations -
-00009480: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-00009490: 2020 2020 2020 2020 6272 6561 6b0a 0a20          break.. 
-000094a0: 2020 2064 6566 206d 6f64 656c 5f63 616c     def model_cal
-000094b0: 6962 7261 7469 6f6e 2873 656c 662c 0a20  ibration(self,. 
-000094c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000094d0: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
-000094e0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000094f0: 2020 2020 2020 2020 2020 2020 6461 7461              data
-00009500: 6c6f 6164 6572 2c0a 2020 2020 2020 2020  loader,.        
-00009510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009520: 2020 6974 6572 6174 696f 6e73 3d31 2c0a    iterations=1,.
-00009530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009540: 2020 2020 2020 2020 2020 636f 6e66 3d4e            conf=N
-00009550: 6f6e 652c 0a20 2020 2020 2020 2020 2020  one,.           
-00009560: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00009570: 616c 6962 5f73 616d 706c 696e 675f 7369  alib_sampling_si
-00009580: 7a65 3d31 293a 0a20 2020 2020 2020 2061  ze=1):.        a
-00009590: 7373 6572 7420 6974 6572 6174 696f 6e73  ssert iterations
-000095a0: 203e 2030 0a20 2020 2020 2020 2077 6974   > 0.        wit
-000095b0: 6820 746f 7263 682e 6e6f 5f67 7261 6428  h torch.no_grad(
-000095c0: 293a 0a20 2020 2020 2020 2020 2020 2069  ):.            i
-000095d0: 6620 6973 696e 7374 616e 6365 2864 6174  f isinstance(dat
-000095e0: 616c 6f61 6465 722c 2042 6173 6544 6174  aloader, BaseDat
-000095f0: 614c 6f61 6465 7229 3a0a 2020 2020 2020  aLoader):.      
-00009600: 2020 2020 2020 2020 2020 6261 7463 685f            batch_
-00009610: 7369 7a65 203d 2064 6174 616c 6f61 6465  size = dataloade
-00009620: 722e 6261 7463 685f 7369 7a65 0a20 2020  r.batch_size.   
-00009630: 2020 2020 2020 2020 2020 2020 2074 7279               try
-00009640: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00009650: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
-00009660: 616e 6765 2862 6174 6368 5f73 697a 6529  ange(batch_size)
-00009670: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00009680: 2020 2020 2020 2020 2020 6966 2063 616c            if cal
-00009690: 6962 5f73 616d 706c 696e 675f 7369 7a65  ib_sampling_size
-000096a0: 2025 2028 6261 7463 685f 7369 7a65 202d   % (batch_size -
-000096b0: 2069 2920 3d3d 2030 3a0a 2020 2020 2020   i) == 0:.      
-000096c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000096d0: 2020 2020 2020 6361 6c69 625f 6261 7463        calib_batc
-000096e0: 685f 7369 7a65 203d 2062 6174 6368 5f73  h_size = batch_s
-000096f0: 697a 6520 2d20 690a 2020 2020 2020 2020  ize - i.        
-00009700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009710: 2020 2020 6966 2069 2021 3d20 303a 0a20      if i != 0:. 
+00009360: 7365 6c66 2e71 5f6d 6170 7069 6e67 203d  self.q_mapping =
+00009370: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+00009380: 2020 2020 2020 2020 2020 2074 712e 7175             tq.qu
+00009390: 616e 7469 7a61 7469 6f6e 5f6d 6170 7069  antization_mappi
+000093a0: 6e67 732e 6765 745f 6465 6661 756c 745f  ngs.get_default_
+000093b0: 6479 6e61 6d69 635f 7175 616e 745f 6d6f  dynamic_quant_mo
+000093c0: 6475 6c65 5f6d 6170 7069 6e67 7328 290a  dule_mappings().
+000093d0: 2020 2020 2020 2020 2020 2020 656c 7365              else
+000093e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000093f0: 2020 6173 7365 7274 2046 616c 7365 2c20    assert False, 
+00009400: 2255 6e73 7570 706f 7274 2061 7070 726f  "Unsupport appro
+00009410: 6163 683a 207b 7d22 2e66 6f72 6d61 7428  ach: {}".format(
+00009420: 7365 6c66 2e61 7070 726f 6163 6829 0a0a  self.approach)..
+00009430: 2020 2020 2020 2020 7365 6c66 2e66 7033          self.fp3
+00009440: 325f 7265 7375 6c74 7320 3d20 5b5d 0a20  2_results = []. 
+00009450: 2020 2020 2020 2073 656c 662e 6670 3332         self.fp32
+00009460: 5f70 7265 6473 5f61 735f 6c61 6265 6c20  _preds_as_label 
+00009470: 3d20 4661 6c73 650a 0a20 2020 2064 6566  = False..    def
+00009480: 2063 616c 6962 5f66 756e 6328 7365 6c66   calib_func(self
+00009490: 2c20 6d6f 6465 6c2c 2064 6174 616c 6f61  , model, dataloa
+000094a0: 6465 722c 2074 6d70 5f69 7465 7261 7469  der, tmp_iterati
+000094b0: 6f6e 732c 2063 6f6e 663d 4e6f 6e65 293a  ons, conf=None):
+000094c0: 0a20 2020 2020 2020 2074 7279 3a0a 2020  .        try:.  
+000094d0: 2020 2020 2020 2020 2020 666f 7220 6964            for id
+000094e0: 782c 2028 696e 7075 742c 206c 6162 656c  x, (input, label
+000094f0: 2920 696e 2065 6e75 6d65 7261 7465 2864  ) in enumerate(d
+00009500: 6174 616c 6f61 6465 7229 3a0a 2020 2020  ataloader):.    
+00009510: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+00009520: 7574 203d 2070 7974 6f72 6368 5f66 6f72  ut = pytorch_for
+00009530: 7761 7264 5f77 7261 7070 6572 286d 6f64  ward_wrapper(mod
+00009540: 656c 2c0a 2020 2020 2020 2020 2020 2020  el,.            
+00009550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009570: 2020 2020 2069 6e70 7574 2c0a 2020 2020       input,.    
+00009580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000095a0: 2020 2020 2020 2020 2020 2020 2064 6576               dev
+000095b0: 6963 653d 7365 6c66 2e64 6576 6963 652c  ice=self.device,
+000095c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000095d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000095e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000095f0: 2020 636f 6e66 3d63 6f6e 662c 0a20 2020    conf=conf,.   
+00009600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009620: 2020 2020 2020 2020 2020 2020 2020 7275                ru
+00009630: 6e6e 696e 675f 6d6f 6465 3d27 6361 6c69  nning_mode='cali
+00009640: 6272 6174 696f 6e27 290a 2020 2020 2020  bration').      
+00009650: 2020 2020 2020 2020 2020 6966 2069 6478            if idx
+00009660: 203e 3d20 746d 705f 6974 6572 6174 696f   >= tmp_iteratio
+00009670: 6e73 202d 2031 3a0a 2020 2020 2020 2020  ns - 1:.        
+00009680: 2020 2020 2020 2020 2020 2020 6272 6561              brea
+00009690: 6b0a 2020 2020 2020 2020 6578 6365 7074  k.        except
+000096a0: 2045 7863 6570 7469 6f6e 2061 7320 653a   Exception as e:
+000096b0: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+000096c0: 2069 6478 2c20 696e 7075 7420 696e 2065   idx, input in e
+000096d0: 6e75 6d65 7261 7465 2864 6174 616c 6f61  numerate(dataloa
+000096e0: 6465 7229 3a0a 2020 2020 2020 2020 2020  der):.          
+000096f0: 2020 2020 2020 6f75 7470 7574 203d 2070        output = p
+00009700: 7974 6f72 6368 5f66 6f72 7761 7264 5f77  ytorch_forward_w
+00009710: 7261 7070 6572 286d 6f64 656c 2c0a 2020  rapper(model,.  
 00009720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009730: 2020 2020 2020 2020 2020 2020 2020 206c                 l
-00009740: 6f67 6765 722e 7761 726e 696e 6728 2252  ogger.warning("R
-00009750: 6573 6574 2060 6361 6c69 6272 6174 696f  eset `calibratio
-00009760: 6e2e 6461 7461 6c6f 6164 6572 2e62 6174  n.dataloader.bat
-00009770: 6368 5f73 697a 6560 2066 6965 6c64 2022  ch_size` field "
-00009780: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009740: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00009750: 6e70 7574 2c0a 2020 2020 2020 2020 2020  nput,.          
+00009760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009780: 2020 2020 2020 2064 6576 6963 653d 7365         device=se
+00009790: 6c66 2e64 6576 6963 652c 0a20 2020 2020  lf.device,.     
 000097a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000097b0: 2274 6f20 7b7d 222e 666f 726d 6174 2863  "to {}".format(c
-000097c0: 616c 6962 5f62 6174 6368 5f73 697a 6529  alib_batch_size)
-000097d0: 202b 0a20 2020 2020 2020 2020 2020 2020   +.             
+000097b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000097c0: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+000097d0: 3d63 6f6e 662c 0a20 2020 2020 2020 2020  =conf,.         
 000097e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000097f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009800: 2020 2220 746f 206d 616b 6520 7375 7265    " to make sure
-00009810: 2074 6865 2073 616d 706c 696e 675f 7369   the sampling_si
-00009820: 7a65 2069 7320 220a 2020 2020 2020 2020  ze is ".        
-00009830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009850: 2020 2020 2020 2022 6469 7669 7369 626c         "divisibl
-00009860: 6520 6578 6163 746c 7920 6279 2062 6174  e exactly by bat
-00009870: 6368 2073 697a 6522 290a 2020 2020 2020  ch size").      
-00009880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009890: 2020 2020 2020 6272 6561 6b0a 2020 2020        break.    
-000098a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000098b0: 746d 705f 6974 6572 6174 696f 6e73 203d  tmp_iterations =
-000098c0: 2069 6e74 286d 6174 682e 6365 696c 2863   int(math.ceil(c
-000098d0: 616c 6962 5f73 616d 706c 696e 675f 7369  alib_sampling_si
-000098e0: 7a65 202f 2063 616c 6962 5f62 6174 6368  ze / calib_batch
-000098f0: 5f73 697a 6529 290a 2020 2020 2020 2020  _size)).        
-00009900: 2020 2020 2020 2020 2020 2020 6461 7461              data
-00009910: 6c6f 6164 6572 2e62 6174 6368 2863 616c  loader.batch(cal
-00009920: 6962 5f62 6174 6368 5f73 697a 6529 0a20  ib_batch_size). 
-00009930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009940: 2020 2073 656c 662e 6361 6c69 625f 6675     self.calib_fu
-00009950: 6e63 2871 5f6d 6f64 656c 2c20 6461 7461  nc(q_model, data
-00009960: 6c6f 6164 6572 2c20 746d 705f 6974 6572  loader, tmp_iter
-00009970: 6174 696f 6e73 2c20 636f 6e66 290a 2020  ations, conf).  
-00009980: 2020 2020 2020 2020 2020 2020 2020 6578                ex
-00009990: 6365 7074 2045 7863 6570 7469 6f6e 3a20  cept Exception: 
-000099a0: 2023 2070 7261 676d 613a 206e 6f20 636f   # pragma: no co
-000099b0: 7665 720a 2020 2020 2020 2020 2020 2020  ver.            
-000099c0: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
-000099d0: 6172 6e69 6e67 2822 4661 696c 2074 6f20  arning("Fail to 
-000099e0: 666f 7277 6172 6420 7769 7468 2062 6174  forward with bat
-000099f0: 6368 2073 697a 653d 7b7d 2c20 7365 7420  ch size={}, set 
-00009a00: 746f 207b 7d20 6e6f 772e 222e 666f 726d  to {} now.".form
-00009a10: 6174 280a 2020 2020 2020 2020 2020 2020  at(.            
-00009a20: 2020 2020 2020 2020 2020 2020 6261 7463              batc
-00009a30: 685f 7369 7a65 2c20 3129 290a 2020 2020  h_size, 1)).    
+00009800: 2020 2020 2020 2020 7275 6e6e 696e 675f          running_
+00009810: 6d6f 6465 3d27 6361 6c69 6272 6174 696f  mode='calibratio
+00009820: 6e27 290a 2020 2020 2020 2020 2020 2020  n').            
+00009830: 2020 2020 6966 2069 6478 203e 3d20 746d      if idx >= tm
+00009840: 705f 6974 6572 6174 696f 6e73 202d 2031  p_iterations - 1
+00009850: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00009860: 2020 2020 2020 6272 6561 6b0a 0a20 2020        break..   
+00009870: 2064 6566 206d 6f64 656c 5f63 616c 6962   def model_calib
+00009880: 7261 7469 6f6e 2873 656c 662c 0a20 2020  ration(self,.   
+00009890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000098a0: 2020 2020 2020 2071 5f6d 6f64 656c 2c0a         q_model,.
+000098b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000098c0: 2020 2020 2020 2020 2020 6461 7461 6c6f            datalo
+000098d0: 6164 6572 2c0a 2020 2020 2020 2020 2020  ader,.          
+000098e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000098f0: 6974 6572 6174 696f 6e73 3d31 2c0a 2020  iterations=1,.  
+00009900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009910: 2020 2020 2020 2020 636f 6e66 3d4e 6f6e          conf=Non
+00009920: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00009930: 2020 2020 2020 2020 2020 2020 2063 616c               cal
+00009940: 6962 5f73 616d 706c 696e 675f 7369 7a65  ib_sampling_size
+00009950: 3d31 293a 0a20 2020 2020 2020 2061 7373  =1):.        ass
+00009960: 6572 7420 6974 6572 6174 696f 6e73 203e  ert iterations >
+00009970: 2030 0a20 2020 2020 2020 2077 6974 6820   0.        with 
+00009980: 746f 7263 682e 6e6f 5f67 7261 6428 293a  torch.no_grad():
+00009990: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+000099a0: 6973 696e 7374 616e 6365 2864 6174 616c  isinstance(datal
+000099b0: 6f61 6465 722c 2042 6173 6544 6174 614c  oader, BaseDataL
+000099c0: 6f61 6465 7229 3a0a 2020 2020 2020 2020  oader):.        
+000099d0: 2020 2020 2020 2020 6261 7463 685f 7369          batch_si
+000099e0: 7a65 203d 2064 6174 616c 6f61 6465 722e  ze = dataloader.
+000099f0: 6261 7463 685f 7369 7a65 0a20 2020 2020  batch_size.     
+00009a00: 2020 2020 2020 2020 2020 2074 7279 3a0a             try:.
+00009a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009a20: 2020 2020 666f 7220 6920 696e 2072 616e      for i in ran
+00009a30: 6765 2862 6174 6368 5f73 697a 6529 3a0a  ge(batch_size):.
 00009a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009a50: 6461 7461 6c6f 6164 6572 2e62 6174 6368  dataloader.batch
-00009a60: 2831 290a 2020 2020 2020 2020 2020 2020  (1).            
-00009a70: 2020 2020 2020 2020 7365 6c66 2e63 616c          self.cal
-00009a80: 6962 5f66 756e 6328 715f 6d6f 6465 6c2c  ib_func(q_model,
-00009a90: 2064 6174 616c 6f61 6465 722c 2063 616c   dataloader, cal
-00009aa0: 6962 5f73 616d 706c 696e 675f 7369 7a65  ib_sampling_size
-00009ab0: 2c20 636f 6e66 290a 2020 2020 2020 2020  , conf).        
-00009ac0: 2020 2020 656c 7365 3a20 2023 2070 7261      else:  # pra
-00009ad0: 676d 613a 206e 6f20 636f 7665 720a 2020  gma: no cover.  
-00009ae0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00009af0: 2068 6173 6174 7472 2864 6174 616c 6f61   hasattr(dataloa
-00009b00: 6465 722c 2027 6261 7463 685f 7369 7a65  der, 'batch_size
-00009b10: 2729 2061 6e64 205c 0a20 2020 2020 2020  ') and \.       
-00009b20: 2020 2020 2020 2020 2020 2063 616c 6962             calib
-00009b30: 5f73 616d 706c 696e 675f 7369 7a65 2025  _sampling_size %
-00009b40: 2064 6174 616c 6f61 6465 722e 6261 7463   dataloader.batc
-00009b50: 685f 7369 7a65 2021 3d20 303a 0a20 2020  h_size != 0:.   
+00009a50: 2020 2020 2020 2020 6966 2063 616c 6962          if calib
+00009a60: 5f73 616d 706c 696e 675f 7369 7a65 2025  _sampling_size %
+00009a70: 2028 6261 7463 685f 7369 7a65 202d 2069   (batch_size - i
+00009a80: 2920 3d3d 2030 3a0a 2020 2020 2020 2020  ) == 0:.        
+00009a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009aa0: 2020 2020 6361 6c69 625f 6261 7463 685f      calib_batch_
+00009ab0: 7369 7a65 203d 2062 6174 6368 5f73 697a  size = batch_siz
+00009ac0: 6520 2d20 690a 2020 2020 2020 2020 2020  e - i.          
+00009ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009ae0: 2020 6966 2069 2021 3d20 303a 0a20 2020    if i != 0:.   
+00009af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009b00: 2020 2020 2020 2020 2020 2020 206c 6f67               log
+00009b10: 6765 722e 7761 726e 696e 6728 2252 6573  ger.warning("Res
+00009b20: 6574 2060 6361 6c69 6272 6174 696f 6e2e  et `calibration.
+00009b30: 6461 7461 6c6f 6164 6572 2e62 6174 6368  dataloader.batch
+00009b40: 5f73 697a 6560 2066 6965 6c64 2022 0a20  _size` field ". 
+00009b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009b70: 206c 6f67 6765 722e 7761 726e 696e 6728   logger.warning(
-00009b80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009b90: 2020 2020 2020 2020 2022 506c 6561 7365           "Please
-00009ba0: 206e 6f74 6520 7468 6174 2063 616c 6962   note that calib
-00009bb0: 7261 7469 6f6e 2073 616d 706c 696e 6720  ration sampling 
-00009bc0: 7369 7a65 207b 7d20 2220 5c0a 2020 2020  size {} " \.    
-00009bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009be0: 2020 2020 2269 736e 2774 2064 6976 6973      "isn't divis
-00009bf0: 6962 6c65 2065 7861 6374 6c79 2062 7920  ible exactly by 
-00009c00: 6261 7463 6820 7369 7a65 207b 7d2e 2022  batch size {}. "
-00009c10: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00009c20: 2020 2020 2020 2020 2020 2022 536f 2074             "So t
-00009c30: 6865 2072 6561 6c20 7361 6d70 6c69 6e67  he real sampling
-00009c40: 2073 697a 6520 6973 207b 7d2e 222e 0a20   size is {}.".. 
+00009b70: 2020 2020 2020 2020 2020 2020 2020 2274                "t
+00009b80: 6f20 7b7d 222e 666f 726d 6174 2863 616c  o {}".format(cal
+00009b90: 6962 5f62 6174 6368 5f73 697a 6529 202b  ib_batch_size) +
+00009ba0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009bd0: 2220 746f 206d 616b 6520 7375 7265 2074  " to make sure t
+00009be0: 6865 2073 616d 706c 696e 675f 7369 7a65  he sampling_size
+00009bf0: 2069 7320 220a 2020 2020 2020 2020 2020   is ".          
+00009c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009c20: 2020 2020 2022 6469 7669 7369 626c 6520       "divisible 
+00009c30: 6578 6163 746c 7920 6279 2062 6174 6368  exactly by batch
+00009c40: 2073 697a 6522 290a 2020 2020 2020 2020   size").        
 00009c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009c60: 2020 2020 2020 2066 6f72 6d61 7428 6361         format(ca
-00009c70: 6c69 625f 7361 6d70 6c69 6e67 5f73 697a  lib_sampling_siz
-00009c80: 652c 2064 6174 616c 6f61 6465 722e 6261  e, dataloader.ba
-00009c90: 7463 685f 7369 7a65 2c0a 2020 2020 2020  tch_size,.      
-00009ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009cb0: 2020 2020 2020 2020 2064 6174 616c 6f61           dataloa
-00009cc0: 6465 722e 6261 7463 685f 7369 7a65 202a  der.batch_size *
-00009cd0: 2069 7465 7261 7469 6f6e 7329 290a 0a20   iterations)).. 
-00009ce0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00009cf0: 656c 662e 6361 6c69 625f 6675 6e63 2871  elf.calib_func(q
-00009d00: 5f6d 6f64 656c 2c20 6461 7461 6c6f 6164  _model, dataload
-00009d10: 6572 2c20 6974 6572 6174 696f 6e73 2c20  er, iterations, 
-00009d20: 636f 6e66 290a 0a20 2020 2064 6566 2065  conf)..    def e
-00009d30: 7661 6c5f 6675 6e63 2873 656c 662c 206d  val_func(self, m
-00009d40: 6f64 656c 2c20 6461 7461 6c6f 6164 6572  odel, dataloader
-00009d50: 2c20 706f 7374 7072 6f63 6573 732c 206d  , postprocess, m
-00009d60: 6574 7269 6373 2c20 6d65 6173 7572 6572  etrics, measurer
-00009d70: 2c20 6974 6572 6174 696f 6e2c 2063 6f6e  , iteration, con
-00009d80: 663d 4e6f 6e65 293a 0a20 2020 2020 2020  f=None):.       
-00009d90: 2072 6573 756c 7473 203d 205b 5d0a 2020   results = [].  
-00009da0: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
-00009db0: 2020 2020 2020 2066 6f72 2069 6478 2c20         for idx, 
-00009dc0: 2869 6e70 7574 2c20 6c61 6265 6c29 2069  (input, label) i
-00009dd0: 6e20 656e 756d 6572 6174 6528 6461 7461  n enumerate(data
-00009de0: 6c6f 6164 6572 293a 0a20 2020 2020 2020  loader):.       
-00009df0: 2020 2020 2020 2020 2069 6620 6d65 6173           if meas
-00009e00: 7572 6572 2069 7320 6e6f 7420 4e6f 6e65  urer is not None
-00009e10: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00009e20: 2020 2020 2020 6d65 6173 7572 6572 2e73        measurer.s
-00009e30: 7461 7274 2829 0a0a 2020 2020 2020 2020  tart()..        
-00009e40: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00009e50: 2070 7974 6f72 6368 5f66 6f72 7761 7264   pytorch_forward
-00009e60: 5f77 7261 7070 6572 286d 6f64 656c 2c20  _wrapper(model, 
-00009e70: 696e 7075 742c 2064 6576 6963 653d 7365  input, device=se
-00009e80: 6c66 2e64 6576 6963 652c 2063 6f6e 663d  lf.device, conf=
-00009e90: 636f 6e66 290a 2020 2020 2020 2020 2020  conf).          
-00009ea0: 2020 2020 2020 6966 2073 656c 662e 6465        if self.de
-00009eb0: 7669 6365 2021 3d20 2263 7075 223a 2020  vice != "cpu":  
-00009ec0: 2320 7072 6167 6d61 3a20 6e6f 2063 6f76  # pragma: no cov
-00009ed0: 6572 0a20 2020 2020 2020 2020 2020 2020  er.             
-00009ee0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00009ef0: 6f75 7470 7574 2e74 6f28 2263 7075 2229  output.to("cpu")
-00009f00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009f10: 2020 2020 206c 6162 656c 203d 206c 6162       label = lab
-00009f20: 656c 2e74 6f28 2263 7075 2229 0a20 2020  el.to("cpu").   
-00009f30: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00009f40: 6d65 6173 7572 6572 2069 7320 6e6f 7420  measurer is not 
-00009f50: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00009f60: 2020 2020 2020 2020 2020 6d65 6173 7572            measur
-00009f70: 6572 2e65 6e64 2829 0a20 2020 2020 2020  er.end().       
-00009f80: 2020 2020 2020 2020 2069 6620 706f 7374           if post
-00009f90: 7072 6f63 6573 7320 6973 206e 6f74 204e  process is not N
-00009fa0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-00009fb0: 2020 2020 2020 2020 206f 7574 7075 742c           output,
-00009fc0: 206c 6162 656c 203d 2070 6f73 7470 726f   label = postpro
-00009fd0: 6365 7373 2828 6f75 7470 7574 2c20 6c61  cess((output, la
-00009fe0: 6265 6c29 290a 2020 2020 2020 2020 2020  bel)).          
-00009ff0: 2020 2020 2020 6966 206d 6574 7269 6373        if metrics
-0000a000: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000a010: 2020 2020 2020 666f 7220 6d65 7472 6963        for metric
-0000a020: 2069 6e20 6d65 7472 6963 733a 0a20 2020   in metrics:.   
-0000a030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a040: 2020 2020 2069 6620 6e6f 7420 6861 7361       if not hasa
-0000a050: 7474 7228 6d65 7472 6963 2c20 2263 6f6d  ttr(metric, "com
-0000a060: 7061 7265 5f6c 6162 656c 2229 206f 7220  pare_label") or 
-0000a070: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-0000a080: 2020 2020 2020 2020 2020 2020 2020 2868                (h
-0000a090: 6173 6174 7472 286d 6574 7269 632c 2022  asattr(metric, "
-0000a0a0: 636f 6d70 6172 655f 6c61 6265 6c22 2920  compare_label") 
-0000a0b0: 616e 6420 6d65 7472 6963 2e63 6f6d 7061  and metric.compa
-0000a0c0: 7265 5f6c 6162 656c 293a 0a20 2020 2020  re_label):.     
-0000a0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a0e0: 2020 2020 2020 206d 6574 7269 632e 7570         metric.up
-0000a0f0: 6461 7465 286f 7574 7075 742c 206c 6162  date(output, lab
-0000a100: 656c 290a 0a20 2020 2020 2020 2020 2020  el)..           
-0000a110: 2020 2020 2020 2020 2023 2049 6620 6469           # If di
-0000a120: 7374 7269 6275 7465 6420 6461 7461 6c6f  stributed datalo
-0000a130: 6164 6572 2c20 6761 7468 6572 2061 6c6c  ader, gather all
-0000a140: 206f 7574 7075 7473 2074 6f20 7570 6461   outputs to upda
-0000a150: 7465 206d 6574 7269 630a 2020 2020 2020  te metric.      
-0000a160: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0000a170: 2067 6574 6174 7472 2864 6174 616c 6f61   getattr(dataloa
-0000a180: 6465 722c 2027 6469 7374 7269 6275 7465  der, 'distribute
-0000a190: 6427 2c20 4661 6c73 6529 206f 7220 5c0a  d', False) or \.
-0000a1a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a1b0: 2020 2020 2020 6973 696e 7374 616e 6365        isinstance
-0000a1c0: 2864 6174 616c 6f61 6465 722e 7361 6d70  (dataloader.samp
-0000a1d0: 6c65 722c 205c 0a20 2020 2020 2020 2020  ler, \.         
-0000a1e0: 2020 2020 2020 2020 2020 2020 2074 6f72               tor
-0000a1f0: 6368 2e75 7469 6c73 2e64 6174 612e 6469  ch.utils.data.di
-0000a200: 7374 7269 6275 7465 642e 4469 7374 7269  stributed.Distri
-0000a210: 6275 7465 6453 616d 706c 6572 293a 0a20  butedSampler):. 
-0000a220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a230: 2020 2020 2020 2068 7664 2e69 6e69 7428         hvd.init(
-0000a240: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-0000a250: 2020 2020 2020 2020 2020 666f 7220 6d65            for me
-0000a260: 7472 6963 2069 6e20 6d65 7472 6963 733a  tric in metrics:
-0000a270: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000a280: 2020 2020 2020 2020 2020 2020 206d 6574               met
-0000a290: 7269 632e 6876 6420 3d20 6876 640a 0a20  ric.hvd = hvd.. 
-0000a2a0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000a2b0: 6620 7365 6c66 2e66 7033 325f 7072 6564  f self.fp32_pred
-0000a2c0: 735f 6173 5f6c 6162 656c 3a0a 2020 2020  s_as_label:.    
+00009c60: 2020 2020 6272 6561 6b0a 2020 2020 2020      break.      
+00009c70: 2020 2020 2020 2020 2020 2020 2020 746d                tm
+00009c80: 705f 6974 6572 6174 696f 6e73 203d 2069  p_iterations = i
+00009c90: 6e74 286d 6174 682e 6365 696c 2863 616c  nt(math.ceil(cal
+00009ca0: 6962 5f73 616d 706c 696e 675f 7369 7a65  ib_sampling_size
+00009cb0: 202f 2063 616c 6962 5f62 6174 6368 5f73   / calib_batch_s
+00009cc0: 697a 6529 290a 2020 2020 2020 2020 2020  ize)).          
+00009cd0: 2020 2020 2020 2020 2020 6461 7461 6c6f            datalo
+00009ce0: 6164 6572 2e62 6174 6368 2863 616c 6962  ader.batch(calib
+00009cf0: 5f62 6174 6368 5f73 697a 6529 0a20 2020  _batch_size).   
+00009d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009d10: 2073 656c 662e 6361 6c69 625f 6675 6e63   self.calib_func
+00009d20: 2871 5f6d 6f64 656c 2c20 6461 7461 6c6f  (q_model, datalo
+00009d30: 6164 6572 2c20 746d 705f 6974 6572 6174  ader, tmp_iterat
+00009d40: 696f 6e73 2c20 636f 6e66 290a 2020 2020  ions, conf).    
+00009d50: 2020 2020 2020 2020 2020 2020 6578 6365              exce
+00009d60: 7074 2045 7863 6570 7469 6f6e 3a20 2023  pt Exception:  #
+00009d70: 2070 7261 676d 613a 206e 6f20 636f 7665   pragma: no cove
+00009d80: 720a 2020 2020 2020 2020 2020 2020 2020  r.              
+00009d90: 2020 2020 2020 6c6f 6767 6572 2e77 6172        logger.war
+00009da0: 6e69 6e67 2822 4661 696c 2074 6f20 666f  ning("Fail to fo
+00009db0: 7277 6172 6420 7769 7468 2062 6174 6368  rward with batch
+00009dc0: 2073 697a 653d 7b7d 2c20 7365 7420 746f   size={}, set to
+00009dd0: 207b 7d20 6e6f 772e 222e 666f 726d 6174   {} now.".format
+00009de0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00009df0: 2020 2020 2020 2020 2020 6261 7463 685f            batch_
+00009e00: 7369 7a65 2c20 3129 290a 2020 2020 2020  size, 1)).      
+00009e10: 2020 2020 2020 2020 2020 2020 2020 6461                da
+00009e20: 7461 6c6f 6164 6572 2e62 6174 6368 2831  taloader.batch(1
+00009e30: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00009e40: 2020 2020 2020 7365 6c66 2e63 616c 6962        self.calib
+00009e50: 5f66 756e 6328 715f 6d6f 6465 6c2c 2064  _func(q_model, d
+00009e60: 6174 616c 6f61 6465 722c 2063 616c 6962  ataloader, calib
+00009e70: 5f73 616d 706c 696e 675f 7369 7a65 2c20  _sampling_size, 
+00009e80: 636f 6e66 290a 2020 2020 2020 2020 2020  conf).          
+00009e90: 2020 656c 7365 3a20 2023 2070 7261 676d    else:  # pragm
+00009ea0: 613a 206e 6f20 636f 7665 720a 2020 2020  a: no cover.    
+00009eb0: 2020 2020 2020 2020 2020 2020 6966 2068              if h
+00009ec0: 6173 6174 7472 2864 6174 616c 6f61 6465  asattr(dataloade
+00009ed0: 722c 2027 6261 7463 685f 7369 7a65 2729  r, 'batch_size')
+00009ee0: 2061 6e64 205c 0a20 2020 2020 2020 2020   and \.         
+00009ef0: 2020 2020 2020 2020 2063 616c 6962 5f73           calib_s
+00009f00: 616d 706c 696e 675f 7369 7a65 2025 2064  ampling_size % d
+00009f10: 6174 616c 6f61 6465 722e 6261 7463 685f  ataloader.batch_
+00009f20: 7369 7a65 2021 3d20 303a 0a20 2020 2020  size != 0:.     
+00009f30: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+00009f40: 6f67 6765 722e 7761 726e 696e 6728 0a20  ogger.warning(. 
+00009f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f60: 2020 2020 2020 2022 506c 6561 7365 206e         "Please n
+00009f70: 6f74 6520 7468 6174 2063 616c 6962 7261  ote that calibra
+00009f80: 7469 6f6e 2073 616d 706c 696e 6720 7369  tion sampling si
+00009f90: 7a65 207b 7d20 2220 5c0a 2020 2020 2020  ze {} " \.      
+00009fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009fb0: 2020 2269 736e 2774 2064 6976 6973 6962    "isn't divisib
+00009fc0: 6c65 2065 7861 6374 6c79 2062 7920 6261  le exactly by ba
+00009fd0: 7463 6820 7369 7a65 207b 7d2e 2022 205c  tch size {}. " \
+00009fe0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009ff0: 2020 2020 2020 2020 2022 536f 2074 6865           "So the
+0000a000: 2072 6561 6c20 7361 6d70 6c69 6e67 2073   real sampling s
+0000a010: 697a 6520 6973 207b 7d2e 222e 0a20 2020  ize is {}."..   
+0000a020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a030: 2020 2020 2066 6f72 6d61 7428 6361 6c69       format(cali
+0000a040: 625f 7361 6d70 6c69 6e67 5f73 697a 652c  b_sampling_size,
+0000a050: 2064 6174 616c 6f61 6465 722e 6261 7463   dataloader.batc
+0000a060: 685f 7369 7a65 2c0a 2020 2020 2020 2020  h_size,.        
+0000a070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a080: 2020 2020 2020 2064 6174 616c 6f61 6465         dataloade
+0000a090: 722e 6261 7463 685f 7369 7a65 202a 2069  r.batch_size * i
+0000a0a0: 7465 7261 7469 6f6e 7329 290a 0a20 2020  terations))..   
+0000a0b0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+0000a0c0: 662e 6361 6c69 625f 6675 6e63 2871 5f6d  f.calib_func(q_m
+0000a0d0: 6f64 656c 2c20 6461 7461 6c6f 6164 6572  odel, dataloader
+0000a0e0: 2c20 6974 6572 6174 696f 6e73 2c20 636f  , iterations, co
+0000a0f0: 6e66 290a 0a20 2020 2064 6566 2065 7661  nf)..    def eva
+0000a100: 6c5f 6675 6e63 2873 656c 662c 206d 6f64  l_func(self, mod
+0000a110: 656c 2c20 6461 7461 6c6f 6164 6572 2c20  el, dataloader, 
+0000a120: 706f 7374 7072 6f63 6573 732c 206d 6574  postprocess, met
+0000a130: 7269 6373 2c20 6d65 6173 7572 6572 2c20  rics, measurer, 
+0000a140: 6974 6572 6174 696f 6e2c 2063 6f6e 663d  iteration, conf=
+0000a150: 4e6f 6e65 293a 0a20 2020 2020 2020 2072  None):.        r
+0000a160: 6573 756c 7473 203d 205b 5d0a 2020 2020  esults = [].    
+0000a170: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
+0000a180: 2020 2020 2066 6f72 2069 6478 2c20 2869       for idx, (i
+0000a190: 6e70 7574 2c20 6c61 6265 6c29 2069 6e20  nput, label) in 
+0000a1a0: 656e 756d 6572 6174 6528 6461 7461 6c6f  enumerate(datalo
+0000a1b0: 6164 6572 293a 0a20 2020 2020 2020 2020  ader):.         
+0000a1c0: 2020 2020 2020 2069 6620 6d65 6173 7572         if measur
+0000a1d0: 6572 2069 7320 6e6f 7420 4e6f 6e65 3a0a  er is not None:.
+0000a1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a1f0: 2020 2020 6d65 6173 7572 6572 2e73 7461      measurer.sta
+0000a200: 7274 2829 0a0a 2020 2020 2020 2020 2020  rt()..          
+0000a210: 2020 2020 2020 6f75 7470 7574 203d 2070        output = p
+0000a220: 7974 6f72 6368 5f66 6f72 7761 7264 5f77  ytorch_forward_w
+0000a230: 7261 7070 6572 286d 6f64 656c 2c20 696e  rapper(model, in
+0000a240: 7075 742c 2064 6576 6963 653d 7365 6c66  put, device=self
+0000a250: 2e64 6576 6963 652c 2063 6f6e 663d 636f  .device, conf=co
+0000a260: 6e66 290a 2020 2020 2020 2020 2020 2020  nf).            
+0000a270: 2020 2020 6966 2073 656c 662e 6465 7669      if self.devi
+0000a280: 6365 2021 3d20 2263 7075 223a 2020 2320  ce != "cpu":  # 
+0000a290: 7072 6167 6d61 3a20 6e6f 2063 6f76 6572  pragma: no cover
+0000a2a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a2b0: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
+0000a2c0: 7470 7574 2e74 6f28 2263 7075 2229 0a20  tput.to("cpu"). 
 0000a2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a2e0: 7365 6c66 2e66 7033 325f 7265 7375 6c74  self.fp32_result
-0000a2f0: 732e 6170 7065 6e64 286f 7574 7075 7429  s.append(output)
-0000a300: 2069 6620 7365 6c66 2e69 735f 6261 7365   if self.is_base
-0000a310: 6c69 6e65 2065 6c73 6520 5c0a 2020 2020  line else \.    
-0000a320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a330: 2020 2020 7265 7375 6c74 732e 6170 7065      results.appe
-0000a340: 6e64 286f 7574 7075 7429 0a20 2020 2020  nd(output).     
-0000a350: 2020 2020 2020 2020 2020 2069 6620 6964             if id
-0000a360: 7820 2b20 3120 3d3d 2069 7465 7261 7469  x + 1 == iterati
-0000a370: 6f6e 3a0a 2020 2020 2020 2020 2020 2020  on:.            
-0000a380: 2020 2020 2020 2020 6272 6561 6b0a 2020          break.  
-0000a390: 2020 2020 2020 6578 6365 7074 2045 7863        except Exc
-0000a3a0: 6570 7469 6f6e 2061 7320 653a 0a20 2020  eption as e:.   
-0000a3b0: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
-0000a3c0: 7761 726e 696e 6728 2254 6865 2064 6174  warning("The dat
-0000a3d0: 616c 6f61 6465 7220 6469 646e 2774 2069  aloader didn't i
-0000a3e0: 6e63 6c75 6465 206c 6162 656c 2c20 7769  nclude label, wi
-0000a3f0: 6c6c 2074 7279 2069 6e70 7574 2077 6974  ll try input wit
-0000a400: 686f 7574 206c 6162 656c 2122 290a 2020  hout label!").  
-0000a410: 2020 2020 2020 2020 2020 666f 7220 6964            for id
-0000a420: 782c 2069 6e70 7574 2069 6e20 656e 756d  x, input in enum
-0000a430: 6572 6174 6528 6461 7461 6c6f 6164 6572  erate(dataloader
-0000a440: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0000a450: 2020 2069 6620 2869 7369 6e73 7461 6e63     if (isinstanc
-0000a460: 6528 696e 7075 742c 2064 6963 7429 206f  e(input, dict) o
-0000a470: 7220 6973 696e 7374 616e 6365 2869 6e70  r isinstance(inp
-0000a480: 7574 2c20 5573 6572 4469 6374 2929 3a0a  ut, UserDict)):.
-0000a490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a4a0: 2020 2020 6966 206e 6f74 2073 656c 662e      if not self.
-0000a4b0: 6265 6e63 686d 6172 6b3a 0a20 2020 2020  benchmark:.     
-0000a4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a4d0: 2020 2061 7373 6572 7420 226c 6162 656c     assert "label
-0000a4e0: 2220 696e 2069 6e70 7574 2c20 5c0a 2020  " in input, \.  
-0000a4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a500: 2020 2020 2020 2020 2020 2254 6865 2064            "The d
-0000a510: 6174 616c 6f61 6465 7220 6d75 7374 2069  ataloader must i
-0000a520: 6e63 6c75 6465 206c 6162 656c 2074 6f20  nclude label to 
-0000a530: 6d65 6173 7572 6520 7468 6520 6d65 7472  measure the metr
-0000a540: 6963 2122 0a20 2020 2020 2020 2020 2020  ic!".           
-0000a550: 2020 2020 2020 2020 2020 2020 206c 6162               lab
-0000a560: 656c 203d 2069 6e70 7574 5b22 6c61 6265  el = input["labe
-0000a570: 6c22 5d2e 746f 2822 6370 7522 290a 2020  l"].to("cpu").  
-0000a580: 2020 2020 2020 2020 2020 2020 2020 656c                el
-0000a590: 6966 206e 6f74 2073 656c 662e 6265 6e63  if not self.benc
-0000a5a0: 686d 6172 6b3a 0a20 2020 2020 2020 2020  hmark:.         
-0000a5b0: 2020 2020 2020 2020 2020 2061 7373 6572             asser
-0000a5c0: 7420 4661 6c73 652c 2022 5468 6520 6461  t False, "The da
-0000a5d0: 7461 6c6f 6164 6572 206d 7573 7420 696e  taloader must in
-0000a5e0: 636c 7564 6520 6c61 6265 6c20 746f 206d  clude label to m
-0000a5f0: 6561 7375 7265 2074 6865 206d 6574 7269  easure the metri
-0000a600: 6321 220a 0a20 2020 2020 2020 2020 2020  c!"..           
-0000a610: 2020 2020 2069 6620 6d65 6173 7572 6572       if measurer
-0000a620: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-0000a630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a640: 2020 6d65 6173 7572 6572 2e73 7461 7274    measurer.start
-0000a650: 2829 0a0a 2020 2020 2020 2020 2020 2020  ()..            
-0000a660: 2020 2020 6f75 7470 7574 203d 2070 7974      output = pyt
-0000a670: 6f72 6368 5f66 6f72 7761 7264 5f77 7261  orch_forward_wra
-0000a680: 7070 6572 286d 6f64 656c 2c20 696e 7075  pper(model, inpu
-0000a690: 742c 2064 6576 6963 653d 7365 6c66 2e64  t, device=self.d
-0000a6a0: 6576 6963 652c 2063 6f6e 663d 636f 6e66  evice, conf=conf
-0000a6b0: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
-0000a6c0: 2020 2069 6620 6d65 6173 7572 6572 2069     if measurer i
-0000a6d0: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
-0000a6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a6f0: 6d65 6173 7572 6572 2e65 6e64 2829 0a0a  measurer.end()..
-0000a700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a710: 6966 2073 656c 662e 6465 7669 6365 2021  if self.device !
-0000a720: 3d20 2263 7075 2220 616e 6420 6e6f 7420  = "cpu" and not 
-0000a730: 7365 6c66 2e62 656e 6368 6d61 726b 3a20  self.benchmark: 
-0000a740: 2023 2070 7261 676d 613a 206e 6f20 636f   # pragma: no co
-0000a750: 7665 720a 2020 2020 2020 2020 2020 2020  ver.            
-0000a760: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
-0000a770: 7461 6e63 6528 6f75 7470 7574 2c20 6469  tance(output, di
-0000a780: 6374 2920 6f72 2069 7369 6e73 7461 6e63  ct) or isinstanc
-0000a790: 6528 696e 7075 742c 2055 7365 7244 6963  e(input, UserDic
-0000a7a0: 7429 3a0a 2020 2020 2020 2020 2020 2020  t):.            
-0000a7b0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-0000a7c0: 6b65 7920 696e 206f 7574 7075 743a 0a20  key in output:. 
-0000a7d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a7e0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-0000a7f0: 745b 6b65 795d 203d 206f 7574 7075 745b  t[key] = output[
-0000a800: 6b65 795d 2e74 6f28 2263 7075 2229 0a20  key].to("cpu"). 
-0000a810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a820: 2020 2065 6c69 6620 6973 696e 7374 616e     elif isinstan
-0000a830: 6365 286f 7574 7075 742c 206c 6973 7429  ce(output, list)
-0000a840: 206f 7220 6973 696e 7374 616e 6365 286f   or isinstance(o
-0000a850: 7574 7075 742c 2074 7570 6c65 293a 0a20  utput, tuple):. 
+0000a2e0: 2020 206c 6162 656c 203d 206c 6162 656c     label = label
+0000a2f0: 2e74 6f28 2263 7075 2229 0a20 2020 2020  .to("cpu").     
+0000a300: 2020 2020 2020 2020 2020 2069 6620 6d65             if me
+0000a310: 6173 7572 6572 2069 7320 6e6f 7420 4e6f  asurer is not No
+0000a320: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+0000a330: 2020 2020 2020 2020 6d65 6173 7572 6572          measurer
+0000a340: 2e65 6e64 2829 0a20 2020 2020 2020 2020  .end().         
+0000a350: 2020 2020 2020 2069 6620 706f 7374 7072         if postpr
+0000a360: 6f63 6573 7320 6973 206e 6f74 204e 6f6e  ocess is not Non
+0000a370: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+0000a380: 2020 2020 2020 206f 7574 7075 742c 206c         output, l
+0000a390: 6162 656c 203d 2070 6f73 7470 726f 6365  abel = postproce
+0000a3a0: 7373 2828 6f75 7470 7574 2c20 6c61 6265  ss((output, labe
+0000a3b0: 6c29 290a 2020 2020 2020 2020 2020 2020  l)).            
+0000a3c0: 2020 2020 6966 206d 6574 7269 6373 3a0a      if metrics:.
+0000a3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a3e0: 2020 2020 666f 7220 6d65 7472 6963 2069      for metric i
+0000a3f0: 6e20 6d65 7472 6963 733a 0a20 2020 2020  n metrics:.     
+0000a400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a410: 2020 2069 6620 6e6f 7420 6861 7361 7474     if not hasatt
+0000a420: 7228 6d65 7472 6963 2c20 2263 6f6d 7061  r(metric, "compa
+0000a430: 7265 5f6c 6162 656c 2229 206f 7220 5c0a  re_label") or \.
+0000a440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a450: 2020 2020 2020 2020 2020 2020 2868 6173              (has
+0000a460: 6174 7472 286d 6574 7269 632c 2022 636f  attr(metric, "co
+0000a470: 6d70 6172 655f 6c61 6265 6c22 2920 616e  mpare_label") an
+0000a480: 6420 6d65 7472 6963 2e63 6f6d 7061 7265  d metric.compare
+0000a490: 5f6c 6162 656c 293a 0a20 2020 2020 2020  _label):.       
+0000a4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a4b0: 2020 2020 206d 6574 7269 632e 7570 6461       metric.upda
+0000a4c0: 7465 286f 7574 7075 742c 206c 6162 656c  te(output, label
+0000a4d0: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
+0000a4e0: 2020 2020 2020 2023 2049 6620 6469 7374         # If dist
+0000a4f0: 7269 6275 7465 6420 6461 7461 6c6f 6164  ributed dataload
+0000a500: 6572 2c20 6761 7468 6572 2061 6c6c 206f  er, gather all o
+0000a510: 7574 7075 7473 2074 6f20 7570 6461 7465  utputs to update
+0000a520: 206d 6574 7269 630a 2020 2020 2020 2020   metric.        
+0000a530: 2020 2020 2020 2020 2020 2020 6966 2067              if g
+0000a540: 6574 6174 7472 2864 6174 616c 6f61 6465  etattr(dataloade
+0000a550: 722c 2027 6469 7374 7269 6275 7465 6427  r, 'distributed'
+0000a560: 2c20 4661 6c73 6529 206f 7220 5c0a 2020  , False) or \.  
+0000a570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a580: 2020 2020 6973 696e 7374 616e 6365 2864      isinstance(d
+0000a590: 6174 616c 6f61 6465 722e 7361 6d70 6c65  ataloader.sample
+0000a5a0: 722c 205c 0a20 2020 2020 2020 2020 2020  r, \.           
+0000a5b0: 2020 2020 2020 2020 2020 2074 6f72 6368             torch
+0000a5c0: 2e75 7469 6c73 2e64 6174 612e 6469 7374  .utils.data.dist
+0000a5d0: 7269 6275 7465 642e 4469 7374 7269 6275  ributed.Distribu
+0000a5e0: 7465 6453 616d 706c 6572 293a 0a20 2020  tedSampler):.   
+0000a5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a600: 2020 2020 2068 7664 2e69 6e69 7428 290a       hvd.init().
+0000a610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a620: 2020 2020 2020 2020 666f 7220 6d65 7472          for metr
+0000a630: 6963 2069 6e20 6d65 7472 6963 733a 0a20  ic in metrics:. 
+0000a640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a650: 2020 2020 2020 2020 2020 206d 6574 7269             metri
+0000a660: 632e 6876 6420 3d20 6876 640a 0a20 2020  c.hvd = hvd..   
+0000a670: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0000a680: 7365 6c66 2e66 7033 325f 7072 6564 735f  self.fp32_preds_
+0000a690: 6173 5f6c 6162 656c 3a0a 2020 2020 2020  as_label:.      
+0000a6a0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+0000a6b0: 6c66 2e66 7033 325f 7265 7375 6c74 732e  lf.fp32_results.
+0000a6c0: 6170 7065 6e64 286f 7574 7075 7429 2069  append(output) i
+0000a6d0: 6620 7365 6c66 2e69 735f 6261 7365 6c69  f self.is_baseli
+0000a6e0: 6e65 2065 6c73 6520 5c0a 2020 2020 2020  ne else \.      
+0000a6f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a700: 2020 7265 7375 6c74 732e 6170 7065 6e64    results.append
+0000a710: 286f 7574 7075 7429 0a20 2020 2020 2020  (output).       
+0000a720: 2020 2020 2020 2020 2069 6620 6964 7820           if idx 
+0000a730: 2b20 3120 3d3d 2069 7465 7261 7469 6f6e  + 1 == iteration
+0000a740: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000a750: 2020 2020 2020 6272 6561 6b0a 2020 2020        break.    
+0000a760: 2020 2020 6578 6365 7074 2045 7863 6570      except Excep
+0000a770: 7469 6f6e 2061 7320 653a 0a20 2020 2020  tion as e:.     
+0000a780: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
+0000a790: 726e 696e 6728 2254 6865 2064 6174 616c  rning("The datal
+0000a7a0: 6f61 6465 7220 6469 646e 2774 2069 6e63  oader didn't inc
+0000a7b0: 6c75 6465 206c 6162 656c 2c20 7769 6c6c  lude label, will
+0000a7c0: 2074 7279 2069 6e70 7574 2077 6974 686f   try input witho
+0000a7d0: 7574 206c 6162 656c 2122 290a 2020 2020  ut label!").    
+0000a7e0: 2020 2020 2020 2020 666f 7220 6964 782c          for idx,
+0000a7f0: 2069 6e70 7574 2069 6e20 656e 756d 6572   input in enumer
+0000a800: 6174 6528 6461 7461 6c6f 6164 6572 293a  ate(dataloader):
+0000a810: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a820: 2069 6620 2869 7369 6e73 7461 6e63 6528   if (isinstance(
+0000a830: 696e 7075 742c 2064 6963 7429 206f 7220  input, dict) or 
+0000a840: 6973 696e 7374 616e 6365 2869 6e70 7574  isinstance(input
+0000a850: 2c20 5573 6572 4469 6374 2929 3a0a 2020  , UserDict)):.  
 0000a860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a870: 2020 2020 2020 2066 6f72 2074 656e 736f         for tenso
-0000a880: 7220 696e 206f 7574 7075 743a 0a20 2020  r in output:.   
+0000a870: 2020 6966 206e 6f74 2073 656c 662e 6265    if not self.be
+0000a880: 6e63 686d 6172 6b3a 0a20 2020 2020 2020  nchmark:.       
 0000a890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a8a0: 2020 2020 2020 2020 2074 656e 736f 7220           tensor 
-0000a8b0: 3d20 7465 6e73 6f72 2e74 6f28 2263 7075  = tensor.to("cpu
-0000a8c0: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
-0000a8d0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0000a8e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a8f0: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
-0000a900: 7470 7574 2e74 6f28 2263 7075 2229 0a0a  tput.to("cpu")..
-0000a910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a920: 6966 2070 6f73 7470 726f 6365 7373 2069  if postprocess i
-0000a930: 7320 6e6f 7420 4e6f 6e65 2061 6e64 206e  s not None and n
-0000a940: 6f74 2073 656c 662e 6265 6e63 686d 6172  ot self.benchmar
-0000a950: 6b3a 0a20 2020 2020 2020 2020 2020 2020  k:.             
-0000a960: 2020 2020 2020 206f 7574 7075 742c 206c         output, l
-0000a970: 6162 656c 203d 2070 6f73 7470 726f 6365  abel = postproce
-0000a980: 7373 2828 6f75 7470 7574 2c20 6c61 6265  ss((output, labe
-0000a990: 6c29 290a 0a20 2020 2020 2020 2020 2020  l))..           
-0000a9a0: 2020 2020 2069 6620 6d65 7472 6963 7320       if metrics 
-0000a9b0: 616e 6420 6e6f 7420 7365 6c66 2e62 656e  and not self.ben
-0000a9c0: 6368 6d61 726b 3a0a 2020 2020 2020 2020  chmark:.        
-0000a9d0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-0000a9e0: 6d65 7472 6963 2069 6e20 6d65 7472 6963  metric in metric
-0000a9f0: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
-0000aa00: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
-0000aa10: 7420 6861 7361 7474 7228 6d65 7472 6963  t hasattr(metric
-0000aa20: 2c20 2263 6f6d 7061 7265 5f6c 6162 656c  , "compare_label
-0000aa30: 2229 206f 7220 5c0a 2020 2020 2020 2020  ") or \.        
-0000aa40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000aa50: 2020 2020 2868 6173 6174 7472 286d 6574      (hasattr(met
-0000aa60: 7269 632c 2022 636f 6d70 6172 655f 6c61  ric, "compare_la
-0000aa70: 6265 6c22 2920 616e 6420 6d65 7472 6963  bel") and metric
-0000aa80: 2e63 6f6d 7061 7265 5f6c 6162 656c 293a  .compare_label):
-0000aa90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000aaa0: 2020 2020 2020 2020 2020 2020 206d 6574               met
-0000aab0: 7269 632e 7570 6461 7465 286f 7574 7075  ric.update(outpu
-0000aac0: 742c 206c 6162 656c 290a 0a20 2020 2020  t, label)..     
-0000aad0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-0000aae0: 2049 6620 6469 7374 7269 6275 7465 6420   If distributed 
-0000aaf0: 6461 7461 6c6f 6164 6572 2c20 6761 7468  dataloader, gath
-0000ab00: 6572 2061 6c6c 206f 7574 7075 7473 2074  er all outputs t
-0000ab10: 6f20 7570 6461 7465 206d 6574 7269 630a  o update metric.
-0000ab20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ab30: 2020 2020 6966 2067 6574 6174 7472 2864      if getattr(d
-0000ab40: 6174 616c 6f61 6465 722c 2027 6469 7374  ataloader, 'dist
-0000ab50: 7269 6275 7465 6427 2c20 4661 6c73 6529  ributed', False)
-0000ab60: 206f 7220 5c0a 2020 2020 2020 2020 2020   or \.          
-0000ab70: 2020 2020 2020 2020 2020 2020 6973 696e              isin
-0000ab80: 7374 616e 6365 2864 6174 616c 6f61 6465  stance(dataloade
-0000ab90: 722e 7361 6d70 6c65 722c 205c 0a20 2020  r.sampler, \.   
+0000a8a0: 2061 7373 6572 7420 226c 6162 656c 2220   assert "label" 
+0000a8b0: 696e 2069 6e70 7574 2c20 5c0a 2020 2020  in input, \.    
+0000a8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a8d0: 2020 2020 2020 2020 2254 6865 2064 6174          "The dat
+0000a8e0: 616c 6f61 6465 7220 6d75 7374 2069 6e63  aloader must inc
+0000a8f0: 6c75 6465 206c 6162 656c 2074 6f20 6d65  lude label to me
+0000a900: 6173 7572 6520 7468 6520 6d65 7472 6963  asure the metric
+0000a910: 2122 0a20 2020 2020 2020 2020 2020 2020  !".             
+0000a920: 2020 2020 2020 2020 2020 206c 6162 656c             label
+0000a930: 203d 2069 6e70 7574 5b22 6c61 6265 6c22   = input["label"
+0000a940: 5d2e 746f 2822 6370 7522 290a 2020 2020  ].to("cpu").    
+0000a950: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+0000a960: 206e 6f74 2073 656c 662e 6265 6e63 686d   not self.benchm
+0000a970: 6172 6b3a 0a20 2020 2020 2020 2020 2020  ark:.           
+0000a980: 2020 2020 2020 2020 2061 7373 6572 7420           assert 
+0000a990: 4661 6c73 652c 2022 5468 6520 6461 7461  False, "The data
+0000a9a0: 6c6f 6164 6572 206d 7573 7420 696e 636c  loader must incl
+0000a9b0: 7564 6520 6c61 6265 6c20 746f 206d 6561  ude label to mea
+0000a9c0: 7375 7265 2074 6865 206d 6574 7269 6321  sure the metric!
+0000a9d0: 220a 0a20 2020 2020 2020 2020 2020 2020  "..             
+0000a9e0: 2020 2069 6620 6d65 6173 7572 6572 2069     if measurer i
+0000a9f0: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
+0000aa00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000aa10: 6d65 6173 7572 6572 2e73 7461 7274 2829  measurer.start()
+0000aa20: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000aa30: 2020 6f75 7470 7574 203d 2070 7974 6f72    output = pytor
+0000aa40: 6368 5f66 6f72 7761 7264 5f77 7261 7070  ch_forward_wrapp
+0000aa50: 6572 286d 6f64 656c 2c20 696e 7075 742c  er(model, input,
+0000aa60: 2064 6576 6963 653d 7365 6c66 2e64 6576   device=self.dev
+0000aa70: 6963 652c 2063 6f6e 663d 636f 6e66 290a  ice, conf=conf).
+0000aa80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000aa90: 2069 6620 6d65 6173 7572 6572 2069 7320   if measurer is 
+0000aaa0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+0000aab0: 2020 2020 2020 2020 2020 2020 2020 6d65                me
+0000aac0: 6173 7572 6572 2e65 6e64 2829 0a0a 2020  asurer.end()..  
+0000aad0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000aae0: 2073 656c 662e 6465 7669 6365 2021 3d20   self.device != 
+0000aaf0: 2263 7075 2220 616e 6420 6e6f 7420 7365  "cpu" and not se
+0000ab00: 6c66 2e62 656e 6368 6d61 726b 3a20 2023  lf.benchmark:  #
+0000ab10: 2070 7261 676d 613a 206e 6f20 636f 7665   pragma: no cove
+0000ab20: 720a 2020 2020 2020 2020 2020 2020 2020  r.              
+0000ab30: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+0000ab40: 6e63 6528 6f75 7470 7574 2c20 6469 6374  nce(output, dict
+0000ab50: 2920 6f72 2069 7369 6e73 7461 6e63 6528  ) or isinstance(
+0000ab60: 696e 7075 742c 2055 7365 7244 6963 7429  input, UserDict)
+0000ab70: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000ab80: 2020 2020 2020 2020 2020 666f 7220 6b65            for ke
+0000ab90: 7920 696e 206f 7574 7075 743a 0a20 2020  y in output:.   
 0000aba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000abb0: 2020 2074 6f72 6368 2e75 7469 6c73 2e64     torch.utils.d
-0000abc0: 6174 612e 6469 7374 7269 6275 7465 642e  ata.distributed.
-0000abd0: 4469 7374 7269 6275 7465 6453 616d 706c  DistributedSampl
-0000abe0: 6572 293a 0a20 2020 2020 2020 2020 2020  er):.           
-0000abf0: 2020 2020 2020 2020 2020 2020 2068 7664               hvd
-0000ac00: 2e69 6e69 7428 290a 2020 2020 2020 2020  .init().        
-0000ac10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ac20: 666f 7220 6d65 7472 6963 2069 6e20 6d65  for metric in me
-0000ac30: 7472 6963 733a 0a20 2020 2020 2020 2020  trics:.         
-0000ac40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ac50: 2020 206d 6574 7269 632e 6876 6420 3d20     metric.hvd = 
-0000ac60: 6876 640a 0a20 2020 2020 2020 2020 2020  hvd..           
-0000ac70: 2020 2020 2069 6620 7365 6c66 2e66 7033       if self.fp3
-0000ac80: 325f 7072 6564 735f 6173 5f6c 6162 656c  2_preds_as_label
-0000ac90: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000aca0: 2020 2020 2020 7365 6c66 2e66 7033 325f        self.fp32_
-0000acb0: 7265 7375 6c74 732e 6170 7065 6e64 286f  results.append(o
-0000acc0: 7574 7075 7429 2069 6620 7365 6c66 2e69  utput) if self.i
-0000acd0: 735f 6261 7365 6c69 6e65 2065 6c73 6520  s_baseline else 
-0000ace0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-0000acf0: 2020 2020 2020 2020 2020 7265 7375 6c74            result
-0000ad00: 732e 6170 7065 6e64 286f 7574 7075 7429  s.append(output)
-0000ad10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ad20: 2069 6620 6964 7820 2b20 3120 3d3d 2069   if idx + 1 == i
-0000ad30: 7465 7261 7469 6f6e 3a0a 2020 2020 2020  teration:.      
-0000ad40: 2020 2020 2020 2020 2020 2020 2020 6272                br
-0000ad50: 6561 6b0a 2020 2020 2020 2020 7265 7475  eak.        retu
-0000ad60: 726e 2072 6573 756c 7473 0a0a 2020 2020  rn results..    
-0000ad70: 6465 6620 6d6f 6465 6c5f 6576 616c 2873  def model_eval(s
-0000ad80: 656c 662c 0a20 2020 2020 2020 2020 2020  elf,.           
-0000ad90: 2020 2020 2020 2020 6d6f 6465 6c2c 0a20          model,. 
-0000ada0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000adb0: 2020 6461 7461 6c6f 6164 6572 2c0a 2020    dataloader,.  
-0000adc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000add0: 2070 6f73 7470 726f 6365 7373 3d4e 6f6e   postprocess=Non
-0000ade0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-0000adf0: 2020 2020 2020 6d65 7472 6963 733d 4e6f        metrics=No
-0000ae00: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
-0000ae10: 2020 2020 2020 206d 6561 7375 7265 723d         measurer=
-0000ae20: 4e6f 6e65 2c0a 2020 2020 2020 2020 2020  None,.          
-0000ae30: 2020 2020 2020 2020 2069 7465 7261 7469           iterati
-0000ae40: 6f6e 3d2d 312c 0a20 2020 2020 2020 2020  on=-1,.         
-0000ae50: 2020 2020 2020 2020 2020 636f 6e66 3d4e            conf=N
-0000ae60: 6f6e 6529 3a0a 2020 2020 2020 2020 7769  one):.        wi
-0000ae70: 7468 2074 6f72 6368 2e6e 6f5f 6772 6164  th torch.no_grad
-0000ae80: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-0000ae90: 6966 206d 6574 7269 6373 3a0a 2020 2020  if metrics:.    
-0000aea0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-0000aeb0: 6d65 7472 6963 2069 6e20 6d65 7472 6963  metric in metric
-0000aec0: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
-0000aed0: 2020 2020 2020 206d 6574 7269 632e 7265         metric.re
-0000aee0: 7365 7428 290a 2020 2020 2020 2020 2020  set().          
-0000aef0: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-0000af00: 6461 7461 6c6f 6164 6572 2c20 4261 7365  dataloader, Base
-0000af10: 4461 7461 4c6f 6164 6572 2920 616e 6420  DataLoader) and 
-0000af20: 6e6f 7420 7365 6c66 2e62 656e 6368 6d61  not self.benchma
-0000af30: 726b 3a0a 2020 2020 2020 2020 2020 2020  rk:.            
-0000af40: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0000af50: 2020 2020 2020 2020 2020 2020 2072 6573               res
-0000af60: 756c 7473 203d 2073 656c 662e 6576 616c  ults = self.eval
-0000af70: 5f66 756e 6328 6d6f 6465 6c2c 2064 6174  _func(model, dat
-0000af80: 616c 6f61 6465 722c 2070 6f73 7470 726f  aloader, postpro
-0000af90: 6365 7373 2c20 6d65 7472 6963 732c 206d  cess, metrics, m
-0000afa0: 6561 7375 7265 722c 0a20 2020 2020 2020  easurer,.       
-0000afb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000afc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000afd0: 2020 2020 2020 6974 6572 6174 696f 6e2c        iteration,
-0000afe0: 2063 6f6e 6629 0a20 2020 2020 2020 2020   conf).         
-0000aff0: 2020 2020 2020 2065 7863 6570 7420 4578         except Ex
-0000b000: 6365 7074 696f 6e3a 2020 2320 7072 6167  ception:  # prag
-0000b010: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
-0000b020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b030: 206c 6f67 6765 722e 7761 726e 696e 6728   logger.warning(
-0000b040: 2246 6169 6c20 746f 2066 6f72 7761 7264  "Fail to forward
-0000b050: 2077 6974 6820 6261 7463 6820 7369 7a65   with batch size
-0000b060: 3d7b 7d2c 2073 6574 2074 6f20 7b7d 206e  ={}, set to {} n
-0000b070: 6f77 2e22 2e66 6f72 6d61 7428 0a20 2020  ow.".format(.   
-0000b080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b090: 2020 2020 2064 6174 616c 6f61 6465 722e       dataloader.
-0000b0a0: 6261 7463 685f 7369 7a65 2c20 3129 290a  batch_size, 1)).
+0000abb0: 2020 2020 2020 2020 206f 7574 7075 745b           output[
+0000abc0: 6b65 795d 203d 206f 7574 7075 745b 6b65  key] = output[ke
+0000abd0: 795d 2e74 6f28 2263 7075 2229 0a20 2020  y].to("cpu").   
+0000abe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000abf0: 2065 6c69 6620 6973 696e 7374 616e 6365   elif isinstance
+0000ac00: 286f 7574 7075 742c 206c 6973 7429 206f  (output, list) o
+0000ac10: 7220 6973 696e 7374 616e 6365 286f 7574  r isinstance(out
+0000ac20: 7075 742c 2074 7570 6c65 293a 0a20 2020  put, tuple):.   
+0000ac30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ac40: 2020 2020 2066 6f72 2074 656e 736f 7220       for tensor 
+0000ac50: 696e 206f 7574 7075 743a 0a20 2020 2020  in output:.     
+0000ac60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ac70: 2020 2020 2020 2074 656e 736f 7220 3d20         tensor = 
+0000ac80: 7465 6e73 6f72 2e74 6f28 2263 7075 2229  tensor.to("cpu")
+0000ac90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000aca0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0000acb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000acc0: 2020 206f 7574 7075 7420 3d20 6f75 7470     output = outp
+0000acd0: 7574 2e74 6f28 2263 7075 2229 0a0a 2020  ut.to("cpu")..  
+0000ace0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000acf0: 2070 6f73 7470 726f 6365 7373 2069 7320   postprocess is 
+0000ad00: 6e6f 7420 4e6f 6e65 2061 6e64 206e 6f74  not None and not
+0000ad10: 2073 656c 662e 6265 6e63 686d 6172 6b3a   self.benchmark:
+0000ad20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ad30: 2020 2020 206f 7574 7075 742c 206c 6162       output, lab
+0000ad40: 656c 203d 2070 6f73 7470 726f 6365 7373  el = postprocess
+0000ad50: 2828 6f75 7470 7574 2c20 6c61 6265 6c29  ((output, label)
+0000ad60: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
+0000ad70: 2020 2069 6620 6d65 7472 6963 7320 616e     if metrics an
+0000ad80: 6420 6e6f 7420 7365 6c66 2e62 656e 6368  d not self.bench
+0000ad90: 6d61 726b 3a0a 2020 2020 2020 2020 2020  mark:.          
+0000ada0: 2020 2020 2020 2020 2020 666f 7220 6d65            for me
+0000adb0: 7472 6963 2069 6e20 6d65 7472 6963 733a  tric in metrics:
+0000adc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000add0: 2020 2020 2020 2020 2069 6620 6e6f 7420           if not 
+0000ade0: 6861 7361 7474 7228 6d65 7472 6963 2c20  hasattr(metric, 
+0000adf0: 2263 6f6d 7061 7265 5f6c 6162 656c 2229  "compare_label")
+0000ae00: 206f 7220 5c0a 2020 2020 2020 2020 2020   or \.          
+0000ae10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ae20: 2020 2868 6173 6174 7472 286d 6574 7269    (hasattr(metri
+0000ae30: 632c 2022 636f 6d70 6172 655f 6c61 6265  c, "compare_labe
+0000ae40: 6c22 2920 616e 6420 6d65 7472 6963 2e63  l") and metric.c
+0000ae50: 6f6d 7061 7265 5f6c 6162 656c 293a 0a20  ompare_label):. 
+0000ae60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ae70: 2020 2020 2020 2020 2020 206d 6574 7269             metri
+0000ae80: 632e 7570 6461 7465 286f 7574 7075 742c  c.update(output,
+0000ae90: 206c 6162 656c 290a 0a20 2020 2020 2020   label)..       
+0000aea0: 2020 2020 2020 2020 2020 2020 2023 2049               # I
+0000aeb0: 6620 6469 7374 7269 6275 7465 6420 6461  f distributed da
+0000aec0: 7461 6c6f 6164 6572 2c20 6761 7468 6572  taloader, gather
+0000aed0: 2061 6c6c 206f 7574 7075 7473 2074 6f20   all outputs to 
+0000aee0: 7570 6461 7465 206d 6574 7269 630a 2020  update metric.  
+0000aef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000af00: 2020 6966 2067 6574 6174 7472 2864 6174    if getattr(dat
+0000af10: 616c 6f61 6465 722c 2027 6469 7374 7269  aloader, 'distri
+0000af20: 6275 7465 6427 2c20 4661 6c73 6529 206f  buted', False) o
+0000af30: 7220 5c0a 2020 2020 2020 2020 2020 2020  r \.            
+0000af40: 2020 2020 2020 2020 2020 6973 696e 7374            isinst
+0000af50: 616e 6365 2864 6174 616c 6f61 6465 722e  ance(dataloader.
+0000af60: 7361 6d70 6c65 722c 205c 0a20 2020 2020  sampler, \.     
+0000af70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000af80: 2074 6f72 6368 2e75 7469 6c73 2e64 6174   torch.utils.dat
+0000af90: 612e 6469 7374 7269 6275 7465 642e 4469  a.distributed.Di
+0000afa0: 7374 7269 6275 7465 6453 616d 706c 6572  stributedSampler
+0000afb0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+0000afc0: 2020 2020 2020 2020 2020 2068 7664 2e69             hvd.i
+0000afd0: 6e69 7428 290a 2020 2020 2020 2020 2020  nit().          
+0000afe0: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+0000aff0: 7220 6d65 7472 6963 2069 6e20 6d65 7472  r metric in metr
+0000b000: 6963 733a 0a20 2020 2020 2020 2020 2020  ics:.           
+0000b010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b020: 206d 6574 7269 632e 6876 6420 3d20 6876   metric.hvd = hv
+0000b030: 640a 0a20 2020 2020 2020 2020 2020 2020  d..             
+0000b040: 2020 2069 6620 7365 6c66 2e66 7033 325f     if self.fp32_
+0000b050: 7072 6564 735f 6173 5f6c 6162 656c 3a0a  preds_as_label:.
+0000b060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b070: 2020 2020 7365 6c66 2e66 7033 325f 7265      self.fp32_re
+0000b080: 7375 6c74 732e 6170 7065 6e64 286f 7574  sults.append(out
+0000b090: 7075 7429 2069 6620 7365 6c66 2e69 735f  put) if self.is_
+0000b0a0: 6261 7365 6c69 6e65 2065 6c73 6520 5c0a  baseline else \.
 0000b0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b0c0: 2020 2020 6461 7461 6c6f 6164 6572 2e62      dataloader.b
-0000b0d0: 6174 6368 2831 290a 2020 2020 2020 2020  atch(1).        
-0000b0e0: 2020 2020 2020 2020 2020 2020 7265 7375              resu
-0000b0f0: 6c74 7320 3d20 7365 6c66 2e65 7661 6c5f  lts = self.eval_
-0000b100: 6675 6e63 286d 6f64 656c 2c20 6461 7461  func(model, data
-0000b110: 6c6f 6164 6572 2c20 706f 7374 7072 6f63  loader, postproc
-0000b120: 6573 732c 206d 6574 7269 6373 2c20 6d65  ess, metrics, me
-0000b130: 6173 7572 6572 2c0a 2020 2020 2020 2020  asurer,.        
-0000b140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b160: 2020 2020 2069 7465 7261 7469 6f6e 2c20       iteration, 
-0000b170: 636f 6e66 290a 2020 2020 2020 2020 2020  conf).          
-0000b180: 2020 656c 7365 3a20 2023 2070 7261 676d    else:  # pragm
-0000b190: 613a 206e 6f20 636f 7665 720a 2020 2020  a: no cover.    
-0000b1a0: 2020 2020 2020 2020 2020 2020 7265 7375              resu
-0000b1b0: 6c74 7320 3d20 7365 6c66 2e65 7661 6c5f  lts = self.eval_
-0000b1c0: 6675 6e63 286d 6f64 656c 2c20 6461 7461  func(model, data
-0000b1d0: 6c6f 6164 6572 2c20 706f 7374 7072 6f63  loader, postproc
-0000b1e0: 6573 732c 206d 6574 7269 6373 2c20 6d65  ess, metrics, me
-0000b1f0: 6173 7572 6572 2c0a 2020 2020 2020 2020  asurer,.        
-0000b200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b220: 2069 7465 7261 7469 6f6e 2c20 636f 6e66   iteration, conf
-0000b230: 290a 0a20 2020 2020 2020 2069 6620 7365  )..        if se
-0000b240: 6c66 2e66 7033 325f 7072 6564 735f 6173  lf.fp32_preds_as
-0000b250: 5f6c 6162 656c 3a0a 2020 2020 2020 2020  _label:.        
-0000b260: 2020 2020 6966 2073 656c 662e 6973 5f62      if self.is_b
-0000b270: 6173 656c 696e 653a 0a20 2020 2020 2020  aseline:.       
-0000b280: 2020 2020 2020 2020 2072 6573 756c 7473           results
-0000b290: 203d 2074 6f72 6368 5f75 7469 6c73 2e75   = torch_utils.u
-0000b2a0: 7469 6c2e 636f 6c6c 6174 655f 746f 7263  til.collate_torc
-0000b2b0: 685f 7072 6564 7328 7365 6c66 2e66 7033  h_preds(self.fp3
-0000b2c0: 325f 7265 7375 6c74 7329 0a20 2020 2020  2_results).     
-0000b2d0: 2020 2020 2020 2020 2020 2072 6566 6572             refer
-0000b2e0: 656e 6365 203d 2072 6573 756c 7473 0a20  ence = results. 
-0000b2f0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0000b300: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b310: 2072 6566 6572 656e 6365 203d 2074 6f72   reference = tor
-0000b320: 6368 5f75 7469 6c73 2e75 7469 6c2e 636f  ch_utils.util.co
-0000b330: 6c6c 6174 655f 746f 7263 685f 7072 6564  llate_torch_pred
-0000b340: 7328 7365 6c66 2e66 7033 325f 7265 7375  s(self.fp32_resu
-0000b350: 6c74 7329 0a20 2020 2020 2020 2020 2020  lts).           
-0000b360: 2020 2020 2072 6573 756c 7473 203d 2074       results = t
-0000b370: 6f72 6368 5f75 7469 6c73 2e75 7469 6c2e  orch_utils.util.
-0000b380: 636f 6c6c 6174 655f 746f 7263 685f 7072  collate_torch_pr
-0000b390: 6564 7328 7265 7375 6c74 7329 0a20 2020  eds(results).   
-0000b3a0: 2020 2020 2020 2020 2066 6f72 206d 6574           for met
-0000b3b0: 7269 6320 696e 206d 6574 7269 6373 3a0a  ric in metrics:.
-0000b3c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b3d0: 6966 2068 6173 6174 7472 286d 6574 7269  if hasattr(metri
-0000b3e0: 632c 2022 636f 6d70 6172 655f 6c61 6265  c, "compare_labe
-0000b3f0: 6c22 2920 616e 6420 6e6f 7420 6d65 7472  l") and not metr
-0000b400: 6963 2e63 6f6d 7061 7265 5f6c 6162 656c  ic.compare_label
-0000b410: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000b420: 2020 2020 2020 6d65 7472 6963 2e75 7064        metric.upd
-0000b430: 6174 6528 7265 7375 6c74 732c 2072 6566  ate(results, ref
-0000b440: 6572 656e 6365 290a 0a20 2020 2020 2020  erence)..       
-0000b450: 2061 6363 203d 2030 2069 6620 6d65 7472   acc = 0 if metr
-0000b460: 6963 7320 6973 204e 6f6e 6520 656c 7365  ics is None else
-0000b470: 205b 6d65 7472 6963 2e72 6573 756c 7428   [metric.result(
-0000b480: 2920 666f 7220 6d65 7472 6963 2069 6e20  ) for metric in 
-0000b490: 6d65 7472 6963 735d 0a20 2020 2020 2020  metrics].       
-0000b4a0: 2072 6574 7572 6e20 6163 6320 6966 206e   return acc if n
-0000b4b0: 6f74 2069 7369 6e73 7461 6e63 6528 6163  ot isinstance(ac
-0000b4c0: 632c 206c 6973 7429 206f 7220 6c65 6e28  c, list) or len(
-0000b4d0: 6163 6329 203e 2031 2065 6c73 6520 6163  acc) > 1 else ac
-0000b4e0: 635b 305d 0a0a 2020 2020 6465 6620 5f67  c[0]..    def _g
-0000b4f0: 6574 5f71 7561 6e74 697a 6162 6c65 5f6f  et_quantizable_o
-0000b500: 7073 5f72 6563 7572 7369 7665 6c79 2873  ps_recursively(s
-0000b510: 656c 662c 206d 6f64 656c 2c20 7072 6566  elf, model, pref
-0000b520: 6978 2c20 7175 616e 7469 7a61 626c 655f  ix, quantizable_
-0000b530: 6f70 7329 3a0a 2020 2020 2020 2020 2222  ops):.        ""
-0000b540: 2254 6869 7320 6973 2061 2068 656c 7065  "This is a helpe
-0000b550: 7220 6675 6e63 7469 6f6e 2066 6f72 2060  r function for `
-0000b560: 7175 6572 795f 6677 5f63 6170 6162 696c  query_fw_capabil
-0000b570: 6974 7960 2c0a 2020 2020 2020 2020 2020  ity`,.          
-0000b580: 2061 6e64 2069 7420 7769 6c6c 2067 6574   and it will get
-0000b590: 2061 6c6c 2071 7561 6e74 697a 6162 6c65   all quantizable
-0000b5a0: 206f 7073 2066 726f 6d20 6d6f 6465 6c2e   ops from model.
-0000b5b0: 0a0a 2020 2020 2020 2020 4172 6773 3a0a  ..        Args:.
-0000b5c0: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
-0000b5d0: 6c20 286f 626a 6563 7429 3a20 696e 7075  l (object): inpu
-0000b5e0: 7420 6d6f 6465 6c0a 2020 2020 2020 2020  t model.        
-0000b5f0: 2020 2020 7072 6566 6978 2028 7374 7269      prefix (stri
-0000b600: 6e67 293a 2070 7265 6669 7820 6f66 206f  ng): prefix of o
-0000b610: 7020 6e61 6d65 0a20 2020 2020 2020 2020  p name.         
-0000b620: 2020 2071 7561 6e74 697a 6162 6c65 5f6f     quantizable_o
-0000b630: 7073 2028 6c69 7374 293a 206c 6973 7420  ps (list): list 
-0000b640: 6f66 2071 7561 6e74 697a 6162 6c65 206f  of quantizable o
-0000b650: 7073 2066 726f 6d20 6d6f 6465 6c20 696e  ps from model in
-0000b660: 636c 7564 6520 6f70 206e 616d 6520 616e  clude op name an
-0000b670: 6420 7479 7065 2e0a 0a20 2020 2020 2020  d type...       
-0000b680: 2052 6574 7572 6e73 3a0a 2020 2020 2020   Returns:.      
-0000b690: 2020 2020 2020 4e6f 6e65 0a20 2020 2020        None.     
-0000b6a0: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
-0000b6b0: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
-0000b6c0: 6e74 6564 4572 726f 720a 0a20 2020 2064  ntedError..    d
-0000b6d0: 6566 205f 6765 745f 7175 616e 7469 7a61  ef _get_quantiza
-0000b6e0: 626c 655f 6f70 7328 7365 6c66 2c20 6d6f  ble_ops(self, mo
-0000b6f0: 6465 6c29 3a0a 2020 2020 2020 2020 2222  del):.        ""
-0000b700: 2254 6869 7320 6973 2061 2068 656c 7065  "This is a helpe
-0000b710: 7220 6675 6e63 7469 6f6e 2074 6f20 6765  r function to ge
-0000b720: 7420 616c 6c20 7175 616e 7469 7a61 626c  t all quantizabl
-0000b730: 6520 6f70 7320 6672 6f6d 206d 6f64 656c  e ops from model
-0000b740: 2e0a 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
-0000b750: 0a20 2020 2020 2020 2020 2020 206d 6f64  .            mod
-0000b760: 656c 2028 6f62 6a65 6374 293a 2069 6e70  el (object): inp
-0000b770: 7574 206d 6f64 656c 2077 6869 6368 2069  ut model which i
-0000b780: 7320 5079 546f 7263 6820 6d6f 6465 6c0a  s PyTorch model.
-0000b790: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
-0000b7a0: 3a0a 2020 2020 2020 2020 2020 2020 715f  :.            q_
-0000b7b0: 6361 7061 6269 6c69 7479 2028 6469 6374  capability (dict
-0000b7c0: 696f 6e61 7279 293a 2074 756e 696e 6720  ionary): tuning 
-0000b7d0: 6361 7061 6269 6c69 7479 2066 6f72 2065  capability for e
-0000b7e0: 6163 6820 6f70 2066 726f 6d20 6d6f 6465  ach op from mode
-0000b7f0: 6c2e 0a20 2020 2020 2020 2022 2222 0a20  l..        """. 
-0000b800: 2020 2020 2020 2074 6d70 5f6d 6f64 656c         tmp_model
-0000b810: 203d 206d 6f64 656c 0a20 2020 2020 2020   = model.       
-0000b820: 2074 6d70 5f6d 6f64 656c 2e65 7661 6c28   tmp_model.eval(
-0000b830: 290a 2020 2020 2020 2020 7175 616e 7469  ).        quanti
-0000b840: 7a61 626c 655f 6f70 7320 3d20 5b5d 0a20  zable_ops = []. 
-0000b850: 2020 2020 2020 2073 656c 662e 5f67 6574         self._get
-0000b860: 5f71 7561 6e74 697a 6162 6c65 5f6f 7073  _quantizable_ops
-0000b870: 5f72 6563 7572 7369 7665 6c79 2874 6d70  _recursively(tmp
-0000b880: 5f6d 6f64 656c 2c20 2727 2c20 7175 616e  _model, '', quan
-0000b890: 7469 7a61 626c 655f 6f70 7329 0a20 2020  tizable_ops).   
-0000b8a0: 2020 2020 2063 6170 6162 696c 6974 7920       capability 
-0000b8b0: 3d20 7365 6c66 2e71 7565 7279 5f68 616e  = self.query_han
-0000b8c0: 646c 6572 2e67 6574 5f71 7561 6e74 697a  dler.get_quantiz
-0000b8d0: 6174 696f 6e5f 6361 7061 6269 6c69 7479  ation_capability
-0000b8e0: 2829 5b27 6479 6e61 6d69 6327 5d20 5c0a  ()['dynamic'] \.
-0000b8f0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-0000b900: 656c 662e 6170 7072 6f61 6368 203d 3d20  elf.approach == 
-0000b910: 2270 6f73 745f 7472 6169 6e69 6e67 5f64  "post_training_d
-0000b920: 796e 616d 6963 5f71 7561 6e74 2220 656c  ynamic_quant" el
-0000b930: 7365 205c 0a20 2020 2020 2020 2020 2020  se \.           
-0000b940: 2073 656c 662e 7175 6572 795f 6861 6e64   self.query_hand
-0000b950: 6c65 722e 6765 745f 7175 616e 7469 7a61  ler.get_quantiza
-0000b960: 7469 6f6e 5f63 6170 6162 696c 6974 7928  tion_capability(
-0000b970: 295b 2771 7561 6e74 5f61 7761 7265 275d  )['quant_aware']
-0000b980: 205c 0a20 2020 2020 2020 2020 2020 2069   \.            i
-0000b990: 6620 7365 6c66 2e61 7070 726f 6163 6820  f self.approach 
-0000b9a0: 3d3d 2022 7175 616e 745f 6177 6172 655f  == "quant_aware_
-0000b9b0: 7472 6169 6e69 6e67 2220 656c 7365 205c  training" else \
-0000b9c0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-0000b9d0: 662e 7175 6572 795f 6861 6e64 6c65 722e  f.query_handler.
-0000b9e0: 6765 745f 7175 616e 7469 7a61 7469 6f6e  get_quantization
-0000b9f0: 5f63 6170 6162 696c 6974 7928 295b 2773  _capability()['s
-0000ba00: 7461 7469 6327 5d0a 0a20 2020 2020 2020  tatic']..       
-0000ba10: 2071 5f63 6170 6162 696c 6974 7920 3d20   q_capability = 
-0000ba20: 7b7d 0a20 2020 2020 2020 2071 5f63 6170  {}.        q_cap
-0000ba30: 6162 696c 6974 795b 276f 7074 7970 6577  ability['optypew
-0000ba40: 6973 6527 5d20 3d20 4f72 6465 7265 6444  ise'] = OrderedD
-0000ba50: 6963 7428 290a 2020 2020 2020 2020 715f  ict().        q_
-0000ba60: 6361 7061 6269 6c69 7479 5b27 6f70 7769  capability['opwi
-0000ba70: 7365 275d 203d 204f 7264 6572 6564 4469  se'] = OrderedDi
-0000ba80: 6374 2829 0a0a 2020 2020 2020 2020 6966  ct()..        if
-0000ba90: 2073 656c 662e 6170 7072 6f61 6368 203d   self.approach =
-0000baa0: 3d20 2270 6f73 745f 7472 6169 6e69 6e67  = "post_training
-0000bab0: 5f64 796e 616d 6963 5f71 7561 6e74 223a  _dynamic_quant":
-0000bac0: 0a20 2020 2020 2020 2020 2020 2063 6170  .            cap
-0000bad0: 6162 696c 6974 795f 7061 6972 203d 205b  ability_pair = [
-0000bae0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000baf0: 2028 7365 6c66 2e71 7565 7279 5f68 616e   (self.query_han
-0000bb00: 646c 6572 2e67 6574 5f71 7561 6e74 697a  dler.get_quantiz
-0000bb10: 6174 696f 6e5f 6361 7061 6269 6c69 7479  ation_capability
-0000bb20: 2829 5b27 6479 6e61 6d69 6327 5d2c 2027  ()['dynamic'], '
-0000bb30: 6479 6e61 6d69 6327 295d 0a20 2020 2020  dynamic')].     
-0000bb40: 2020 2065 6c69 6620 7365 6c66 2e61 7070     elif self.app
-0000bb50: 726f 6163 6820 3d3d 2022 7175 616e 745f  roach == "quant_
-0000bb60: 6177 6172 655f 7472 6169 6e69 6e67 223a  aware_training":
-0000bb70: 0a20 2020 2020 2020 2020 2020 2063 6170  .            cap
-0000bb80: 6162 696c 6974 795f 7061 6972 203d 205b  ability_pair = [
-0000bb90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000bba0: 2028 7365 6c66 2e71 7565 7279 5f68 616e   (self.query_han
-0000bbb0: 646c 6572 2e67 6574 5f71 7561 6e74 697a  dler.get_quantiz
-0000bbc0: 6174 696f 6e5f 6361 7061 6269 6c69 7479  ation_capability
-0000bbd0: 2829 5b27 7175 616e 745f 6177 6172 6527  ()['quant_aware'
-0000bbe0: 5d2c 2027 7374 6174 6963 2729 5d0a 2020  ], 'static')].  
-0000bbf0: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
-0000bc00: 6170 7072 6f61 6368 203d 3d20 2270 6f73  approach == "pos
-0000bc10: 745f 7472 6169 6e69 6e67 5f73 7461 7469  t_training_stati
-0000bc20: 635f 7175 616e 7422 3a0a 2020 2020 2020  c_quant":.      
-0000bc30: 2020 2020 2020 6361 7061 6269 6c69 7479        capability
-0000bc40: 5f70 6169 7220 3d20 5b0a 2020 2020 2020  _pair = [.      
-0000bc50: 2020 2020 2020 2020 2020 2873 656c 662e            (self.
-0000bc60: 7175 6572 795f 6861 6e64 6c65 722e 6765  query_handler.ge
-0000bc70: 745f 7175 616e 7469 7a61 7469 6f6e 5f63  t_quantization_c
-0000bc80: 6170 6162 696c 6974 7928 295b 2773 7461  apability()['sta
-0000bc90: 7469 6327 5d2c 2027 7374 6174 6963 2729  tic'], 'static')
-0000bca0: 5d0a 2020 2020 2020 2020 656c 7365 3a0a  ].        else:.
-0000bcb0: 2020 2020 2020 2020 2020 2020 6361 7061              capa
-0000bcc0: 6269 6c69 7479 5f70 6169 7220 3d20 5b0a  bility_pair = [.
-0000bcd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bce0: 2873 656c 662e 7175 6572 795f 6861 6e64  (self.query_hand
-0000bcf0: 6c65 722e 6765 745f 7175 616e 7469 7a61  ler.get_quantiza
-0000bd00: 7469 6f6e 5f63 6170 6162 696c 6974 7928  tion_capability(
-0000bd10: 295b 2773 7461 7469 6327 5d2c 2027 7374  )['static'], 'st
-0000bd20: 6174 6963 2729 2c0a 2020 2020 2020 2020  atic'),.        
-0000bd30: 2020 2020 2020 2020 2873 656c 662e 7175          (self.qu
-0000bd40: 6572 795f 6861 6e64 6c65 722e 6765 745f  ery_handler.get_
-0000bd50: 7175 616e 7469 7a61 7469 6f6e 5f63 6170  quantization_cap
-0000bd60: 6162 696c 6974 7928 295b 2764 796e 616d  ability()['dynam
-0000bd70: 6963 275d 2c20 2764 796e 616d 6963 2729  ic'], 'dynamic')
-0000bd80: 5d0a 2020 2020 2020 2020 6670 3332 5f63  ].        fp32_c
-0000bd90: 6f6e 6669 6720 3d20 7b27 6163 7469 7661  onfig = {'activa
-0000bda0: 7469 6f6e 273a 207b 2764 7479 7065 273a  tion': {'dtype':
-0000bdb0: 2027 6670 3332 277d 2c20 2777 6569 6768   'fp32'}, 'weigh
-0000bdc0: 7427 3a20 7b27 6474 7970 6527 3a20 2766  t': {'dtype': 'f
-0000bdd0: 7033 3227 7d7d 0a20 2020 2020 2020 2023  p32'}}.        #
-0000bde0: 2049 676e 6f72 6520 4c61 7965 724e 6f72   Ignore LayerNor
-0000bdf0: 6d2c 2049 6e73 7461 6e63 654e 6f72 6d33  m, InstanceNorm3
-0000be00: 6420 616e 6420 456d 6265 6464 696e 6720  d and Embedding 
-0000be10: 7175 616e 7469 7a61 626c 6520 6f70 732c  quantizable ops,
-0000be20: 0a20 2020 2020 2020 2023 2064 7565 2074  .        # due t
-0000be30: 6f20 6875 6765 2061 6363 7572 6163 7920  o huge accuracy 
-0000be40: 7265 6772 6573 7369 6f6e 2069 6e20 5079  regression in Py
-0000be50: 546f 7263 682e 0a20 2020 2020 2020 2069  Torch..        i
-0000be60: 6620 6973 696e 7374 616e 6365 2873 656c  f isinstance(sel
-0000be70: 662c 2050 7954 6f72 6368 5f49 5045 5841  f, PyTorch_IPEXA
-0000be80: 6461 7074 6f72 293a 0a20 2020 2020 2020  daptor):.       
-0000be90: 2020 2020 2061 6464 6974 696f 6e61 6c5f       additional_
-0000bea0: 736b 6970 7065 645f 6d6f 6475 6c65 5f63  skipped_module_c
-0000beb0: 6c61 7373 6573 203d 207b 7d0a 2020 2020  lasses = {}.    
-0000bec0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0000bed0: 2020 2020 2020 6164 6469 7469 6f6e 616c        additional
-0000bee0: 5f73 6b69 7070 6564 5f6d 6f64 756c 655f  _skipped_module_
-0000bef0: 636c 6173 7365 7320 3d20 7b27 4c61 7965  classes = {'Laye
-0000bf00: 724e 6f72 6d27 2c20 2749 6e73 7461 6e63  rNorm', 'Instanc
-0000bf10: 654e 6f72 6d33 6427 2c20 2744 726f 706f  eNorm3d', 'Dropo
-0000bf20: 7574 277d 0a20 2020 2020 2020 206e 6f5f  ut'}.        no_
-0000bf30: 6670 3332 5f6f 7073 203d 207b 2751 7561  fp32_ops = {'Qua
-0000bf40: 6e74 5374 7562 277d 0a20 2020 2020 2020  ntStub'}.       
-0000bf50: 2066 6f72 2070 6169 7220 696e 2063 6170   for pair in cap
-0000bf60: 6162 696c 6974 795f 7061 6972 3a0a 2020  ability_pair:.  
-0000bf70: 2020 2020 2020 2020 2020 6361 7061 6269            capabi
-0000bf80: 6c69 7479 2c20 6d6f 6465 203d 2070 6169  lity, mode = pai
-0000bf90: 720a 2020 2020 2020 2020 2020 2020 666f  r.            fo
-0000bfa0: 7220 715f 6f70 2069 6e20 7175 616e 7469  r q_op in quanti
-0000bfb0: 7a61 626c 655f 6f70 733a 0a20 2020 2020  zable_ops:.     
-0000bfc0: 2020 2020 2020 2020 2020 2069 6620 715f             if q_
-0000bfd0: 6f70 206e 6f74 2069 6e20 715f 6361 7061  op not in q_capa
-0000bfe0: 6269 6c69 7479 5b27 6f70 7769 7365 275d  bility['opwise']
-0000bff0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000c000: 2020 2020 2020 715f 6361 7061 6269 6c69        q_capabili
-0000c010: 7479 5b27 6f70 7769 7365 275d 5b71 5f6f  ty['opwise'][q_o
-0000c020: 705d 203d 205b 5d0a 2020 2020 2020 2020  p] = [].        
-0000c030: 2020 2020 2020 2020 6966 2071 5f6f 705b          if q_op[
-0000c040: 315d 206e 6f74 2069 6e20 715f 6361 7061  1] not in q_capa
-0000c050: 6269 6c69 7479 5b27 6f70 7479 7065 7769  bility['optypewi
-0000c060: 7365 275d 3a0a 2020 2020 2020 2020 2020  se']:.          
-0000c070: 2020 2020 2020 2020 2020 715f 6361 7061            q_capa
-0000c080: 6269 6c69 7479 5b27 6f70 7479 7065 7769  bility['optypewi
-0000c090: 7365 275d 5b71 5f6f 705b 315d 5d20 3d20  se'][q_op[1]] = 
-0000c0a0: 5b5d 0a0a 2020 2020 2020 2020 2020 2020  []..            
-0000c0b0: 2020 2020 6966 206d 6f64 6520 3d3d 2027      if mode == '
-0000c0c0: 7374 6174 6963 2720 616e 6420 7365 6c66  static' and self
-0000c0d0: 2e61 7070 726f 6163 6820 213d 2022 7175  .approach != "qu
-0000c0e0: 616e 745f 6177 6172 655f 7472 6169 6e69  ant_aware_traini
-0000c0f0: 6e67 2220 616e 6420 5c0a 2020 2020 2020  ng" and \.      
-0000c100: 2020 2020 2020 2020 2020 2020 2020 715f                q_
-0000c110: 6f70 5b31 5d20 696e 205b 274c 5354 4d27  op[1] in ['LSTM'
-0000c120: 2c20 2747 5255 272c 2027 4c53 544d 4365  , 'GRU', 'LSTMCe
-0000c130: 6c6c 272c 2027 4752 5543 656c 6c27 2c20  ll', 'GRUCell', 
-0000c140: 2752 4e4e 4365 6c6c 275d 3a0a 2020 2020  'RNNCell']:.    
-0000c150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c160: 636f 6e74 696e 7565 0a20 2020 2020 2020  continue.       
-0000c170: 2020 2020 2020 2020 206f 705f 6366 6720           op_cfg 
-0000c180: 3d20 636f 7079 2e64 6565 7063 6f70 7928  = copy.deepcopy(
-0000c190: 6361 7061 6269 6c69 7479 5b71 5f6f 705b  capability[q_op[
-0000c1a0: 315d 5d29 2069 6620 715f 6f70 5b31 5d20  1]]) if q_op[1] 
-0000c1b0: 696e 2063 6170 6162 696c 6974 7920 5c0a  in capability \.
-0000c1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c1d0: 2020 2020 656c 7365 2063 6f70 792e 6465      else copy.de
-0000c1e0: 6570 636f 7079 2863 6170 6162 696c 6974  epcopy(capabilit
-0000c1f0: 795b 2764 6566 6175 6c74 275d 290a 0a20  y['default']).. 
-0000c200: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-0000c210: 705f 6366 675b 2761 6374 6976 6174 696f  p_cfg['activatio
-0000c220: 6e27 5d5b 2771 7561 6e74 5f6d 6f64 6527  n']['quant_mode'
-0000c230: 5d20 3d20 6d6f 6465 2069 6620 715f 6f70  ] = mode if q_op
-0000c240: 5b31 5d20 6e6f 7420 696e 205c 0a20 2020  [1] not in \.   
-0000c250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c260: 205b 274c 5354 4d27 2c20 2747 5255 272c   ['LSTM', 'GRU',
-0000c270: 2027 4c53 544d 4365 6c6c 272c 2027 4752   'LSTMCell', 'GR
-0000c280: 5543 656c 6c27 2c20 2752 4e4e 4365 6c6c  UCell', 'RNNCell
-0000c290: 275d 2065 6c73 6520 2764 796e 616d 6963  '] else 'dynamic
-0000c2a0: 270a 0a20 2020 2020 2020 2020 2020 2020  '..             
-0000c2b0: 2020 2023 2073 6b69 7020 7468 6520 6f70     # skip the op
-0000c2c0: 2074 6861 7420 6f6e 6c79 2069 6e63 6c75   that only inclu
-0000c2d0: 6465 2066 7033 320a 2020 2020 2020 2020  de fp32.        
-0000c2e0: 2020 2020 2020 2020 6966 2071 5f6f 705b          if q_op[
-0000c2f0: 315d 206e 6f74 2069 6e20 6164 6469 7469  1] not in additi
-0000c300: 6f6e 616c 5f73 6b69 7070 6564 5f6d 6f64  onal_skipped_mod
-0000c310: 756c 655f 636c 6173 7365 733a 0a20 2020  ule_classes:.   
-0000c320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c330: 2069 6620 6f70 5f63 6667 206e 6f74 2069   if op_cfg not i
-0000c340: 6e20 715f 6361 7061 6269 6c69 7479 5b27  n q_capability['
-0000c350: 6f70 7769 7365 275d 5b71 5f6f 705d 3a0a  opwise'][q_op]:.
-0000c360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c370: 2020 2020 2020 2020 715f 6361 7061 6269          q_capabi
-0000c380: 6c69 7479 5b27 6f70 7769 7365 275d 5b71  lity['opwise'][q
-0000c390: 5f6f 705d 2e61 7070 656e 6428 6f70 5f63  _op].append(op_c
-0000c3a0: 6667 290a 2020 2020 2020 2020 2020 2020  fg).            
-0000c3b0: 2020 2020 2020 2020 6966 206f 705f 6366          if op_cf
-0000c3c0: 6720 6e6f 7420 696e 2071 5f63 6170 6162  g not in q_capab
-0000c3d0: 696c 6974 795b 276f 7074 7970 6577 6973  ility['optypewis
-0000c3e0: 6527 5d5b 715f 6f70 5b31 5d5d 3a0a 2020  e'][q_op[1]]:.  
-0000c3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c400: 2020 2020 2020 715f 6361 7061 6269 6c69        q_capabili
-0000c410: 7479 5b27 6f70 7479 7065 7769 7365 275d  ty['optypewise']
-0000c420: 5b71 5f6f 705b 315d 5d2e 6170 7065 6e64  [q_op[1]].append
-0000c430: 286f 705f 6366 6729 0a0a 2020 2020 2020  (op_cfg)..      
-0000c440: 2020 2020 2020 2020 2020 6966 2071 5f6f            if q_o
-0000c450: 705b 315d 206e 6f74 2069 6e20 6e6f 5f66  p[1] not in no_f
-0000c460: 7033 325f 6f70 733a 0a20 2020 2020 2020  p32_ops:.       
-0000c470: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-0000c480: 6670 3332 5f63 6f6e 6669 6720 6e6f 7420  fp32_config not 
-0000c490: 696e 2071 5f63 6170 6162 696c 6974 795b  in q_capability[
-0000c4a0: 276f 7077 6973 6527 5d5b 715f 6f70 5d3a  'opwise'][q_op]:
-0000c4b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000c4c0: 2020 2020 2020 2020 2071 5f63 6170 6162           q_capab
-0000c4d0: 696c 6974 795b 276f 7077 6973 6527 5d5b  ility['opwise'][
-0000c4e0: 715f 6f70 5d2e 6170 7065 6e64 2866 7033  q_op].append(fp3
-0000c4f0: 325f 636f 6e66 6967 290a 2020 2020 2020  2_config).      
-0000c500: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0000c510: 2066 7033 325f 636f 6e66 6967 206e 6f74   fp32_config not
-0000c520: 2069 6e20 715f 6361 7061 6269 6c69 7479   in q_capability
-0000c530: 5b27 6f70 7479 7065 7769 7365 275d 5b71  ['optypewise'][q
-0000c540: 5f6f 705b 315d 5d3a 0a20 2020 2020 2020  _op[1]]:.       
+0000b0c0: 2020 2020 2020 2020 7265 7375 6c74 732e          results.
+0000b0d0: 6170 7065 6e64 286f 7574 7075 7429 0a20  append(output). 
+0000b0e0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0000b0f0: 6620 6964 7820 2b20 3120 3d3d 2069 7465  f idx + 1 == ite
+0000b100: 7261 7469 6f6e 3a0a 2020 2020 2020 2020  ration:.        
+0000b110: 2020 2020 2020 2020 2020 2020 6272 6561              brea
+0000b120: 6b0a 2020 2020 2020 2020 7265 7475 726e  k.        return
+0000b130: 2072 6573 756c 7473 0a0a 2020 2020 6465   results..    de
+0000b140: 6620 6d6f 6465 6c5f 6576 616c 2873 656c  f model_eval(sel
+0000b150: 662c 0a20 2020 2020 2020 2020 2020 2020  f,.             
+0000b160: 2020 2020 2020 6d6f 6465 6c2c 0a20 2020        model,.   
+0000b170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b180: 6461 7461 6c6f 6164 6572 2c0a 2020 2020  dataloader,.    
+0000b190: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0000b1a0: 6f73 7470 726f 6365 7373 3d4e 6f6e 652c  ostprocess=None,
+0000b1b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000b1c0: 2020 2020 6d65 7472 6963 733d 4e6f 6e65      metrics=None
+0000b1d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000b1e0: 2020 2020 206d 6561 7375 7265 723d 4e6f       measurer=No
+0000b1f0: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
+0000b200: 2020 2020 2020 2069 7465 7261 7469 6f6e         iteration
+0000b210: 3d2d 312c 0a20 2020 2020 2020 2020 2020  =-1,.           
+0000b220: 2020 2020 2020 2020 636f 6e66 3d4e 6f6e          conf=Non
+0000b230: 6529 3a0a 2020 2020 2020 2020 7769 7468  e):.        with
+0000b240: 2074 6f72 6368 2e6e 6f5f 6772 6164 2829   torch.no_grad()
+0000b250: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+0000b260: 206d 6574 7269 6373 3a0a 2020 2020 2020   metrics:.      
+0000b270: 2020 2020 2020 2020 2020 666f 7220 6d65            for me
+0000b280: 7472 6963 2069 6e20 6d65 7472 6963 733a  tric in metrics:
+0000b290: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000b2a0: 2020 2020 206d 6574 7269 632e 7265 7365       metric.rese
+0000b2b0: 7428 290a 2020 2020 2020 2020 2020 2020  t().            
+0000b2c0: 6966 2069 7369 6e73 7461 6e63 6528 6461  if isinstance(da
+0000b2d0: 7461 6c6f 6164 6572 2c20 4261 7365 4461  taloader, BaseDa
+0000b2e0: 7461 4c6f 6164 6572 2920 616e 6420 6e6f  taLoader) and no
+0000b2f0: 7420 7365 6c66 2e62 656e 6368 6d61 726b  t self.benchmark
+0000b300: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000b310: 2020 7472 793a 0a20 2020 2020 2020 2020    try:.         
+0000b320: 2020 2020 2020 2020 2020 2072 6573 756c             resul
+0000b330: 7473 203d 2073 656c 662e 6576 616c 5f66  ts = self.eval_f
+0000b340: 756e 6328 6d6f 6465 6c2c 2064 6174 616c  unc(model, datal
+0000b350: 6f61 6465 722c 2070 6f73 7470 726f 6365  oader, postproce
+0000b360: 7373 2c20 6d65 7472 6963 732c 206d 6561  ss, metrics, mea
+0000b370: 7375 7265 722c 0a20 2020 2020 2020 2020  surer,.         
+0000b380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b3a0: 2020 2020 6974 6572 6174 696f 6e2c 2063      iteration, c
+0000b3b0: 6f6e 6629 0a20 2020 2020 2020 2020 2020  onf).           
+0000b3c0: 2020 2020 2065 7863 6570 7420 4578 6365       except Exce
+0000b3d0: 7074 696f 6e3a 2020 2320 7072 6167 6d61  ption:  # pragma
+0000b3e0: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
+0000b3f0: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+0000b400: 6f67 6765 722e 7761 726e 696e 6728 2246  ogger.warning("F
+0000b410: 6169 6c20 746f 2066 6f72 7761 7264 2077  ail to forward w
+0000b420: 6974 6820 6261 7463 6820 7369 7a65 3d7b  ith batch size={
+0000b430: 7d2c 2073 6574 2074 6f20 7b7d 206e 6f77  }, set to {} now
+0000b440: 2e22 2e66 6f72 6d61 7428 0a20 2020 2020  .".format(.     
+0000b450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b460: 2020 2064 6174 616c 6f61 6465 722e 6261     dataloader.ba
+0000b470: 7463 685f 7369 7a65 2c20 3129 290a 2020  tch_size, 1)).  
+0000b480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b490: 2020 6461 7461 6c6f 6164 6572 2e62 6174    dataloader.bat
+0000b4a0: 6368 2831 290a 2020 2020 2020 2020 2020  ch(1).          
+0000b4b0: 2020 2020 2020 2020 2020 7265 7375 6c74            result
+0000b4c0: 7320 3d20 7365 6c66 2e65 7661 6c5f 6675  s = self.eval_fu
+0000b4d0: 6e63 286d 6f64 656c 2c20 6461 7461 6c6f  nc(model, datalo
+0000b4e0: 6164 6572 2c20 706f 7374 7072 6f63 6573  ader, postproces
+0000b4f0: 732c 206d 6574 7269 6373 2c20 6d65 6173  s, metrics, meas
+0000b500: 7572 6572 2c0a 2020 2020 2020 2020 2020  urer,.          
+0000b510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b530: 2020 2069 7465 7261 7469 6f6e 2c20 636f     iteration, co
+0000b540: 6e66 290a 2020 2020 2020 2020 2020 2020  nf).            
+0000b550: 656c 7365 3a20 2023 2070 7261 676d 613a  else:  # pragma:
+0000b560: 206e 6f20 636f 7665 720a 2020 2020 2020   no cover.      
+0000b570: 2020 2020 2020 2020 2020 7265 7375 6c74            result
+0000b580: 7320 3d20 7365 6c66 2e65 7661 6c5f 6675  s = self.eval_fu
+0000b590: 6e63 286d 6f64 656c 2c20 6461 7461 6c6f  nc(model, datalo
+0000b5a0: 6164 6572 2c20 706f 7374 7072 6f63 6573  ader, postproces
+0000b5b0: 732c 206d 6574 7269 6373 2c20 6d65 6173  s, metrics, meas
+0000b5c0: 7572 6572 2c0a 2020 2020 2020 2020 2020  urer,.          
+0000b5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b5e0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0000b5f0: 7465 7261 7469 6f6e 2c20 636f 6e66 290a  teration, conf).
+0000b600: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+0000b610: 2e66 7033 325f 7072 6564 735f 6173 5f6c  .fp32_preds_as_l
+0000b620: 6162 656c 3a0a 2020 2020 2020 2020 2020  abel:.          
+0000b630: 2020 6966 2073 656c 662e 6973 5f62 6173    if self.is_bas
+0000b640: 656c 696e 653a 0a20 2020 2020 2020 2020  eline:.         
+0000b650: 2020 2020 2020 2072 6573 756c 7473 203d         results =
+0000b660: 2074 6f72 6368 5f75 7469 6c73 2e75 7469   torch_utils.uti
+0000b670: 6c2e 636f 6c6c 6174 655f 746f 7263 685f  l.collate_torch_
+0000b680: 7072 6564 7328 7365 6c66 2e66 7033 325f  preds(self.fp32_
+0000b690: 7265 7375 6c74 7329 0a20 2020 2020 2020  results).       
+0000b6a0: 2020 2020 2020 2020 2072 6566 6572 656e           referen
+0000b6b0: 6365 203d 2072 6573 756c 7473 0a20 2020  ce = results.   
+0000b6c0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+0000b6d0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+0000b6e0: 6566 6572 656e 6365 203d 2074 6f72 6368  eference = torch
+0000b6f0: 5f75 7469 6c73 2e75 7469 6c2e 636f 6c6c  _utils.util.coll
+0000b700: 6174 655f 746f 7263 685f 7072 6564 7328  ate_torch_preds(
+0000b710: 7365 6c66 2e66 7033 325f 7265 7375 6c74  self.fp32_result
+0000b720: 7329 0a20 2020 2020 2020 2020 2020 2020  s).             
+0000b730: 2020 2072 6573 756c 7473 203d 2074 6f72     results = tor
+0000b740: 6368 5f75 7469 6c73 2e75 7469 6c2e 636f  ch_utils.util.co
+0000b750: 6c6c 6174 655f 746f 7263 685f 7072 6564  llate_torch_pred
+0000b760: 7328 7265 7375 6c74 7329 0a20 2020 2020  s(results).     
+0000b770: 2020 2020 2020 2066 6f72 206d 6574 7269         for metri
+0000b780: 6320 696e 206d 6574 7269 6373 3a0a 2020  c in metrics:.  
+0000b790: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000b7a0: 2068 6173 6174 7472 286d 6574 7269 632c   hasattr(metric,
+0000b7b0: 2022 636f 6d70 6172 655f 6c61 6265 6c22   "compare_label"
+0000b7c0: 2920 616e 6420 6e6f 7420 6d65 7472 6963  ) and not metric
+0000b7d0: 2e63 6f6d 7061 7265 5f6c 6162 656c 3a0a  .compare_label:.
+0000b7e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b7f0: 2020 2020 6d65 7472 6963 2e75 7064 6174      metric.updat
+0000b800: 6528 7265 7375 6c74 732c 2072 6566 6572  e(results, refer
+0000b810: 656e 6365 290a 0a20 2020 2020 2020 2061  ence)..        a
+0000b820: 6363 203d 2030 2069 6620 6d65 7472 6963  cc = 0 if metric
+0000b830: 7320 6973 204e 6f6e 6520 656c 7365 205b  s is None else [
+0000b840: 6d65 7472 6963 2e72 6573 756c 7428 2920  metric.result() 
+0000b850: 666f 7220 6d65 7472 6963 2069 6e20 6d65  for metric in me
+0000b860: 7472 6963 735d 0a20 2020 2020 2020 2072  trics].        r
+0000b870: 6574 7572 6e20 6163 6320 6966 206e 6f74  eturn acc if not
+0000b880: 2069 7369 6e73 7461 6e63 6528 6163 632c   isinstance(acc,
+0000b890: 206c 6973 7429 206f 7220 6c65 6e28 6163   list) or len(ac
+0000b8a0: 6329 203e 2031 2065 6c73 6520 6163 635b  c) > 1 else acc[
+0000b8b0: 305d 0a0a 2020 2020 6465 6620 5f67 6574  0]..    def _get
+0000b8c0: 5f71 7561 6e74 697a 6162 6c65 5f6f 7073  _quantizable_ops
+0000b8d0: 5f72 6563 7572 7369 7665 6c79 2873 656c  _recursively(sel
+0000b8e0: 662c 206d 6f64 656c 2c20 7072 6566 6978  f, model, prefix
+0000b8f0: 2c20 7175 616e 7469 7a61 626c 655f 6f70  , quantizable_op
+0000b900: 7329 3a0a 2020 2020 2020 2020 2222 2254  s):.        """T
+0000b910: 6869 7320 6973 2061 2068 656c 7065 7220  his is a helper 
+0000b920: 6675 6e63 7469 6f6e 2066 6f72 2060 7175  function for `qu
+0000b930: 6572 795f 6677 5f63 6170 6162 696c 6974  ery_fw_capabilit
+0000b940: 7960 2c0a 2020 2020 2020 2020 2020 2061  y`,.           a
+0000b950: 6e64 2069 7420 7769 6c6c 2067 6574 2061  nd it will get a
+0000b960: 6c6c 2071 7561 6e74 697a 6162 6c65 206f  ll quantizable o
+0000b970: 7073 2066 726f 6d20 6d6f 6465 6c2e 0a0a  ps from model...
+0000b980: 2020 2020 2020 2020 4172 6773 3a0a 2020          Args:.  
+0000b990: 2020 2020 2020 2020 2020 6d6f 6465 6c20            model 
+0000b9a0: 286f 626a 6563 7429 3a20 696e 7075 7420  (object): input 
+0000b9b0: 6d6f 6465 6c0a 2020 2020 2020 2020 2020  model.          
+0000b9c0: 2020 7072 6566 6978 2028 7374 7269 6e67    prefix (string
+0000b9d0: 293a 2070 7265 6669 7820 6f66 206f 7020  ): prefix of op 
+0000b9e0: 6e61 6d65 0a20 2020 2020 2020 2020 2020  name.           
+0000b9f0: 2071 7561 6e74 697a 6162 6c65 5f6f 7073   quantizable_ops
+0000ba00: 2028 6c69 7374 293a 206c 6973 7420 6f66   (list): list of
+0000ba10: 2071 7561 6e74 697a 6162 6c65 206f 7073   quantizable ops
+0000ba20: 2066 726f 6d20 6d6f 6465 6c20 696e 636c   from model incl
+0000ba30: 7564 6520 6f70 206e 616d 6520 616e 6420  ude op name and 
+0000ba40: 7479 7065 2e0a 0a20 2020 2020 2020 2052  type...        R
+0000ba50: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
+0000ba60: 2020 2020 4e6f 6e65 0a20 2020 2020 2020      None.       
+0000ba70: 2022 2222 0a0a 2020 2020 2020 2020 7261   """..        ra
+0000ba80: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
+0000ba90: 6564 4572 726f 720a 0a20 2020 2064 6566  edError..    def
+0000baa0: 205f 6765 745f 7175 616e 7469 7a61 626c   _get_quantizabl
+0000bab0: 655f 6f70 7328 7365 6c66 2c20 6d6f 6465  e_ops(self, mode
+0000bac0: 6c29 3a0a 2020 2020 2020 2020 2222 2254  l):.        """T
+0000bad0: 6869 7320 6973 2061 2068 656c 7065 7220  his is a helper 
+0000bae0: 6675 6e63 7469 6f6e 2074 6f20 6765 7420  function to get 
+0000baf0: 616c 6c20 7175 616e 7469 7a61 626c 6520  all quantizable 
+0000bb00: 6f70 7320 6672 6f6d 206d 6f64 656c 2e0a  ops from model..
+0000bb10: 0a20 2020 2020 2020 2041 7267 733a 0a20  .        Args:. 
+0000bb20: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+0000bb30: 2028 6f62 6a65 6374 293a 2069 6e70 7574   (object): input
+0000bb40: 206d 6f64 656c 2077 6869 6368 2069 7320   model which is 
+0000bb50: 5079 546f 7263 6820 6d6f 6465 6c0a 0a20  PyTorch model.. 
+0000bb60: 2020 2020 2020 2052 6574 7572 6e73 3a0a         Returns:.
+0000bb70: 2020 2020 2020 2020 2020 2020 715f 6361              q_ca
+0000bb80: 7061 6269 6c69 7479 2028 6469 6374 696f  pability (dictio
+0000bb90: 6e61 7279 293a 2074 756e 696e 6720 6361  nary): tuning ca
+0000bba0: 7061 6269 6c69 7479 2066 6f72 2065 6163  pability for eac
+0000bbb0: 6820 6f70 2066 726f 6d20 6d6f 6465 6c2e  h op from model.
+0000bbc0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+0000bbd0: 2020 2020 2074 6d70 5f6d 6f64 656c 203d       tmp_model =
+0000bbe0: 206d 6f64 656c 0a20 2020 2020 2020 2074   model.        t
+0000bbf0: 6d70 5f6d 6f64 656c 2e65 7661 6c28 290a  mp_model.eval().
+0000bc00: 2020 2020 2020 2020 7175 616e 7469 7a61          quantiza
+0000bc10: 626c 655f 6f70 7320 3d20 5b5d 0a20 2020  ble_ops = [].   
+0000bc20: 2020 2020 2073 656c 662e 5f67 6574 5f71       self._get_q
+0000bc30: 7561 6e74 697a 6162 6c65 5f6f 7073 5f72  uantizable_ops_r
+0000bc40: 6563 7572 7369 7665 6c79 2874 6d70 5f6d  ecursively(tmp_m
+0000bc50: 6f64 656c 2c20 2727 2c20 7175 616e 7469  odel, '', quanti
+0000bc60: 7a61 626c 655f 6f70 7329 0a20 2020 2020  zable_ops).     
+0000bc70: 2020 2023 2063 6170 6162 696c 6974 7920     # capability 
+0000bc80: 3d20 7365 6c66 2e71 7565 7279 5f68 616e  = self.query_han
+0000bc90: 646c 6572 2e67 6574 5f71 7561 6e74 697a  dler.get_quantiz
+0000bca0: 6174 696f 6e5f 6361 7061 6269 6c69 7479  ation_capability
+0000bcb0: 2829 5b27 6479 6e61 6d69 6327 5d20 5c0a  ()['dynamic'] \.
+0000bcc0: 2020 2020 2020 2020 2320 2020 2020 6966          #     if
+0000bcd0: 2073 656c 662e 6170 7072 6f61 6368 203d   self.approach =
+0000bce0: 3d20 2270 6f73 745f 7472 6169 6e69 6e67  = "post_training
+0000bcf0: 5f64 796e 616d 6963 5f71 7561 6e74 2220  _dynamic_quant" 
+0000bd00: 656c 7365 205c 0a20 2020 2020 2020 2023  else \.        #
+0000bd10: 2020 2020 2073 656c 662e 7175 6572 795f       self.query_
+0000bd20: 6861 6e64 6c65 722e 6765 745f 7175 616e  handler.get_quan
+0000bd30: 7469 7a61 7469 6f6e 5f63 6170 6162 696c  tization_capabil
+0000bd40: 6974 7928 295b 2771 7561 6e74 5f61 7761  ity()['quant_awa
+0000bd50: 7265 275d 205c 0a20 2020 2020 2020 2023  re'] \.        #
+0000bd60: 2020 2020 2069 6620 7365 6c66 2e61 7070       if self.app
+0000bd70: 726f 6163 6820 3d3d 2022 7175 616e 745f  roach == "quant_
+0000bd80: 6177 6172 655f 7472 6169 6e69 6e67 2220  aware_training" 
+0000bd90: 656c 7365 205c 0a20 2020 2020 2020 2023  else \.        #
+0000bda0: 2020 2020 2073 656c 662e 7175 6572 795f       self.query_
+0000bdb0: 6861 6e64 6c65 722e 6765 745f 7175 616e  handler.get_quan
+0000bdc0: 7469 7a61 7469 6f6e 5f63 6170 6162 696c  tization_capabil
+0000bdd0: 6974 7928 295b 2773 7461 7469 6327 5d0a  ity()['static'].
+0000bde0: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
+0000bdf0: 2071 5f63 6170 6162 696c 6974 7920 3d20   q_capability = 
+0000be00: 7b7d 0a20 2020 2020 2020 2071 5f63 6170  {}.        q_cap
+0000be10: 6162 696c 6974 795b 276f 7074 7970 6577  ability['optypew
+0000be20: 6973 6527 5d20 3d20 4f72 6465 7265 6444  ise'] = OrderedD
+0000be30: 6963 7428 290a 2020 2020 2020 2020 715f  ict().        q_
+0000be40: 6361 7061 6269 6c69 7479 5b27 6f70 7769  capability['opwi
+0000be50: 7365 275d 203d 204f 7264 6572 6564 4469  se'] = OrderedDi
+0000be60: 6374 2829 0a20 2020 2020 2020 2071 7561  ct().        qua
+0000be70: 6e74 5f64 6174 6174 7970 6573 203d 2073  nt_datatypes = s
+0000be80: 656c 662e 7175 6572 795f 6861 6e64 6c65  elf.query_handle
+0000be90: 722e 6765 745f 7175 616e 745f 6461 7461  r.get_quant_data
+0000bea0: 7479 7065 7328 290a 0a20 2020 2020 2020  types()..       
+0000beb0: 2069 6620 7365 6c66 2e61 7070 726f 6163   if self.approac
+0000bec0: 6820 3d3d 2022 7175 616e 745f 6177 6172  h == "quant_awar
+0000bed0: 655f 7472 6169 6e69 6e67 223a 0a20 2020  e_training":.   
+0000bee0: 2020 2020 2020 2020 2063 6170 6162 696c           capabil
+0000bef0: 6974 795f 7061 6972 203d 205b 2873 656c  ity_pair = [(sel
+0000bf00: 662e 7175 6572 795f 6861 6e64 6c65 722e  f.query_handler.
+0000bf10: 6765 745f 7175 616e 7469 7a61 7469 6f6e  get_quantization
+0000bf20: 5f63 6170 6162 696c 6974 7928 295b 2771  _capability()['q
+0000bf30: 7561 6e74 5f61 7761 7265 275d 2c20 2773  uant_aware'], 's
+0000bf40: 7461 7469 6327 295d 0a20 2020 2020 2020  tatic')].       
+0000bf50: 2020 2020 2066 7033 325f 636f 6e66 6967       fp32_config
+0000bf60: 203d 207b 2761 6374 6976 6174 696f 6e27   = {'activation'
+0000bf70: 3a20 7b27 6474 7970 6527 3a20 2766 7033  : {'dtype': 'fp3
+0000bf80: 3227 7d2c 2027 7765 6967 6874 273a 207b  2'}, 'weight': {
+0000bf90: 2764 7479 7065 273a 2027 6670 3332 277d  'dtype': 'fp32'}
+0000bfa0: 7d0a 2020 2020 2020 2020 2020 2020 2320  }.            # 
+0000bfb0: 4967 6e6f 7265 204c 6179 6572 4e6f 726d  Ignore LayerNorm
+0000bfc0: 2c20 496e 7374 616e 6365 4e6f 726d 3364  , InstanceNorm3d
+0000bfd0: 2061 6e64 2045 6d62 6564 6469 6e67 2071   and Embedding q
+0000bfe0: 7561 6e74 697a 6162 6c65 206f 7073 2c0a  uantizable ops,.
+0000bff0: 2020 2020 2020 2020 2020 2020 2320 6475              # du
+0000c000: 6520 746f 2068 7567 6520 6163 6375 7261  e to huge accura
+0000c010: 6379 2072 6567 7265 7373 696f 6e20 696e  cy regression in
+0000c020: 2050 7954 6f72 6368 2e0a 2020 2020 2020   PyTorch..      
+0000c030: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+0000c040: 6e63 6528 7365 6c66 2c20 5079 546f 7263  nce(self, PyTorc
+0000c050: 685f 4950 4558 4164 6170 746f 7229 3a0a  h_IPEXAdaptor):.
+0000c060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c070: 6164 6469 7469 6f6e 616c 5f73 6b69 7070  additional_skipp
+0000c080: 6564 5f6d 6f64 756c 655f 636c 6173 7365  ed_module_classe
+0000c090: 7320 3d20 7b7d 0a20 2020 2020 2020 2020  s = {}.         
+0000c0a0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0000c0b0: 2020 2020 2020 2020 2061 6464 6974 696f           additio
+0000c0c0: 6e61 6c5f 736b 6970 7065 645f 6d6f 6475  nal_skipped_modu
+0000c0d0: 6c65 5f63 6c61 7373 6573 203d 207b 274c  le_classes = {'L
+0000c0e0: 6179 6572 4e6f 726d 272c 2027 496e 7374  ayerNorm', 'Inst
+0000c0f0: 616e 6365 4e6f 726d 3364 272c 2027 4472  anceNorm3d', 'Dr
+0000c100: 6f70 6f75 7427 7d0a 2020 2020 2020 2020  opout'}.        
+0000c110: 2020 2020 6e6f 5f66 7033 325f 6f70 7320      no_fp32_ops 
+0000c120: 3d20 7b27 5175 616e 7453 7475 6227 7d0a  = {'QuantStub'}.
+0000c130: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+0000c140: 7061 6972 2069 6e20 6361 7061 6269 6c69  pair in capabili
+0000c150: 7479 5f70 6169 723a 0a20 2020 2020 2020  ty_pair:.       
+0000c160: 2020 2020 2020 2020 2063 6170 6162 696c           capabil
+0000c170: 6974 792c 206d 6f64 6520 3d20 7061 6972  ity, mode = pair
+0000c180: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c190: 2066 6f72 2071 5f6f 7020 696e 2071 7561   for q_op in qua
+0000c1a0: 6e74 697a 6162 6c65 5f6f 7073 3a0a 2020  ntizable_ops:.  
+0000c1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c1c0: 2020 6966 2071 5f6f 7020 6e6f 7420 696e    if q_op not in
+0000c1d0: 2071 5f63 6170 6162 696c 6974 795b 276f   q_capability['o
+0000c1e0: 7077 6973 6527 5d3a 0a20 2020 2020 2020  pwise']:.       
+0000c1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c200: 2071 5f63 6170 6162 696c 6974 795b 276f   q_capability['o
+0000c210: 7077 6973 6527 5d5b 715f 6f70 5d20 3d20  pwise'][q_op] = 
+0000c220: 5b5d 0a20 2020 2020 2020 2020 2020 2020  [].             
+0000c230: 2020 2020 2020 2069 6620 715f 6f70 5b31         if q_op[1
+0000c240: 5d20 6e6f 7420 696e 2071 5f63 6170 6162  ] not in q_capab
+0000c250: 696c 6974 795b 276f 7074 7970 6577 6973  ility['optypewis
+0000c260: 6527 5d3a 0a20 2020 2020 2020 2020 2020  e']:.           
+0000c270: 2020 2020 2020 2020 2020 2020 2071 5f63               q_c
+0000c280: 6170 6162 696c 6974 795b 276f 7074 7970  apability['optyp
+0000c290: 6577 6973 6527 5d5b 715f 6f70 5b31 5d5d  ewise'][q_op[1]]
+0000c2a0: 203d 205b 5d0a 0a20 2020 2020 2020 2020   = []..         
+0000c2b0: 2020 2020 2020 2020 2020 206f 705f 6366             op_cf
+0000c2c0: 6720 3d20 636f 7079 2e64 6565 7063 6f70  g = copy.deepcop
+0000c2d0: 7928 6361 7061 6269 6c69 7479 5b71 5f6f  y(capability[q_o
+0000c2e0: 705b 315d 5d29 2069 6620 715f 6f70 5b31  p[1]]) if q_op[1
+0000c2f0: 5d20 696e 2063 6170 6162 696c 6974 7920  ] in capability 
+0000c300: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+0000c310: 2020 2020 2020 2020 2020 656c 7365 2063            else c
+0000c320: 6f70 792e 6465 6570 636f 7079 2863 6170  opy.deepcopy(cap
+0000c330: 6162 696c 6974 795b 2764 6566 6175 6c74  ability['default
+0000c340: 275d 290a 0a20 2020 2020 2020 2020 2020  '])..           
+0000c350: 2020 2020 2020 2020 206f 705f 6366 675b           op_cfg[
+0000c360: 2761 6374 6976 6174 696f 6e27 5d5b 2771  'activation']['q
+0000c370: 7561 6e74 5f6d 6f64 6527 5d20 3d20 6d6f  uant_mode'] = mo
+0000c380: 6465 2069 6620 715f 6f70 5b31 5d20 6e6f  de if q_op[1] no
+0000c390: 7420 696e 205c 0a20 2020 2020 2020 2020  t in \.         
+0000c3a0: 2020 2020 2020 2020 2020 2020 2020 205b                 [
+0000c3b0: 274c 5354 4d27 2c20 2747 5255 272c 2027  'LSTM', 'GRU', '
+0000c3c0: 4c53 544d 4365 6c6c 272c 2027 4752 5543  LSTMCell', 'GRUC
+0000c3d0: 656c 6c27 2c20 2752 4e4e 4365 6c6c 275d  ell', 'RNNCell']
+0000c3e0: 2065 6c73 6520 2764 796e 616d 6963 270a   else 'dynamic'.
+0000c3f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c400: 2020 2020 2023 2073 6b69 7020 7468 6520       # skip the 
+0000c410: 6f70 2074 6861 7420 6f6e 6c79 2069 6e63  op that only inc
+0000c420: 6c75 6465 2066 7033 320a 2020 2020 2020  lude fp32.      
+0000c430: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000c440: 2071 5f6f 705b 315d 206e 6f74 2069 6e20   q_op[1] not in 
+0000c450: 6164 6469 7469 6f6e 616c 5f73 6b69 7070  additional_skipp
+0000c460: 6564 5f6d 6f64 756c 655f 636c 6173 7365  ed_module_classe
+0000c470: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
+0000c480: 2020 2020 2020 2020 2020 2069 6620 6f70             if op
+0000c490: 5f63 6667 206e 6f74 2069 6e20 715f 6361  _cfg not in q_ca
+0000c4a0: 7061 6269 6c69 7479 5b27 6f70 7769 7365  pability['opwise
+0000c4b0: 275d 5b71 5f6f 705d 3a0a 2020 2020 2020  '][q_op]:.      
+0000c4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c4d0: 2020 2020 2020 715f 6361 7061 6269 6c69        q_capabili
+0000c4e0: 7479 5b27 6f70 7769 7365 275d 5b71 5f6f  ty['opwise'][q_o
+0000c4f0: 705d 2e61 7070 656e 6428 6f70 5f63 6667  p].append(op_cfg
+0000c500: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0000c510: 2020 2020 2020 2020 2020 6966 206f 705f            if op_
+0000c520: 6366 6720 6e6f 7420 696e 2071 5f63 6170  cfg not in q_cap
+0000c530: 6162 696c 6974 795b 276f 7074 7970 6577  ability['optypew
+0000c540: 6973 6527 5d5b 715f 6f70 5b31 5d5d 3a0a  ise'][q_op[1]]:.
 0000c550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c560: 2071 5f63 6170 6162 696c 6974 795b 276f   q_capability['o
-0000c570: 7074 7970 6577 6973 6527 5d5b 715f 6f70  ptypewise'][q_op
-0000c580: 5b31 5d5d 2e61 7070 656e 6428 6670 3332  [1]].append(fp32
-0000c590: 5f63 6f6e 6669 6729 0a0a 0a20 2020 2020  _config)...     
-0000c5a0: 2020 2023 2067 6574 2062 6631 3620 6361     # get bf16 ca
-0000c5b0: 7061 6269 6c69 7479 0a20 2020 2020 2020  pability.       
-0000c5c0: 2069 6620 7365 6c66 2e75 7365 5f62 6631   if self.use_bf1
-0000c5d0: 3620 616e 6420 2843 7075 496e 666f 2829  6 and (CpuInfo()
-0000c5e0: 2e62 6631 3620 6f72 206f 732e 6765 7465  .bf16 or os.gete
-0000c5f0: 6e76 2827 464f 5243 455f 4246 3136 2729  nv('FORCE_BF16')
-0000c600: 203d 3d20 2731 2729 2061 6e64 205c 0a20   == '1') and \. 
-0000c610: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
-0000c620: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
-0000c630: 203e 3d20 5665 7273 696f 6e28 2231 2e31   >= Version("1.1
-0000c640: 312e 3022 292e 7265 6c65 6173 6529 3a0a  1.0").release):.
-0000c650: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0000c660: 2e62 6631 365f 6f70 7320 3d20 7365 6c66  .bf16_ops = self
-0000c670: 2e71 7565 7279 5f68 616e 646c 6572 2e67  .query_handler.g
-0000c680: 6574 5f6f 705f 7479 7065 735f 6279 5f70  et_op_types_by_p
-0000c690: 7265 6369 7369 6f6e 2822 6266 3136 2229  recision("bf16")
-0000c6a0: 0a20 2020 2020 2020 2020 2020 2062 6631  .            bf1
-0000c6b0: 365f 6f70 7320 3d20 5b5d 0a20 2020 2020  6_ops = [].     
-0000c6c0: 2020 2020 2020 2073 656c 662e 5f67 6574         self._get
-0000c6d0: 5f62 6631 365f 6f70 735f 7265 6375 7273  _bf16_ops_recurs
-0000c6e0: 6976 656c 7928 746d 705f 6d6f 6465 6c2c  ively(tmp_model,
-0000c6f0: 2027 272c 2062 6631 365f 6f70 7329 0a20   '', bf16_ops). 
-0000c700: 2020 2020 2020 2020 2020 206d 6978 6564             mixed
-0000c710: 5f63 6170 6162 696c 6974 7920 3d20 7365  _capability = se
-0000c720: 6c66 2e5f 636f 6d62 696e 655f 6361 7061  lf._combine_capa
-0000c730: 6269 6c69 7479 2862 6631 365f 6f70 732c  bility(bf16_ops,
-0000c740: 2071 5f63 6170 6162 696c 6974 7929 0a20   q_capability). 
-0000c750: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0000c760: 6e20 6d69 7865 645f 6361 7061 6269 6c69  n mixed_capabili
-0000c770: 7479 0a0a 2020 2020 2020 2020 7265 7475  ty..        retu
-0000c780: 726e 2071 5f63 6170 6162 696c 6974 790a  rn q_capability.
-0000c790: 0a20 2020 2064 6566 205f 6765 745f 6266  .    def _get_bf
-0000c7a0: 3136 5f6f 7073 5f72 6563 7572 7369 7665  16_ops_recursive
-0000c7b0: 6c79 2873 656c 662c 206d 6f64 656c 2c20  ly(self, model, 
-0000c7c0: 7072 6566 6978 2c20 6266 3136 5f6f 7073  prefix, bf16_ops
-0000c7d0: 293a 0a20 2020 2020 2020 2022 2222 5468  ):.        """Th
-0000c7e0: 6973 2069 7320 6120 6865 6c70 6572 2066  is is a helper f
-0000c7f0: 756e 6374 696f 6e20 666f 7220 6071 7565  unction for `que
-0000c800: 7279 5f66 775f 6361 7061 6269 6c69 7479  ry_fw_capability
-0000c810: 602c 0a20 2020 2020 2020 2020 2020 616e  `,.           an
-0000c820: 6420 6974 2077 696c 6c20 6765 7420 616c  d it will get al
-0000c830: 6c20 7175 616e 7469 7a61 626c 6520 6f70  l quantizable op
-0000c840: 7320 6672 6f6d 206d 6f64 656c 2e0a 0a20  s from model... 
-0000c850: 2020 2020 2020 2041 7267 733a 0a20 2020         Args:.   
-0000c860: 2020 2020 2020 2020 206d 6f64 656c 2028           model (
-0000c870: 6f62 6a65 6374 293a 2069 6e70 7574 206d  object): input m
-0000c880: 6f64 656c 0a20 2020 2020 2020 2020 2020  odel.           
-0000c890: 2070 7265 6669 7820 2873 7472 696e 6729   prefix (string)
-0000c8a0: 3a20 7072 6566 6978 206f 6620 6f70 206e  : prefix of op n
-0000c8b0: 616d 650a 2020 2020 2020 2020 2020 2020  ame.            
-0000c8c0: 6266 3136 5f6f 7073 2028 6c69 7374 293a  bf16_ops (list):
-0000c8d0: 206c 6973 7420 6f66 2071 7561 6e74 697a   list of quantiz
-0000c8e0: 6162 6c65 206f 7073 2066 726f 6d20 6d6f  able ops from mo
-0000c8f0: 6465 6c20 696e 636c 7564 6520 6f70 206e  del include op n
-0000c900: 616d 6520 616e 6420 7479 7065 2e0a 0a20  ame and type... 
-0000c910: 2020 2020 2020 2052 6574 7572 6e73 3a0a         Returns:.
-0000c920: 2020 2020 2020 2020 2020 2020 4e6f 6e65              None
-0000c930: 0a20 2020 2020 2020 2022 2222 0a0a 2020  .        """..  
-0000c940: 2020 2020 2020 666f 7220 6e61 6d65 2c20        for name, 
-0000c950: 6368 696c 6420 696e 206d 6f64 656c 2e6e  child in model.n
-0000c960: 616d 6564 5f63 6869 6c64 7265 6e28 293a  amed_children():
-0000c970: 0a20 2020 2020 2020 2020 2020 206f 705f  .            op_
-0000c980: 6e61 6d65 203d 2070 7265 6669 7820 2b20  name = prefix + 
-0000c990: 272e 2720 2b20 6e61 6d65 2069 6620 7072  '.' + name if pr
-0000c9a0: 6566 6978 2021 3d20 2727 2065 6c73 6520  efix != '' else 
-0000c9b0: 6e61 6d65 0a20 2020 2020 2020 2020 2020  name.           
-0000c9c0: 2069 6620 7374 7228 6368 696c 642e 5f5f   if str(child.__
-0000c9d0: 636c 6173 735f 5f2e 5f5f 6e61 6d65 5f5f  class__.__name__
-0000c9e0: 2920 696e 2073 656c 662e 6266 3136 5f6f  ) in self.bf16_o
-0000c9f0: 7073 205c 0a20 2020 2020 2020 2020 2020  ps \.           
-0000ca00: 2020 2020 616e 6420 7479 7065 2863 6869      and type(chi
-0000ca10: 6c64 2920 213d 2074 6f72 6368 2e6e 6e2e  ld) != torch.nn.
-0000ca20: 5365 7175 656e 7469 616c 205c 0a20 2020  Sequential \.   
-0000ca30: 2020 2020 2020 2020 2020 2020 616e 6420              and 
-0000ca40: 7479 7065 2863 6869 6c64 2920 213d 2074  type(child) != t
-0000ca50: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
-0000ca60: 6e2e 7374 7562 732e 4465 5175 616e 7453  n.stubs.DeQuantS
-0000ca70: 7475 623a 0a20 2020 2020 2020 2020 2020  tub:.           
-0000ca80: 2020 2020 2062 6631 365f 6f70 732e 6170       bf16_ops.ap
-0000ca90: 7065 6e64 2828 6f70 5f6e 616d 652c 2075  pend((op_name, u
-0000caa0: 6e69 6679 5f6f 705f 7479 7065 5f6d 6170  nify_op_type_map
-0000cab0: 7069 6e67 5b73 7472 2863 6869 6c64 2e5f  ping[str(child._
-0000cac0: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
-0000cad0: 5f29 5d0a 2020 2020 2020 2020 2020 2020  _)].            
-0000cae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000caf0: 2020 2020 2069 6620 7374 7228 6368 696c       if str(chil
-0000cb00: 642e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  d.__class__.__na
-0000cb10: 6d65 5f5f 2920 696e 2075 6e69 6679 5f6f  me__) in unify_o
-0000cb20: 705f 7479 7065 5f6d 6170 7069 6e67 2065  p_type_mapping e
-0000cb30: 6c73 650a 2020 2020 2020 2020 2020 2020  lse.            
-0000cb40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cb50: 2020 2020 2073 7472 2863 6869 6c64 2e5f       str(child._
-0000cb60: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
-0000cb70: 5f29 2929 0a20 2020 2020 2020 2020 2020  _))).           
-0000cb80: 2065 6c69 6620 7365 6c66 2e69 735f 6675   elif self.is_fu
-0000cb90: 7365 645f 6d6f 6475 6c65 2863 6869 6c64  sed_module(child
-0000cba0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0000cbb0: 2020 2063 6f6e 7469 6e75 650a 2020 2020     continue.    
-0000cbc0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0000cbd0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-0000cbe0: 6c66 2e5f 6765 745f 6266 3136 5f6f 7073  lf._get_bf16_ops
-0000cbf0: 5f72 6563 7572 7369 7665 6c79 2863 6869  _recursively(chi
-0000cc00: 6c64 2c20 6f70 5f6e 616d 652c 2062 6631  ld, op_name, bf1
-0000cc10: 365f 6f70 7329 0a0a 2020 2020 6465 6620  6_ops)..    def 
-0000cc20: 5f63 6f6d 6269 6e65 5f63 6170 6162 696c  _combine_capabil
-0000cc30: 6974 7928 7365 6c66 2c20 6266 3136 5f6f  ity(self, bf16_o
-0000cc40: 7073 2c20 715f 6361 7061 6269 6c69 7479  ps, q_capability
-0000cc50: 293a 0a20 2020 2020 2020 2062 6631 365f  ):.        bf16_
-0000cc60: 636f 6e66 6967 203d 207b 2761 6374 6976  config = {'activ
-0000cc70: 6174 696f 6e27 3a20 7b27 6474 7970 6527  ation': {'dtype'
-0000cc80: 3a20 2762 6631 3627 7d2c 2027 7765 6967  : 'bf16'}, 'weig
-0000cc90: 6874 273a 207b 2764 7479 7065 273a 2027  ht': {'dtype': '
-0000cca0: 6266 3136 277d 7d0a 2020 2020 2020 2020  bf16'}}.        
-0000ccb0: 6670 3332 5f63 6f6e 6669 6720 3d20 7b27  fp32_config = {'
-0000ccc0: 6163 7469 7661 7469 6f6e 273a 207b 2764  activation': {'d
-0000ccd0: 7479 7065 273a 2027 6670 3332 277d 2c20  type': 'fp32'}, 
-0000cce0: 2777 6569 6768 7427 3a20 7b27 6474 7970  'weight': {'dtyp
-0000ccf0: 6527 3a20 2766 7033 3227 7d7d 0a20 2020  e': 'fp32'}}.   
-0000cd00: 2020 2020 2066 6f72 2062 6631 365f 6f70       for bf16_op
-0000cd10: 2069 6e20 6266 3136 5f6f 7073 3a0a 2020   in bf16_ops:.  
-0000cd20: 2020 2020 2020 2020 2020 6966 2062 6631            if bf1
-0000cd30: 365f 6f70 2069 6e20 715f 6361 7061 6269  6_op in q_capabi
-0000cd40: 6c69 7479 5b27 6f70 7769 7365 275d 2061  lity['opwise'] a
-0000cd50: 6e64 205c 0a20 2020 2020 2020 2020 2020  nd \.           
-0000cd60: 2020 2020 2062 6631 365f 636f 6e66 6967       bf16_config
-0000cd70: 206e 6f74 2069 6e20 715f 6361 7061 6269   not in q_capabi
-0000cd80: 6c69 7479 5b27 6f70 7769 7365 275d 5b62  lity['opwise'][b
-0000cd90: 6631 365f 6f70 5d3a 0a20 2020 2020 2020  f16_op]:.       
-0000cda0: 2020 2020 2020 2020 2071 5f63 6170 6162           q_capab
-0000cdb0: 696c 6974 795b 276f 7077 6973 6527 5d5b  ility['opwise'][
-0000cdc0: 6266 3136 5f6f 705d 2e61 7070 656e 6428  bf16_op].append(
-0000cdd0: 6266 3136 5f63 6f6e 6669 6729 0a20 2020  bf16_config).   
-0000cde0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-0000cdf0: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-0000ce00: 5f63 6170 6162 696c 6974 795b 276f 7077  _capability['opw
-0000ce10: 6973 6527 5d5b 6266 3136 5f6f 705d 203d  ise'][bf16_op] =
-0000ce20: 205b 6266 3136 5f63 6f6e 6669 672c 2066   [bf16_config, f
-0000ce30: 7033 325f 636f 6e66 6967 5d0a 2020 2020  p32_config].    
-0000ce40: 2020 2020 2020 2020 2020 2020 6966 2062              if b
-0000ce50: 6631 365f 6f70 5b31 5d20 6e6f 7420 696e  f16_op[1] not in
-0000ce60: 2071 5f63 6170 6162 696c 6974 795b 276f   q_capability['o
-0000ce70: 7074 7970 6577 6973 6527 5d3a 0a20 2020  ptypewise']:.   
+0000c560: 2020 2020 2020 2020 2020 2020 715f 6361              q_ca
+0000c570: 7061 6269 6c69 7479 5b27 6f70 7479 7065  pability['optype
+0000c580: 7769 7365 275d 5b71 5f6f 705b 315d 5d2e  wise'][q_op[1]].
+0000c590: 6170 7065 6e64 286f 705f 6366 6729 0a0a  append(op_cfg)..
+0000c5a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c5b0: 2020 2020 6966 2071 5f6f 705b 315d 206e      if q_op[1] n
+0000c5c0: 6f74 2069 6e20 6e6f 5f66 7033 325f 6f70  ot in no_fp32_op
+0000c5d0: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
+0000c5e0: 2020 2020 2020 2020 2020 2069 6620 6670             if fp
+0000c5f0: 3332 5f63 6f6e 6669 6720 6e6f 7420 696e  32_config not in
+0000c600: 2071 5f63 6170 6162 696c 6974 795b 276f   q_capability['o
+0000c610: 7077 6973 6527 5d5b 715f 6f70 5d3a 0a20  pwise'][q_op]:. 
+0000c620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c630: 2020 2020 2020 2020 2020 2071 5f63 6170             q_cap
+0000c640: 6162 696c 6974 795b 276f 7077 6973 6527  ability['opwise'
+0000c650: 5d5b 715f 6f70 5d2e 6170 7065 6e64 2866  ][q_op].append(f
+0000c660: 7033 325f 636f 6e66 6967 290a 2020 2020  p32_config).    
+0000c670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c680: 2020 2020 6966 2066 7033 325f 636f 6e66      if fp32_conf
+0000c690: 6967 206e 6f74 2069 6e20 715f 6361 7061  ig not in q_capa
+0000c6a0: 6269 6c69 7479 5b27 6f70 7479 7065 7769  bility['optypewi
+0000c6b0: 7365 275d 5b71 5f6f 705b 315d 5d3a 0a20  se'][q_op[1]]:. 
+0000c6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c6d0: 2020 2020 2020 2020 2020 2071 5f63 6170             q_cap
+0000c6e0: 6162 696c 6974 795b 276f 7074 7970 6577  ability['optypew
+0000c6f0: 6973 6527 5d5b 715f 6f70 5b31 5d5d 2e61  ise'][q_op[1]].a
+0000c700: 7070 656e 6428 6670 3332 5f63 6f6e 6669  ppend(fp32_confi
+0000c710: 6729 0a20 2020 2020 2020 2065 6c73 653a  g).        else:
+0000c720: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+0000c730: 2064 6174 6174 7970 6520 696e 2071 7561   datatype in qua
+0000c740: 6e74 5f64 6174 6174 7970 6573 3a0a 2020  nt_datatypes:.  
+0000c750: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000c760: 2073 656c 662e 6170 7072 6f61 6368 203d   self.approach =
+0000c770: 3d20 2270 6f73 745f 7472 6169 6e69 6e67  = "post_training
+0000c780: 5f64 796e 616d 6963 5f71 7561 6e74 223a  _dynamic_quant":
+0000c790: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c7a0: 2020 2020 2063 6170 6162 696c 6974 795f       capability_
+0000c7b0: 7061 6972 203d 205b 0a20 2020 2020 2020  pair = [.       
+0000c7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c7d0: 2028 7365 6c66 2e71 7565 7279 5f68 616e   (self.query_han
+0000c7e0: 646c 6572 2e67 6574 5f71 7561 6e74 697a  dler.get_quantiz
+0000c7f0: 6174 696f 6e5f 6361 7061 6269 6c69 7479  ation_capability
+0000c800: 2864 6174 6174 7970 6529 2e67 6574 2827  (datatype).get('
+0000c810: 6479 6e61 6d69 6327 2c20 7b7d 292c 2027  dynamic', {}), '
+0000c820: 6479 6e61 6d69 6327 295d 0a20 2020 2020  dynamic')].     
+0000c830: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+0000c840: 7365 6c66 2e61 7070 726f 6163 6820 3d3d  self.approach ==
+0000c850: 2022 706f 7374 5f74 7261 696e 696e 675f   "post_training_
+0000c860: 7374 6174 6963 5f71 7561 6e74 223a 0a20  static_quant":. 
+0000c870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c880: 2020 2063 6170 6162 696c 6974 795f 7061     capability_pa
+0000c890: 6972 203d 205b 0a20 2020 2020 2020 2020  ir = [.         
+0000c8a0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+0000c8b0: 7365 6c66 2e71 7565 7279 5f68 616e 646c  self.query_handl
+0000c8c0: 6572 2e67 6574 5f71 7561 6e74 697a 6174  er.get_quantizat
+0000c8d0: 696f 6e5f 6361 7061 6269 6c69 7479 2864  ion_capability(d
+0000c8e0: 6174 6174 7970 6529 2e67 6574 2827 7374  atatype).get('st
+0000c8f0: 6174 6963 272c 207b 7d29 2c20 2773 7461  atic', {}), 'sta
+0000c900: 7469 6327 295d 0a20 2020 2020 2020 2020  tic')].         
+0000c910: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0000c920: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c930: 2063 6170 6162 696c 6974 795f 7061 6972   capability_pair
+0000c940: 203d 205b 0a20 2020 2020 2020 2020 2020   = [.           
+0000c950: 2020 2020 2020 2020 2020 2020 2028 7365               (se
+0000c960: 6c66 2e71 7565 7279 5f68 616e 646c 6572  lf.query_handler
+0000c970: 2e67 6574 5f71 7561 6e74 697a 6174 696f  .get_quantizatio
+0000c980: 6e5f 6361 7061 6269 6c69 7479 2864 6174  n_capability(dat
+0000c990: 6174 7970 6529 2e67 6574 2827 7374 6174  atype).get('stat
+0000c9a0: 6963 272c 207b 7d29 2c20 2773 7461 7469  ic', {}), 'stati
+0000c9b0: 6327 292c 0a20 2020 2020 2020 2020 2020  c'),.           
+0000c9c0: 2020 2020 2020 2020 2020 2020 2028 7365               (se
+0000c9d0: 6c66 2e71 7565 7279 5f68 616e 646c 6572  lf.query_handler
+0000c9e0: 2e67 6574 5f71 7561 6e74 697a 6174 696f  .get_quantizatio
+0000c9f0: 6e5f 6361 7061 6269 6c69 7479 2864 6174  n_capability(dat
+0000ca00: 6174 7970 6529 2e67 6574 2827 6479 6e61  atype).get('dyna
+0000ca10: 6d69 6327 2c20 7b7d 292c 2027 6479 6e61  mic', {}), 'dyna
+0000ca20: 6d69 6327 295d 0a0a 2020 2020 2020 2020  mic')]..        
+0000ca30: 2020 2020 2020 2020 6670 3332 5f63 6f6e          fp32_con
+0000ca40: 6669 6720 3d20 7b27 6163 7469 7661 7469  fig = {'activati
+0000ca50: 6f6e 273a 207b 2764 7479 7065 273a 2027  on': {'dtype': '
+0000ca60: 6670 3332 277d 2c20 2777 6569 6768 7427  fp32'}, 'weight'
+0000ca70: 3a20 7b27 6474 7970 6527 3a20 2766 7033  : {'dtype': 'fp3
+0000ca80: 3227 7d7d 0a20 2020 2020 2020 2020 2020  2'}}.           
+0000ca90: 2020 2020 2023 2049 676e 6f72 6520 4c61       # Ignore La
+0000caa0: 7965 724e 6f72 6d2c 2049 6e73 7461 6e63  yerNorm, Instanc
+0000cab0: 654e 6f72 6d33 6420 616e 6420 456d 6265  eNorm3d and Embe
+0000cac0: 6464 696e 6720 7175 616e 7469 7a61 626c  dding quantizabl
+0000cad0: 6520 6f70 732c 0a20 2020 2020 2020 2020  e ops,.         
+0000cae0: 2020 2020 2020 2023 2064 7565 2074 6f20         # due to 
+0000caf0: 6875 6765 2061 6363 7572 6163 7920 7265  huge accuracy re
+0000cb00: 6772 6573 7369 6f6e 2069 6e20 5079 546f  gression in PyTo
+0000cb10: 7263 682e 0a20 2020 2020 2020 2020 2020  rch..           
+0000cb20: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
+0000cb30: 6365 2873 656c 662c 2050 7954 6f72 6368  ce(self, PyTorch
+0000cb40: 5f49 5045 5841 6461 7074 6f72 293a 0a20  _IPEXAdaptor):. 
+0000cb50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cb60: 2020 2061 6464 6974 696f 6e61 6c5f 736b     additional_sk
+0000cb70: 6970 7065 645f 6d6f 6475 6c65 5f63 6c61  ipped_module_cla
+0000cb80: 7373 6573 203d 207b 7d0a 2020 2020 2020  sses = {}.      
+0000cb90: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+0000cba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbb0: 2020 2020 6164 6469 7469 6f6e 616c 5f73      additional_s
+0000cbc0: 6b69 7070 6564 5f6d 6f64 756c 655f 636c  kipped_module_cl
+0000cbd0: 6173 7365 7320 3d20 7b27 4c61 7965 724e  asses = {'LayerN
+0000cbe0: 6f72 6d27 2c20 2749 6e73 7461 6e63 654e  orm', 'InstanceN
+0000cbf0: 6f72 6d33 6427 2c20 2744 726f 706f 7574  orm3d', 'Dropout
+0000cc00: 277d 0a20 2020 2020 2020 2020 2020 2020  '}.             
+0000cc10: 2020 206e 6f5f 6670 3332 5f6f 7073 203d     no_fp32_ops =
+0000cc20: 207b 2751 7561 6e74 5374 7562 277d 0a20   {'QuantStub'}. 
+0000cc30: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000cc40: 6f72 2070 6169 7220 696e 2063 6170 6162  or pair in capab
+0000cc50: 696c 6974 795f 7061 6972 3a0a 2020 2020  ility_pair:.    
+0000cc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cc70: 6361 7061 6269 6c69 7479 2c20 6d6f 6465  capability, mode
+0000cc80: 203d 2070 6169 720a 2020 2020 2020 2020   = pair.        
+0000cc90: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+0000cca0: 715f 6f70 2069 6e20 7175 616e 7469 7a61  q_op in quantiza
+0000ccb0: 626c 655f 6f70 733a 0a20 2020 2020 2020  ble_ops:.       
+0000ccc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ccd0: 206f 705f 6366 6720 3d20 4e6f 6e65 0a20   op_cfg = None. 
+0000cce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ccf0: 2020 2020 2020 2069 6620 715f 6f70 206e         if q_op n
+0000cd00: 6f74 2069 6e20 715f 6361 7061 6269 6c69  ot in q_capabili
+0000cd10: 7479 5b27 6f70 7769 7365 275d 3a0a 2020  ty['opwise']:.  
+0000cd20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd30: 2020 2020 2020 2020 2020 715f 6361 7061            q_capa
+0000cd40: 6269 6c69 7479 5b27 6f70 7769 7365 275d  bility['opwise']
+0000cd50: 5b71 5f6f 705d 203d 205b 5d0a 2020 2020  [q_op] = [].    
+0000cd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd70: 2020 2020 6966 2071 5f6f 705b 315d 206e      if q_op[1] n
+0000cd80: 6f74 2069 6e20 715f 6361 7061 6269 6c69  ot in q_capabili
+0000cd90: 7479 5b27 6f70 7479 7065 7769 7365 275d  ty['optypewise']
+0000cda0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000cdb0: 2020 2020 2020 2020 2020 2020 2020 715f                q_
+0000cdc0: 6361 7061 6269 6c69 7479 5b27 6f70 7479  capability['opty
+0000cdd0: 7065 7769 7365 275d 5b71 5f6f 705b 315d  pewise'][q_op[1]
+0000cde0: 5d20 3d20 5b5d 0a0a 2020 2020 2020 2020  ] = []..        
+0000cdf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ce00: 6966 206d 6f64 6520 3d3d 2027 7374 6174  if mode == 'stat
+0000ce10: 6963 2720 616e 6420 715f 6f70 5b31 5d20  ic' and q_op[1] 
+0000ce20: 696e 205b 274c 5354 4d27 2c20 2747 5255  in ['LSTM', 'GRU
+0000ce30: 272c 2027 4c53 544d 4365 6c6c 272c 2027  ', 'LSTMCell', '
+0000ce40: 4752 5543 656c 6c27 2c20 2752 4e4e 4365  GRUCell', 'RNNCe
+0000ce50: 6c6c 275d 3a0a 2020 2020 2020 2020 2020  ll']:.          
+0000ce60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ce70: 2020 636f 6e74 696e 7565 0a0a 2020 2020    continue..    
 0000ce80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ce90: 2071 5f63 6170 6162 696c 6974 795b 276f   q_capability['o
-0000cea0: 7074 7970 6577 6973 6527 5d5b 6266 3136  ptypewise'][bf16
-0000ceb0: 5f6f 705b 315d 5d20 3d20 5b62 6631 365f  _op[1]] = [bf16_
-0000cec0: 636f 6e66 6967 2c20 6670 3332 5f63 6f6e  config, fp32_con
-0000ced0: 6669 675d 0a20 2020 2020 2020 2072 6574  fig].        ret
-0000cee0: 7572 6e20 715f 6361 7061 6269 6c69 7479  urn q_capability
-0000cef0: 0a0a 2020 2020 6465 6620 6973 5f66 7573  ..    def is_fus
-0000cf00: 6564 5f6d 6f64 756c 6528 7365 6c66 2c20  ed_module(self, 
-0000cf10: 6d6f 6475 6c65 293a 0a20 2020 2020 2020  module):.       
-0000cf20: 2022 2222 5468 6973 2069 7320 6120 6865   """This is a he
-0000cf30: 6c70 6572 2066 756e 6374 696f 6e20 666f  lper function fo
-0000cf40: 7220 605f 7072 6f70 6167 6174 655f 7163  r `_propagate_qc
-0000cf50: 6f6e 6669 675f 6865 6c70 6572 6020 746f  onfig_helper` to
-0000cf60: 2064 6574 6563 7465 0a20 2020 2020 2020   detecte.       
-0000cf70: 2020 2020 6966 2074 6869 7320 6d6f 6475      if this modu
-0000cf80: 6c65 2069 7320 6675 7365 642e 0a0a 2020  le is fused...  
-0000cf90: 2020 2020 2020 4172 6773 3a0a 2020 2020        Args:.    
-0000cfa0: 2020 2020 2020 2020 6d6f 6475 6c65 2028          module (
-0000cfb0: 6f62 6a65 6374 293a 2069 6e70 7574 206d  object): input m
-0000cfc0: 6f64 756c 650a 0a20 2020 2020 2020 2052  odule..        R
-0000cfd0: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
-0000cfe0: 2020 2020 2862 6f6f 6c29 3a20 6973 2066      (bool): is f
-0000cff0: 7573 6564 206f 7220 6e6f 740a 2020 2020  used or not.    
-0000d000: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-0000d010: 6f70 5f74 7970 6520 3d20 7374 7228 7479  op_type = str(ty
-0000d020: 7065 286d 6f64 756c 6529 290a 2020 2020  pe(module)).    
-0000d030: 2020 2020 6966 2027 6675 7365 6427 2069      if 'fused' i
-0000d040: 6e20 6f70 5f74 7970 653a 0a20 2020 2020  n op_type:.     
-0000d050: 2020 2020 2020 2072 6574 7572 6e20 5472         return Tr
-0000d060: 7565 0a20 2020 2020 2020 2065 6c73 653a  ue.        else:
-0000d070: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0000d080: 7572 6e20 4661 6c73 650a 0a20 2020 2064  urn False..    d
-0000d090: 6566 2063 616c 6375 6c61 7465 5f68 6573  ef calculate_hes
-0000d0a0: 7369 616e 5f74 7261 6365 2873 656c 662c  sian_trace(self,
-0000d0b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ce90: 2020 2020 6f70 5f63 6667 203d 2063 6f70      op_cfg = cop
+0000cea0: 792e 6465 6570 636f 7079 2863 6170 6162  y.deepcopy(capab
+0000ceb0: 696c 6974 795b 715f 6f70 5b31 5d5d 2920  ility[q_op[1]]) 
+0000cec0: 6966 2071 5f6f 705b 315d 2069 6e20 6361  if q_op[1] in ca
+0000ced0: 7061 6269 6c69 7479 205c 0a20 2020 2020  pability \.     
+0000cee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cef0: 2020 2020 2020 2065 6c73 6520 636f 7079         else copy
+0000cf00: 2e64 6565 7063 6f70 7928 6361 7061 6269  .deepcopy(capabi
+0000cf10: 6c69 7479 2e67 6574 2827 6465 6661 756c  lity.get('defaul
+0000cf20: 7427 2c20 6670 3332 5f63 6f6e 6669 6729  t', fp32_config)
+0000cf30: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
+0000cf40: 2020 2020 2020 2020 2020 206f 705f 6366             op_cf
+0000cf50: 675b 2761 6374 6976 6174 696f 6e27 5d5b  g['activation'][
+0000cf60: 2771 7561 6e74 5f6d 6f64 6527 5d20 3d20  'quant_mode'] = 
+0000cf70: 6d6f 6465 2069 6620 715f 6f70 5b31 5d20  mode if q_op[1] 
+0000cf80: 6e6f 7420 696e 205c 0a20 2020 2020 2020  not in \.       
+0000cf90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cfa0: 2020 2020 205b 274c 5354 4d27 2c20 2747       ['LSTM', 'G
+0000cfb0: 5255 272c 2027 4c53 544d 4365 6c6c 272c  RU', 'LSTMCell',
+0000cfc0: 2027 4752 5543 656c 6c27 2c20 2752 4e4e   'GRUCell', 'RNN
+0000cfd0: 4365 6c6c 275d 2065 6c73 6520 2764 796e  Cell'] else 'dyn
+0000cfe0: 616d 6963 270a 0a20 2020 2020 2020 2020  amic'..         
+0000cff0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0000d000: 2073 6b69 7020 7468 6520 6f70 2074 6861   skip the op tha
+0000d010: 7420 6f6e 6c79 2069 6e63 6c75 6465 2066  t only include f
+0000d020: 7033 320a 2020 2020 2020 2020 2020 2020  p32.            
+0000d030: 2020 2020 2020 2020 2020 2020 6966 2071              if q
+0000d040: 5f6f 705b 315d 206e 6f74 2069 6e20 6164  _op[1] not in ad
+0000d050: 6469 7469 6f6e 616c 5f73 6b69 7070 6564  ditional_skipped
+0000d060: 5f6d 6f64 756c 655f 636c 6173 7365 733a  _module_classes:
+0000d070: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d080: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0000d090: 6f70 5f63 6667 206e 6f74 2069 6e20 715f  op_cfg not in q_
+0000d0a0: 6361 7061 6269 6c69 7479 5b27 6f70 7769  capability['opwi
+0000d0b0: 7365 275d 5b71 5f6f 705d 3a0a 2020 2020  se'][q_op]:.    
 0000d0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d0d0: 2066 7033 325f 6d6f 6465 6c2c 0a20 2020   fp32_model,.   
-0000d0e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d0f0: 2020 2020 2020 2020 2020 2020 2064 6174               dat
-0000d100: 616c 6f61 6465 722c 0a20 2020 2020 2020  aloader,.       
+0000d0d0: 2020 2020 2020 2020 2020 2020 715f 6361              q_ca
+0000d0e0: 7061 6269 6c69 7479 5b27 6f70 7769 7365  pability['opwise
+0000d0f0: 275d 5b71 5f6f 705d 2e61 7070 656e 6428  '][q_op].append(
+0000d100: 6f70 5f63 6667 290a 2020 2020 2020 2020  op_cfg).        
 0000d110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d120: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
-0000d130: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000d140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d150: 2020 6372 6974 6572 696f 6e2c 0a20 2020    criterion,.   
+0000d120: 2020 2020 6966 206f 705f 6366 6720 6e6f      if op_cfg no
+0000d130: 7420 696e 2071 5f63 6170 6162 696c 6974  t in q_capabilit
+0000d140: 795b 276f 7074 7970 6577 6973 6527 5d5b  y['optypewise'][
+0000d150: 715f 6f70 5b31 5d5d 3a0a 2020 2020 2020  q_op[1]]:.      
 0000d160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d170: 2020 2020 2020 2020 2020 2020 2065 6e61               ena
-0000d180: 626c 655f 6163 743d 4661 6c73 650a 2020  ble_act=False.  
-0000d190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d1a0: 2020 2020 2020 2020 2020 2020 2020 293a                ):
-0000d1b0: 0a20 2020 2020 2020 2022 2222 4361 6c63  .        """Calc
-0000d1c0: 756c 6174 6520 6865 7373 6961 6e20 7472  ulate hessian tr
-0000d1d0: 6163 652e 0a0a 2020 2020 2020 2020 4172  ace...        Ar
-0000d1e0: 6773 3a0a 2020 2020 2020 2020 2020 2020  gs:.            
-0000d1f0: 6670 3332 5f6d 6f64 656c 3a20 5468 6520  fp32_model: The 
-0000d200: 6f72 6967 696e 616c 2066 7033 3220 6d6f  original fp32 mo
-0000d210: 6465 6c2e 0a20 2020 2020 2020 2020 2020  del..           
-0000d220: 2063 7269 7465 7269 6f6e 3a20 5468 6520   criterion: The 
-0000d230: 6c6f 7373 2066 756e 6374 696f 6e20 666f  loss function fo
-0000d240: 7220 6361 6c63 756c 6174 6520 7468 6520  r calculate the 
-0000d250: 6865 7373 6961 6e20 7472 6163 652e 2023  hessian trace. #
-0000d260: 206c 6f73 7320 3d20 6372 6974 6572 696f   loss = criterio
-0000d270: 6e28 6f75 7470 7574 2c20 7461 7267 6574  n(output, target
-0000d280: 290a 2020 2020 2020 2020 2020 2020 6461  ).            da
-0000d290: 7461 6c6f 6164 6572 3a20 5468 6520 6461  taloader: The da
-0000d2a0: 7461 6c6f 6164 6572 2066 6f72 2063 616c  taloader for cal
-0000d2b0: 6375 6c61 7465 2074 6865 2067 7261 6469  culate the gradi
-0000d2c0: 656e 742e 0a20 2020 2020 2020 2020 2020  ent..           
-0000d2d0: 2071 5f6d 6f64 656c 3a20 5468 6520 494e   q_model: The IN
-0000d2e0: 5438 2041 4d41 5020 6d6f 6465 6c2e 0a20  T8 AMAP model.. 
-0000d2f0: 2020 2020 2020 2020 2020 2065 6e61 626c             enabl
-0000d300: 655f 6163 743a 2045 6e61 626c 696e 6720  e_act: Enabling 
-0000d310: 7175 616e 7469 7a61 7469 6f6e 2065 7272  quantization err
-0000d320: 6f72 206f 7220 6e6f 742e 0a0a 2020 2020  or or not...    
-0000d330: 2020 2020 5265 7475 726e 3a0a 2020 2020      Return:.    
-0000d340: 2020 2020 2020 2020 6865 7373 6961 6e5f          hessian_
-0000d350: 7472 6163 6528 4469 6374 5b54 7570 6c65  trace(Dict[Tuple
-0000d360: 2c20 666c 6f61 745d 292c 206b 6579 3a20  , float]), key: 
-0000d370: 286f 705f 6e61 6d65 2c20 6f70 5f74 7970  (op_name, op_typ
-0000d380: 6529 3b20 7661 6c75 653a 2068 6573 7369  e); value: hessi
-0000d390: 616e 2074 7261 6365 2e0a 2020 2020 2020  an trace..      
-0000d3a0: 2020 2222 220a 2020 2020 2020 2020 6672    """.        fr
-0000d3b0: 6f6d 202e 746f 7263 685f 7574 696c 732e  om .torch_utils.
-0000d3c0: 6861 7771 5f6d 6574 7269 6320 696d 706f  hawq_metric impo
-0000d3d0: 7274 2068 6177 715f 746f 700a 2020 2020  rt hawq_top.    
-0000d3e0: 2020 2020 6f70 5f74 6f5f 7472 6163 6573      op_to_traces
-0000d3f0: 203d 2068 6177 715f 746f 7028 6670 3332   = hawq_top(fp32
-0000d400: 5f6d 6f64 656c 3d66 7033 325f 6d6f 6465  _model=fp32_mode
-0000d410: 6c2c 0a20 2020 2020 2020 2020 2020 2020  l,.             
-0000d420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d430: 2020 2064 6174 616c 6f61 6465 723d 6461     dataloader=da
-0000d440: 7461 6c6f 6164 6572 2c0a 2020 2020 2020  taloader,.      
-0000d450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d460: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
-0000d470: 6c3d 715f 6d6f 6465 6c2c 0a20 2020 2020  l=q_model,.     
-0000d480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d490: 2020 2020 2020 2020 2020 2063 7269 7465             crite
-0000d4a0: 7269 6f6e 3d63 7269 7465 7269 6f6e 2c0a  rion=criterion,.
-0000d4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d4d0: 656e 6162 6c65 5f61 6374 3d65 6e61 626c  enable_act=enabl
-0000d4e0: 655f 6163 7429 0a20 2020 2020 2020 2072  e_act).        r
-0000d4f0: 6574 7572 6e20 6f70 5f74 6f5f 7472 6163  eturn op_to_trac
-0000d500: 6573 0a0a 2020 2020 6465 6620 736d 6f6f  es..    def smoo
-0000d510: 7468 5f71 7561 6e74 2873 656c 662c 206d  th_quant(self, m
-0000d520: 6f64 656c 2c20 6461 7461 6c6f 6164 6572  odel, dataloader
-0000d530: 2c20 6361 6c69 625f 6974 6572 2c20 7475  , calib_iter, tu
-0000d540: 6e65 5f63 6667 3d4e 6f6e 652c 2061 6c70  ne_cfg=None, alp
-0000d550: 6861 3d30 2e35 2c0a 2020 2020 2020 2020  ha=0.5,.        
-0000d560: 2020 2020 2020 2020 2020 2020 2070 6572               per
-0000d570: 6365 6e74 696c 653d 4e6f 6e65 2c20 6f70  centile=None, op
-0000d580: 5f74 7970 6573 3d4e 6f6e 652c 2073 6361  _types=None, sca
-0000d590: 6c65 735f 7065 725f 6f70 3d4e 6f6e 652c  les_per_op=None,
-0000d5a0: 2066 6f72 6365 5f72 655f 736d 6f6f 7468   force_re_smooth
-0000d5b0: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
-0000d5c0: 2022 2222 2063 6f6e 7665 7274 2074 6865   """ convert the
-0000d5d0: 206d 6f64 656c 2062 7920 736d 6f6f 7468   model by smooth
-0000d5e0: 2071 7561 6e74 2e0a 0a20 2020 2020 2020   quant...       
+0000d170: 2020 2020 2020 2020 2020 715f 6361 7061            q_capa
+0000d180: 6269 6c69 7479 5b27 6f70 7479 7065 7769  bility['optypewi
+0000d190: 7365 275d 5b71 5f6f 705b 315d 5d2e 6170  se'][q_op[1]].ap
+0000d1a0: 7065 6e64 286f 705f 6366 6729 0a0a 2020  pend(op_cfg)..  
+0000d1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d1c0: 2020 2020 2020 6966 2071 5f6f 705b 315d        if q_op[1]
+0000d1d0: 206e 6f74 2069 6e20 6e6f 5f66 7033 325f   not in no_fp32_
+0000d1e0: 6f70 733a 0a20 2020 2020 2020 2020 2020  ops:.           
+0000d1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d200: 2069 6620 6670 3332 5f63 6f6e 6669 6720   if fp32_config 
+0000d210: 6e6f 7420 696e 2071 5f63 6170 6162 696c  not in q_capabil
+0000d220: 6974 795b 276f 7077 6973 6527 5d5b 715f  ity['opwise'][q_
+0000d230: 6f70 5d3a 0a20 2020 2020 2020 2020 2020  op]:.           
+0000d240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d250: 2020 2020 2071 5f63 6170 6162 696c 6974       q_capabilit
+0000d260: 795b 276f 7077 6973 6527 5d5b 715f 6f70  y['opwise'][q_op
+0000d270: 5d2e 6170 7065 6e64 2866 7033 325f 636f  ].append(fp32_co
+0000d280: 6e66 6967 290a 2020 2020 2020 2020 2020  nfig).          
+0000d290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d2a0: 2020 6966 2066 7033 325f 636f 6e66 6967    if fp32_config
+0000d2b0: 206e 6f74 2069 6e20 715f 6361 7061 6269   not in q_capabi
+0000d2c0: 6c69 7479 5b27 6f70 7479 7065 7769 7365  lity['optypewise
+0000d2d0: 275d 5b71 5f6f 705b 315d 5d3a 0a20 2020  '][q_op[1]]:.   
+0000d2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d2f0: 2020 2020 2020 2020 2020 2020 2071 5f63               q_c
+0000d300: 6170 6162 696c 6974 795b 276f 7074 7970  apability['optyp
+0000d310: 6577 6973 6527 5d5b 715f 6f70 5b31 5d5d  ewise'][q_op[1]]
+0000d320: 2e61 7070 656e 6428 6670 3332 5f63 6f6e  .append(fp32_con
+0000d330: 6669 6729 0a0a 2020 2020 2020 2020 2320  fig)..        # 
+0000d340: 6765 7420 6266 3136 2063 6170 6162 696c  get bf16 capabil
+0000d350: 6974 790a 2020 2020 2020 2020 6966 2073  ity.        if s
+0000d360: 656c 662e 7573 655f 6266 3136 2061 6e64  elf.use_bf16 and
+0000d370: 2028 4370 7549 6e66 6f28 292e 6266 3136   (CpuInfo().bf16
+0000d380: 206f 7220 6f73 2e67 6574 656e 7628 2746   or os.getenv('F
+0000d390: 4f52 4345 5f42 4631 3627 2920 3d3d 2027  ORCE_BF16') == '
+0000d3a0: 3127 2920 616e 6420 5c0a 2020 2020 2020  1') and \.      
+0000d3b0: 2020 2020 2020 2873 656c 662e 7665 7273        (self.vers
+0000d3c0: 696f 6e2e 7265 6c65 6173 6520 3e3d 2056  ion.release >= V
+0000d3d0: 6572 7369 6f6e 2822 312e 3131 2e30 2229  ersion("1.11.0")
+0000d3e0: 2e72 656c 6561 7365 293a 0a20 2020 2020  .release):.     
+0000d3f0: 2020 2020 2020 2073 656c 662e 6266 3136         self.bf16
+0000d400: 5f6f 7073 203d 2073 656c 662e 7175 6572  _ops = self.quer
+0000d410: 795f 6861 6e64 6c65 722e 6765 745f 6f70  y_handler.get_op
+0000d420: 5f74 7970 6573 5f62 795f 7072 6563 6973  _types_by_precis
+0000d430: 696f 6e28 2262 6631 3622 290a 2020 2020  ion("bf16").    
+0000d440: 2020 2020 2020 2020 6266 3136 5f6f 7073          bf16_ops
+0000d450: 203d 205b 5d0a 2020 2020 2020 2020 2020   = [].          
+0000d460: 2020 7365 6c66 2e5f 6765 745f 6266 3136    self._get_bf16
+0000d470: 5f6f 7073 5f72 6563 7572 7369 7665 6c79  _ops_recursively
+0000d480: 2874 6d70 5f6d 6f64 656c 2c20 2727 2c20  (tmp_model, '', 
+0000d490: 6266 3136 5f6f 7073 290a 2020 2020 2020  bf16_ops).      
+0000d4a0: 2020 2020 2020 6d69 7865 645f 6361 7061        mixed_capa
+0000d4b0: 6269 6c69 7479 203d 2073 656c 662e 5f63  bility = self._c
+0000d4c0: 6f6d 6269 6e65 5f63 6170 6162 696c 6974  ombine_capabilit
+0000d4d0: 7928 6266 3136 5f6f 7073 2c20 715f 6361  y(bf16_ops, q_ca
+0000d4e0: 7061 6269 6c69 7479 290a 2020 2020 2020  pability).      
+0000d4f0: 2020 2020 2020 7265 7475 726e 206d 6978        return mix
+0000d500: 6564 5f63 6170 6162 696c 6974 790a 2020  ed_capability.  
+0000d510: 2020 2020 2020 7265 7475 726e 2071 5f63        return q_c
+0000d520: 6170 6162 696c 6974 790a 0a20 2020 2064  apability..    d
+0000d530: 6566 205f 6765 745f 6266 3136 5f6f 7073  ef _get_bf16_ops
+0000d540: 5f72 6563 7572 7369 7665 6c79 2873 656c  _recursively(sel
+0000d550: 662c 206d 6f64 656c 2c20 7072 6566 6978  f, model, prefix
+0000d560: 2c20 6266 3136 5f6f 7073 293a 0a20 2020  , bf16_ops):.   
+0000d570: 2020 2020 2022 2222 5468 6973 2069 7320       """This is 
+0000d580: 6120 6865 6c70 6572 2066 756e 6374 696f  a helper functio
+0000d590: 6e20 666f 7220 6071 7565 7279 5f66 775f  n for `query_fw_
+0000d5a0: 6361 7061 6269 6c69 7479 602c 0a20 2020  capability`,.   
+0000d5b0: 2020 2020 2020 2020 616e 6420 6974 2077          and it w
+0000d5c0: 696c 6c20 6765 7420 616c 6c20 7175 616e  ill get all quan
+0000d5d0: 7469 7a61 626c 6520 6f70 7320 6672 6f6d  tizable ops from
+0000d5e0: 206d 6f64 656c 2e0a 0a20 2020 2020 2020   model...       
 0000d5f0: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
-0000d600: 2020 206d 6f64 656c 3a20 6f72 6967 696e     model: origin
-0000d610: 2046 5033 3220 6d6f 6465 6c0a 2020 2020   FP32 model.    
-0000d620: 2020 2020 2020 2020 6461 7461 6c6f 6164          dataload
-0000d630: 6572 3a20 6361 6c69 6220 6461 7461 6c6f  er: calib datalo
-0000d640: 6164 6572 0a20 2020 2020 2020 2020 2020  ader.           
-0000d650: 2063 616c 6962 5f69 7465 723a 2063 616c   calib_iter: cal
-0000d660: 6962 2069 7465 7273 0a20 2020 2020 2020  ib iters.       
-0000d670: 2020 2020 2074 756e 655f 6366 673a 2071       tune_cfg: q
-0000d680: 7561 6e74 697a 6174 696f 6e20 636f 6e66  uantization conf
-0000d690: 6967 0a20 2020 2020 2020 2020 2020 2061  ig.            a
-0000d6a0: 6c70 6861 3a20 736d 6f6f 7468 2061 6c70  lpha: smooth alp
-0000d6b0: 6861 2069 6e20 536d 6f6f 7468 5175 616e  ha in SmoothQuan
-0000d6c0: 742c 2031 2e30 2077 696c 6c20 6661 6c6c  t, 1.0 will fall
-0000d6d0: 6261 636b 2074 6f20 5350 4951 0a20 2020  back to SPIQ.   
-0000d6e0: 2020 2020 2020 2020 2070 6572 6365 6e74           percent
-0000d6f0: 696c 653a 5065 7263 656e 7469 6c65 206f  ile:Percentile o
-0000d700: 6620 6361 6c69 6272 6174 696f 6e20 746f  f calibration to
-0000d710: 2072 656d 6f76 6520 6f75 746c 6965 7273   remove outliers
-0000d720: 2c20 6e6f 7420 7375 7070 6f72 7465 6420  , not supported 
-0000d730: 6e6f 770a 2020 2020 2020 2020 2020 2020  now.            
-0000d740: 6f70 5f74 7970 6573 3a20 5468 6520 6f70  op_types: The op
-0000d750: 2074 7970 6573 2077 686f 7365 2069 6e70   types whose inp
-0000d760: 7574 2074 656e 736f 7220 7769 6c6c 2062  ut tensor will b
-0000d770: 6520 6475 6d70 6564 0a20 2020 2020 2020  e dumped.       
-0000d780: 2020 2020 2073 6361 6c65 735f 7065 725f       scales_per_
-0000d790: 6f70 3a20 5472 7565 2c20 6561 6368 206f  op: True, each o
-0000d7a0: 7020 7769 6c6c 2068 6176 6520 616e 2069  p will have an i
-0000d7b0: 6e64 6976 6964 7561 6c20 7363 616c 652c  ndividual scale,
-0000d7c0: 206d 6169 6e6c 7920 666f 7220 6163 6375   mainly for accu
-0000d7d0: 7261 6379 0a20 2020 2020 2020 2020 2020  racy.           
-0000d7e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d7f0: 4661 6c73 652c 206f 7073 2077 6974 6820  False, ops with 
-0000d800: 7468 6520 7361 6d65 2069 6e70 7574 2077  the same input w
-0000d810: 696c 6c20 7368 6172 6520 6120 7363 616c  ill share a scal
-0000d820: 652c 206d 6169 6e6c 7920 666f 7220 7065  e, mainly for pe
-0000d830: 7266 6f72 6d61 6e63 650a 0a20 2020 2020  rformance..     
-0000d840: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
-0000d850: 2020 2020 2020 2020 6d6f 6465 6c3a 2041          model: A
-0000d860: 206d 6f64 6966 6965 6420 6670 3332 206d   modified fp32 m
-0000d870: 6f64 656c 0a20 2020 2020 2020 2022 2222  odel.        """
-0000d880: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-0000d890: 6861 7361 7474 7228 7365 6c66 2c20 2773  hasattr(self, 's
-0000d8a0: 7127 2920 6f72 2066 6f72 6365 5f72 655f  q') or force_re_
-0000d8b0: 736d 6f6f 7468 3a0a 2020 2020 2020 2020  smooth:.        
-0000d8c0: 2020 2020 7365 6c66 2e73 7120 3d20 546f      self.sq = To
-0000d8d0: 7263 6853 6d6f 6f74 6851 7561 6e74 286d  rchSmoothQuant(m
-0000d8e0: 6f64 656c 2e5f 6d6f 6465 6c2c 2064 6174  odel._model, dat
-0000d8f0: 616c 6f61 6465 723d 6461 7461 6c6f 6164  aloader=dataload
-0000d900: 6572 290a 2020 2020 2020 2020 6172 6773  er).        args
-0000d910: 203d 207b 7d20 2023 2364 6966 6665 7265   = {}  ##differe
-0000d920: 6e74 2062 6163 6b65 6e64 7320 6d61 7920  nt backends may 
-0000d930: 6861 7665 2064 6966 6665 7265 6e74 2064  have different d
-0000d940: 6566 6175 6c74 2076 616c 7565 730a 2020  efault values.  
-0000d950: 2020 2020 2020 6966 206f 705f 7479 7065        if op_type
-0000d960: 7320 213d 204e 6f6e 653a 0a20 2020 2020  s != None:.     
-0000d970: 2020 2020 2020 2061 7267 735b 226f 705f         args["op_
-0000d980: 7479 7065 7322 5d20 3d20 6f70 5f74 7970  types"] = op_typ
-0000d990: 6573 0a20 2020 2020 2020 2069 6620 7065  es.        if pe
-0000d9a0: 7263 656e 7469 6c65 2021 3d20 4e6f 6e65  rcentile != None
-0000d9b0: 3a0a 2020 2020 2020 2020 2020 2020 6172  :.            ar
-0000d9c0: 6773 5b27 7065 7263 656e 7469 6c65 275d  gs['percentile']
-0000d9d0: 203d 2070 6572 6365 6e74 696c 650a 2020   = percentile.  
-0000d9e0: 2020 2020 2020 6966 2073 6361 6c65 735f        if scales_
-0000d9f0: 7065 725f 6f70 2021 3d20 4e6f 6e65 3a0a  per_op != None:.
-0000da00: 2020 2020 2020 2020 2020 2020 6172 6773              args
-0000da10: 5b27 7363 616c 6573 5f70 6572 5f6f 7027  ['scales_per_op'
-0000da20: 5d20 3d20 7363 616c 6573 5f70 6572 5f6f  ] = scales_per_o
-0000da30: 700a 2020 2020 2020 2020 6d6f 6465 6c2e  p.        model.
-0000da40: 5f6d 6f64 656c 203d 2073 656c 662e 7371  _model = self.sq
-0000da50: 2e74 7261 6e73 666f 726d 2861 6c70 6861  .transform(alpha
-0000da60: 3d61 6c70 6861 2c20 6361 6c69 625f 6974  =alpha, calib_it
-0000da70: 6572 3d63 616c 6962 5f69 7465 722c 202a  er=calib_iter, *
-0000da80: 2a61 7267 7329 0a20 2020 2020 2020 2072  *args).        r
-0000da90: 6574 7572 6e20 6d6f 6465 6c0a 0a0a 0a75  eturn model....u
-0000daa0: 6e69 6679 5f6f 705f 7479 7065 5f6d 6170  nify_op_type_map
-0000dab0: 7069 6e67 203d 207b 0a20 2020 2022 436f  ping = {.    "Co
-0000dac0: 6e76 5265 4c55 3264 223a 2022 436f 6e76  nvReLU2d": "Conv
-0000dad0: 3264 222c 0a20 2020 2022 436f 6e76 5265  2d",.    "ConvRe
-0000dae0: 4c55 3364 223a 2022 436f 6e76 3364 222c  LU3d": "Conv3d",
-0000daf0: 0a20 2020 2022 4c69 6e65 6172 5265 4c55  .    "LinearReLU
-0000db00: 223a 2022 4c69 6e65 6172 222c 0a20 2020  ": "Linear",.   
-0000db10: 2022 436f 6e76 426e 3264 223a 2022 436f   "ConvBn2d": "Co
-0000db20: 6e76 3264 222c 0a20 2020 2022 436f 6e76  nv2d",.    "Conv
-0000db30: 426e 5265 4c55 3264 223a 2022 436f 6e76  BnReLU2d": "Conv
-0000db40: 3264 220a 7d0a 0a0a 4061 6461 7074 6f72  2d".}...@adaptor
-0000db50: 5f72 6567 6973 7472 790a 636c 6173 7320  _registry.class 
-0000db60: 5079 546f 7263 6841 6461 7074 6f72 2854  PyTorchAdaptor(T
-0000db70: 656d 706c 6174 6541 6461 7074 6f72 293a  emplateAdaptor):
-0000db80: 0a20 2020 2022 2222 4164 6170 746f 7220  .    """Adaptor 
-0000db90: 6f66 2050 7954 6f72 6368 2066 7261 6d65  of PyTorch frame
-0000dba0: 776f 726b 2c20 616c 6c20 5079 546f 7263  work, all PyTorc
-0000dbb0: 6820 4150 4920 6973 2069 6e20 7468 6973  h API is in this
-0000dbc0: 2063 6c61 7373 2e0a 0a20 2020 2041 7267   class...    Arg
-0000dbd0: 733a 0a20 2020 2020 2020 2066 7261 6d65  s:.        frame
-0000dbe0: 776f 726b 5f73 7065 6369 6669 635f 696e  work_specific_in
-0000dbf0: 666f 2028 6469 6374 293a 2064 6963 7469  fo (dict): dicti
-0000dc00: 6f6e 6172 7920 6f66 2074 756e 696e 6720  onary of tuning 
-0000dc10: 636f 6e66 6967 7572 6520 6672 6f6d 2079  configure from y
-0000dc20: 616d 6c20 6669 6c65 2e0a 2020 2020 2222  aml file..    ""
-0000dc30: 220a 2020 2020 6465 6620 5f5f 696e 6974  ".    def __init
-0000dc40: 5f5f 2873 656c 662c 2066 7261 6d65 776f  __(self, framewo
-0000dc50: 726b 5f73 7065 6369 6669 635f 696e 666f  rk_specific_info
-0000dc60: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
-0000dc70: 2850 7954 6f72 6368 4164 6170 746f 722c  (PyTorchAdaptor,
-0000dc80: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
-0000dc90: 6672 616d 6577 6f72 6b5f 7370 6563 6966  framework_specif
-0000dca0: 6963 5f69 6e66 6f29 0a20 2020 2020 2020  ic_info).       
-0000dcb0: 2022 2222 0a20 2020 2020 2020 2023 204d   """.        # M
-0000dcc0: 6170 2066 6f72 2073 7761 7070 696e 6720  ap for swapping 
-0000dcd0: 666c 6f61 7420 6d6f 6475 6c65 2074 6f20  float module to 
-0000dce0: 7175 616e 7469 7a65 6420 6f6e 6573 2c0a  quantized ones,.
-0000dcf0: 2020 2020 2020 2020 2320 616e 6420 7468          # and th
-0000dd00: 6973 2064 6963 7469 6f6e 6172 7920 7769  is dictionary wi
-0000dd10: 6c6c 2063 6861 6e67 6520 7769 7468 2064  ll change with d
-0000dd20: 6966 6665 7265 6e74 2050 6f54 6f72 6368  ifferent PoTorch
-0000dd30: 2076 6572 7369 6f6e 730a 2020 2020 2020   versions.      
-0000dd40: 2020 4445 4641 554c 545f 4d4f 4455 4c45    DEFAULT_MODULE
-0000dd50: 5f4d 4150 5049 4e47 203d 207b 0a20 2020  _MAPPING = {.   
-0000dd60: 2020 2020 2020 2020 206e 6e2e 4c69 6e65           nn.Line
-0000dd70: 6172 3a20 6e6e 712e 4c69 6e65 6172 2c0a  ar: nnq.Linear,.
-0000dd80: 2020 2020 2020 2020 2020 2020 6e6e 2e52              nn.R
-0000dd90: 654c 553a 206e 6e71 2e52 654c 552c 0a20  eLU: nnq.ReLU,. 
-0000dda0: 2020 2020 2020 2020 2020 206e 6e2e 5265             nn.Re
-0000ddb0: 4c55 363a 206e 6e71 2e52 654c 5536 2c0a  LU6: nnq.ReLU6,.
-0000ddc0: 2020 2020 2020 2020 2020 2020 6e6e 2e43              nn.C
-0000ddd0: 6f6e 7632 643a 206e 6e71 2e43 6f6e 7632  onv2d: nnq.Conv2
-0000dde0: 642c 0a20 2020 2020 2020 2020 2020 206e  d,.            n
-0000ddf0: 6e2e 436f 6e76 3364 3a20 6e6e 712e 436f  n.Conv3d: nnq.Co
-0000de00: 6e76 3364 2c0a 2020 2020 2020 2020 2020  nv3d,.          
-0000de10: 2020 5175 616e 7453 7475 623a 206e 6e71    QuantStub: nnq
-0000de20: 2e51 7561 6e74 697a 652c 0a20 2020 2020  .Quantize,.     
-0000de30: 2020 2020 2020 2044 6551 7561 6e74 5374         DeQuantSt
-0000de40: 7562 3a20 6e6e 712e 4465 5175 616e 7469  ub: nnq.DeQuanti
-0000de50: 7a65 2c0a 2020 2020 2020 2020 2020 2020  ze,.            
-0000de60: 2320 5772 6170 7065 7220 4d6f 6475 6c65  # Wrapper Module
-0000de70: 733a 0a20 2020 2020 2020 2020 2020 206e  s:.            n
-0000de80: 6e71 2e46 6c6f 6174 4675 6e63 7469 6f6e  nq.FloatFunction
-0000de90: 616c 3a20 6e6e 712e 5146 756e 6374 696f  al: nnq.QFunctio
-0000dea0: 6e61 6c2c 0a20 2020 2020 2020 2020 2020  nal,.           
-0000deb0: 2023 2049 6e74 7269 6e73 6963 206d 6f64   # Intrinsic mod
-0000dec0: 756c 6573 3a0a 2020 2020 2020 2020 2020  ules:.          
-0000ded0: 2020 6e6e 692e 436f 6e76 5265 4c55 3264    nni.ConvReLU2d
-0000dee0: 3a20 6e6e 6971 2e43 6f6e 7652 654c 5532  : nniq.ConvReLU2
-0000def0: 642c 0a20 2020 2020 2020 2020 2020 206e  d,.            n
-0000df00: 6e69 2e43 6f6e 7652 654c 5533 643a 206e  ni.ConvReLU3d: n
-0000df10: 6e69 712e 436f 6e76 5265 4c55 3364 2c0a  niq.ConvReLU3d,.
-0000df20: 2020 2020 2020 2020 2020 2020 6e6e 692e              nni.
-0000df30: 4c69 6e65 6172 5265 4c55 3a20 6e6e 6971  LinearReLU: nniq
-0000df40: 2e4c 696e 6561 7252 654c 552c 0a20 2020  .LinearReLU,.   
-0000df50: 2020 2020 2020 2020 206e 6e69 7161 742e           nniqat.
-0000df60: 436f 6e76 5265 4c55 3264 3a20 6e6e 6971  ConvReLU2d: nniq
-0000df70: 2e43 6f6e 7652 654c 5532 642c 0a20 2020  .ConvReLU2d,.   
-0000df80: 2020 2020 2020 2020 206e 6e69 7161 742e           nniqat.
-0000df90: 4c69 6e65 6172 5265 4c55 3a20 6e6e 6971  LinearReLU: nniq
-0000dfa0: 2e4c 696e 6561 7252 654c 552c 0a20 2020  .LinearReLU,.   
-0000dfb0: 2020 2020 2020 2020 206e 6e69 7161 742e           nniqat.
-0000dfc0: 436f 6e76 426e 3264 3a20 6e6e 712e 436f  ConvBn2d: nnq.Co
-0000dfd0: 6e76 3264 2c0a 2020 2020 2020 2020 2020  nv2d,.          
-0000dfe0: 2020 6e6e 6971 6174 2e43 6f6e 7642 6e52    nniqat.ConvBnR
-0000dff0: 654c 5532 643a 206e 6e69 712e 436f 6e76  eLU2d: nniq.Conv
-0000e000: 5265 4c55 3264 2c0a 2020 2020 2020 2020  ReLU2d,.        
-0000e010: 2020 2020 2320 5141 5420 6d6f 6475 6c65      # QAT module
-0000e020: 733a 0a20 2020 2020 2020 2020 2020 206e  s:.            n
-0000e030: 6e71 6174 2e4c 696e 6561 723a 206e 6e71  nqat.Linear: nnq
-0000e040: 2e4c 696e 6561 722c 0a20 2020 2020 2020  .Linear,.       
-0000e050: 2020 2020 206e 6e71 6174 2e43 6f6e 7632       nnqat.Conv2
-0000e060: 643a 206e 6e71 2e43 6f6e 7632 642c 0a20  d: nnq.Conv2d,. 
-0000e070: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
-0000e080: 2022 2222 0a0a 2020 2020 2020 2020 7365   """..        se
-0000e090: 6c66 2e74 756e 655f 6366 6720 3d20 4e6f  lf.tune_cfg = No
-0000e0a0: 6e65 0a20 2020 2020 2020 2069 6620 7365  ne.        if se
-0000e0b0: 6c66 2e64 6576 6963 6520 3d3d 2022 6370  lf.device == "cp
-0000e0c0: 7522 3a0a 2020 2020 2020 2020 2020 2020  u":.            
-0000e0d0: 7175 6572 795f 636f 6e66 6967 5f66 696c  query_config_fil
-0000e0e0: 6520 3d20 2270 7974 6f72 6368 5f63 7075  e = "pytorch_cpu
-0000e0f0: 2e79 616d 6c22 0a20 2020 2020 2020 2065  .yaml".        e
-0000e100: 6c69 6620 7365 6c66 2e64 6576 6963 6520  lif self.device 
-0000e110: 3d3d 2022 6770 7522 3a0a 2020 2020 2020  == "gpu":.      
-0000e120: 2020 2020 2020 7175 6572 795f 636f 6e66        query_conf
-0000e130: 6967 5f66 696c 6520 3d20 2270 7974 6f72  ig_file = "pytor
-0000e140: 6368 5f67 7075 2e79 616d 6c22 0a20 2020  ch_gpu.yaml".   
-0000e150: 2020 2020 2065 6c73 653a 2020 2320 7072       else:  # pr
-0000e160: 6167 6d61 3a20 6e6f 2063 6f76 6572 0a20  agma: no cover. 
-0000e170: 2020 2020 2020 2020 2020 2061 7373 6572             asser
-0000e180: 7420 4661 6c73 652c 2022 556e 7375 7070  t False, "Unsupp
-0000e190: 6f72 7420 7468 6973 2064 6576 6963 6520  ort this device 
-0000e1a0: 7b7d 222e 666f 726d 6174 2873 656c 662e  {}".format(self.
-0000e1b0: 6465 7669 6365 290a 2020 2020 2020 2020  device).        
-0000e1c0: 7365 6c66 2e71 7565 7279 5f68 616e 646c  self.query_handl
-0000e1d0: 6572 203d 2050 7954 6f72 6368 5175 6572  er = PyTorchQuer
-0000e1e0: 7928 0a20 2020 2020 2020 2020 2020 206c  y(.            l
-0000e1f0: 6f63 616c 5f63 6f6e 6669 675f 6669 6c65  ocal_config_file
-0000e200: 3d6f 732e 7061 7468 2e6a 6f69 6e28 6f73  =os.path.join(os
-0000e210: 2e70 6174 682e 6469 726e 616d 6528 5f5f  .path.dirname(__
-0000e220: 6669 6c65 5f5f 292c 2071 7565 7279 5f63  file__), query_c
-0000e230: 6f6e 6669 675f 6669 6c65 2929 0a0a 2020  onfig_file))..  
-0000e240: 2020 2020 2020 7365 6c66 2e77 6869 7465        self.white
-0000e250: 5f6c 6973 7420 3d20 6765 745f 746f 7263  _list = get_torc
-0000e260: 685f 7768 6974 655f 6c69 7374 2873 656c  h_white_list(sel
-0000e270: 662e 6170 7072 6f61 6368 290a 0a20 2020  f.approach)..   
-0000e280: 2020 2020 2023 2066 6f72 2074 656e 736f       # for tenso
-0000e290: 7262 6f61 7264 0a20 2020 2020 2020 2073  rboard.        s
-0000e2a0: 656c 662e 6475 6d70 5f74 696d 6573 203d  elf.dump_times =
-0000e2b0: 2030 0a20 2020 2020 2020 2073 656c 662e   0.        self.
-0000e2c0: 6675 7365 645f 6469 6374 203d 207b 7d0a  fused_dict = {}.
-0000e2d0: 0a20 2020 2020 2020 2073 656c 662e 6f70  .        self.op
-0000e2e0: 7479 7065 5f73 7461 7469 7374 6963 7320  type_statistics 
-0000e2f0: 3d20 4e6f 6e65 0a0a 2020 2020 4064 756d  = None..    @dum
-0000e300: 705f 656c 6170 7365 645f 7469 6d65 2822  p_elapsed_time("
-0000e310: 5061 7373 2071 7561 6e74 697a 6520 6d6f  Pass quantize mo
-0000e320: 6465 6c22 290a 2020 2020 6465 6620 7175  del").    def qu
-0000e330: 616e 7469 7a65 2873 656c 662c 2074 756e  antize(self, tun
-0000e340: 655f 6366 672c 206d 6f64 656c 2c20 6461  e_cfg, model, da
-0000e350: 7461 6c6f 6164 6572 2c20 715f 6675 6e63  taloader, q_func
-0000e360: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
-0000e370: 2222 2245 7865 6375 7465 2074 6865 2071  """Execute the q
-0000e380: 7561 6e74 697a 6520 7072 6f63 6573 7320  uantize process 
-0000e390: 6f6e 2074 6865 2073 7065 6369 6669 6564  on the specified
-0000e3a0: 206d 6f64 656c 2e0a 0a20 2020 2020 2020   model...       
-0000e3b0: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
-0000e3c0: 2020 2074 756e 655f 6366 6720 2864 6963     tune_cfg (dic
-0000e3d0: 7429 3a20 7175 616e 7469 7a61 7469 6f6e  t): quantization
-0000e3e0: 2063 6f6e 6669 672e 0a20 2020 2020 2020   config..       
-0000e3f0: 2020 2020 206d 6f64 656c 2028 6f62 6a65       model (obje
-0000e400: 6374 293a 206d 6f64 656c 206e 6565 6420  ct): model need 
-0000e410: 746f 2064 6f20 7175 616e 7469 7a61 7469  to do quantizati
-0000e420: 6f6e 2e0a 2020 2020 2020 2020 2020 2020  on..            
-0000e430: 6461 7461 6c6f 6164 6572 2028 6f62 6a65  dataloader (obje
-0000e440: 6374 293a 2063 616c 6962 7261 7469 6f6e  ct): calibration
-0000e450: 2064 6174 6173 6574 2e0a 2020 2020 2020   dataset..      
-0000e460: 2020 2020 2020 715f 6675 6e63 2028 6f62        q_func (ob
-0000e470: 6a65 7874 2c20 6f70 7469 6f6e 616c 293a  jext, optional):
-0000e480: 2074 7261 696e 696e 6720 6675 6e63 7469   training functi
-0000e490: 6f6e 2066 6f72 2071 7561 6e74 697a 6174  on for quantizat
-0000e4a0: 696f 6e20 6177 6172 6520 7472 6169 6e69  ion aware traini
-0000e4b0: 6e67 206d 6f64 652e 0a0a 2020 2020 2020  ng mode...      
-0000e4c0: 2020 5265 7475 726e 733a 0a20 2020 2020    Returns:.     
-0000e4d0: 2020 2020 2020 2028 6f62 6a65 6374 293a         (object):
-0000e4e0: 2071 7561 6e74 697a 6564 206d 6f64 656c   quantized model
-0000e4f0: 0a20 2020 2020 2020 2022 2222 0a0a 2020  .        """..  
-0000e500: 2020 2020 2020 6173 7365 7274 2069 7369        assert isi
-0000e510: 6e73 7461 6e63 6528 6d6f 6465 6c2e 5f6d  nstance(model._m
-0000e520: 6f64 656c 2c20 746f 7263 682e 6e6e 2e4d  odel, torch.nn.M
-0000e530: 6f64 756c 6529 2c20 5c0a 2020 2020 2020  odule), \.      
-0000e540: 2020 2020 2020 2020 2022 5468 6520 6d6f           "The mo
-0000e550: 6465 6c20 7061 7373 6564 2069 6e20 6973  del passed in is
-0000e560: 206e 6f74 2074 6865 2069 6e73 7461 6e63   not the instanc
-0000e570: 6520 6f66 2074 6f72 6368 2e6e 6e2e 4d6f  e of torch.nn.Mo
-0000e580: 6475 6c65 220a 0a20 2020 2020 2020 2023  dule"..        #
-0000e590: 2046 6f72 2074 656e 736f 7262 6f61 7264   For tensorboard
-0000e5a0: 2064 6973 706c 6179 0a20 2020 2020 2020   display.       
-0000e5b0: 2073 656c 662e 7475 6e65 5f63 6667 203d   self.tune_cfg =
-0000e5c0: 2074 756e 655f 6366 670a 2020 2020 2020   tune_cfg.      
-0000e5d0: 2020 7365 6c66 2e74 756e 655f 6366 675b    self.tune_cfg[
-0000e5e0: 2261 7070 726f 6163 6822 5d20 3d20 7365  "approach"] = se
-0000e5f0: 6c66 2e61 7070 726f 6163 680a 2020 2020  lf.approach.    
-0000e600: 2020 2020 7365 6c66 2e74 756e 655f 6366      self.tune_cf
-0000e610: 675b 2272 6564 7563 655f 7261 6e67 6522  g["reduce_range"
-0000e620: 5d20 3d20 5245 4455 4345 5f52 414e 4745  ] = REDUCE_RANGE
-0000e630: 0a20 2020 2020 2020 2073 656c 662e 7475  .        self.tu
-0000e640: 6e65 5f63 6667 5b22 6672 616d 6577 6f72  ne_cfg["framewor
-0000e650: 6b22 5d20 3d20 2270 7974 6f72 6368 220a  k"] = "pytorch".
-0000e660: 2020 2020 2020 2020 6f70 5f63 6667 7320          op_cfgs 
-0000e670: 3d20 5f63 6667 5f74 6f5f 7163 6f6e 6669  = _cfg_to_qconfi
-0000e680: 6728 7475 6e65 5f63 6667 2c20 7365 6c66  g(tune_cfg, self
-0000e690: 2e61 7070 726f 6163 6829 0a20 2020 2020  .approach).     
-0000e6a0: 2020 2073 656c 662e 7475 6e65 5f63 6667     self.tune_cfg
-0000e6b0: 5b27 6266 3136 5f6f 7073 5f6c 6973 7427  ['bf16_ops_list'
-0000e6c0: 5d20 3d20 6f70 5f63 6667 735b 2762 6631  ] = op_cfgs['bf1
-0000e6d0: 365f 6f70 735f 6c69 7374 275d 0a20 2020  6_ops_list'].   
-0000e6e0: 2020 2020 2064 656c 206f 705f 6366 6773       del op_cfgs
-0000e6f0: 5b27 6266 3136 5f6f 7073 5f6c 6973 7427  ['bf16_ops_list'
-0000e700: 5d0a 2020 2020 2020 2020 6763 2e63 6f6c  ].        gc.col
-0000e710: 6c65 6374 2829 0a0a 2020 2020 2020 2020  lect()..        
-0000e720: 6966 2073 656c 662e 7665 7273 696f 6e2e  if self.version.
-0000e730: 7265 6c65 6173 6520 3c20 5665 7273 696f  release < Versio
-0000e740: 6e28 2232 2e30 2e30 2229 2e72 656c 6561  n("2.0.0").relea
-0000e750: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0000e760: 6672 6f6d 2074 6f72 6368 2e71 7561 6e74  from torch.quant
-0000e770: 697a 6174 696f 6e2e 7175 616e 7469 7a65  ization.quantize
-0000e780: 2069 6d70 6f72 7420 6164 645f 6f62 7365   import add_obse
-0000e790: 7276 6572 5f0a 2020 2020 2020 2020 656c  rver_.        el
-0000e7a0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0000e7b0: 6672 6f6d 2074 6f72 6368 2e71 7561 6e74  from torch.quant
-0000e7c0: 697a 6174 696f 6e2e 7175 616e 7469 7a65  ization.quantize
-0000e7d0: 2069 6d70 6f72 7420 5f61 6464 5f6f 6273   import _add_obs
-0000e7e0: 6572 7665 725f 2061 7320 6164 645f 6f62  erver_ as add_ob
-0000e7f0: 7365 7276 6572 5f0a 0a20 2020 2020 2020  server_..       
-0000e800: 2069 6620 7365 6c66 2e70 6572 666f 726d   if self.perform
-0000e810: 616e 6365 5f6f 6e6c 793a 0a20 2020 2020  ance_only:.     
-0000e820: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
-0000e830: 206d 6f64 656c 0a20 2020 2020 2020 2065   model.        e
-0000e840: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0000e850: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
-0000e860: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
-0000e870: 636f 7079 2e64 6565 7063 6f70 7928 6d6f  copy.deepcopy(mo
-0000e880: 6465 6c29 0a20 2020 2020 2020 2020 2020  del).           
-0000e890: 2065 7863 6570 7420 4578 6365 7074 696f   except Exceptio
-0000e8a0: 6e20 6173 2065 3a20 2023 2070 7261 676d  n as e:  # pragm
-0000e8b0: 613a 206e 6f20 636f 7665 720a 2020 2020  a: no cover.    
-0000e8c0: 2020 2020 2020 2020 2020 2020 6c6f 6767              logg
-0000e8d0: 6572 2e77 6172 6e69 6e67 2822 4661 696c  er.warning("Fail
-0000e8e0: 2074 6f20 6465 6570 2063 6f70 7920 7468   to deep copy th
-0000e8f0: 6520 6d6f 6465 6c20 6475 6520 746f 207b  e model due to {
-0000e900: 7d2c 2069 6e70 6c61 6365 2069 7320 7573  }, inplace is us
-0000e910: 6564 206e 6f77 2e22 2e66 6f72 6d61 7428  ed now.".format(
-0000e920: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e930: 2020 2020 2072 6570 7228 6529 2929 0a20       repr(e))). 
-0000e940: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-0000e950: 5f6d 6f64 656c 203d 206d 6f64 656c 0a0a  _model = model..
-0000e960: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-0000e970: 6170 7072 6f61 6368 203d 3d20 2771 7561  approach == 'qua
-0000e980: 6e74 5f61 7761 7265 5f74 7261 696e 696e  nt_aware_trainin
-0000e990: 6727 3a0a 2020 2020 2020 2020 2020 2020  g':.            
-0000e9a0: 715f 6d6f 6465 6c2e 5f6d 6f64 656c 2e74  q_model._model.t
-0000e9b0: 7261 696e 2829 0a20 2020 2020 2020 2065  rain().        e
-0000e9c0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0000e9d0: 2071 5f6d 6f64 656c 2e5f 6d6f 6465 6c2e   q_model._model.
-0000e9e0: 6576 616c 2829 0a20 2020 2020 2020 2069  eval().        i
-0000e9f0: 6620 7365 6c66 2e76 6572 7369 6f6e 2e72  f self.version.r
-0000ea00: 656c 6561 7365 203c 2056 6572 7369 6f6e  elease < Version
-0000ea10: 2822 312e 372e 3022 292e 7265 6c65 6173  ("1.7.0").releas
-0000ea20: 6520 6f72 205c 0a20 2020 2020 2020 2020  e or \.         
-0000ea30: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0000ea40: 6170 7072 6f61 6368 2021 3d20 2771 7561  approach != 'qua
-0000ea50: 6e74 5f61 7761 7265 5f74 7261 696e 696e  nt_aware_trainin
-0000ea60: 6727 3a0a 2020 2020 2020 2020 2020 2020  g':.            
-0000ea70: 5f70 726f 7061 6761 7465 5f71 636f 6e66  _propagate_qconf
-0000ea80: 6967 2871 5f6d 6f64 656c 2e5f 6d6f 6465  ig(q_model._mode
-0000ea90: 6c2c 206f 705f 6366 6773 2c20 6170 7072  l, op_cfgs, appr
-0000eaa0: 6f61 6368 3d73 656c 662e 6170 7072 6f61  oach=self.approa
-0000eab0: 6368 290a 2020 2020 2020 2020 2020 2020  ch).            
-0000eac0: 2320 7361 6e69 7479 2063 6865 636b 2063  # sanity check c
-0000ead0: 6f6d 6d6f 6e20 4150 4920 6d69 7375 7361  ommon API misusa
-0000eae0: 6765 0a20 2020 2020 2020 2020 2020 2069  ge.            i
-0000eaf0: 6620 6e6f 7420 616e 7928 6861 7361 7474  f not any(hasatt
-0000eb00: 7228 6d2c 2027 7163 6f6e 6669 6727 2920  r(m, 'qconfig') 
-0000eb10: 616e 6420 6d2e 7163 6f6e 6669 6720 666f  and m.qconfig fo
-0000eb20: 7220 6d20 696e 2071 5f6d 6f64 656c 2e5f  r m in q_model._
-0000eb30: 6d6f 6465 6c2e 6d6f 6475 6c65 7328 2929  model.modules())
-0000eb40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000eb50: 2020 6c6f 6767 6572 2e77 6172 6e28 224e    logger.warn("N
-0000eb60: 6f6e 6520 6f66 2074 6865 2073 7562 6d6f  one of the submo
-0000eb70: 6475 6c65 2067 6f74 2071 636f 6e66 6967  dule got qconfig
-0000eb80: 2061 7070 6c69 6564 2e20 4d61 6b65 2073   applied. Make s
-0000eb90: 7572 6520 796f 7520 220a 2020 2020 2020  ure you ".      
-0000eba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ebb0: 2020 2020 2020 2270 6173 7365 6420 636f        "passed co
-0000ebc0: 7272 6563 7420 636f 6e66 6967 7572 6174  rrect configurat
-0000ebd0: 696f 6e20 7468 726f 7567 6820 6071 636f  ion through `qco
-0000ebe0: 6e66 6967 5f64 6963 7460 206f 7220 220a  nfig_dict` or ".
-0000ebf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ec00: 2020 2020 2020 2020 2020 2020 2262 7920              "by 
-0000ec10: 6173 7369 676e 696e 6720 7468 6520 602e  assigning the `.
-0000ec20: 7163 6f6e 6669 6760 2061 7474 7269 6275  qconfig` attribu
-0000ec30: 7465 2064 6972 6563 746c 7920 6f6e 2073  te directly on s
-0000ec40: 7562 6d6f 6475 6c65 732e 2229 0a0a 2020  ubmodules.")..  
-0000ec50: 2020 2020 2020 6966 2073 656c 662e 6170        if self.ap
-0000ec60: 7072 6f61 6368 2069 6e20 5b27 706f 7374  proach in ['post
-0000ec70: 5f74 7261 696e 696e 675f 7374 6174 6963  _training_static
-0000ec80: 5f71 7561 6e74 272c 2027 706f 7374 5f74  _quant', 'post_t
-0000ec90: 7261 696e 696e 675f 6175 746f 5f71 7561  raining_auto_qua
-0000eca0: 6e74 275d 3a0a 2020 2020 2020 2020 2020  nt']:.          
-0000ecb0: 2020 6164 645f 6f62 7365 7276 6572 5f28    add_observer_(
-0000ecc0: 715f 6d6f 6465 6c2e 5f6d 6f64 656c 290a  q_model._model).
-0000ecd0: 2020 2020 2020 2020 2020 2020 6966 2071              if q
-0000ece0: 5f66 756e 6320 6973 204e 6f6e 653a 0a20  _func is None:. 
-0000ecf0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000ed00: 7465 7261 7469 6f6e 7320 3d20 7475 6e65  terations = tune
-0000ed10: 5f63 6667 2e67 6574 2827 6361 6c69 625f  _cfg.get('calib_
-0000ed20: 6974 6572 6174 696f 6e27 2c20 3129 0a20  iteration', 1). 
-0000ed30: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000ed40: 656c 662e 6d6f 6465 6c5f 6361 6c69 6272  elf.model_calibr
-0000ed50: 6174 696f 6e28 715f 6d6f 6465 6c2e 5f6d  ation(q_model._m
-0000ed60: 6f64 656c 2c0a 2020 2020 2020 2020 2020  odel,.          
-0000ed70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ed80: 2020 2020 2020 2020 2020 2020 2064 6174               dat
-0000ed90: 616c 6f61 6465 722c 0a20 2020 2020 2020  aloader,.       
-0000eda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000edb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000edc0: 6974 6572 6174 696f 6e73 2c0a 2020 2020  iterations,.    
-0000edd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ede0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000edf0: 2020 2063 616c 6962 5f73 616d 706c 696e     calib_samplin
-0000ee00: 675f 7369 7a65 3d74 756e 655f 6366 672e  g_size=tune_cfg.
-0000ee10: 6765 7428 2763 616c 6962 5f73 616d 706c  get('calib_sampl
-0000ee20: 696e 675f 7369 7a65 272c 2031 2929 0a20  ing_size', 1)). 
-0000ee30: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0000ee40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ee50: 2071 5f66 756e 6328 715f 6d6f 6465 6c2e   q_func(q_model.
-0000ee60: 5f6d 6f64 656c 290a 2020 2020 2020 2020  _model).        
-0000ee70: 656c 6966 2073 656c 662e 6170 7072 6f61  elif self.approa
-0000ee80: 6368 203d 3d20 2771 7561 6e74 5f61 7761  ch == 'quant_awa
-0000ee90: 7265 5f74 7261 696e 696e 6727 3a0a 2020  re_training':.  
-0000eea0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-0000eeb0: 662e 7665 7273 696f 6e2e 7265 6c65 6173  f.version.releas
-0000eec0: 6520 3e3d 2056 6572 7369 6f6e 2822 312e  e >= Version("1.
-0000eed0: 372e 3022 292e 7265 6c65 6173 653a 0a20  7.0").release:. 
-0000eee0: 2020 2020 2020 2020 2020 2020 2020 205f                 _
-0000eef0: 7072 6f70 6167 6174 655f 7163 6f6e 6669  propagate_qconfi
-0000ef00: 6728 715f 6d6f 6465 6c2e 5f6d 6f64 656c  g(q_model._model
-0000ef10: 2c20 6f70 5f63 6667 732c 2069 735f 7161  , op_cfgs, is_qa
-0000ef20: 745f 636f 6e76 6572 743d 5472 7565 290a  t_convert=True).
-0000ef30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef40: 746f 7263 682e 7175 616e 7469 7a61 7469  torch.quantizati
-0000ef50: 6f6e 2e63 6f6e 7665 7274 2871 5f6d 6f64  on.convert(q_mod
-0000ef60: 656c 2e5f 6d6f 6465 6c2c 0a20 2020 2020  el._model,.     
-0000ef70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef90: 2020 2020 2020 6d61 7070 696e 673d 7365        mapping=se
-0000efa0: 6c66 2e71 5f6d 6170 7069 6e67 2c0a 2020  lf.q_mapping,.  
-0000efb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000efc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000efd0: 2020 2020 2020 2020 2069 6e70 6c61 6365           inplace
-0000efe0: 3d54 7275 652c 0a20 2020 2020 2020 2020  =True,.         
-0000eff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f010: 2020 7265 6d6f 7665 5f71 636f 6e66 6967    remove_qconfig
-0000f020: 3d46 616c 7365 290a 2020 2020 2020 2020  =False).        
-0000f030: 2020 2020 2020 2020 5f70 726f 7061 6761          _propaga
-0000f040: 7465 5f71 636f 6e66 6967 2871 5f6d 6f64  te_qconfig(q_mod
-0000f050: 656c 2e5f 6d6f 6465 6c2c 206f 705f 6366  el._model, op_cf
-0000f060: 6773 290a 2020 2020 2020 2020 2020 2020  gs).            
-0000f070: 2020 2020 6164 645f 6f62 7365 7276 6572      add_observer
-0000f080: 5f28 715f 6d6f 6465 6c2e 5f6d 6f64 656c  _(q_model._model
-0000f090: 2c20 7365 6c66 2e77 6869 7465 5f6c 6973  , self.white_lis
-0000f0a0: 742c 0a20 2020 2020 2020 2020 2020 2020  t,.             
-0000f0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f0d0: 2020 2020 7365 7428 7365 6c66 2e71 5f6d      set(self.q_m
-0000f0e0: 6170 7069 6e67 2e76 616c 7565 7328 2929  apping.values())
-0000f0f0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-0000f100: 7365 3a20 2023 2070 7261 676d 613a 206e  se:  # pragma: n
-0000f110: 6f20 636f 7665 720a 2020 2020 2020 2020  o cover.        
-0000f120: 2020 2020 2020 2020 6164 645f 6f62 7365          add_obse
-0000f130: 7276 6572 5f28 715f 6d6f 6465 6c2e 5f6d  rver_(q_model._m
-0000f140: 6f64 656c 290a 2020 2020 2020 2020 2020  odel).          
-0000f150: 2020 2020 2020 746f 7263 682e 7175 616e        torch.quan
-0000f160: 7469 7a61 7469 6f6e 2e63 6f6e 7665 7274  tization.convert
-0000f170: 2871 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c  (q_model._model,
-0000f180: 2073 656c 662e 715f 6d61 7070 696e 672c   self.q_mapping,
-0000f190: 2069 6e70 6c61 6365 3d54 7275 6529 0a20   inplace=True). 
-0000f1a0: 2020 2020 2020 2020 2020 2023 2071 5f66             # q_f
-0000f1b0: 756e 6320 6361 6e20 6265 2063 7265 6174  unc can be creat
-0000f1c0: 6564 2062 7920 6e65 7572 616c 5f63 6f6d  ed by neural_com
-0000f1d0: 7072 6573 736f 7220 696e 7465 726e 616c  pressor internal
-0000f1e0: 206f 7220 7061 7373 6564 2062 7920 7573   or passed by us
-0000f1f0: 6572 2e20 4974 2773 2063 7269 7469 6361  er. It's critica
-0000f200: 6c20 746f 0a20 2020 2020 2020 2020 2020  l to.           
-0000f210: 2023 2064 6973 7469 6e67 7569 7368 2068   # distinguish h
-0000f220: 6f77 2071 5f66 756e 6320 6973 2070 6173  ow q_func is pas
-0000f230: 7365 6420 7369 6e63 6520 6e65 7572 616c  sed since neural
-0000f240: 5f63 6f6d 7072 6573 736f 7220 6275 696c  _compressor buil
-0000f250: 742d 696e 2066 756e 6374 696f 6e73 2061  t-in functions a
-0000f260: 6363 6570 7420 6e65 7572 616c 5f63 6f6d  ccept neural_com
-0000f270: 7072 6573 736f 720a 2020 2020 2020 2020  pressor.        
-0000f280: 2020 2020 2320 6d6f 6465 6c20 616e 6420      # model and 
-0000f290: 7573 6572 2064 6566 696e 6564 2066 756e  user defined fun
-0000f2a0: 6320 7368 6f75 6c64 2061 6363 6570 7420  c should accept 
-0000f2b0: 6672 616d 6577 6f72 6b20 6d6f 6465 6c2e  framework model.
-0000f2c0: 0a20 2020 2020 2020 2020 2020 2071 5f6d  .            q_m
-0000f2d0: 6f64 656c 2e5f 6d6f 6465 6c20 3d20 715f  odel._model = q_
-0000f2e0: 6675 6e63 280a 2020 2020 2020 2020 2020  func(.          
-0000f2f0: 2020 2020 2020 715f 6d6f 6465 6c20 6966        q_model if
-0000f300: 2067 6574 6174 7472 2871 5f66 756e 632c   getattr(q_func,
-0000f310: 2027 6275 696c 7469 6e27 2c20 4e6f 6e65   'builtin', None
-0000f320: 2920 656c 7365 2071 5f6d 6f64 656c 2e5f  ) else q_model._
-0000f330: 6d6f 6465 6c29 0a20 2020 2020 2020 2020  model).         
-0000f340: 2020 2061 7373 6572 7420 715f 6d6f 6465     assert q_mode
-0000f350: 6c2e 5f6d 6f64 656c 2069 7320 6e6f 7420  l._model is not 
-0000f360: 4e6f 6e65 2c20 2250 6c65 6173 6520 7265  None, "Please re
-0000f370: 7475 726e 2061 2074 7261 696e 6564 206d  turn a trained m
-0000f380: 6f64 656c 2069 6e20 7472 6169 6e20 6675  odel in train fu
-0000f390: 6e63 7469 6f6e 2122 0a20 2020 2020 2020  nction!".       
-0000f3a0: 2020 2020 2071 5f6d 6f64 656c 2e5f 6d6f       q_model._mo
-0000f3b0: 6465 6c2e 6576 616c 2829 0a0a 2020 2020  del.eval()..    
-0000f3c0: 2020 2020 6966 2073 656c 662e 6170 7072      if self.appr
-0000f3d0: 6f61 6368 203d 3d20 2771 7561 6e74 5f61  oach == 'quant_a
-0000f3e0: 7761 7265 5f74 7261 696e 696e 6727 3a0a  ware_training':.
-0000f3f0: 2020 2020 2020 2020 2020 2020 746f 7263              torc
-0000f400: 682e 7175 616e 7469 7a61 7469 6f6e 2e63  h.quantization.c
-0000f410: 6f6e 7665 7274 2871 5f6d 6f64 656c 2e5f  onvert(q_model._
-0000f420: 6d6f 6465 6c2c 2069 6e70 6c61 6365 3d54  model, inplace=T
-0000f430: 7275 6529 0a20 2020 2020 2020 2065 6c73  rue).        els
-0000f440: 653a 0a20 2020 2020 2020 2020 2020 2074  e:.            t
-0000f450: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
-0000f460: 6e2e 636f 6e76 6572 7428 715f 6d6f 6465  n.convert(q_mode
-0000f470: 6c2e 5f6d 6f64 656c 2c20 6d61 7070 696e  l._model, mappin
-0000f480: 673d 7365 6c66 2e71 5f6d 6170 7069 6e67  g=self.q_mapping
-0000f490: 2c20 696e 706c 6163 653d 5472 7565 290a  , inplace=True).
-0000f4a0: 0a20 2020 2020 2020 2069 6620 6c65 6e28  .        if len(
-0000f4b0: 7365 6c66 2e74 756e 655f 6366 675b 2762  self.tune_cfg['b
-0000f4c0: 6631 365f 6f70 735f 6c69 7374 275d 2920  f16_ops_list']) 
-0000f4d0: 3e20 3020 616e 6420 5c0a 2020 2020 2020  > 0 and \.      
-0000f4e0: 2020 2020 2020 2873 656c 662e 7665 7273        (self.vers
-0000f4f0: 696f 6e2e 7265 6c65 6173 6520 3e3d 2056  ion.release >= V
-0000f500: 6572 7369 6f6e 2822 312e 3131 2e30 2229  ersion("1.11.0")
-0000f510: 2e72 656c 6561 7365 2920 616e 6420 5c0a  .release) and \.
-0000f520: 2020 2020 2020 2020 2020 2020 2843 7075              (Cpu
-0000f530: 496e 666f 2829 2e62 6631 3620 6f72 206f  Info().bf16 or o
-0000f540: 732e 6765 7465 6e76 2827 464f 5243 455f  s.getenv('FORCE_
-0000f550: 4246 3136 2729 203d 3d20 2731 2729 3a20  BF16') == '1'): 
-0000f560: 2320 7072 6167 6d61 3a20 6e6f 2063 6f76  # pragma: no cov
-0000f570: 6572 0a20 2020 2020 2020 2020 2020 2071  er.            q
-0000f580: 5f6d 6f64 656c 2e5f 6d6f 6465 6c20 3d20  _model._model = 
-0000f590: 746f 7263 685f 7574 696c 732e 6266 3136  torch_utils.bf16
-0000f5a0: 5f63 6f6e 7665 7274 2e43 6f6e 7665 7274  _convert.Convert
-0000f5b0: 2871 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c  (q_model._model,
-0000f5c0: 2073 656c 662e 7475 6e65 5f63 6667 290a   self.tune_cfg).
-0000f5d0: 0a20 2020 2020 2020 2071 5f6d 6f64 656c  .        q_model
-0000f5e0: 2e71 5f63 6f6e 6669 6720 3d20 636f 7079  .q_config = copy
-0000f5f0: 2e64 6565 7063 6f70 7928 7365 6c66 2e74  .deepcopy(self.t
-0000f600: 756e 655f 6366 6729 0a20 2020 2020 2020  une_cfg).       
-0000f610: 2069 6620 7365 6c66 2e61 7070 726f 6163   if self.approac
-0000f620: 6820 213d 2027 706f 7374 5f74 7261 696e  h != 'post_train
-0000f630: 696e 675f 6479 6e61 6d69 635f 7175 616e  ing_dynamic_quan
-0000f640: 7427 3a0a 2020 2020 2020 2020 2020 2020  t':.            
-0000f650: 7365 6c66 2e5f 6765 745f 7363 616c 655f  self._get_scale_
-0000f660: 7a65 726f 706f 696e 7428 715f 6d6f 6465  zeropoint(q_mode
-0000f670: 6c2e 5f6d 6f64 656c 2c20 715f 6d6f 6465  l._model, q_mode
-0000f680: 6c2e 715f 636f 6e66 6967 290a 2020 2020  l.q_config).    
-0000f690: 2020 2020 715f 6d6f 6465 6c2e 6973 5f71      q_model.is_q
-0000f6a0: 7561 6e74 697a 6564 203d 2054 7275 650a  uantized = True.
-0000f6b0: 0a20 2020 2020 2020 2073 656c 662e 5f64  .        self._d
-0000f6c0: 756d 705f 6d6f 6465 6c5f 6f70 5f73 7461  ump_model_op_sta
-0000f6d0: 7473 2871 5f6d 6f64 656c 2e5f 6d6f 6465  ts(q_model._mode
-0000f6e0: 6c2c 2071 5f6d 6f64 656c 2e71 5f63 6f6e  l, q_model.q_con
-0000f6f0: 6669 6729 0a20 2020 2020 2020 2074 6f72  fig).        tor
-0000f700: 6368 5f75 7469 6c73 2e75 7469 6c2e 6765  ch_utils.util.ge
-0000f710: 745f 656d 6265 6464 696e 675f 636f 6e74  t_embedding_cont
-0000f720: 6967 756f 7573 2871 5f6d 6f64 656c 2e5f  iguous(q_model._
-0000f730: 6d6f 6465 6c29 0a20 2020 2020 2020 2072  model).        r
-0000f740: 6574 7572 6e20 715f 6d6f 6465 6c0a 0a20  eturn q_model.. 
-0000f750: 2020 2064 6566 2065 7661 6c75 6174 6528     def evaluate(
-0000f760: 7365 6c66 2c0a 2020 2020 2020 2020 2020  self,.          
-0000f770: 2020 2020 2020 206d 6f64 656c 2c0a 2020         model,.  
-0000f780: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-0000f790: 6174 616c 6f61 6465 722c 0a20 2020 2020  ataloader,.     
-0000f7a0: 2020 2020 2020 2020 2020 2020 706f 7374              post
-0000f7b0: 7072 6f63 6573 733d 4e6f 6e65 2c0a 2020  process=None,.  
-0000f7c0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-0000f7d0: 6574 7269 6373 3d4e 6f6e 652c 0a20 2020  etrics=None,.   
-0000f7e0: 2020 2020 2020 2020 2020 2020 2020 6d65                me
-0000f7f0: 6173 7572 6572 3d4e 6f6e 652c 0a20 2020  asurer=None,.   
-0000f800: 2020 2020 2020 2020 2020 2020 2020 6974                it
-0000f810: 6572 6174 696f 6e3d 2d31 2c0a 2020 2020  eration=-1,.    
-0000f820: 2020 2020 2020 2020 2020 2020 2074 656e               ten
-0000f830: 736f 7262 6f61 7264 3d46 616c 7365 2c0a  sorboard=False,.
-0000f840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f850: 2066 7033 325f 6261 7365 6c69 6e65 3d46   fp32_baseline=F
-0000f860: 616c 7365 293a 0a20 2020 2020 2020 2022  alse):.        "
-0000f870: 2222 4578 6563 7574 6520 7468 6520 6576  ""Execute the ev
-0000f880: 616c 7561 7465 2070 726f 6365 7373 206f  aluate process o
-0000f890: 6e20 7468 6520 7370 6563 6966 6965 6420  n the specified 
-0000f8a0: 6d6f 6465 6c2e 0a0a 2020 2020 2020 2020  model...        
-0000f8b0: 4172 6773 3a0a 2020 2020 2020 2020 2020  Args:.          
-0000f8c0: 2020 6d6f 6465 6c20 286f 626a 6563 7429    model (object)
-0000f8d0: 3a20 6d6f 6465 6c20 746f 2072 756e 2065  : model to run e
-0000f8e0: 7661 6c75 6174 696f 6e2e 0a20 2020 2020  valuation..     
-0000f8f0: 2020 2020 2020 2064 6174 616c 6f61 6465         dataloade
-0000f900: 7220 286f 626a 6563 7429 3a20 6576 616c  r (object): eval
-0000f910: 7561 7469 6f6e 2064 6174 6173 6574 2e0a  uation dataset..
-0000f920: 2020 2020 2020 2020 2020 2020 706f 7374              post
-0000f930: 7072 6f63 6573 7320 286f 626a 6563 742c  process (object,
-0000f940: 206f 7074 696f 6e61 6c29 3a20 7072 6f63   optional): proc
-0000f950: 6573 7320 6675 6e63 7469 6f6e 2061 6674  ess function aft
-0000f960: 6572 2065 7661 6c75 6174 696f 6e2e 0a20  er evaluation.. 
-0000f970: 2020 2020 2020 2020 2020 206d 6574 7269             metri
-0000f980: 6373 2028 6c69 7374 2c20 6f70 7469 6f6e  cs (list, option
-0000f990: 616c 293a 206c 6973 7420 6f66 206d 6574  al): list of met
-0000f9a0: 7269 6320 6675 6e63 7469 6f6e 2e0a 2020  ric function..  
-0000f9b0: 2020 2020 2020 2020 2020 6d65 6173 7572            measur
-0000f9c0: 6572 2028 6f62 6a65 6374 2c20 6f70 7469  er (object, opti
-0000f9d0: 6f6e 616c 293a 206d 6561 7375 7265 7220  onal): measurer 
-0000f9e0: 6675 6e63 7469 6f6e 2e0a 2020 2020 2020  function..      
-0000f9f0: 2020 2020 2020 6974 6572 6174 696f 6e20        iteration 
-0000fa00: 2869 6e74 2c20 6f70 7469 6f6e 616c 293a  (int, optional):
-0000fa10: 206e 756d 6265 7220 6f66 2069 7465 7261   number of itera
-0000fa20: 7469 6f6e 7320 746f 2065 7661 6c75 6174  tions to evaluat
-0000fa30: 652e 0a20 2020 2020 2020 2020 2020 2074  e..            t
-0000fa40: 656e 736f 7262 6f61 7264 2028 626f 6f6c  ensorboard (bool
-0000fa50: 2c20 6f70 7469 6f6e 616c 293a 2064 756d  , optional): dum
-0000fa60: 7020 6f75 7470 7574 2074 656e 736f 7220  p output tensor 
-0000fa70: 746f 2074 656e 736f 7262 6f61 7264 2073  to tensorboard s
-0000fa80: 756d 6d61 7279 2066 696c 6573 2e0a 2020  ummary files..  
-0000fa90: 2020 2020 2020 2020 2020 6670 3332 5f62            fp32_b
-0000faa0: 6173 656c 696e 6520 2862 6f6f 6c65 6e2c  aseline (boolen,
-0000fab0: 206f 7074 696f 6e61 6c29 3a20 6f6e 6c79   optional): only
-0000fac0: 2066 6f72 2063 6f6d 7061 7265 5f6c 6162   for compare_lab
-0000fad0: 656c 3d46 616c 7365 2070 6970 656c 696e  el=False pipelin
-0000fae0: 650a 0a20 2020 2020 2020 2052 6574 7572  e..        Retur
-0000faf0: 6e73 3a0a 2020 2020 2020 2020 2020 2020  ns:.            
-0000fb00: 286f 626a 6563 7429 3a20 6163 6375 7261  (object): accura
-0000fb10: 6379 0a20 2020 2020 2020 2022 2222 0a20  cy.        """. 
-0000fb20: 2020 2020 2020 2073 656c 662e 6973 5f62         self.is_b
-0000fb30: 6173 656c 696e 6520 3d20 6670 3332 5f62  aseline = fp32_b
-0000fb40: 6173 656c 696e 650a 2020 2020 2020 2020  aseline.        
-0000fb50: 6966 2074 656e 736f 7262 6f61 7264 3a0a  if tensorboard:.
-0000fb60: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
-0000fb70: 6c20 3d20 7365 6c66 2e5f 7072 655f 6576  l = self._pre_ev
-0000fb80: 616c 5f68 6f6f 6b28 6d6f 6465 6c29 0a0a  al_hook(model)..
-0000fb90: 2020 2020 2020 2020 6d6f 6465 6c5f 203d          model_ =
-0000fba0: 206d 6f64 656c 2e5f 6d6f 6465 6c0a 2020   model._model.  
-0000fbb0: 2020 2020 2020 6173 7365 7274 2069 7369        assert isi
-0000fbc0: 6e73 7461 6e63 6528 0a20 2020 2020 2020  nstance(.       
-0000fbd0: 2020 2020 206d 6f64 656c 5f2c 2074 6f72       model_, tor
-0000fbe0: 6368 2e6e 6e2e 4d6f 6475 6c65 292c 2022  ch.nn.Module), "
-0000fbf0: 5468 6520 6d6f 6465 6c20 7061 7373 6564  The model passed
-0000fc00: 2069 6e20 6973 206e 6f74 2074 6865 2069   in is not the i
-0000fc10: 6e73 7461 6e63 6520 6f66 2074 6f72 6368  nstance of torch
-0000fc20: 2e6e 6e2e 4d6f 6475 6c65 220a 2020 2020  .nn.Module".    
-0000fc30: 2020 2020 6d6f 6465 6c5f 2e65 7661 6c28      model_.eval(
-0000fc40: 290a 2020 2020 2020 2020 6966 2073 656c  ).        if sel
-0000fc50: 662e 6465 7669 6365 203d 3d20 2263 7075  f.device == "cpu
-0000fc60: 223a 0a20 2020 2020 2020 2020 2020 206d  ":.            m
-0000fc70: 6f64 656c 5f2e 746f 2822 6370 7522 290a  odel_.to("cpu").
-0000fc80: 2020 2020 2020 2020 656c 6966 2073 656c          elif sel
-0000fc90: 662e 6465 7669 6365 203d 3d20 2267 7075  f.device == "gpu
-0000fca0: 223a 0a20 2020 2020 2020 2020 2020 2069  ":.            i
-0000fcb0: 6620 7365 6c66 2e69 735f 6261 7365 6c69  f self.is_baseli
-0000fcc0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-0000fcd0: 2020 2020 6d6f 6465 6c5f 2e74 6f28 2264      model_.to("d
-0000fce0: 7063 7070 2229 0a0a 2020 2020 2020 2020  pcpp")..        
-0000fcf0: 6966 206d 6574 7269 6373 3a0a 2020 2020  if metrics:.    
-0000fd00: 2020 2020 2020 2020 7365 6c66 2e66 7033          self.fp3
-0000fd10: 325f 7072 6564 735f 6173 5f6c 6162 656c  2_preds_as_label
-0000fd20: 203d 2061 6e79 285b 6861 7361 7474 7228   = any([hasattr(
-0000fd30: 6d65 7472 6963 2c20 2263 6f6d 7061 7265  metric, "compare
-0000fd40: 5f6c 6162 656c 2229 2061 6e64 205c 0a20  _label") and \. 
-0000fd50: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-0000fd60: 6f74 206d 6574 7269 632e 636f 6d70 6172  ot metric.compar
-0000fd70: 655f 6c61 6265 6c20 666f 7220 6d65 7472  e_label for metr
-0000fd80: 6963 2069 6e20 6d65 7472 6963 735d 290a  ic in metrics]).
-0000fd90: 2020 2020 2020 2020 6163 6320 3d20 7365          acc = se
-0000fda0: 6c66 2e6d 6f64 656c 5f65 7661 6c28 6d6f  lf.model_eval(mo
-0000fdb0: 6465 6c5f 2c20 6461 7461 6c6f 6164 6572  del_, dataloader
-0000fdc0: 2c20 706f 7374 7072 6f63 6573 732c 206d  , postprocess, m
-0000fdd0: 6574 7269 6373 2c20 6d65 6173 7572 6572  etrics, measurer
-0000fde0: 2c20 6974 6572 6174 696f 6e29 0a0a 2020  , iteration)..  
-0000fdf0: 2020 2020 2020 6966 2074 656e 736f 7262        if tensorb
-0000fe00: 6f61 7264 3a0a 2020 2020 2020 2020 2020  oard:.          
-0000fe10: 2020 7365 6c66 2e5f 706f 7374 5f65 7661    self._post_eva
-0000fe20: 6c5f 686f 6f6b 286d 6f64 656c 2c20 6163  l_hook(model, ac
-0000fe30: 6375 7261 6379 3d61 6363 290a 2020 2020  curacy=acc).    
-0000fe40: 2020 2020 7265 7475 726e 2061 6363 2069      return acc i
-0000fe50: 6620 6e6f 7420 6973 696e 7374 616e 6365  f not isinstance
-0000fe60: 2861 6363 2c20 6c69 7374 2920 6f72 206c  (acc, list) or l
-0000fe70: 656e 2861 6363 2920 3e20 3120 656c 7365  en(acc) > 1 else
-0000fe80: 2061 6363 5b30 5d0a 0a20 2020 2064 6566   acc[0]..    def
-0000fe90: 205f 7072 655f 686f 6f6b 5f66 6f72 5f71   _pre_hook_for_q
-0000fea0: 6174 2873 656c 662c 2064 6174 616c 6f61  at(self, dataloa
-0000feb0: 6465 723d 4e6f 6e65 293a 0a20 2020 2020  der=None):.     
-0000fec0: 2020 2023 2073 656c 662e 6d6f 6465 6c2e     # self.model.
-0000fed0: 5f6d 6f64 656c 2069 7320 6e65 6564 6564  _model is needed
-0000fee0: 2068 6572 652e 0a20 2020 2020 2020 2073   here..        s
-0000fef0: 656c 662e 6d6f 6465 6c2e 5f6d 6f64 656c  elf.model._model
-0000ff00: 2e71 636f 6e66 6967 203d 2074 6f72 6368  .qconfig = torch
-0000ff10: 2e71 7561 6e74 697a 6174 696f 6e2e 5143  .quantization.QC
-0000ff20: 6f6e 6669 6728 0a20 2020 2020 2020 2020  onfig(.         
-0000ff30: 2020 2061 6374 6976 6174 696f 6e3d 746f     activation=to
-0000ff40: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
-0000ff50: 2e46 616b 6551 7561 6e74 697a 652e 7769  .FakeQuantize.wi
-0000ff60: 7468 5f61 7267 7328 6474 7970 653d 746f  th_args(dtype=to
-0000ff70: 7263 682e 7175 696e 7438 2c0a 2020 2020  rch.quint8,.    
-0000ff80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ff90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ffa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ffb0: 2020 2020 2020 2020 2020 2020 2071 7363               qsc
-0000ffc0: 6865 6d65 3d74 6f72 6368 2e70 6572 5f74  heme=torch.per_t
-0000ffd0: 656e 736f 725f 6166 6669 6e65 2c0a 2020  ensor_affine,.  
-0000ffe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010010: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00010020: 6564 7563 655f 7261 6e67 653d 5245 4455  educe_range=REDU
-00010030: 4345 5f52 414e 4745 292c 0a20 2020 2020  CE_RANGE),.     
-00010040: 2020 2020 2020 2077 6569 6768 743d 746f         weight=to
-00010050: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
-00010060: 2e64 6566 6175 6c74 5f77 6569 6768 745f  .default_weight_
-00010070: 6661 6b65 5f71 7561 6e74 290a 2020 2020  fake_quant).    
-00010080: 2020 2020 7365 6c66 2e6e 6f6e 5f71 7561      self.non_qua
-00010090: 6e74 5f64 6963 7420 3d20 7365 6c66 2e67  nt_dict = self.g
-000100a0: 6574 5f6e 6f6e 5f71 7561 6e74 5f6d 6f64  et_non_quant_mod
-000100b0: 756c 6573 2873 656c 662e 6d6f 6465 6c2e  ules(self.model.
-000100c0: 6b77 6172 6773 290a 2020 2020 2020 2020  kwargs).        
-000100d0: 7175 616e 7469 7a61 626c 655f 6f70 7320  quantizable_ops 
-000100e0: 3d20 5b5d 0a20 2020 2020 2020 2073 656c  = [].        sel
-000100f0: 662e 5f67 6574 5f71 7561 6e74 697a 6162  f._get_quantizab
-00010100: 6c65 5f6f 7073 5f72 6563 7572 7369 7665  le_ops_recursive
-00010110: 6c79 2873 656c 662e 6d6f 6465 6c2e 5f6d  ly(self.model._m
-00010120: 6f64 656c 2c20 2727 2c20 7175 616e 7469  odel, '', quanti
-00010130: 7a61 626c 655f 6f70 7329 0a20 2020 2020  zable_ops).     
-00010140: 2020 2062 6631 365f 6f70 7320 3d20 5b5d     bf16_ops = []
-00010150: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-00010160: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
-00010170: 203e 3d20 5665 7273 696f 6e28 2231 2e31   >= Version("1.1
-00010180: 312e 3022 292e 7265 6c65 6173 6520 616e  1.0").release an
-00010190: 6420 7365 6c66 2e75 7365 5f62 6631 3620  d self.use_bf16 
-000101a0: 616e 6420 5c0a 2020 2020 2020 2020 2020  and \.          
-000101b0: 2020 2843 7075 496e 666f 2829 2e62 6631    (CpuInfo().bf1
-000101c0: 3620 6f72 206f 732e 6765 7465 6e76 2827  6 or os.getenv('
-000101d0: 464f 5243 455f 4246 3136 2729 203d 3d20  FORCE_BF16') == 
-000101e0: 2731 2729 3a20 2320 7072 6167 6d61 3a20  '1'): # pragma: 
-000101f0: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
-00010200: 2020 2020 2073 656c 662e 6266 3136 5f6f       self.bf16_o
-00010210: 7073 203d 2073 656c 662e 7175 6572 795f  ps = self.query_
-00010220: 6861 6e64 6c65 722e 6765 745f 6f70 5f74  handler.get_op_t
-00010230: 7970 6573 5f62 795f 7072 6563 6973 696f  ypes_by_precisio
-00010240: 6e28 2262 6631 3622 290a 2020 2020 2020  n("bf16").      
-00010250: 2020 2020 2020 7365 6c66 2e5f 6765 745f        self._get_
-00010260: 6266 3136 5f6f 7073 5f72 6563 7572 7369  bf16_ops_recursi
-00010270: 7665 6c79 2873 656c 662e 6d6f 6465 6c2e  vely(self.model.
-00010280: 5f6d 6f64 656c 2c20 2727 2c20 6266 3136  _model, '', bf16
-00010290: 5f6f 7073 290a 2020 2020 2020 2020 6266  _ops).        bf
-000102a0: 3136 5f6f 7073 5f6c 6973 7420 3d20 5b28  16_ops_list = [(
-000102b0: 6f70 2920 666f 7220 6f70 2069 6e20 6266  op) for op in bf
-000102c0: 3136 5f6f 7073 2069 6620 6f70 206e 6f74  16_ops if op not
-000102d0: 2069 6e20 7175 616e 7469 7a61 626c 655f   in quantizable_
-000102e0: 6f70 735d 0a20 2020 2020 2020 2073 656c  ops].        sel
-000102f0: 662e 6d6f 6465 6c2e 6d6f 6465 6c2e 7472  f.model.model.tr
-00010300: 6169 6e69 6e67 203d 2054 7275 650a 2020  aining = True.  
-00010310: 2020 2020 2020 746f 7263 682e 7175 616e        torch.quan
-00010320: 7469 7a61 7469 6f6e 2e70 7265 7061 7265  tization.prepare
-00010330: 5f71 6174 2873 656c 662e 6d6f 6465 6c2e  _qat(self.model.
-00010340: 5f6d 6f64 656c 2c20 696e 706c 6163 653d  _model, inplace=
-00010350: 5472 7565 290a 0a20 2020 2020 2020 2023  True)..        #
-00010360: 2054 6869 7320 6973 2061 2066 6c61 6720   This is a flag 
-00010370: 666f 7220 7265 6c6f 6164 696e 670a 2020  for reloading.  
-00010380: 2020 2020 2020 7365 6c66 2e6d 6f64 656c        self.model
-00010390: 2e71 5f63 6f6e 6669 6720 3d20 7b0a 2020  .q_config = {.  
-000103a0: 2020 2020 2020 2020 2020 2769 735f 6f6e            'is_on
-000103b0: 6573 686f 7427 3a20 5472 7565 2c0a 2020  eshot': True,.  
-000103c0: 2020 2020 2020 2020 2020 2766 7261 6d65            'frame
-000103d0: 776f 726b 273a 2027 7079 746f 7263 6827  work': 'pytorch'
-000103e0: 2c0a 2020 2020 2020 2020 2020 2020 2772  ,.            'r
-000103f0: 6564 7563 655f 7261 6e67 6527 3a20 5245  educe_range': RE
-00010400: 4455 4345 5f52 414e 4745 2c0a 2020 2020  DUCE_RANGE,.    
-00010410: 2020 2020 2020 2020 2761 7070 726f 6163          'approac
-00010420: 6827 3a20 2771 7561 6e74 5f61 7761 7265  h': 'quant_aware
-00010430: 5f74 7261 696e 696e 6727 2c0a 2020 2020  _training',.    
-00010440: 2020 2020 2020 2020 2762 6631 365f 6f70          'bf16_op
-00010450: 735f 6c69 7374 273a 2062 6631 365f 6f70  s_list': bf16_op
-00010460: 735f 6c69 7374 2c0a 2020 2020 2020 2020  s_list,.        
-00010470: 7d0a 0a20 2020 2064 6566 205f 706f 7374  }..    def _post
-00010480: 5f68 6f6f 6b5f 666f 725f 7161 7428 7365  _hook_for_qat(se
-00010490: 6c66 293a 0a20 2020 2020 2020 2074 6f72  lf):.        tor
-000104a0: 6368 2e71 7561 6e74 697a 6174 696f 6e2e  ch.quantization.
-000104b0: 636f 6e76 6572 7428 7365 6c66 2e6d 6f64  convert(self.mod
-000104c0: 656c 2e5f 6d6f 6465 6c2c 2069 6e70 6c61  el._model, inpla
-000104d0: 6365 3d54 7275 6529 0a20 2020 2020 2020  ce=True).       
-000104e0: 2069 6620 7365 6c66 2e6d 6f64 656c 2e71   if self.model.q
-000104f0: 5f63 6f6e 6669 6720 6973 206e 6f74 204e  _config is not N
-00010500: 6f6e 6520 616e 6420 6c65 6e28 7365 6c66  one and len(self
-00010510: 2e6d 6f64 656c 2e71 5f63 6f6e 6669 675b  .model.q_config[
-00010520: 2762 6631 365f 6f70 735f 6c69 7374 275d  'bf16_ops_list']
-00010530: 2920 3e20 3020 616e 6420 5c0a 2020 2020  ) > 0 and \.    
-00010540: 2020 2020 2020 2020 7365 6c66 2e76 6572          self.ver
-00010550: 7369 6f6e 2e72 656c 6561 7365 203e 3d20  sion.release >= 
-00010560: 5665 7273 696f 6e28 2231 2e31 312e 3022  Version("1.11.0"
-00010570: 292e 7265 6c65 6173 6520 616e 6420 7365  ).release and se
-00010580: 6c66 2e75 7365 5f62 6631 3620 616e 6420  lf.use_bf16 and 
-00010590: 5c0a 2020 2020 2020 2020 2020 2020 2843  \.            (C
-000105a0: 7075 496e 666f 2829 2e62 6631 3620 6f72  puInfo().bf16 or
-000105b0: 206f 732e 6765 7465 6e76 2827 464f 5243   os.getenv('FORC
-000105c0: 455f 4246 3136 2729 203d 3d20 2731 2729  E_BF16') == '1')
-000105d0: 3a20 2320 7072 6167 6d61 3a20 6e6f 2063  : # pragma: no c
-000105e0: 6f76 6572 0a20 2020 2020 2020 2020 2020  over.           
-000105f0: 2073 656c 662e 6d6f 6465 6c2e 5f6d 6f64   self.model._mod
-00010600: 656c 203d 2074 6f72 6368 5f75 7469 6c73  el = torch_utils
-00010610: 2e62 6631 365f 636f 6e76 6572 742e 436f  .bf16_convert.Co
-00010620: 6e76 6572 7428 7365 6c66 2e6d 6f64 656c  nvert(self.model
-00010630: 2e5f 6d6f 6465 6c2c 2073 656c 662e 6d6f  ._model, self.mo
-00010640: 6465 6c2e 715f 636f 6e66 6967 290a 0a20  del.q_config).. 
-00010650: 2020 2064 6566 205f 7072 655f 686f 6f6b     def _pre_hook
-00010660: 5f66 6f72 5f68 7664 2873 656c 662c 2064  _for_hvd(self, d
-00010670: 6174 616c 6f61 6465 723d 4e6f 6e65 293a  ataloader=None):
-00010680: 0a20 2020 2020 2020 2023 2054 4f44 4f3a  .        # TODO:
-00010690: 206c 617a 7920 696e 6974 2068 6572 650a   lazy init here.
-000106a0: 2020 2020 2020 2020 6876 642e 696e 6974          hvd.init
-000106b0: 2829 0a20 2020 2020 2020 2068 7664 2e62  ().        hvd.b
-000106c0: 726f 6164 6361 7374 5f70 6172 616d 6574  roadcast_paramet
-000106d0: 6572 7328 7365 6c66 2e6d 6f64 656c 2e5f  ers(self.model._
-000106e0: 6d6f 6465 6c2e 7374 6174 655f 6469 6374  model.state_dict
-000106f0: 2829 2c20 726f 6f74 5f72 616e 6b3d 3029  (), root_rank=0)
-00010700: 0a20 2020 2020 2020 2068 7664 2e62 726f  .        hvd.bro
-00010710: 6164 6361 7374 5f6f 7074 696d 697a 6572  adcast_optimizer
-00010720: 5f73 7461 7465 2873 656c 662e 6f70 7469  _state(self.opti
-00010730: 6d69 7a65 722c 2072 6f6f 745f 7261 6e6b  mizer, root_rank
-00010740: 3d30 290a 2020 2020 2020 2020 7365 6c66  =0).        self
-00010750: 2e6f 7074 696d 697a 6572 203d 2068 7664  .optimizer = hvd
-00010760: 2e44 6973 7472 6962 7574 6564 4f70 7469  .DistributedOpti
-00010770: 6d69 7a65 7228 0a20 2020 2020 2020 2020  mizer(.         
-00010780: 2020 2073 656c 662e 6f70 7469 6d69 7a65     self.optimize
-00010790: 722c 206e 616d 6564 5f70 6172 616d 6574  r, named_paramet
-000107a0: 6572 733d 7365 6c66 2e6d 6f64 656c 2e5f  ers=self.model._
-000107b0: 6d6f 6465 6c2e 6e61 6d65 645f 7061 7261  model.named_para
-000107c0: 6d65 7465 7273 2829 290a 0a20 2020 2064  meters())..    d
-000107d0: 6566 2074 7261 696e 2873 656c 662c 206d  ef train(self, m
-000107e0: 6f64 656c 2c20 6461 7461 6c6f 6164 6572  odel, dataloader
-000107f0: 2c20 6f70 7469 6d69 7a65 725f 7475 706c  , optimizer_tupl
-00010800: 652c 2063 7269 7465 7269 6f6e 5f74 7570  e, criterion_tup
-00010810: 6c65 2c20 686f 6f6b 732c 202a 2a6b 7761  le, hooks, **kwa
-00010820: 7267 7329 3a0a 2020 2020 2020 2020 2222  rgs):.        ""
-00010830: 2245 7865 6375 7465 2074 6865 2074 7261  "Execute the tra
-00010840: 696e 2070 726f 6365 7373 206f 6e20 7468  in process on th
-00010850: 6520 7370 6563 6966 6965 6420 6d6f 6465  e specified mode
-00010860: 6c2e 0a0a 2020 2020 2020 2020 4172 6773  l...        Args
-00010870: 3a0a 2020 2020 2020 2020 2020 2020 6d6f  :.            mo
-00010880: 6465 6c20 286f 626a 6563 7429 3a20 6d6f  del (object): mo
-00010890: 6465 6c20 746f 2072 756e 2065 7661 6c75  del to run evalu
-000108a0: 6174 696f 6e2e 0a20 2020 2020 2020 2020  ation..         
-000108b0: 2020 2064 6174 616c 6f61 6465 7220 286f     dataloader (o
-000108c0: 626a 6563 7429 3a20 7472 6169 6e69 6e67  bject): training
-000108d0: 2064 6174 6173 6574 2e0a 2020 2020 2020   dataset..      
-000108e0: 2020 2020 2020 6f70 7469 6d69 7a65 7220        optimizer 
-000108f0: 2874 7570 6c65 293a 2049 7420 6973 2061  (tuple): It is a
-00010900: 2074 7570 6c65 206f 6620 2863 6c73 2c20   tuple of (cls, 
-00010910: 7061 7261 6d65 7465 7273 2920 666f 7220  parameters) for 
-00010920: 6f70 7469 6d69 7a65 722e 0a20 2020 2020  optimizer..     
-00010930: 2020 2020 2020 2063 7269 7465 7269 6f6e         criterion
-00010940: 2028 7475 706c 6529 3a20 4974 2069 7320   (tuple): It is 
-00010950: 6120 7475 706c 6520 6f66 2028 636c 732c  a tuple of (cls,
-00010960: 2070 6172 616d 6574 6572 7329 2066 6f72   parameters) for
-00010970: 2063 7269 7465 7269 6f6e 2e0a 2020 2020   criterion..    
-00010980: 2020 2020 2020 2020 6b77 6172 6773 2028          kwargs (
-00010990: 6469 6374 2c20 6f70 7469 6f6e 616c 293a  dict, optional):
-000109a0: 206f 7468 6572 2070 6172 616d 6574 6572   other parameter
-000109b0: 732e 0a0a 2020 2020 2020 2020 5265 7475  s...        Retu
-000109c0: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
-000109d0: 204e 6f6e 650a 2020 2020 2020 2020 2222   None.        ""
-000109e0: 220a 2020 2020 2020 2020 6d6f 6465 6c5f  ".        model_
-000109f0: 203d 206d 6f64 656c 2e5f 6d6f 6465 6c0a   = model._model.
-00010a00: 2020 2020 2020 2020 6465 7669 6365 203d          device =
-00010a10: 2022 6375 6461 3a30 2220 6966 2073 656c   "cuda:0" if sel
-00010a20: 662e 6465 7669 6365 2021 3d20 2247 5055  f.device != "GPU
-00010a30: 2220 616e 6420 746f 7263 682e 6375 6461  " and torch.cuda
-00010a40: 2e69 735f 6176 6169 6c61 626c 6528 2920  .is_available() 
-00010a50: 656c 7365 2073 656c 662e 6465 7669 6365  else self.device
-00010a60: 0a20 2020 2020 2020 2023 2073 656c 662e  .        # self.
-00010a70: 6d6f 6465 6c20 6973 2073 6574 2074 6f20  model is set to 
-00010a80: 6e65 7572 616c 5f63 6f6d 7072 6573 736f  neural_compresso
-00010a90: 7220 6d6f 6465 6c20 6865 7265 2074 6f20  r model here to 
-00010aa0: 686f 6c64 2074 6865 2069 6e70 6c61 6365  hold the inplace
-00010ab0: 2063 6861 6e67 6520 696e 2046 574b 206d   change in FWK m
-00010ac0: 6f64 656c 2e0a 2020 2020 2020 2020 7365  odel..        se
-00010ad0: 6c66 2e6d 6f64 656c 203d 206d 6f64 656c  lf.model = model
-00010ae0: 0a20 2020 2020 2020 206f 7074 696d 697a  .        optimiz
-00010af0: 6572 203d 206f 7074 696d 697a 6572 5f74  er = optimizer_t
-00010b00: 7570 6c65 5b30 5d28 6d6f 6465 6c5f 2e70  uple[0](model_.p
-00010b10: 6172 616d 6574 6572 7328 292c 202a 2a6f  arameters(), **o
-00010b20: 7074 696d 697a 6572 5f74 7570 6c65 5b31  ptimizer_tuple[1
-00010b30: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
-00010b40: 6f70 7469 6d69 7a65 7220 3d20 6f70 7469  optimizer = opti
-00010b50: 6d69 7a65 720a 2020 2020 2020 2020 6372  mizer.        cr
-00010b60: 6974 6572 696f 6e20 3d20 6372 6974 6572  iterion = criter
-00010b70: 696f 6e5f 7475 706c 655b 305d 282a 2a63  ion_tuple[0](**c
-00010b80: 7269 7465 7269 6f6e 5f74 7570 6c65 5b31  riterion_tuple[1
-00010b90: 5d29 0a20 2020 2020 2020 2073 7461 7274  ]).        start
-00010ba0: 5f65 706f 6368 7320 3d20 6b77 6172 6773  _epochs = kwargs
-00010bb0: 5b27 6b77 6172 6773 275d 5b27 7374 6172  ['kwargs']['star
-00010bc0: 745f 6570 6f63 6827 5d0a 2020 2020 2020  t_epoch'].      
-00010bd0: 2020 656e 645f 6570 6f63 6873 203d 206b    end_epochs = k
-00010be0: 7761 7267 735b 276b 7761 7267 7327 5d5b  wargs['kwargs'][
-00010bf0: 2765 6e64 5f65 706f 6368 275d 0a20 2020  'end_epoch'].   
-00010c00: 2020 2020 2069 7465 7273 203d 206b 7761       iters = kwa
-00010c10: 7267 735b 276b 7761 7267 7327 5d5b 2769  rgs['kwargs']['i
-00010c20: 7465 7261 7469 6f6e 275d 0a20 2020 2020  teration'].     
-00010c30: 2020 2069 6620 686f 6f6b 7320 6973 206e     if hooks is n
-00010c40: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
-00010c50: 2020 2020 206f 6e5f 7472 6169 6e5f 6265       on_train_be
-00010c60: 6769 6e20 3d20 686f 6f6b 735b 276f 6e5f  gin = hooks['on_
-00010c70: 7472 6169 6e5f 6265 6769 6e27 5d0a 2020  train_begin'].  
-00010c80: 2020 2020 2020 2020 2020 6f6e 5f74 7261            on_tra
-00010c90: 696e 5f65 6e64 203d 2068 6f6f 6b73 5b27  in_end = hooks['
-00010ca0: 6f6e 5f74 7261 696e 5f65 6e64 275d 0a20  on_train_end']. 
-00010cb0: 2020 2020 2020 2020 2020 206f 6e5f 6570             on_ep
-00010cc0: 6f63 685f 6265 6769 6e20 3d20 686f 6f6b  och_begin = hook
-00010cd0: 735b 276f 6e5f 6570 6f63 685f 6265 6769  s['on_epoch_begi
-00010ce0: 6e27 5d0a 2020 2020 2020 2020 2020 2020  n'].            
-00010cf0: 6f6e 5f65 706f 6368 5f65 6e64 203d 2068  on_epoch_end = h
-00010d00: 6f6f 6b73 5b27 6f6e 5f65 706f 6368 5f65  ooks['on_epoch_e
-00010d10: 6e64 275d 0a20 2020 2020 2020 2020 2020  nd'].           
-00010d20: 206f 6e5f 7374 6570 5f62 6567 696e 203d   on_step_begin =
-00010d30: 2068 6f6f 6b73 5b27 6f6e 5f73 7465 705f   hooks['on_step_
-00010d40: 6265 6769 6e27 5d0a 2020 2020 2020 2020  begin'].        
-00010d50: 2020 2020 6f6e 5f73 7465 705f 656e 6420      on_step_end 
-00010d60: 3d20 686f 6f6b 735b 276f 6e5f 7374 6570  = hooks['on_step
-00010d70: 5f65 6e64 275d 0a20 2020 2020 2020 2020  _end'].         
-00010d80: 2020 206f 6e5f 6166 7465 725f 636f 6d70     on_after_comp
-00010d90: 7574 655f 6c6f 7373 203d 2068 6f6f 6b73  ute_loss = hooks
-00010da0: 5b27 6f6e 5f61 6674 6572 5f63 6f6d 7075  ['on_after_compu
-00010db0: 7465 5f6c 6f73 7327 5d0a 2020 2020 2020  te_loss'].      
-00010dc0: 2020 2020 2020 6f6e 5f62 6566 6f72 655f        on_before_
-00010dd0: 6f70 7469 6d69 7a65 725f 7374 6570 203d  optimizer_step =
-00010de0: 2068 6f6f 6b73 5b27 6f6e 5f62 6566 6f72   hooks['on_befor
-00010df0: 655f 6f70 7469 6d69 7a65 725f 7374 6570  e_optimizer_step
-00010e00: 275d 0a20 2020 2020 2020 2069 6620 686f  '].        if ho
-00010e10: 6f6b 7320 6973 206e 6f74 204e 6f6e 653a  oks is not None:
-00010e20: 0a20 2020 2020 2020 2020 2020 206f 6e5f  .            on_
-00010e30: 7472 6169 6e5f 6265 6769 6e28 290a 2020  train_begin().  
-00010e40: 2020 2020 2020 666f 7220 6e65 706f 6368        for nepoch
-00010e50: 2069 6e20 7261 6e67 6528 7374 6172 745f   in range(start_
-00010e60: 6570 6f63 6873 2c20 656e 645f 6570 6f63  epochs, end_epoc
-00010e70: 6873 293a 0a20 2020 2020 2020 2020 2020  hs):.           
-00010e80: 206d 6f64 656c 5f2e 746f 2864 6576 6963   model_.to(devic
-00010e90: 6529 0a20 2020 2020 2020 2020 2020 206d  e).            m
-00010ea0: 6f64 656c 5f2e 7472 6169 6e28 290a 2020  odel_.train().  
-00010eb0: 2020 2020 2020 2020 2020 636e 7420 3d20            cnt = 
-00010ec0: 300a 2020 2020 2020 2020 2020 2020 6966  0.            if
-00010ed0: 2068 6f6f 6b73 2069 7320 6e6f 7420 4e6f   hooks is not No
-00010ee0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00010ef0: 2020 2020 6f6e 5f65 706f 6368 5f62 6567      on_epoch_beg
-00010f00: 696e 286e 6570 6f63 6829 0a20 2020 2020  in(nepoch).     
-00010f10: 2020 2020 2020 2069 6620 6765 7461 7474         if getatt
-00010f20: 7228 6461 7461 6c6f 6164 6572 2c20 2764  r(dataloader, 'd
-00010f30: 6973 7472 6962 7574 6564 272c 2046 616c  istributed', Fal
-00010f40: 7365 2920 5c0a 2020 2020 2020 2020 2020  se) \.          
-00010f50: 2020 2020 2020 2020 2020 6f72 2069 7369            or isi
-00010f60: 6e73 7461 6e63 6528 6461 7461 6c6f 6164  nstance(dataload
-00010f70: 6572 2e73 616d 706c 6572 2c20 5c0a 2020  er.sampler, \.  
+0000d600: 2020 206d 6f64 656c 2028 6f62 6a65 6374     model (object
+0000d610: 293a 2069 6e70 7574 206d 6f64 656c 0a20  ): input model. 
+0000d620: 2020 2020 2020 2020 2020 2070 7265 6669             prefi
+0000d630: 7820 2873 7472 696e 6729 3a20 7072 6566  x (string): pref
+0000d640: 6978 206f 6620 6f70 206e 616d 650a 2020  ix of op name.  
+0000d650: 2020 2020 2020 2020 2020 6266 3136 5f6f            bf16_o
+0000d660: 7073 2028 6c69 7374 293a 206c 6973 7420  ps (list): list 
+0000d670: 6f66 2071 7561 6e74 697a 6162 6c65 206f  of quantizable o
+0000d680: 7073 2066 726f 6d20 6d6f 6465 6c20 696e  ps from model in
+0000d690: 636c 7564 6520 6f70 206e 616d 6520 616e  clude op name an
+0000d6a0: 6420 7479 7065 2e0a 0a20 2020 2020 2020  d type...       
+0000d6b0: 2052 6574 7572 6e73 3a0a 2020 2020 2020   Returns:.      
+0000d6c0: 2020 2020 2020 4e6f 6e65 0a20 2020 2020        None.     
+0000d6d0: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
+0000d6e0: 666f 7220 6e61 6d65 2c20 6368 696c 6420  for name, child 
+0000d6f0: 696e 206d 6f64 656c 2e6e 616d 6564 5f63  in model.named_c
+0000d700: 6869 6c64 7265 6e28 293a 0a20 2020 2020  hildren():.     
+0000d710: 2020 2020 2020 206f 705f 6e61 6d65 203d         op_name =
+0000d720: 2070 7265 6669 7820 2b20 272e 2720 2b20   prefix + '.' + 
+0000d730: 6e61 6d65 2069 6620 7072 6566 6978 2021  name if prefix !
+0000d740: 3d20 2727 2065 6c73 6520 6e61 6d65 0a20  = '' else name. 
+0000d750: 2020 2020 2020 2020 2020 2069 6620 7374             if st
+0000d760: 7228 6368 696c 642e 5f5f 636c 6173 735f  r(child.__class_
+0000d770: 5f2e 5f5f 6e61 6d65 5f5f 2920 696e 2073  _.__name__) in s
+0000d780: 656c 662e 6266 3136 5f6f 7073 205c 0a20  elf.bf16_ops \. 
+0000d790: 2020 2020 2020 2020 2020 2020 2020 616e                an
+0000d7a0: 6420 7479 7065 2863 6869 6c64 2920 213d  d type(child) !=
+0000d7b0: 2074 6f72 6368 2e6e 6e2e 5365 7175 656e   torch.nn.Sequen
+0000d7c0: 7469 616c 205c 0a20 2020 2020 2020 2020  tial \.         
+0000d7d0: 2020 2020 2020 616e 6420 7479 7065 2863        and type(c
+0000d7e0: 6869 6c64 2920 213d 2074 6f72 6368 2e71  hild) != torch.q
+0000d7f0: 7561 6e74 697a 6174 696f 6e2e 7374 7562  uantization.stub
+0000d800: 732e 4465 5175 616e 7453 7475 623a 0a20  s.DeQuantStub:. 
+0000d810: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+0000d820: 6631 365f 6f70 732e 6170 7065 6e64 2828  f16_ops.append((
+0000d830: 6f70 5f6e 616d 652c 2075 6e69 6679 5f6f  op_name, unify_o
+0000d840: 705f 7479 7065 5f6d 6170 7069 6e67 5b73  p_type_mapping[s
+0000d850: 7472 2863 6869 6c64 2e5f 5f63 6c61 7373  tr(child.__class
+0000d860: 5f5f 2e5f 5f6e 616d 655f 5f29 5d0a 2020  __.__name__)].  
+0000d870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d880: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0000d890: 6620 7374 7228 6368 696c 642e 5f5f 636c  f str(child.__cl
+0000d8a0: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 2920  ass__.__name__) 
+0000d8b0: 696e 2075 6e69 6679 5f6f 705f 7479 7065  in unify_op_type
+0000d8c0: 5f6d 6170 7069 6e67 2065 6c73 650a 2020  _mapping else.  
+0000d8d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d8e0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0000d8f0: 7472 2863 6869 6c64 2e5f 5f63 6c61 7373  tr(child.__class
+0000d900: 5f5f 2e5f 5f6e 616d 655f 5f29 2929 0a20  __.__name__))). 
+0000d910: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+0000d920: 7365 6c66 2e69 735f 6675 7365 645f 6d6f  self.is_fused_mo
+0000d930: 6475 6c65 2863 6869 6c64 293a 0a20 2020  dule(child):.   
+0000d940: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
+0000d950: 7469 6e75 650a 2020 2020 2020 2020 2020  tinue.          
+0000d960: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0000d970: 2020 2020 2020 2020 7365 6c66 2e5f 6765          self._ge
+0000d980: 745f 6266 3136 5f6f 7073 5f72 6563 7572  t_bf16_ops_recur
+0000d990: 7369 7665 6c79 2863 6869 6c64 2c20 6f70  sively(child, op
+0000d9a0: 5f6e 616d 652c 2062 6631 365f 6f70 7329  _name, bf16_ops)
+0000d9b0: 0a0a 2020 2020 6465 6620 5f63 6f6d 6269  ..    def _combi
+0000d9c0: 6e65 5f63 6170 6162 696c 6974 7928 7365  ne_capability(se
+0000d9d0: 6c66 2c20 6266 3136 5f6f 7073 2c20 715f  lf, bf16_ops, q_
+0000d9e0: 6361 7061 6269 6c69 7479 293a 0a20 2020  capability):.   
+0000d9f0: 2020 2020 2062 6631 365f 636f 6e66 6967       bf16_config
+0000da00: 203d 207b 2761 6374 6976 6174 696f 6e27   = {'activation'
+0000da10: 3a20 7b27 6474 7970 6527 3a20 2762 6631  : {'dtype': 'bf1
+0000da20: 3627 7d2c 2027 7765 6967 6874 273a 207b  6'}, 'weight': {
+0000da30: 2764 7479 7065 273a 2027 6266 3136 277d  'dtype': 'bf16'}
+0000da40: 7d0a 2020 2020 2020 2020 6670 3332 5f63  }.        fp32_c
+0000da50: 6f6e 6669 6720 3d20 7b27 6163 7469 7661  onfig = {'activa
+0000da60: 7469 6f6e 273a 207b 2764 7479 7065 273a  tion': {'dtype':
+0000da70: 2027 6670 3332 277d 2c20 2777 6569 6768   'fp32'}, 'weigh
+0000da80: 7427 3a20 7b27 6474 7970 6527 3a20 2766  t': {'dtype': 'f
+0000da90: 7033 3227 7d7d 0a20 2020 2020 2020 2066  p32'}}.        f
+0000daa0: 6f72 2062 6631 365f 6f70 2069 6e20 6266  or bf16_op in bf
+0000dab0: 3136 5f6f 7073 3a0a 2020 2020 2020 2020  16_ops:.        
+0000dac0: 2020 2020 6966 2062 6631 365f 6f70 2069      if bf16_op i
+0000dad0: 6e20 715f 6361 7061 6269 6c69 7479 5b27  n q_capability['
+0000dae0: 6f70 7769 7365 275d 2061 6e64 205c 0a20  opwise'] and \. 
+0000daf0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+0000db00: 6631 365f 636f 6e66 6967 206e 6f74 2069  f16_config not i
+0000db10: 6e20 715f 6361 7061 6269 6c69 7479 5b27  n q_capability['
+0000db20: 6f70 7769 7365 275d 5b62 6631 365f 6f70  opwise'][bf16_op
+0000db30: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
+0000db40: 2020 2071 5f63 6170 6162 696c 6974 795b     q_capability[
+0000db50: 276f 7077 6973 6527 5d5b 6266 3136 5f6f  'opwise'][bf16_o
+0000db60: 705d 2e61 7070 656e 6428 6266 3136 5f63  p].append(bf16_c
+0000db70: 6f6e 6669 6729 0a20 2020 2020 2020 2020  onfig).         
+0000db80: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0000db90: 2020 2020 2020 2020 2071 5f63 6170 6162           q_capab
+0000dba0: 696c 6974 795b 276f 7077 6973 6527 5d5b  ility['opwise'][
+0000dbb0: 6266 3136 5f6f 705d 203d 205b 6266 3136  bf16_op] = [bf16
+0000dbc0: 5f63 6f6e 6669 672c 2066 7033 325f 636f  _config, fp32_co
+0000dbd0: 6e66 6967 5d0a 2020 2020 2020 2020 2020  nfig].          
+0000dbe0: 2020 2020 2020 6966 2062 6631 365f 6f70        if bf16_op
+0000dbf0: 5b31 5d20 6e6f 7420 696e 2071 5f63 6170  [1] not in q_cap
+0000dc00: 6162 696c 6974 795b 276f 7074 7970 6577  ability['optypew
+0000dc10: 6973 6527 5d3a 0a20 2020 2020 2020 2020  ise']:.         
+0000dc20: 2020 2020 2020 2020 2020 2071 5f63 6170             q_cap
+0000dc30: 6162 696c 6974 795b 276f 7074 7970 6577  ability['optypew
+0000dc40: 6973 6527 5d5b 6266 3136 5f6f 705b 315d  ise'][bf16_op[1]
+0000dc50: 5d20 3d20 5b62 6631 365f 636f 6e66 6967  ] = [bf16_config
+0000dc60: 2c20 6670 3332 5f63 6f6e 6669 675d 0a20  , fp32_config]. 
+0000dc70: 2020 2020 2020 2072 6574 7572 6e20 715f         return q_
+0000dc80: 6361 7061 6269 6c69 7479 0a0a 2020 2020  capability..    
+0000dc90: 6465 6620 6973 5f66 7573 6564 5f6d 6f64  def is_fused_mod
+0000dca0: 756c 6528 7365 6c66 2c20 6d6f 6475 6c65  ule(self, module
+0000dcb0: 293a 0a20 2020 2020 2020 2022 2222 5468  ):.        """Th
+0000dcc0: 6973 2069 7320 6120 6865 6c70 6572 2066  is is a helper f
+0000dcd0: 756e 6374 696f 6e20 666f 7220 605f 7072  unction for `_pr
+0000dce0: 6f70 6167 6174 655f 7163 6f6e 6669 675f  opagate_qconfig_
+0000dcf0: 6865 6c70 6572 6020 746f 2064 6574 6563  helper` to detec
+0000dd00: 7465 0a20 2020 2020 2020 2020 2020 6966  te.           if
+0000dd10: 2074 6869 7320 6d6f 6475 6c65 2069 7320   this module is 
+0000dd20: 6675 7365 642e 0a0a 2020 2020 2020 2020  fused...        
+0000dd30: 4172 6773 3a0a 2020 2020 2020 2020 2020  Args:.          
+0000dd40: 2020 6d6f 6475 6c65 2028 6f62 6a65 6374    module (object
+0000dd50: 293a 2069 6e70 7574 206d 6f64 756c 650a  ): input module.
+0000dd60: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
+0000dd70: 3a0a 2020 2020 2020 2020 2020 2020 2862  :.            (b
+0000dd80: 6f6f 6c29 3a20 6973 2066 7573 6564 206f  ool): is fused o
+0000dd90: 7220 6e6f 740a 2020 2020 2020 2020 2222  r not.        ""
+0000dda0: 220a 2020 2020 2020 2020 6f70 5f74 7970  ".        op_typ
+0000ddb0: 6520 3d20 7374 7228 7479 7065 286d 6f64  e = str(type(mod
+0000ddc0: 756c 6529 290a 2020 2020 2020 2020 6966  ule)).        if
+0000ddd0: 2027 6675 7365 6427 2069 6e20 6f70 5f74   'fused' in op_t
+0000dde0: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
+0000ddf0: 2072 6574 7572 6e20 5472 7565 0a20 2020   return True.   
+0000de00: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0000de10: 2020 2020 2020 2072 6574 7572 6e20 4661         return Fa
+0000de20: 6c73 650a 0a20 2020 2064 6566 2063 616c  lse..    def cal
+0000de30: 6375 6c61 7465 5f68 6573 7369 616e 5f74  culate_hessian_t
+0000de40: 7261 6365 2873 656c 662c 0a20 2020 2020  race(self,.     
+0000de50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000de60: 2020 2020 2020 2020 2020 2066 7033 325f             fp32_
+0000de70: 6d6f 6465 6c2c 0a20 2020 2020 2020 2020  model,.         
+0000de80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000de90: 2020 2020 2020 2064 6174 616c 6f61 6465         dataloade
+0000dea0: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
+0000deb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dec0: 2020 2071 5f6d 6f64 656c 2c0a 2020 2020     q_model,.    
+0000ded0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dee0: 2020 2020 2020 2020 2020 2020 6372 6974              crit
+0000def0: 6572 696f 6e2c 0a20 2020 2020 2020 2020  erion,.         
+0000df00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000df10: 2020 2020 2020 2065 6e61 626c 655f 6163         enable_ac
+0000df20: 743d 4661 6c73 650a 2020 2020 2020 2020  t=False.        
+0000df30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000df40: 2020 2020 2020 2020 293a 0a20 2020 2020          ):.     
+0000df50: 2020 2022 2222 4361 6c63 756c 6174 6520     """Calculate 
+0000df60: 6865 7373 6961 6e20 7472 6163 652e 0a0a  hessian trace...
+0000df70: 2020 2020 2020 2020 4172 6773 3a0a 2020          Args:.  
+0000df80: 2020 2020 2020 2020 2020 6670 3332 5f6d            fp32_m
+0000df90: 6f64 656c 3a20 5468 6520 6f72 6967 696e  odel: The origin
+0000dfa0: 616c 2066 7033 3220 6d6f 6465 6c2e 0a20  al fp32 model.. 
+0000dfb0: 2020 2020 2020 2020 2020 2063 7269 7465             crite
+0000dfc0: 7269 6f6e 3a20 5468 6520 6c6f 7373 2066  rion: The loss f
+0000dfd0: 756e 6374 696f 6e20 666f 7220 6361 6c63  unction for calc
+0000dfe0: 756c 6174 6520 7468 6520 6865 7373 6961  ulate the hessia
+0000dff0: 6e20 7472 6163 652e 2023 206c 6f73 7320  n trace. # loss 
+0000e000: 3d20 6372 6974 6572 696f 6e28 6f75 7470  = criterion(outp
+0000e010: 7574 2c20 7461 7267 6574 290a 2020 2020  ut, target).    
+0000e020: 2020 2020 2020 2020 6461 7461 6c6f 6164          dataload
+0000e030: 6572 3a20 5468 6520 6461 7461 6c6f 6164  er: The dataload
+0000e040: 6572 2066 6f72 2063 616c 6375 6c61 7465  er for calculate
+0000e050: 2074 6865 2067 7261 6469 656e 742e 0a20   the gradient.. 
+0000e060: 2020 2020 2020 2020 2020 2071 5f6d 6f64             q_mod
+0000e070: 656c 3a20 5468 6520 494e 5438 2041 4d41  el: The INT8 AMA
+0000e080: 5020 6d6f 6465 6c2e 0a20 2020 2020 2020  P model..       
+0000e090: 2020 2020 2065 6e61 626c 655f 6163 743a       enable_act:
+0000e0a0: 2045 6e61 626c 696e 6720 7175 616e 7469   Enabling quanti
+0000e0b0: 7a61 7469 6f6e 2065 7272 6f72 206f 7220  zation error or 
+0000e0c0: 6e6f 742e 0a0a 2020 2020 2020 2020 5265  not...        Re
+0000e0d0: 7475 726e 3a0a 2020 2020 2020 2020 2020  turn:.          
+0000e0e0: 2020 6865 7373 6961 6e5f 7472 6163 6528    hessian_trace(
+0000e0f0: 4469 6374 5b54 7570 6c65 2c20 666c 6f61  Dict[Tuple, floa
+0000e100: 745d 292c 206b 6579 3a20 286f 705f 6e61  t]), key: (op_na
+0000e110: 6d65 2c20 6f70 5f74 7970 6529 3b20 7661  me, op_type); va
+0000e120: 6c75 653a 2068 6573 7369 616e 2074 7261  lue: hessian tra
+0000e130: 6365 2e0a 2020 2020 2020 2020 2222 220a  ce..        """.
+0000e140: 2020 2020 2020 2020 6672 6f6d 202e 746f          from .to
+0000e150: 7263 685f 7574 696c 732e 6861 7771 5f6d  rch_utils.hawq_m
+0000e160: 6574 7269 6320 696d 706f 7274 2068 6177  etric import haw
+0000e170: 715f 746f 700a 2020 2020 2020 2020 6f70  q_top.        op
+0000e180: 5f74 6f5f 7472 6163 6573 203d 2068 6177  _to_traces = haw
+0000e190: 715f 746f 7028 6670 3332 5f6d 6f64 656c  q_top(fp32_model
+0000e1a0: 3d66 7033 325f 6d6f 6465 6c2c 0a20 2020  =fp32_model,.   
+0000e1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e1c0: 2020 2020 2020 2020 2020 2020 2064 6174               dat
+0000e1d0: 616c 6f61 6465 723d 6461 7461 6c6f 6164  aloader=dataload
+0000e1e0: 6572 2c0a 2020 2020 2020 2020 2020 2020  er,.            
+0000e1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e200: 2020 2020 715f 6d6f 6465 6c3d 715f 6d6f      q_model=q_mo
+0000e210: 6465 6c2c 0a20 2020 2020 2020 2020 2020  del,.           
+0000e220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e230: 2020 2020 2063 7269 7465 7269 6f6e 3d63       criterion=c
+0000e240: 7269 7465 7269 6f6e 2c0a 2020 2020 2020  riterion,.      
+0000e250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e260: 2020 2020 2020 2020 2020 656e 6162 6c65            enable
+0000e270: 5f61 6374 3d65 6e61 626c 655f 6163 7429  _act=enable_act)
+0000e280: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000e290: 6f70 5f74 6f5f 7472 6163 6573 0a0a 2020  op_to_traces..  
+0000e2a0: 2020 6465 6620 736d 6f6f 7468 5f71 7561    def smooth_qua
+0000e2b0: 6e74 2873 656c 662c 206d 6f64 656c 2c20  nt(self, model, 
+0000e2c0: 6461 7461 6c6f 6164 6572 2c20 6361 6c69  dataloader, cali
+0000e2d0: 625f 6974 6572 2c20 7475 6e65 5f63 6667  b_iter, tune_cfg
+0000e2e0: 3d4e 6f6e 652c 2061 6c70 6861 3d30 2e35  =None, alpha=0.5
+0000e2f0: 2c20 666f 6c64 696e 673d 4661 6c73 652c  , folding=False,
+0000e300: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e310: 2020 2020 2020 7065 7263 656e 7469 6c65        percentile
+0000e320: 3d4e 6f6e 652c 206f 705f 7479 7065 733d  =None, op_types=
+0000e330: 4e6f 6e65 2c20 7363 616c 6573 5f70 6572  None, scales_per
+0000e340: 5f6f 703d 4e6f 6e65 2c20 666f 7263 655f  _op=None, force_
+0000e350: 7265 5f73 6d6f 6f74 683d 4661 6c73 6529  re_smooth=False)
+0000e360: 3a0a 2020 2020 2020 2020 2222 2220 636f  :.        """ co
+0000e370: 6e76 6572 7420 7468 6520 6d6f 6465 6c20  nvert the model 
+0000e380: 6279 2073 6d6f 6f74 6820 7175 616e 742e  by smooth quant.
+0000e390: 0a0a 2020 2020 2020 2020 4172 6773 3a0a  ..        Args:.
+0000e3a0: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
+0000e3b0: 6c3a 206f 7269 6769 6e20 4650 3332 206d  l: origin FP32 m
+0000e3c0: 6f64 656c 0a20 2020 2020 2020 2020 2020  odel.           
+0000e3d0: 2064 6174 616c 6f61 6465 723a 2063 616c   dataloader: cal
+0000e3e0: 6962 2064 6174 616c 6f61 6465 720a 2020  ib dataloader.  
+0000e3f0: 2020 2020 2020 2020 2020 6361 6c69 625f            calib_
+0000e400: 6974 6572 3a20 6361 6c69 6220 6974 6572  iter: calib iter
+0000e410: 730a 2020 2020 2020 2020 2020 2020 7475  s.            tu
+0000e420: 6e65 5f63 6667 3a20 7175 616e 7469 7a61  ne_cfg: quantiza
+0000e430: 7469 6f6e 2063 6f6e 6669 670a 2020 2020  tion config.    
+0000e440: 2020 2020 2020 2020 616c 7068 613a 2073          alpha: s
+0000e450: 6d6f 6f74 6820 616c 7068 6120 696e 2053  mooth alpha in S
+0000e460: 6d6f 6f74 6851 7561 6e74 2c20 312e 3020  moothQuant, 1.0 
+0000e470: 7769 6c6c 2066 616c 6c62 6163 6b20 746f  will fallback to
+0000e480: 2053 5049 510a 2020 2020 2020 2020 2020   SPIQ.          
+0000e490: 2020 666f 6c64 696e 673a 2077 6865 7468    folding: wheth
+0000e4a0: 6572 2069 6e73 6572 7420 6d75 6c28 4661  er insert mul(Fa
+0000e4b0: 6c73 6529 206f 7220 6a75 7374 2061 6c6c  lse) or just all
+0000e4c0: 6f77 2066 6f6c 6461 626c 6520 6c61 7965  ow foldable laye
+0000e4d0: 7273 2854 7275 6529 2066 6f72 2053 6d6f  rs(True) for Smo
+0000e4e0: 6f74 6851 7561 6e74 0a20 2020 2020 2020  othQuant.       
+0000e4f0: 2020 2020 2070 6572 6365 6e74 696c 653a       percentile:
+0000e500: 5065 7263 656e 7469 6c65 206f 6620 6361  Percentile of ca
+0000e510: 6c69 6272 6174 696f 6e20 746f 2072 656d  libration to rem
+0000e520: 6f76 6520 6f75 746c 6965 7273 2c20 6e6f  ove outliers, no
+0000e530: 7420 7375 7070 6f72 7465 6420 6e6f 770a  t supported now.
+0000e540: 2020 2020 2020 2020 2020 2020 6f70 5f74              op_t
+0000e550: 7970 6573 3a20 5468 6520 6f70 2074 7970  ypes: The op typ
+0000e560: 6573 2077 686f 7365 2069 6e70 7574 2074  es whose input t
+0000e570: 656e 736f 7220 7769 6c6c 2062 6520 6475  ensor will be du
+0000e580: 6d70 6564 0a20 2020 2020 2020 2020 2020  mped.           
+0000e590: 2073 6361 6c65 735f 7065 725f 6f70 3a20   scales_per_op: 
+0000e5a0: 5472 7565 2c20 6561 6368 206f 7020 7769  True, each op wi
+0000e5b0: 6c6c 2068 6176 6520 616e 2069 6e64 6976  ll have an indiv
+0000e5c0: 6964 7561 6c20 7363 616c 652c 206d 6169  idual scale, mai
+0000e5d0: 6e6c 7920 666f 7220 6163 6375 7261 6379  nly for accuracy
+0000e5e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e5f0: 2020 2020 2020 2020 2020 2020 4661 6c73              Fals
+0000e600: 652c 206f 7073 2077 6974 6820 7468 6520  e, ops with the 
+0000e610: 7361 6d65 2069 6e70 7574 2077 696c 6c20  same input will 
+0000e620: 7368 6172 6520 6120 7363 616c 652c 206d  share a scale, m
+0000e630: 6169 6e6c 7920 666f 7220 7065 7266 6f72  ainly for perfor
+0000e640: 6d61 6e63 650a 0a20 2020 2020 2020 2052  mance..        R
+0000e650: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
+0000e660: 2020 2020 6d6f 6465 6c3a 2041 206d 6f64      model: A mod
+0000e670: 6966 6965 6420 6670 3332 206d 6f64 656c  ified fp32 model
+0000e680: 2c20 696e 706c 6163 653d 5472 7565 2e0a  , inplace=True..
+0000e690: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+0000e6a0: 2020 2020 2320 4e6f 7465 3a20 7765 2073      # Note: we s
+0000e6b0: 686f 756c 6420 6d61 6b65 2073 7572 6520  hould make sure 
+0000e6c0: 736d 6f6f 7468 7175 616e 7420 6973 206f  smoothquant is o
+0000e6d0: 6e6c 7920 6578 6563 7574 6564 206f 6e63  nly executed onc
+0000e6e0: 6520 7769 7468 2069 6e70 6c61 6369 6e67  e with inplacing
+0000e6f0: 2066 7033 3220 6d6f 6465 6c2e 0a20 2020   fp32 model..   
+0000e700: 2020 2020 2069 6620 6861 7361 7474 7228       if hasattr(
+0000e710: 6d6f 6465 6c2e 5f6d 6f64 656c 2c20 275f  model._model, '_
+0000e720: 736d 6f6f 7468 7175 616e 745f 6f70 7469  smoothquant_opti
+0000e730: 6d69 7a65 6427 2920 616e 6420 6d6f 6465  mized') and mode
+0000e740: 6c2e 5f6d 6f64 656c 2e5f 736d 6f6f 7468  l._model._smooth
+0000e750: 7175 616e 745f 6f70 7469 6d69 7a65 643a  quant_optimized:
+0000e760: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
+0000e770: 6765 722e 696e 666f 2822 5468 6520 6d6f  ger.info("The mo
+0000e780: 6465 6c20 6973 2061 6c72 6561 6479 206f  del is already o
+0000e790: 7074 696d 697a 6564 2062 7920 536d 6f6f  ptimized by Smoo
+0000e7a0: 7468 5175 616e 7420 616c 676f 7269 7468  thQuant algorith
+0000e7b0: 6d2c 2073 6b69 7020 6974 2e22 290a 2020  m, skip it.").  
+0000e7c0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+0000e7d0: 206d 6f64 656c 0a20 2020 2020 2020 2069   model.        i
+0000e7e0: 6620 7365 6c66 2e5f 5f63 6c61 7373 5f5f  f self.__class__
+0000e7f0: 2e5f 5f6e 616d 655f 5f20 3d3d 2027 5079  .__name__ == 'Py
+0000e800: 546f 7263 685f 4950 4558 4164 6170 746f  Torch_IPEXAdapto
+0000e810: 7227 2061 6e64 2066 6f6c 6469 6e67 2069  r' and folding i
+0000e820: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+0000e830: 2020 2020 6966 2073 656c 662e 7665 7273      if self.vers
+0000e840: 696f 6e2e 7265 6c65 6173 6520 3c20 5665  ion.release < Ve
+0000e850: 7273 696f 6e28 2232 2e31 2229 2e72 656c  rsion("2.1").rel
+0000e860: 6561 7365 3a0a 2020 2020 2020 2020 2020  ease:.          
+0000e870: 2020 2020 2020 666f 6c64 696e 6720 3d20        folding = 
+0000e880: 5472 7565 0a20 2020 2020 2020 2020 2020  True.           
+0000e890: 2020 2020 206c 6f67 6765 722e 696e 666f       logger.info
+0000e8a0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0000e8b0: 2020 2020 2020 2249 5045 5820 7665 7273        "IPEX vers
+0000e8c0: 696f 6e20 3e3d 2032 2e31 2069 7320 7265  ion >= 2.1 is re
+0000e8d0: 7175 6972 6564 2066 6f72 2053 6d6f 6f74  quired for Smoot
+0000e8e0: 6851 7561 6e74 2066 6f6c 6469 6e67 3d46  hQuant folding=F
+0000e8f0: 616c 7365 2c20 7265 7365 7420 666f 6c64  alse, reset fold
+0000e900: 696e 673d 5472 7565 2e22 290a 0a20 2020  ing=True.")..   
+0000e910: 2020 2020 2069 6620 6e6f 7420 6861 7361       if not hasa
+0000e920: 7474 7228 7365 6c66 2c20 2773 7127 2920  ttr(self, 'sq') 
+0000e930: 6f72 2066 6f72 6365 5f72 655f 736d 6f6f  or force_re_smoo
+0000e940: 7468 3a0a 2020 2020 2020 2020 2020 2020  th:.            
+0000e950: 7365 6c66 2e73 7120 3d20 546f 7263 6853  self.sq = TorchS
+0000e960: 6d6f 6f74 6851 7561 6e74 286d 6f64 656c  moothQuant(model
+0000e970: 2e5f 6d6f 6465 6c2c 2064 6174 616c 6f61  ._model, dataloa
+0000e980: 6465 723d 6461 7461 6c6f 6164 6572 290a  der=dataloader).
+0000e990: 2020 2020 2020 2020 6b77 6172 6773 203d          kwargs =
+0000e9a0: 207b 7d20 2023 2364 6966 6665 7265 6e74   {}  ##different
+0000e9b0: 2062 6163 6b65 6e64 7320 6d61 7920 6861   backends may ha
+0000e9c0: 7665 2064 6966 6665 7265 6e74 2064 6566  ve different def
+0000e9d0: 6175 6c74 2076 616c 7565 730a 2020 2020  ault values.    
+0000e9e0: 2020 2020 6966 206f 705f 7479 7065 7320      if op_types 
+0000e9f0: 213d 204e 6f6e 653a 0a20 2020 2020 2020  != None:.       
+0000ea00: 2020 2020 206b 7761 7267 735b 226f 705f       kwargs["op_
+0000ea10: 7479 7065 7322 5d20 3d20 6f70 5f74 7970  types"] = op_typ
+0000ea20: 6573 0a20 2020 2020 2020 2069 6620 7065  es.        if pe
+0000ea30: 7263 656e 7469 6c65 2021 3d20 4e6f 6e65  rcentile != None
+0000ea40: 3a0a 2020 2020 2020 2020 2020 2020 6b77  :.            kw
+0000ea50: 6172 6773 5b27 7065 7263 656e 7469 6c65  args['percentile
+0000ea60: 275d 203d 2070 6572 6365 6e74 696c 650a  '] = percentile.
+0000ea70: 2020 2020 2020 2020 6966 2073 6361 6c65          if scale
+0000ea80: 735f 7065 725f 6f70 2021 3d20 4e6f 6e65  s_per_op != None
+0000ea90: 3a0a 2020 2020 2020 2020 2020 2020 6b77  :.            kw
+0000eaa0: 6172 6773 5b27 7363 616c 6573 5f70 6572  args['scales_per
+0000eab0: 5f6f 7027 5d20 3d20 7363 616c 6573 5f70  _op'] = scales_p
+0000eac0: 6572 5f6f 700a 2020 2020 2020 2020 6d6f  er_op.        mo
+0000ead0: 6465 6c2e 5f6d 6f64 656c 203d 2073 656c  del._model = sel
+0000eae0: 662e 7371 2e74 7261 6e73 666f 726d 280a  f.sq.transform(.
+0000eaf0: 2020 2020 2020 2020 2020 2020 616c 7068              alph
+0000eb00: 613d 616c 7068 612c 0a20 2020 2020 2020  a=alpha,.       
+0000eb10: 2020 2020 2066 6f6c 6469 6e67 3d66 6f6c       folding=fol
+0000eb20: 6469 6e67 2c0a 2020 2020 2020 2020 2020  ding,.          
+0000eb30: 2020 6361 6c69 625f 6974 6572 3d63 616c    calib_iter=cal
+0000eb40: 6962 5f69 7465 722c 0a20 2020 2020 2020  ib_iter,.       
+0000eb50: 2020 2020 202a 2a6b 7761 7267 730a 2020       **kwargs.  
+0000eb60: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0000eb70: 6d6f 6465 6c2e 5f6d 6f64 656c 2e5f 736d  model._model._sm
+0000eb80: 6f6f 7468 7175 616e 745f 6f70 7469 6d69  oothquant_optimi
+0000eb90: 7a65 6420 3d20 5472 7565 0a20 2020 2020  zed = True.     
+0000eba0: 2020 2072 6574 7572 6e20 6d6f 6465 6c0a     return model.
+0000ebb0: 0a20 2020 2064 6566 2071 6471 5f71 7561  .    def qdq_qua
+0000ebc0: 6e74 697a 6528 7365 6c66 2c20 6d6f 6465  ntize(self, mode
+0000ebd0: 6c2c 2074 756e 655f 6366 6729 3a0a 2020  l, tune_cfg):.  
+0000ebe0: 2020 2020 2020 2222 2269 6e73 6572 7420        """insert 
+0000ebf0: 7175 616e 742c 2064 6571 7561 6e74 2070  quant, dequant p
+0000ec00: 6169 7273 2062 6566 6f72 6520 6c69 6e65  airs before line
+0000ec10: 6172 2074 6f20 7369 6d75 6c61 7465 2071  ar to simulate q
+0000ec20: 7561 6e74 697a 6174 696f 6e2e 0a0a 2020  uantization...  
+0000ec30: 2020 2020 2020 4172 6773 3a0a 2020 2020        Args:.    
+0000ec40: 2020 2020 2020 2020 6d6f 6465 6c20 2874          model (t
+0000ec50: 6f72 6368 2e6e 6e2e 4d6f 6475 6c65 293a  orch.nn.Module):
+0000ec60: 2073 6d6f 6f74 6871 7561 6e74 206f 7074   smoothquant opt
+0000ec70: 696d 697a 6564 206d 6f64 656c 2e0a 2020  imized model..  
+0000ec80: 2020 2020 2020 2020 2020 7475 6e65 5f63            tune_c
+0000ec90: 6667 2028 6469 6374 293a 2071 7561 6e74  fg (dict): quant
+0000eca0: 697a 6174 696f 6e20 636f 6e66 6967 2e0a  ization config..
+0000ecb0: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
+0000ecc0: 3a0a 2020 2020 2020 2020 2020 2020 6d6f  :.            mo
+0000ecd0: 6465 6c3a 2071 6471 2071 7561 6e74 697a  del: qdq quantiz
+0000ece0: 6564 206d 6f64 656c 2e0a 2020 2020 2020  ed model..      
+0000ecf0: 2020 2222 220a 2020 2020 2020 2020 715f    """.        q_
+0000ed00: 6d6f 6465 6c20 3d20 6d6f 6465 6c2e 5f6d  model = model._m
+0000ed10: 6f64 656c 0a20 2020 2020 2020 2066 726f  odel.        fro
+0000ed20: 6d20 2e74 6f72 6368 5f75 7469 6c73 2e73  m .torch_utils.s
+0000ed30: 6d6f 6f74 685f 7175 616e 7420 696d 706f  mooth_quant impo
+0000ed40: 7274 2073 6574 5f6d 6f64 756c 650a 2020  rt set_module.  
+0000ed50: 2020 2020 2020 6672 6f6d 202e 746f 7263        from .torc
+0000ed60: 685f 7574 696c 732e 6d6f 6465 6c5f 7772  h_utils.model_wr
+0000ed70: 6170 7065 7220 696d 706f 7274 2051 4451  apper import QDQ
+0000ed80: 4c69 6e65 6172 2c20 5351 4c69 6e65 6172  Linear, SQLinear
+0000ed90: 5772 6170 7065 720a 2020 2020 2020 2020  Wrapper.        
+0000eda0: 736d 6f6f 7468 7175 616e 745f 7363 616c  smoothquant_scal
+0000edb0: 655f 696e 666f 203d 207b 7d0a 2020 2020  e_info = {}.    
+0000edc0: 2020 2020 6661 6c6c 6261 636b 5f6f 705f      fallback_op_
+0000edd0: 6e61 6d65 5f6c 6973 7420 3d20 5b5d 0a20  name_list = []. 
+0000ede0: 2020 2020 2020 2073 7461 7473 5f72 6573         stats_res
+0000edf0: 756c 7420 3d20 7b7d 0a20 2020 2020 2020  ult = {}.       
+0000ee00: 2066 6f72 2028 6f70 5f6e 616d 652c 206f   for (op_name, o
+0000ee10: 705f 7479 7065 292c 2071 636f 6e66 6967  p_type), qconfig
+0000ee20: 2069 6e20 7475 6e65 5f63 6667 5b27 6f70   in tune_cfg['op
+0000ee30: 275d 2e69 7465 6d73 2829 3a0a 2020 2020  '].items():.    
+0000ee40: 2020 2020 2020 2020 6966 206f 705f 7479          if op_ty
+0000ee50: 7065 203d 3d20 274c 696e 6561 7227 2061  pe == 'Linear' a
+0000ee60: 6e64 2071 636f 6e66 6967 5b27 7765 6967  nd qconfig['weig
+0000ee70: 6874 275d 5b27 6474 7970 6527 5d20 213d  ht']['dtype'] !=
+0000ee80: 2027 696e 7438 273a 0a20 2020 2020 2020   'int8':.       
+0000ee90: 2020 2020 2020 2020 2023 2072 7374 7269           # rstri
+0000eea0: 7020 6973 2066 6f72 2061 7574 6f20 7374  p is for auto st
+0000eeb0: 7261 7465 6779 2c20 7468 6520 6d6f 6465  rategy, the mode
+0000eec0: 6c20 7061 7373 6564 2074 6f20 7468 6520  l passed to the 
+0000eed0: 7365 636f 6e64 2073 7472 6174 6567 7920  second strategy 
+0000eee0: 6973 2061 6c72 6561 6479 206f 7074 696d  is already optim
+0000eef0: 697a 6564 2e0a 2020 2020 2020 2020 2020  ized..          
+0000ef00: 2020 2020 2020 6f70 5f6e 616d 6520 3d20        op_name = 
+0000ef10: 6f70 5f6e 616d 652e 7273 7472 6970 2827  op_name.rstrip('
+0000ef20: 2e73 715f 6c69 6e65 6172 2729 200a 2020  .sq_linear') .  
+0000ef30: 2020 2020 2020 2020 2020 2020 2020 6661                fa
+0000ef40: 6c6c 6261 636b 5f6f 705f 6e61 6d65 5f6c  llback_op_name_l
+0000ef50: 6973 742e 6170 7065 6e64 286f 705f 6e61  ist.append(op_na
+0000ef60: 6d65 290a 0a20 2020 2020 2020 2073 7461  me)..        sta
+0000ef70: 7473 5f72 6573 756c 745b 2753 514c 696e  ts_result['SQLin
+0000ef80: 6561 7257 7261 7070 6572 275d 203d 207b  earWrapper'] = {
+0000ef90: 2749 4e54 3828 5144 5129 273a 2030 2c20  'INT8(QDQ)': 0, 
+0000efa0: 2742 4631 3627 3a20 302c 2027 4650 3332  'BF16': 0, 'FP32
+0000efb0: 273a 2030 7d0a 2020 2020 2020 2020 666f  ': 0}.        fo
+0000efc0: 7220 6e61 6d65 2c20 6d6f 6475 6c65 2069  r name, module i
+0000efd0: 6e20 715f 6d6f 6465 6c2e 6e61 6d65 645f  n q_model.named_
+0000efe0: 6d6f 6475 6c65 7328 293a 0a20 2020 2020  modules():.     
+0000eff0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+0000f000: 616e 6365 286d 6f64 756c 652c 2053 514c  ance(module, SQL
+0000f010: 696e 6561 7257 7261 7070 6572 293a 0a20  inearWrapper):. 
+0000f020: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0000f030: 6620 6e61 6d65 206e 6f74 2069 6e20 6661  f name not in fa
+0000f040: 6c6c 6261 636b 5f6f 705f 6e61 6d65 5f6c  llback_op_name_l
+0000f050: 6973 743a 0a20 2020 2020 2020 2020 2020  ist:.           
+0000f060: 2020 2020 2020 2020 2073 6d6f 6f74 6871           smoothq
+0000f070: 7561 6e74 5f73 6361 6c65 5f69 6e66 6f5b  uant_scale_info[
+0000f080: 6e61 6d65 5d20 3d20 7b0a 2020 2020 2020  name] = {.      
+0000f090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f0a0: 2020 2769 6e70 7574 5f73 6361 6c65 5f66    'input_scale_f
+0000f0b0: 6f72 5f6d 756c 273a 206d 6f64 756c 652e  or_mul': module.
+0000f0c0: 696e 7075 745f 7363 616c 652c 0a20 2020  input_scale,.   
+0000f0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f0e0: 2020 2020 2027 7175 616e 745f 7363 616c       'quant_scal
+0000f0f0: 6527 3a20 6d6f 6475 6c65 2e73 6361 6c65  e': module.scale
+0000f100: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000f110: 2020 2020 2020 2020 2020 2771 7561 6e74            'quant
+0000f120: 5f7a 6572 6f5f 706f 696e 7427 3a20 6d6f  _zero_point': mo
+0000f130: 6475 6c65 2e7a 6572 6f5f 706f 696e 742c  dule.zero_point,
+0000f140: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f150: 2020 2020 2020 2020 2027 7175 616e 745f           'quant_
+0000f160: 6474 7970 6527 3a20 6d6f 6475 6c65 2e64  dtype': module.d
+0000f170: 7479 7065 2c0a 2020 2020 2020 2020 2020  type,.          
+0000f180: 2020 2020 2020 2020 2020 2020 2020 7d0a                }.
+0000f190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f1a0: 2020 2020 6e65 775f 6d6f 6475 6c65 203d      new_module =
+0000f1b0: 2051 4451 4c69 6e65 6172 286d 6f64 756c   QDQLinear(modul
+0000f1c0: 652e 7371 5f6c 696e 6561 722c 206d 6f64  e.sq_linear, mod
+0000f1d0: 756c 652e 7363 616c 652c 206d 6f64 756c  ule.scale, modul
+0000f1e0: 652e 7a65 726f 5f70 6f69 6e74 2c20 6d6f  e.zero_point, mo
+0000f1f0: 6475 6c65 2e64 7479 7065 290a 2020 2020  dule.dtype).    
+0000f200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f210: 7365 745f 6d6f 6475 6c65 2871 5f6d 6f64  set_module(q_mod
+0000f220: 656c 2c20 6e61 6d65 2b27 2e73 715f 6c69  el, name+'.sq_li
+0000f230: 6e65 6172 272c 206e 6577 5f6d 6f64 756c  near', new_modul
+0000f240: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+0000f250: 2020 2020 2020 2073 7461 7473 5f72 6573         stats_res
+0000f260: 756c 745b 2753 514c 696e 6561 7257 7261  ult['SQLinearWra
+0000f270: 7070 6572 275d 5b27 494e 5438 2851 4451  pper']['INT8(QDQ
+0000f280: 2927 5d20 2b3d 2031 0a20 2020 2020 2020  )'] += 1.       
+0000f290: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+0000f2a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f2b0: 2020 2073 7461 7473 5f72 6573 756c 745b     stats_result[
+0000f2c0: 2753 514c 696e 6561 7257 7261 7070 6572  'SQLinearWrapper
+0000f2d0: 275d 5b27 4650 3332 275d 202b 3d20 310a  ']['FP32'] += 1.
+0000f2e0: 0a20 2020 2020 2020 2074 756e 655f 6366  .        tune_cf
+0000f2f0: 675b 2772 6563 6970 655f 6366 6773 275d  g['recipe_cfgs']
+0000f300: 5b27 736d 6f6f 7468 7175 616e 745f 7363  ['smoothquant_sc
+0000f310: 616c 655f 696e 666f 275d 203d 2073 6d6f  ale_info'] = smo
+0000f320: 6f74 6871 7561 6e74 5f73 6361 6c65 5f69  othquant_scale_i
+0000f330: 6e66 6f0a 2020 2020 2020 2020 6d6f 6465  nfo.        mode
+0000f340: 6c2e 5f6d 6f64 656c 203d 2071 5f6d 6f64  l._model = q_mod
+0000f350: 656c 0a20 2020 2020 2020 206d 6f64 656c  el.        model
+0000f360: 2e71 5f63 6f6e 6669 6720 3d20 636f 7079  .q_config = copy
+0000f370: 2e64 6565 7063 6f70 7928 7475 6e65 5f63  .deepcopy(tune_c
+0000f380: 6667 290a 2020 2020 2020 2020 6669 656c  fg).        fiel
+0000f390: 645f 6e61 6d65 733d 5b22 4f70 2054 7970  d_names=["Op Typ
+0000f3a0: 6522 2c20 2254 6f74 616c 222c 2022 494e  e", "Total", "IN
+0000f3b0: 5438 222c 2022 4246 3136 222c 2022 4650  T8", "BF16", "FP
+0000f3c0: 3332 225d 0a20 2020 2020 2020 206f 7574  32"].        out
+0000f3d0: 7075 745f 6461 7461 203d 205b 5b0a 2020  put_data = [[.  
+0000f3e0: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+0000f3f0: 5f74 7970 652c 2073 756d 2873 7461 7473  _type, sum(stats
+0000f400: 5f72 6573 756c 745b 6f70 5f74 7970 655d  _result[op_type]
+0000f410: 2e76 616c 7565 7328 2929 2c20 7374 6174  .values()), stat
+0000f420: 735f 7265 7375 6c74 5b6f 705f 7479 7065  s_result[op_type
+0000f430: 5d5b 2749 4e54 3828 5144 5129 275d 2c20  ]['INT8(QDQ)'], 
+0000f440: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f450: 2073 7461 7473 5f72 6573 756c 745b 6f70   stats_result[op
+0000f460: 5f74 7970 655d 5b27 4246 3136 275d 2c20  _type]['BF16'], 
+0000f470: 7374 6174 735f 7265 7375 6c74 5b6f 705f  stats_result[op_
+0000f480: 7479 7065 5d5b 2746 5033 3227 5d5d 0a20  type]['FP32']]. 
+0000f490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f4a0: 2020 2066 6f72 206f 705f 7479 7065 2069     for op_type i
+0000f4b0: 6e20 7374 6174 735f 7265 7375 6c74 2e6b  n stats_result.k
+0000f4c0: 6579 7328 295d 0a20 2020 2020 2020 2053  eys()].        S
+0000f4d0: 7461 7469 7374 6963 7328 6f75 7470 7574  tatistics(output
+0000f4e0: 5f64 6174 612c 0a20 2020 2020 2020 2020  _data,.         
+0000f4f0: 2020 2020 2020 2020 2020 6865 6164 6572            header
+0000f500: 3d27 4d69 7865 6420 5072 6563 6973 696f  ='Mixed Precisio
+0000f510: 6e20 5374 6174 6973 7469 6373 272c 0a20  n Statistics',. 
+0000f520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f530: 2020 6669 656c 645f 6e61 6d65 733d 6669    field_names=fi
+0000f540: 656c 645f 6e61 6d65 7329 2e70 7269 6e74  eld_names).print
+0000f550: 5f73 7461 7428 290a 0a20 2020 2020 2020  _stat()..       
+0000f560: 2072 6574 7572 6e20 6d6f 6465 6c0a 0a20   return model.. 
+0000f570: 2020 2064 6566 205f 7772 6170 7065 725f     def _wrapper_
+0000f580: 7371 5f6c 696e 6561 7228 7365 6c66 2c20  sq_linear(self, 
+0000f590: 746d 705f 6d6f 6465 6c29 3a0a 2020 2020  tmp_model):.    
+0000f5a0: 2020 2020 2222 2248 656c 7020 6675 6e63      """Help func
+0000f5b0: 7469 6f6e 2066 6f72 205f 6765 745f 7175  tion for _get_qu
+0000f5c0: 616e 7469 7a61 626c 655f 6f70 735f 7265  antizable_ops_re
+0000f5d0: 6375 7273 6976 656c 7920 746f 2061 6c69  cursively to ali
+0000f5e0: 676e 2073 6d6f 6f74 6871 7561 6e74 2070  gn smoothquant p
+0000f5f0: 726f 6365 7373 6564 206d 6f64 656c 2222  rocessed model""
+0000f600: 220a 2020 2020 2020 2020 636c 6173 7320  ".        class 
+0000f610: 5351 4c69 6e65 6172 5772 6170 7065 7228  SQLinearWrapper(
+0000f620: 746f 7263 682e 6e6e 2e4d 6f64 756c 6529  torch.nn.Module)
+0000f630: 3a0a 2020 2020 2020 2020 2020 2020 6465  :.            de
+0000f640: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
+0000f650: 206d 6f64 756c 6529 3a0a 2020 2020 2020   module):.      
+0000f660: 2020 2020 2020 2020 2020 7375 7065 7228            super(
+0000f670: 292e 5f5f 696e 6974 5f5f 2829 0a20 2020  ).__init__().   
+0000f680: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+0000f690: 662e 6164 645f 6d6f 6475 6c65 2827 7371  f.add_module('sq
+0000f6a0: 5f6c 696e 6561 7227 2c20 6d6f 6475 6c65  _linear', module
+0000f6b0: 290a 0a20 2020 2020 2020 2020 2020 2064  )..            d
+0000f6c0: 6566 2066 6f72 7761 7264 2873 656c 662c  ef forward(self,
+0000f6d0: 2058 293a 0a20 2020 2020 2020 2020 2020   X):.           
+0000f6e0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+0000f6f0: 2e73 715f 6c69 6e65 6172 2858 290a 0a20  .sq_linear(X).. 
+0000f700: 2020 2020 2020 206d 6f64 756c 655f 6e61         module_na
+0000f710: 6d65 5f6c 6973 7420 3d20 5b5d 0a20 2020  me_list = [].   
+0000f720: 2020 2020 2066 726f 6d20 2e74 6f72 6368       from .torch
+0000f730: 5f75 7469 6c73 2e73 6d6f 6f74 685f 7175  _utils.smooth_qu
+0000f740: 616e 7420 696d 706f 7274 2067 6574 5f6d  ant import get_m
+0000f750: 6f64 756c 652c 2073 6574 5f6d 6f64 756c  odule, set_modul
+0000f760: 650a 2020 2020 2020 2020 666f 7220 6e61  e.        for na
+0000f770: 6d65 2c20 6d6f 6475 6c65 2069 6e20 746d  me, module in tm
+0000f780: 705f 6d6f 6465 6c2e 6e61 6d65 645f 6d6f  p_model.named_mo
+0000f790: 6475 6c65 7328 293a 0a20 2020 2020 2020  dules():.       
+0000f7a0: 2020 2020 2069 6620 274c 696e 6561 7227       if 'Linear'
+0000f7b0: 203d 3d20 7374 7228 6d6f 6475 6c65 2e5f   == str(module._
+0000f7c0: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
+0000f7d0: 5f29 3a0a 2020 2020 2020 2020 2020 2020  _):.            
+0000f7e0: 2020 2020 6d6f 6475 6c65 5f6e 616d 655f      module_name_
+0000f7f0: 6c69 7374 2e61 7070 656e 6428 6e61 6d65  list.append(name
+0000f800: 290a 2020 2020 2020 2020 666f 7220 6e61  ).        for na
+0000f810: 6d65 2069 6e20 6d6f 6475 6c65 5f6e 616d  me in module_nam
+0000f820: 655f 6c69 7374 3a0a 2020 2020 2020 2020  e_list:.        
+0000f830: 2020 2020 6d6f 6475 6c65 203d 2067 6574      module = get
+0000f840: 5f6d 6f64 756c 6528 746d 705f 6d6f 6465  _module(tmp_mode
+0000f850: 6c2c 206e 616d 6529 0a20 2020 2020 2020  l, name).       
+0000f860: 2020 2020 206e 6577 5f6d 6f64 756c 6520       new_module 
+0000f870: 3d20 5351 4c69 6e65 6172 5772 6170 7065  = SQLinearWrappe
+0000f880: 7228 6d6f 6475 6c65 290a 2020 2020 2020  r(module).      
+0000f890: 2020 2020 2020 7365 745f 6d6f 6475 6c65        set_module
+0000f8a0: 2874 6d70 5f6d 6f64 656c 2c20 6e61 6d65  (tmp_model, name
+0000f8b0: 2c20 6e65 775f 6d6f 6475 6c65 290a 2020  , new_module).  
+0000f8c0: 2020 2020 2020 7265 7475 726e 2074 6d70        return tmp
+0000f8d0: 5f6d 6f64 656c 0a0a 0a75 6e69 6679 5f6f  _model...unify_o
+0000f8e0: 705f 7479 7065 5f6d 6170 7069 6e67 203d  p_type_mapping =
+0000f8f0: 207b 0a20 2020 2022 436f 6e76 5265 4c55   {.    "ConvReLU
+0000f900: 3264 223a 2022 436f 6e76 3264 222c 0a20  2d": "Conv2d",. 
+0000f910: 2020 2022 436f 6e76 5265 4c55 3364 223a     "ConvReLU3d":
+0000f920: 2022 436f 6e76 3364 222c 0a20 2020 2022   "Conv3d",.    "
+0000f930: 4c69 6e65 6172 5265 4c55 223a 2022 4c69  LinearReLU": "Li
+0000f940: 6e65 6172 222c 0a20 2020 2022 436f 6e76  near",.    "Conv
+0000f950: 426e 3264 223a 2022 436f 6e76 3264 222c  Bn2d": "Conv2d",
+0000f960: 0a20 2020 2022 436f 6e76 426e 5265 4c55  .    "ConvBnReLU
+0000f970: 3264 223a 2022 436f 6e76 3264 220a 7d0a  2d": "Conv2d".}.
+0000f980: 0a0a 4061 6461 7074 6f72 5f72 6567 6973  ..@adaptor_regis
+0000f990: 7472 790a 636c 6173 7320 5079 546f 7263  try.class PyTorc
+0000f9a0: 6841 6461 7074 6f72 2854 656d 706c 6174  hAdaptor(Templat
+0000f9b0: 6541 6461 7074 6f72 293a 0a20 2020 2022  eAdaptor):.    "
+0000f9c0: 2222 4164 6170 746f 7220 6f66 2050 7954  ""Adaptor of PyT
+0000f9d0: 6f72 6368 2066 7261 6d65 776f 726b 2c20  orch framework, 
+0000f9e0: 616c 6c20 5079 546f 7263 6820 4150 4920  all PyTorch API 
+0000f9f0: 6973 2069 6e20 7468 6973 2063 6c61 7373  is in this class
+0000fa00: 2e0a 0a20 2020 2041 7267 733a 0a20 2020  ...    Args:.   
+0000fa10: 2020 2020 2066 7261 6d65 776f 726b 5f73       framework_s
+0000fa20: 7065 6369 6669 635f 696e 666f 2028 6469  pecific_info (di
+0000fa30: 6374 293a 2064 6963 7469 6f6e 6172 7920  ct): dictionary 
+0000fa40: 6f66 2074 756e 696e 6720 636f 6e66 6967  of tuning config
+0000fa50: 7572 6520 6672 6f6d 2079 616d 6c20 6669  ure from yaml fi
+0000fa60: 6c65 2e0a 2020 2020 2222 220a 2020 2020  le..    """.    
+0000fa70: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+0000fa80: 662c 2066 7261 6d65 776f 726b 5f73 7065  f, framework_spe
+0000fa90: 6369 6669 635f 696e 666f 293a 0a20 2020  cific_info):.   
+0000faa0: 2020 2020 2073 7570 6572 2850 7954 6f72       super(PyTor
+0000fab0: 6368 4164 6170 746f 722c 2073 656c 6629  chAdaptor, self)
+0000fac0: 2e5f 5f69 6e69 745f 5f28 6672 616d 6577  .__init__(framew
+0000fad0: 6f72 6b5f 7370 6563 6966 6963 5f69 6e66  ork_specific_inf
+0000fae0: 6f29 0a20 2020 2020 2020 2022 2222 0a20  o).        """. 
+0000faf0: 2020 2020 2020 2023 204d 6170 2066 6f72         # Map for
+0000fb00: 2073 7761 7070 696e 6720 666c 6f61 7420   swapping float 
+0000fb10: 6d6f 6475 6c65 2074 6f20 7175 616e 7469  module to quanti
+0000fb20: 7a65 6420 6f6e 6573 2c0a 2020 2020 2020  zed ones,.      
+0000fb30: 2020 2320 616e 6420 7468 6973 2064 6963    # and this dic
+0000fb40: 7469 6f6e 6172 7920 7769 6c6c 2063 6861  tionary will cha
+0000fb50: 6e67 6520 7769 7468 2064 6966 6665 7265  nge with differe
+0000fb60: 6e74 2050 6f54 6f72 6368 2076 6572 7369  nt PoTorch versi
+0000fb70: 6f6e 730a 2020 2020 2020 2020 4445 4641  ons.        DEFA
+0000fb80: 554c 545f 4d4f 4455 4c45 5f4d 4150 5049  ULT_MODULE_MAPPI
+0000fb90: 4e47 203d 207b 0a20 2020 2020 2020 2020  NG = {.         
+0000fba0: 2020 206e 6e2e 4c69 6e65 6172 3a20 6e6e     nn.Linear: nn
+0000fbb0: 712e 4c69 6e65 6172 2c0a 2020 2020 2020  q.Linear,.      
+0000fbc0: 2020 2020 2020 6e6e 2e52 654c 553a 206e        nn.ReLU: n
+0000fbd0: 6e71 2e52 654c 552c 0a20 2020 2020 2020  nq.ReLU,.       
+0000fbe0: 2020 2020 206e 6e2e 5265 4c55 363a 206e       nn.ReLU6: n
+0000fbf0: 6e71 2e52 654c 5536 2c0a 2020 2020 2020  nq.ReLU6,.      
+0000fc00: 2020 2020 2020 6e6e 2e43 6f6e 7632 643a        nn.Conv2d:
+0000fc10: 206e 6e71 2e43 6f6e 7632 642c 0a20 2020   nnq.Conv2d,.   
+0000fc20: 2020 2020 2020 2020 206e 6e2e 436f 6e76           nn.Conv
+0000fc30: 3364 3a20 6e6e 712e 436f 6e76 3364 2c0a  3d: nnq.Conv3d,.
+0000fc40: 2020 2020 2020 2020 2020 2020 5175 616e              Quan
+0000fc50: 7453 7475 623a 206e 6e71 2e51 7561 6e74  tStub: nnq.Quant
+0000fc60: 697a 652c 0a20 2020 2020 2020 2020 2020  ize,.           
+0000fc70: 2044 6551 7561 6e74 5374 7562 3a20 6e6e   DeQuantStub: nn
+0000fc80: 712e 4465 5175 616e 7469 7a65 2c0a 2020  q.DeQuantize,.  
+0000fc90: 2020 2020 2020 2020 2020 2320 5772 6170            # Wrap
+0000fca0: 7065 7220 4d6f 6475 6c65 733a 0a20 2020  per Modules:.   
+0000fcb0: 2020 2020 2020 2020 206e 6e71 2e46 6c6f           nnq.Flo
+0000fcc0: 6174 4675 6e63 7469 6f6e 616c 3a20 6e6e  atFunctional: nn
+0000fcd0: 712e 5146 756e 6374 696f 6e61 6c2c 0a20  q.QFunctional,. 
+0000fce0: 2020 2020 2020 2020 2020 2023 2049 6e74             # Int
+0000fcf0: 7269 6e73 6963 206d 6f64 756c 6573 3a0a  rinsic modules:.
+0000fd00: 2020 2020 2020 2020 2020 2020 6e6e 692e              nni.
+0000fd10: 436f 6e76 5265 4c55 3264 3a20 6e6e 6971  ConvReLU2d: nniq
+0000fd20: 2e43 6f6e 7652 654c 5532 642c 0a20 2020  .ConvReLU2d,.   
+0000fd30: 2020 2020 2020 2020 206e 6e69 2e43 6f6e           nni.Con
+0000fd40: 7652 654c 5533 643a 206e 6e69 712e 436f  vReLU3d: nniq.Co
+0000fd50: 6e76 5265 4c55 3364 2c0a 2020 2020 2020  nvReLU3d,.      
+0000fd60: 2020 2020 2020 6e6e 692e 4c69 6e65 6172        nni.Linear
+0000fd70: 5265 4c55 3a20 6e6e 6971 2e4c 696e 6561  ReLU: nniq.Linea
+0000fd80: 7252 654c 552c 0a20 2020 2020 2020 2020  rReLU,.         
+0000fd90: 2020 206e 6e69 7161 742e 436f 6e76 5265     nniqat.ConvRe
+0000fda0: 4c55 3264 3a20 6e6e 6971 2e43 6f6e 7652  LU2d: nniq.ConvR
+0000fdb0: 654c 5532 642c 0a20 2020 2020 2020 2020  eLU2d,.         
+0000fdc0: 2020 206e 6e69 7161 742e 4c69 6e65 6172     nniqat.Linear
+0000fdd0: 5265 4c55 3a20 6e6e 6971 2e4c 696e 6561  ReLU: nniq.Linea
+0000fde0: 7252 654c 552c 0a20 2020 2020 2020 2020  rReLU,.         
+0000fdf0: 2020 206e 6e69 7161 742e 436f 6e76 426e     nniqat.ConvBn
+0000fe00: 3264 3a20 6e6e 712e 436f 6e76 3264 2c0a  2d: nnq.Conv2d,.
+0000fe10: 2020 2020 2020 2020 2020 2020 6e6e 6971              nniq
+0000fe20: 6174 2e43 6f6e 7642 6e52 654c 5532 643a  at.ConvBnReLU2d:
+0000fe30: 206e 6e69 712e 436f 6e76 5265 4c55 3264   nniq.ConvReLU2d
+0000fe40: 2c0a 2020 2020 2020 2020 2020 2020 2320  ,.            # 
+0000fe50: 5141 5420 6d6f 6475 6c65 733a 0a20 2020  QAT modules:.   
+0000fe60: 2020 2020 2020 2020 206e 6e71 6174 2e4c           nnqat.L
+0000fe70: 696e 6561 723a 206e 6e71 2e4c 696e 6561  inear: nnq.Linea
+0000fe80: 722c 0a20 2020 2020 2020 2020 2020 206e  r,.            n
+0000fe90: 6e71 6174 2e43 6f6e 7632 643a 206e 6e71  nqat.Conv2d: nnq
+0000fea0: 2e43 6f6e 7632 642c 0a20 2020 2020 2020  .Conv2d,.       
+0000feb0: 207d 0a20 2020 2020 2020 2022 2222 0a0a   }.        """..
+0000fec0: 2020 2020 2020 2020 7365 6c66 2e74 756e          self.tun
+0000fed0: 655f 6366 6720 3d20 4e6f 6e65 0a20 2020  e_cfg = None.   
+0000fee0: 2020 2020 2069 6620 7365 6c66 2e64 6576       if self.dev
+0000fef0: 6963 6520 3d3d 2022 6370 7522 3a0a 2020  ice == "cpu":.  
+0000ff00: 2020 2020 2020 2020 2020 7175 6572 795f            query_
+0000ff10: 636f 6e66 6967 5f66 696c 6520 3d20 2270  config_file = "p
+0000ff20: 7974 6f72 6368 5f63 7075 2e79 616d 6c22  ytorch_cpu.yaml"
+0000ff30: 0a20 2020 2020 2020 2065 6c69 6620 7365  .        elif se
+0000ff40: 6c66 2e64 6576 6963 6520 3d3d 2022 6770  lf.device == "gp
+0000ff50: 7522 3a0a 2020 2020 2020 2020 2020 2020  u":.            
+0000ff60: 7175 6572 795f 636f 6e66 6967 5f66 696c  query_config_fil
+0000ff70: 6520 3d20 2270 7974 6f72 6368 5f67 7075  e = "pytorch_gpu
+0000ff80: 2e79 616d 6c22 0a20 2020 2020 2020 2065  .yaml".        e
+0000ff90: 6c73 653a 2020 2320 7072 6167 6d61 3a20  lse:  # pragma: 
+0000ffa0: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
+0000ffb0: 2020 2020 2061 7373 6572 7420 4661 6c73       assert Fals
+0000ffc0: 652c 2022 556e 7375 7070 6f72 7420 7468  e, "Unsupport th
+0000ffd0: 6973 2064 6576 6963 6520 7b7d 222e 666f  is device {}".fo
+0000ffe0: 726d 6174 2873 656c 662e 6465 7669 6365  rmat(self.device
+0000fff0: 290a 2020 2020 2020 2020 7365 6c66 2e71  ).        self.q
+00010000: 7565 7279 5f68 616e 646c 6572 203d 2050  uery_handler = P
+00010010: 7954 6f72 6368 5175 6572 7928 0a20 2020  yTorchQuery(.   
+00010020: 2020 2020 2020 2020 206c 6f63 616c 5f63           local_c
+00010030: 6f6e 6669 675f 6669 6c65 3d6f 732e 7061  onfig_file=os.pa
+00010040: 7468 2e6a 6f69 6e28 6f73 2e70 6174 682e  th.join(os.path.
+00010050: 6469 726e 616d 6528 5f5f 6669 6c65 5f5f  dirname(__file__
+00010060: 292c 2071 7565 7279 5f63 6f6e 6669 675f  ), query_config_
+00010070: 6669 6c65 2929 0a0a 2020 2020 2020 2020  file))..        
+00010080: 7365 6c66 2e77 6869 7465 5f6c 6973 7420  self.white_list 
+00010090: 3d20 6765 745f 746f 7263 685f 7768 6974  = get_torch_whit
+000100a0: 655f 6c69 7374 2873 656c 662e 6170 7072  e_list(self.appr
+000100b0: 6f61 6368 290a 0a20 2020 2020 2020 2023  oach)..        #
+000100c0: 2066 6f72 2074 656e 736f 7262 6f61 7264   for tensorboard
+000100d0: 0a20 2020 2020 2020 2073 656c 662e 6475  .        self.du
+000100e0: 6d70 5f74 696d 6573 203d 2030 0a20 2020  mp_times = 0.   
+000100f0: 2020 2020 2073 656c 662e 6675 7365 645f       self.fused_
+00010100: 6469 6374 203d 207b 7d0a 0a20 2020 2020  dict = {}..     
+00010110: 2020 2073 656c 662e 6f70 7479 7065 5f73     self.optype_s
+00010120: 7461 7469 7374 6963 7320 3d20 4e6f 6e65  tatistics = None
+00010130: 0a0a 2020 2020 4064 756d 705f 656c 6170  ..    @dump_elap
+00010140: 7365 645f 7469 6d65 2822 5061 7373 2071  sed_time("Pass q
+00010150: 7561 6e74 697a 6520 6d6f 6465 6c22 290a  uantize model").
+00010160: 2020 2020 6465 6620 7175 616e 7469 7a65      def quantize
+00010170: 2873 656c 662c 2074 756e 655f 6366 672c  (self, tune_cfg,
+00010180: 206d 6f64 656c 2c20 6461 7461 6c6f 6164   model, dataload
+00010190: 6572 2c20 715f 6675 6e63 3d4e 6f6e 6529  er, q_func=None)
+000101a0: 3a0a 2020 2020 2020 2020 2222 2245 7865  :.        """Exe
+000101b0: 6375 7465 2074 6865 2071 7561 6e74 697a  cute the quantiz
+000101c0: 6520 7072 6f63 6573 7320 6f6e 2074 6865  e process on the
+000101d0: 2073 7065 6369 6669 6564 206d 6f64 656c   specified model
+000101e0: 2e0a 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
+000101f0: 0a20 2020 2020 2020 2020 2020 2074 756e  .            tun
+00010200: 655f 6366 6720 2864 6963 7429 3a20 7175  e_cfg (dict): qu
+00010210: 616e 7469 7a61 7469 6f6e 2063 6f6e 6669  antization confi
+00010220: 672e 0a20 2020 2020 2020 2020 2020 206d  g..            m
+00010230: 6f64 656c 2028 6f62 6a65 6374 293a 206d  odel (object): m
+00010240: 6f64 656c 206e 6565 6420 746f 2064 6f20  odel need to do 
+00010250: 7175 616e 7469 7a61 7469 6f6e 2e0a 2020  quantization..  
+00010260: 2020 2020 2020 2020 2020 6461 7461 6c6f            datalo
+00010270: 6164 6572 2028 6f62 6a65 6374 293a 2063  ader (object): c
+00010280: 616c 6962 7261 7469 6f6e 2064 6174 6173  alibration datas
+00010290: 6574 2e0a 2020 2020 2020 2020 2020 2020  et..            
+000102a0: 715f 6675 6e63 2028 6f62 6a65 7874 2c20  q_func (objext, 
+000102b0: 6f70 7469 6f6e 616c 293a 2074 7261 696e  optional): train
+000102c0: 696e 6720 6675 6e63 7469 6f6e 2066 6f72  ing function for
+000102d0: 2071 7561 6e74 697a 6174 696f 6e20 6177   quantization aw
+000102e0: 6172 6520 7472 6169 6e69 6e67 206d 6f64  are training mod
+000102f0: 652e 0a0a 2020 2020 2020 2020 5265 7475  e...        Retu
+00010300: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
+00010310: 2028 6f62 6a65 6374 293a 2071 7561 6e74   (object): quant
+00010320: 697a 6564 206d 6f64 656c 0a20 2020 2020  ized model.     
+00010330: 2020 2022 2222 0a20 2020 2020 2020 2061     """.        a
+00010340: 7373 6572 7420 6973 696e 7374 616e 6365  ssert isinstance
+00010350: 286d 6f64 656c 2e5f 6d6f 6465 6c2c 2074  (model._model, t
+00010360: 6f72 6368 2e6e 6e2e 4d6f 6475 6c65 292c  orch.nn.Module),
+00010370: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+00010380: 2020 2254 6865 206d 6f64 656c 2070 6173    "The model pas
+00010390: 7365 6420 696e 2069 7320 6e6f 7420 7468  sed in is not th
+000103a0: 6520 696e 7374 616e 6365 206f 6620 746f  e instance of to
+000103b0: 7263 682e 6e6e 2e4d 6f64 756c 6522 0a20  rch.nn.Module". 
+000103c0: 2020 2020 2020 2069 6620 7365 6c66 2e70         if self.p
+000103d0: 6572 666f 726d 616e 6365 5f6f 6e6c 793a  erformance_only:
+000103e0: 0a20 2020 2020 2020 2020 2020 2071 5f6d  .            q_m
+000103f0: 6f64 656c 203d 206d 6f64 656c 0a20 2020  odel = model.   
+00010400: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00010410: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
+00010420: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
+00010430: 6465 6c20 3d20 636f 7079 2e64 6565 7063  del = copy.deepc
+00010440: 6f70 7928 6d6f 6465 6c29 0a20 2020 2020  opy(model).     
+00010450: 2020 2020 2020 2065 7863 6570 7420 4578         except Ex
+00010460: 6365 7074 696f 6e20 6173 2065 3a20 2023  ception as e:  #
+00010470: 2070 7261 676d 613a 206e 6f20 636f 7665   pragma: no cove
+00010480: 720a 2020 2020 2020 2020 2020 2020 2020  r.              
+00010490: 2020 6c6f 6767 6572 2e77 6172 6e69 6e67    logger.warning
+000104a0: 2822 4661 696c 2074 6f20 6465 6570 2063  ("Fail to deep c
+000104b0: 6f70 7920 7468 6520 6d6f 6465 6c20 6475  opy the model du
+000104c0: 6520 746f 207b 7d2c 2069 6e70 6c61 6365  e to {}, inplace
+000104d0: 2069 7320 7573 6564 206e 6f77 2e22 2e66   is used now.".f
+000104e0: 6f72 6d61 7428 0a20 2020 2020 2020 2020  ormat(.         
+000104f0: 2020 2020 2020 2020 2020 2072 6570 7228             repr(
+00010500: 6529 2929 0a20 2020 2020 2020 2020 2020  e))).           
+00010510: 2020 2020 2071 5f6d 6f64 656c 203d 206d       q_model = m
+00010520: 6f64 656c 0a0a 2020 2020 2020 2020 2320  odel..        # 
+00010530: 466f 7220 736d 6f6f 7468 7175 616e 7420  For smoothquant 
+00010540: 6f70 7469 6d69 7a65 6420 6d6f 6465 6c0a  optimized model.
+00010550: 2020 2020 2020 2020 7265 6369 7065 5f63          recipe_c
+00010560: 6667 7320 3d20 7475 6e65 5f63 6667 2e67  fgs = tune_cfg.g
+00010570: 6574 2827 7265 6369 7065 5f63 6667 7327  et('recipe_cfgs'
+00010580: 2c20 4e6f 6e65 290a 2020 2020 2020 2020  , None).        
+00010590: 6966 2072 6563 6970 655f 6366 6773 2061  if recipe_cfgs a
+000105a0: 6e64 2072 6563 6970 655f 6366 6773 2e67  nd recipe_cfgs.g
+000105b0: 6574 2827 736d 6f6f 7468 5f71 7561 6e74  et('smooth_quant
+000105c0: 272c 2046 616c 7365 2920 5c0a 2020 2020  ', False) \.    
+000105d0: 2020 2020 2020 616e 6420 6e6f 7420 7265        and not re
+000105e0: 6369 7065 5f63 6667 735b 2773 6d6f 6f74  cipe_cfgs['smoot
+000105f0: 685f 7175 616e 745f 6172 6773 275d 5b27  h_quant_args']['
+00010600: 666f 6c64 696e 6727 5d20 5c0a 2020 2020  folding'] \.    
+00010610: 2020 2020 2020 616e 6420 7365 6c66 2e61        and self.a
+00010620: 7070 726f 6163 6820 213d 2027 706f 7374  pproach != 'post
+00010630: 5f74 7261 696e 696e 675f 6479 6e61 6d69  _training_dynami
+00010640: 635f 7175 616e 7427 3a0a 2020 2020 2020  c_quant':.      
+00010650: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+00010660: 662e 7164 715f 7175 616e 7469 7a65 2871  f.qdq_quantize(q
+00010670: 5f6d 6f64 656c 2c20 7475 6e65 5f63 6667  _model, tune_cfg
+00010680: 290a 0a20 2020 2020 2020 2023 2046 6f72  )..        # For
+00010690: 2074 656e 736f 7262 6f61 7264 2064 6973   tensorboard dis
+000106a0: 706c 6179 0a20 2020 2020 2020 2073 656c  play.        sel
+000106b0: 662e 7475 6e65 5f63 6667 203d 2074 756e  f.tune_cfg = tun
+000106c0: 655f 6366 670a 2020 2020 2020 2020 7365  e_cfg.        se
+000106d0: 6c66 2e74 756e 655f 6366 675b 2261 7070  lf.tune_cfg["app
+000106e0: 726f 6163 6822 5d20 3d20 7365 6c66 2e61  roach"] = self.a
+000106f0: 7070 726f 6163 680a 2020 2020 2020 2020  pproach.        
+00010700: 7365 6c66 2e74 756e 655f 6366 675b 2272  self.tune_cfg["r
+00010710: 6564 7563 655f 7261 6e67 6522 5d20 3d20  educe_range"] = 
+00010720: 5245 4455 4345 5f52 414e 4745 0a20 2020  REDUCE_RANGE.   
+00010730: 2020 2020 2073 656c 662e 7475 6e65 5f63       self.tune_c
+00010740: 6667 5b22 6672 616d 6577 6f72 6b22 5d20  fg["framework"] 
+00010750: 3d20 2270 7974 6f72 6368 220a 2020 2020  = "pytorch".    
+00010760: 2020 2020 6f70 5f63 6667 7320 3d20 5f63      op_cfgs = _c
+00010770: 6667 5f74 6f5f 7163 6f6e 6669 6728 7475  fg_to_qconfig(tu
+00010780: 6e65 5f63 6667 2c20 7365 6c66 2e61 7070  ne_cfg, self.app
+00010790: 726f 6163 6829 0a20 2020 2020 2020 2073  roach).        s
+000107a0: 656c 662e 7475 6e65 5f63 6667 5b27 6266  elf.tune_cfg['bf
+000107b0: 3136 5f6f 7073 5f6c 6973 7427 5d20 3d20  16_ops_list'] = 
+000107c0: 6f70 5f63 6667 735b 2762 6631 365f 6f70  op_cfgs['bf16_op
+000107d0: 735f 6c69 7374 275d 0a20 2020 2020 2020  s_list'].       
+000107e0: 2064 656c 206f 705f 6366 6773 5b27 6266   del op_cfgs['bf
+000107f0: 3136 5f6f 7073 5f6c 6973 7427 5d0a 2020  16_ops_list'].  
+00010800: 2020 2020 2020 6763 2e63 6f6c 6c65 6374        gc.collect
+00010810: 2829 0a0a 2020 2020 2020 2020 6966 2073  ()..        if s
+00010820: 656c 662e 7665 7273 696f 6e2e 7265 6c65  elf.version.rele
+00010830: 6173 6520 3c20 5665 7273 696f 6e28 2232  ase < Version("2
+00010840: 2e30 2e30 2229 2e72 656c 6561 7365 3a0a  .0.0").release:.
+00010850: 2020 2020 2020 2020 2020 2020 6672 6f6d              from
+00010860: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
+00010870: 696f 6e2e 7175 616e 7469 7a65 2069 6d70  ion.quantize imp
+00010880: 6f72 7420 6164 645f 6f62 7365 7276 6572  ort add_observer
+00010890: 5f0a 2020 2020 2020 2020 656c 7365 3a0a  _.        else:.
+000108a0: 2020 2020 2020 2020 2020 2020 6672 6f6d              from
+000108b0: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
+000108c0: 696f 6e2e 7175 616e 7469 7a65 2069 6d70  ion.quantize imp
+000108d0: 6f72 7420 5f61 6464 5f6f 6273 6572 7665  ort _add_observe
+000108e0: 725f 2061 7320 6164 645f 6f62 7365 7276  r_ as add_observ
+000108f0: 6572 5f0a 0a20 2020 2020 2020 2069 6620  er_..        if 
+00010900: 7365 6c66 2e61 7070 726f 6163 6820 3d3d  self.approach ==
+00010910: 2027 7175 616e 745f 6177 6172 655f 7472   'quant_aware_tr
+00010920: 6169 6e69 6e67 273a 0a20 2020 2020 2020  aining':.       
+00010930: 2020 2020 2071 5f6d 6f64 656c 2e5f 6d6f       q_model._mo
+00010940: 6465 6c2e 7472 6169 6e28 290a 2020 2020  del.train().    
+00010950: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00010960: 2020 2020 2020 715f 6d6f 6465 6c2e 5f6d        q_model._m
+00010970: 6f64 656c 2e65 7661 6c28 290a 2020 2020  odel.eval().    
+00010980: 2020 2020 6966 2073 656c 662e 7665 7273      if self.vers
+00010990: 696f 6e2e 7265 6c65 6173 6520 3c20 5665  ion.release < Ve
+000109a0: 7273 696f 6e28 2231 2e37 2e30 2229 2e72  rsion("1.7.0").r
+000109b0: 656c 6561 7365 206f 7220 5c0a 2020 2020  elease or \.    
+000109c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000109d0: 7365 6c66 2e61 7070 726f 6163 6820 213d  self.approach !=
+000109e0: 2027 7175 616e 745f 6177 6172 655f 7472   'quant_aware_tr
+000109f0: 6169 6e69 6e67 273a 0a20 2020 2020 2020  aining':.       
+00010a00: 2020 2020 205f 7072 6f70 6167 6174 655f       _propagate_
+00010a10: 7163 6f6e 6669 6728 715f 6d6f 6465 6c2e  qconfig(q_model.
+00010a20: 5f6d 6f64 656c 2c20 6f70 5f63 6667 732c  _model, op_cfgs,
+00010a30: 2061 7070 726f 6163 683d 7365 6c66 2e61   approach=self.a
+00010a40: 7070 726f 6163 6829 0a20 2020 2020 2020  pproach).       
+00010a50: 2020 2020 2023 2073 616e 6974 7920 6368       # sanity ch
+00010a60: 6563 6b20 636f 6d6d 6f6e 2041 5049 206d  eck common API m
+00010a70: 6973 7573 6167 650a 2020 2020 2020 2020  isusage.        
+00010a80: 2020 2020 6966 206e 6f74 2061 6e79 2868      if not any(h
+00010a90: 6173 6174 7472 286d 2c20 2771 636f 6e66  asattr(m, 'qconf
+00010aa0: 6967 2729 2061 6e64 206d 2e71 636f 6e66  ig') and m.qconf
+00010ab0: 6967 2066 6f72 206d 2069 6e20 715f 6d6f  ig for m in q_mo
+00010ac0: 6465 6c2e 5f6d 6f64 656c 2e6d 6f64 756c  del._model.modul
+00010ad0: 6573 2829 293a 0a20 2020 2020 2020 2020  es()):.         
+00010ae0: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
+00010af0: 726e 2822 4e6f 6e65 206f 6620 7468 6520  rn("None of the 
+00010b00: 7375 626d 6f64 756c 6520 676f 7420 7163  submodule got qc
+00010b10: 6f6e 6669 6720 6170 706c 6965 642e 204d  onfig applied. M
+00010b20: 616b 6520 7375 7265 2079 6f75 2022 0a20  ake sure you ". 
+00010b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010b40: 2020 2020 2020 2020 2020 2022 7061 7373             "pass
+00010b50: 6564 2063 6f72 7265 6374 2063 6f6e 6669  ed correct confi
+00010b60: 6775 7261 7469 6f6e 2074 6872 6f75 6768  guration through
+00010b70: 2060 7163 6f6e 6669 675f 6469 6374 6020   `qconfig_dict` 
+00010b80: 6f72 2022 0a20 2020 2020 2020 2020 2020  or ".           
+00010b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010ba0: 2022 6279 2061 7373 6967 6e69 6e67 2074   "by assigning t
+00010bb0: 6865 2060 2e71 636f 6e66 6967 6020 6174  he `.qconfig` at
+00010bc0: 7472 6962 7574 6520 6469 7265 6374 6c79  tribute directly
+00010bd0: 206f 6e20 7375 626d 6f64 756c 6573 2e22   on submodules."
+00010be0: 290a 0a20 2020 2020 2020 2069 6620 7365  )..        if se
+00010bf0: 6c66 2e61 7070 726f 6163 6820 696e 205b  lf.approach in [
+00010c00: 2770 6f73 745f 7472 6169 6e69 6e67 5f73  'post_training_s
+00010c10: 7461 7469 635f 7175 616e 7427 2c20 2770  tatic_quant', 'p
+00010c20: 6f73 745f 7472 6169 6e69 6e67 5f61 7574  ost_training_aut
+00010c30: 6f5f 7175 616e 7427 5d3a 0a20 2020 2020  o_quant']:.     
+00010c40: 2020 2020 2020 2061 6464 5f6f 6273 6572         add_obser
+00010c50: 7665 725f 2871 5f6d 6f64 656c 2e5f 6d6f  ver_(q_model._mo
+00010c60: 6465 6c29 0a20 2020 2020 2020 2020 2020  del).           
+00010c70: 2069 6620 715f 6675 6e63 2069 7320 4e6f   if q_func is No
+00010c80: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00010c90: 2020 2020 6974 6572 6174 696f 6e73 203d      iterations =
+00010ca0: 2074 756e 655f 6366 672e 6765 7428 2763   tune_cfg.get('c
+00010cb0: 616c 6962 5f69 7465 7261 7469 6f6e 272c  alib_iteration',
+00010cc0: 2031 290a 2020 2020 2020 2020 2020 2020   1).            
+00010cd0: 2020 2020 7365 6c66 2e6d 6f64 656c 5f63      self.model_c
+00010ce0: 616c 6962 7261 7469 6f6e 2871 5f6d 6f64  alibration(q_mod
+00010cf0: 656c 2e5f 6d6f 6465 6c2c 0a20 2020 2020  el._model,.     
+00010d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010d20: 2020 6461 7461 6c6f 6164 6572 2c0a 2020    dataloader,.  
+00010d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010d50: 2020 2020 2069 7465 7261 7469 6f6e 732c       iterations,
+00010d60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010d80: 2020 2020 2020 2020 6361 6c69 625f 7361          calib_sa
+00010d90: 6d70 6c69 6e67 5f73 697a 653d 7475 6e65  mpling_size=tune
+00010da0: 5f63 6667 2e67 6574 2827 6361 6c69 625f  _cfg.get('calib_
+00010db0: 7361 6d70 6c69 6e67 5f73 697a 6527 2c20  sampling_size', 
+00010dc0: 3129 290a 2020 2020 2020 2020 2020 2020  1)).            
+00010dd0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00010de0: 2020 2020 2020 715f 6675 6e63 2871 5f6d        q_func(q_m
+00010df0: 6f64 656c 2e5f 6d6f 6465 6c29 0a20 2020  odel._model).   
+00010e00: 2020 2020 2065 6c69 6620 7365 6c66 2e61       elif self.a
+00010e10: 7070 726f 6163 6820 3d3d 2027 7175 616e  pproach == 'quan
+00010e20: 745f 6177 6172 655f 7472 6169 6e69 6e67  t_aware_training
+00010e30: 273a 0a20 2020 2020 2020 2020 2020 2069  ':.            i
+00010e40: 6620 7365 6c66 2e76 6572 7369 6f6e 2e72  f self.version.r
+00010e50: 656c 6561 7365 203e 3d20 5665 7273 696f  elease >= Versio
+00010e60: 6e28 2231 2e37 2e30 2229 2e72 656c 6561  n("1.7.0").relea
+00010e70: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00010e80: 2020 2020 5f70 726f 7061 6761 7465 5f71      _propagate_q
+00010e90: 636f 6e66 6967 2871 5f6d 6f64 656c 2e5f  config(q_model._
+00010ea0: 6d6f 6465 6c2c 206f 705f 6366 6773 2c20  model, op_cfgs, 
+00010eb0: 6973 5f71 6174 5f63 6f6e 7665 7274 3d54  is_qat_convert=T
+00010ec0: 7275 6529 0a20 2020 2020 2020 2020 2020  rue).           
+00010ed0: 2020 2020 2074 6f72 6368 2e71 7561 6e74       torch.quant
+00010ee0: 697a 6174 696f 6e2e 636f 6e76 6572 7428  ization.convert(
+00010ef0: 715f 6d6f 6465 6c2e 5f6d 6f64 656c 2c0a  q_model._model,.
+00010f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f20: 2020 2020 2020 2020 2020 206d 6170 7069             mappi
+00010f30: 6e67 3d73 656c 662e 715f 6d61 7070 696e  ng=self.q_mappin
+00010f40: 672c 0a20 2020 2020 2020 2020 2020 2020  g,.             
+00010f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f60: 2020 2020 2020 2020 2020 2020 2020 696e                in
+00010f70: 706c 6163 653d 5472 7565 2c0a 2020 2020  place=True,.    
 00010f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010f90: 2020 746f 7263 682e 7574 696c 732e 6461    torch.utils.da
-00010fa0: 7461 2e64 6973 7472 6962 7574 6564 2e44  ta.distributed.D
-00010fb0: 6973 7472 6962 7574 6564 5361 6d70 6c65  istributedSample
-00010fc0: 7229 3a0a 2020 2020 2020 2020 2020 2020  r):.            
-00010fd0: 2020 2020 6461 7461 6c6f 6164 6572 2e73      dataloader.s
-00010fe0: 616d 706c 6572 2e73 6574 5f65 706f 6368  ampler.set_epoch
-00010ff0: 286e 6570 6f63 6829 0a20 2020 2020 2020  (nepoch).       
-00011000: 2020 2020 2066 6f72 2069 6d61 6765 2c20       for image, 
-00011010: 7461 7267 6574 2069 6e20 6461 7461 6c6f  target in datalo
-00011020: 6164 6572 3a0a 2020 2020 2020 2020 2020  ader:.          
-00011030: 2020 2020 2020 2320 544f 444f 3a20 746f        # TODO: to
-00011040: 2073 7570 706f 7274 2061 646a 7573 7420   support adjust 
-00011050: 6c72 2077 6974 6820 6570 6f63 680a 2020  lr with epoch.  
-00011060: 2020 2020 2020 2020 2020 2020 2020 7461                ta
-00011070: 7267 6574 203d 2074 6172 6765 742e 746f  rget = target.to
-00011080: 2864 6576 6963 6529 0a20 2020 2020 2020  (device).       
-00011090: 2020 2020 2020 2020 2069 6620 686f 6f6b           if hook
-000110a0: 7320 6973 206e 6f74 204e 6f6e 653a 0a20  s is not None:. 
-000110b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000110c0: 2020 206f 6e5f 7374 6570 5f62 6567 696e     on_step_begin
-000110d0: 2863 6e74 290a 2020 2020 2020 2020 2020  (cnt).          
-000110e0: 2020 2020 2020 7072 696e 7428 272e 272c        print('.',
-000110f0: 2065 6e64 3d27 272c 2066 6c75 7368 3d54   end='', flush=T
-00011100: 7275 6529 0a20 2020 2020 2020 2020 2020  rue).           
-00011110: 2020 2020 2063 6e74 202b 3d20 310a 2020       cnt += 1.  
-00011120: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-00011130: 7470 7574 203d 2070 7974 6f72 6368 5f66  tput = pytorch_f
-00011140: 6f72 7761 7264 5f77 7261 7070 6572 286d  orward_wrapper(m
-00011150: 6f64 656c 5f2c 2069 6d61 6765 2c20 6465  odel_, image, de
-00011160: 7669 6365 3d64 6576 6963 6529 0a20 2020  vice=device).   
-00011170: 2020 2020 2020 2020 2020 2020 206c 6f73               los
-00011180: 7320 3d20 6372 6974 6572 696f 6e28 6f75  s = criterion(ou
-00011190: 7470 7574 2c20 7461 7267 6574 290a 2020  tput, target).  
-000111a0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-000111b0: 2068 6f6f 6b73 2069 7320 6e6f 7420 4e6f   hooks is not No
-000111c0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-000111d0: 2020 2020 2020 2020 6c6f 7373 203d 206f          loss = o
-000111e0: 6e5f 6166 7465 725f 636f 6d70 7574 655f  n_after_compute_
-000111f0: 6c6f 7373 2869 6d61 6765 2c20 6f75 7470  loss(image, outp
-00011200: 7574 2c20 6c6f 7373 290a 2020 2020 2020  ut, loss).      
-00011210: 2020 2020 2020 2020 2020 7365 6c66 2e6f            self.o
-00011220: 7074 696d 697a 6572 2e7a 6572 6f5f 6772  ptimizer.zero_gr
-00011230: 6164 2829 0a20 2020 2020 2020 2020 2020  ad().           
-00011240: 2020 2020 206c 6f73 732e 6261 636b 7761       loss.backwa
-00011250: 7264 2829 0a20 2020 2020 2020 2020 2020  rd().           
-00011260: 2020 2020 2069 6620 686f 6f6b 7320 6973       if hooks is
-00011270: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
-00011280: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00011290: 6e5f 6265 666f 7265 5f6f 7074 696d 697a  n_before_optimiz
-000112a0: 6572 5f73 7465 7028 290a 2020 2020 2020  er_step().      
-000112b0: 2020 2020 2020 2020 2020 7365 6c66 2e6f            self.o
-000112c0: 7074 696d 697a 6572 2e73 7465 7028 290a  ptimizer.step().
-000112d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000112e0: 6966 2068 6f6f 6b73 2069 7320 6e6f 7420  if hooks is not 
-000112f0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00011300: 2020 2020 2020 2020 2020 6f6e 5f73 7465            on_ste
-00011310: 705f 656e 6428 290a 2020 2020 2020 2020  p_end().        
-00011320: 2020 2020 2020 2020 6966 2063 6e74 203e          if cnt >
-00011330: 3d20 6974 6572 733a 0a20 2020 2020 2020  = iters:.       
-00011340: 2020 2020 2020 2020 2020 2020 2062 7265               bre
-00011350: 616b 0a20 2020 2020 2020 2020 2020 2069  ak.            i
-00011360: 6620 686f 6f6b 7320 6973 206e 6f74 204e  f hooks is not N
-00011370: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-00011380: 2020 2020 206f 6e5f 6570 6f63 685f 656e       on_epoch_en
-00011390: 6428 290a 0a20 2020 2020 2020 2069 6620  d()..        if 
-000113a0: 6465 7669 6365 2021 3d20 7365 6c66 2e64  device != self.d
-000113b0: 6576 6963 653a 2020 2320 7072 6167 6d61  evice:  # pragma
-000113c0: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
-000113d0: 2020 2020 2020 206d 6f64 656c 5f2e 746f         model_.to
-000113e0: 2873 656c 662e 6465 7669 6365 290a 0a20  (self.device).. 
-000113f0: 2020 2020 2020 2069 6620 686f 6f6b 7320         if hooks 
-00011400: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-00011410: 2020 2020 2020 2020 206f 6e5f 7472 6169           on_trai
-00011420: 6e5f 656e 6428 290a 0a20 2020 2020 2020  n_end()..       
-00011430: 2072 6574 7572 6e20 6d6f 6465 6c5f 0a0a   return model_..
-00011440: 2020 2020 6465 6620 5f64 756d 705f 6d6f      def _dump_mo
-00011450: 6465 6c5f 6f70 5f73 7461 7473 2873 656c  del_op_stats(sel
-00011460: 662c 206d 6f64 656c 2c20 7475 6e65 5f63  f, model, tune_c
-00011470: 6667 293a 0a20 2020 2020 2020 2022 2222  fg):.        """
-00011480: 5468 6973 2069 7320 6120 6675 6e63 7469  This is a functi
-00011490: 6f6e 2074 6f20 6475 6d70 2071 7561 6e74  on to dump quant
-000114a0: 697a 6162 6c65 206f 7073 206f 6620 6d6f  izable ops of mo
-000114b0: 6465 6c20 746f 2075 7365 722e 0a20 2020  del to user..   
-000114c0: 2020 2020 2041 7267 733a 0a20 2020 2020       Args:.     
-000114d0: 2020 2020 2020 206d 6f64 656c 2028 6f62         model (ob
-000114e0: 6a65 6374 293a 2069 6e70 7574 206d 6f64  ject): input mod
-000114f0: 656c 0a20 2020 2020 2020 2020 2020 2074  el.            t
-00011500: 756e 655f 6366 6720 2864 6963 7429 3a20  une_cfg (dict): 
-00011510: 7175 616e 7469 7a61 7469 6f6e 2063 6f6e  quantization con
-00011520: 6669 670a 2020 2020 2020 2020 5265 7475  fig.        Retu
-00011530: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
-00011540: 204e 6f6e 650a 2020 2020 2020 2020 2222   None.        ""
-00011550: 220a 2020 2020 2020 2020 7265 7320 3d20  ".        res = 
-00011560: 7b7d 0a20 2020 2020 2020 2069 676e 6f72  {}.        ignor
-00011570: 655f 6c6f 6720 3d20 4661 6c73 650a 2020  e_log = False.  
-00011580: 2020 2020 2020 6d6f 6475 6c65 7320 3d20        modules = 
-00011590: 6469 6374 286d 6f64 656c 2e6e 616d 6564  dict(model.named
-000115a0: 5f6d 6f64 756c 6573 2829 290a 2020 2020  _modules()).    
-000115b0: 2020 2020 2320 6665 7463 6820 7175 616e      # fetch quan
-000115c0: 7469 7a61 626c 6520 6f70 7320 7375 7070  tizable ops supp
-000115d0: 6f72 7465 6420 696e 204e 6575 7261 6c20  orted in Neural 
-000115e0: 436f 6d70 7265 7373 6f72 2066 726f 6d20  Compressor from 
-000115f0: 7475 6e65 5f63 6667 0a20 2020 2020 2020  tune_cfg.       
-00011600: 2066 6f72 206b 6579 2069 6e20 7475 6e65   for key in tune
-00011610: 5f63 6667 5b27 6f70 275d 3a0a 2020 2020  _cfg['op']:.    
-00011620: 2020 2020 2020 2020 6f70 5f6e 616d 6520          op_name 
-00011630: 3d20 6b65 795b 305d 0a20 2020 2020 2020  = key[0].       
-00011640: 2020 2020 206f 705f 7479 7065 203d 2073       op_type = s
-00011650: 7472 2874 7970 6528 6d6f 6475 6c65 735b  tr(type(modules[
-00011660: 6f70 5f6e 616d 655d 2929 2e72 7374 7269  op_name])).rstri
-00011670: 7028 275c 273e 2729 2e73 706c 6974 2827  p('\'>').split('
-00011680: 2e27 295b 2d31 5d0a 2020 2020 2020 2020  .')[-1].        
-00011690: 2020 2020 6966 206f 705f 7479 7065 203d      if op_type =
-000116a0: 3d20 2742 4631 364d 6f64 756c 6557 7261  = 'BF16ModuleWra
-000116b0: 7070 6572 273a 2020 2320 7072 6167 6d61  pper':  # pragma
-000116c0: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
-000116d0: 2020 2020 2020 2020 2020 206f 705f 7479             op_ty
-000116e0: 7065 203d 2073 7472 2874 7970 6528 6d6f  pe = str(type(mo
-000116f0: 6475 6c65 735b 6f70 5f6e 616d 655d 2e6d  dules[op_name].m
-00011700: 6f64 756c 6529 292e 7273 7472 6970 2827  odule)).rstrip('
-00011710: 5c27 3e27 292e 7370 6c69 7428 272e 2729  \'>').split('.')
-00011720: 5b2d 315d 0a20 2020 2020 2020 2020 2020  [-1].           
-00011730: 2069 6620 6f70 5f74 7970 6520 3d3d 2027   if op_type == '
-00011740: 4465 7175 616e 7451 7561 6e74 5772 6170  DequantQuantWrap
-00011750: 7065 7227 3a0a 2020 2020 2020 2020 2020  per':.          
-00011760: 2020 2020 2020 6f70 5f74 7970 6520 3d20        op_type = 
-00011770: 7374 7228 7479 7065 286d 6f64 756c 6573  str(type(modules
-00011780: 5b6f 705f 6e61 6d65 5d2e 6d6f 6475 6c65  [op_name].module
-00011790: 2929 2e72 7374 7269 7028 275c 273e 2729  )).rstrip('\'>')
-000117a0: 2e73 706c 6974 2827 2e27 295b 2d31 5d0a  .split('.')[-1].
-000117b0: 2020 2020 2020 2020 2020 2020 6966 2027              if '
-000117c0: 4675 6e63 7469 6f6e 616c 2720 696e 206f  Functional' in o
-000117d0: 705f 7479 7065 3a0a 2020 2020 2020 2020  p_type:.        
-000117e0: 2020 2020 2020 2020 6f70 5f74 7970 6520          op_type 
-000117f0: 3d20 6f70 5f6e 616d 652e 7370 6c69 7428  = op_name.split(
-00011800: 272e 2729 5b2d 315d 0a20 2020 2020 2020  '.')[-1].       
-00011810: 2020 2020 2069 6620 6f70 5f74 7970 6520       if op_type 
-00011820: 6e6f 7420 696e 2072 6573 2e6b 6579 7328  not in res.keys(
-00011830: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00011840: 2020 2072 6573 5b6f 705f 7479 7065 5d20     res[op_type] 
-00011850: 3d20 7b27 494e 5438 273a 2030 2c20 2742  = {'INT8': 0, 'B
-00011860: 4631 3627 3a20 302c 2027 4650 3332 273a  F16': 0, 'FP32':
-00011870: 2030 7d0a 2020 2020 2020 2020 2020 2020   0}.            
-00011880: 7661 6c75 6520 3d20 7475 6e65 5f63 6667  value = tune_cfg
-00011890: 5b27 6f70 275d 5b6b 6579 5d0a 2020 2020  ['op'][key].    
-000118a0: 2020 2020 2020 2020 2320 5370 6563 6961          # Specia
-000118b0: 6c20 6361 7365 733a 2051 7561 6e74 5374  l cases: QuantSt
-000118c0: 7562 2c20 456d 6265 6464 696e 670a 2020  ub, Embedding.  
-000118d0: 2020 2020 2020 2020 2020 6966 2028 2777            if ('w
-000118e0: 6569 6768 7427 2069 6e20 7661 6c75 6520  eight' in value 
-000118f0: 616e 6420 7661 6c75 655b 2777 6569 6768  and value['weigh
-00011900: 7427 5d5b 2764 7479 7065 275d 203d 3d20  t']['dtype'] == 
-00011910: 2766 7033 3227 2920 6f72 205c 0a20 2020  'fp32') or \.   
-00011920: 2020 2020 2020 2020 2020 2028 2777 6569             ('wei
-00011930: 6768 7427 206e 6f74 2069 6e20 7661 6c75  ght' not in valu
-00011940: 6520 616e 6420 7661 6c75 655b 2761 6374  e and value['act
-00011950: 6976 6174 696f 6e27 5d5b 2764 7479 7065  ivation']['dtype
-00011960: 275d 203d 3d20 2766 7033 3227 293a 0a20  '] == 'fp32'):. 
-00011970: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00011980: 6573 5b6f 705f 7479 7065 5d5b 2746 5033  es[op_type]['FP3
-00011990: 3227 5d20 2b3d 2031 0a20 2020 2020 2020  2'] += 1.       
-000119a0: 2020 2020 2065 6c69 6620 7661 6c75 655b       elif value[
-000119b0: 2761 6374 6976 6174 696f 6e27 5d5b 2764  'activation']['d
-000119c0: 7479 7065 275d 203d 3d20 2762 6631 3627  type'] == 'bf16'
-000119d0: 3a20 2023 2070 7261 676d 613a 206e 6f20  :  # pragma: no 
-000119e0: 636f 7665 720a 2020 2020 2020 2020 2020  cover.          
-000119f0: 2020 2020 2020 7265 735b 6f70 5f74 7970        res[op_typ
-00011a00: 655d 5b27 4246 3136 275d 202b 3d20 310a  e]['BF16'] += 1.
-00011a10: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00011a20: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00011a30: 2020 7265 735b 6f70 5f74 7970 655d 5b27    res[op_type]['
-00011a40: 494e 5438 275d 202b 3d20 310a 2020 2020  INT8'] += 1.    
-00011a50: 2020 2020 2320 6665 7463 6820 6f74 6865      # fetch othe
-00011a60: 7220 7175 616e 7469 7a61 626c 6520 6f70  r quantizable op
-00011a70: 7320 7375 7070 6f72 7465 6420 696e 2050  s supported in P
-00011a80: 7954 6f72 6368 2066 726f 6d20 6d6f 6465  yTorch from mode
-00011a90: 6c0a 2020 2020 2020 2020 666f 7220 6e61  l.        for na
-00011aa0: 6d65 2c20 6368 696c 6420 696e 206d 6f64  me, child in mod
-00011ab0: 756c 6573 2e69 7465 6d73 2829 3a0a 2020  ules.items():.  
-00011ac0: 2020 2020 2020 2020 2020 6f70 5f74 7970            op_typ
-00011ad0: 6520 3d20 7374 7228 7479 7065 2863 6869  e = str(type(chi
-00011ae0: 6c64 2929 2e72 7374 7269 7028 275c 273e  ld)).rstrip('\'>
-00011af0: 2729 2e73 706c 6974 2827 2e27 295b 2d31  ').split('.')[-1
-00011b00: 5d0a 2020 2020 2020 2020 2020 2020 6966  ].            if
-00011b10: 2074 756e 655f 6366 675b 2761 7070 726f   tune_cfg['appro
-00011b20: 6163 6827 5d20 213d 2027 706f 7374 5f74  ach'] != 'post_t
-00011b30: 7261 696e 696e 675f 6479 6e61 6d69 635f  raining_dynamic_
-00011b40: 7175 616e 7427 3a0a 2020 2020 2020 2020  quant':.        
-00011b50: 2020 2020 2020 2020 6966 206f 705f 7479          if op_ty
-00011b60: 7065 203d 3d20 2744 6551 7561 6e74 697a  pe == 'DeQuantiz
-00011b70: 6527 3a0a 2020 2020 2020 2020 2020 2020  e':.            
-00011b80: 2020 2020 2020 2020 6966 206f 705f 7479          if op_ty
-00011b90: 7065 206e 6f74 2069 6e20 7265 732e 6b65  pe not in res.ke
-00011ba0: 7973 2829 3a0a 2020 2020 2020 2020 2020  ys():.          
-00011bb0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-00011bc0: 735b 6f70 5f74 7970 655d 203d 207b 2749  s[op_type] = {'I
-00011bd0: 4e54 3827 3a20 302c 2027 4246 3136 273a  NT8': 0, 'BF16':
-00011be0: 2030 2c20 2746 5033 3227 3a20 307d 0a20   0, 'FP32': 0}. 
-00011bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c00: 2020 2072 6573 5b6f 705f 7479 7065 5d5b     res[op_type][
-00011c10: 2749 4e54 3827 5d20 2b3d 2031 0a20 2020  'INT8'] += 1.   
-00011c20: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00011c30: 6f70 5f74 7970 6520 696e 2073 656c 662e  op_type in self.
-00011c40: 6e6f 6e5f 7175 616e 745f 6469 6374 5b27  non_quant_dict['
-00011c50: 736b 6970 7065 645f 6d6f 6475 6c65 5f63  skipped_module_c
-00011c60: 6c61 7373 6573 275d 3a0a 2020 2020 2020  lasses']:.      
-00011c70: 2020 2020 2020 2020 2020 2020 2020 6967                ig
-00011c80: 6e6f 7265 5f6c 6f67 203d 2054 7275 650a  nore_log = True.
-00011c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ca0: 2020 2020 6966 206f 705f 7479 7065 206e      if op_type n
-00011cb0: 6f74 2069 6e20 7265 732e 6b65 7973 2829  ot in res.keys()
-00011cc0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00011cd0: 2020 2020 2020 2020 2020 7265 735b 6f70            res[op
-00011ce0: 5f74 7970 655d 203d 207b 2749 4e54 3827  _type] = {'INT8'
-00011cf0: 3a20 302c 2027 4246 3136 273a 2030 2c20  : 0, 'BF16': 0, 
-00011d00: 2746 5033 3227 3a20 307d 0a20 2020 2020  'FP32': 0}.     
-00011d10: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00011d20: 6573 5b6f 705f 7479 7065 5d5b 2746 5033  es[op_type]['FP3
-00011d30: 3227 5d20 2b3d 2031 0a20 2020 2020 2020  2'] += 1.       
-00011d40: 2023 2073 686f 7720 7265 7375 6c74 7320   # show results 
-00011d50: 746f 2075 7365 7273 0a20 2020 2020 2020  to users.       
-00011d60: 2069 6620 6967 6e6f 7265 5f6c 6f67 3a0a   if ignore_log:.
-00011d70: 2020 2020 2020 2020 2020 2020 6c6f 6767              logg
-00011d80: 6572 2e69 6e66 6f28 2249 676e 6f72 6520  er.info("Ignore 
-00011d90: 4c61 7965 724e 6f72 6d2c 2049 6e73 7461  LayerNorm, Insta
-00011da0: 6e63 654e 6f72 6d33 6420 616e 6420 456d  nceNorm3d and Em
-00011db0: 6265 6464 696e 6720 7175 616e 7469 7a61  bedding quantiza
-00011dc0: 626c 6520 6f70 7322 205c 0a20 2020 2020  ble ops" \.     
-00011dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011de0: 2020 2022 2064 7565 2074 6f20 6163 6375     " due to accu
-00011df0: 7261 6379 2069 7373 7565 2069 6e20 5079  racy issue in Py
-00011e00: 546f 7263 682e 2229 0a0a 2020 2020 2020  Torch.")..      
-00011e10: 2020 6669 656c 645f 6e61 6d65 733d 5b22    field_names=["
-00011e20: 4f70 2054 7970 6522 2c20 2254 6f74 616c  Op Type", "Total
-00011e30: 222c 2022 494e 5438 222c 2022 4246 3136  ", "INT8", "BF16
-00011e40: 222c 2022 4650 3332 225d 0a20 2020 2020  ", "FP32"].     
-00011e50: 2020 206f 7574 7075 745f 6461 7461 203d     output_data =
-00011e60: 205b 5b0a 2020 2020 2020 2020 2020 2020   [[.            
-00011e70: 6f70 5f74 7970 652c 2073 756d 2872 6573  op_type, sum(res
-00011e80: 5b6f 705f 7479 7065 5d2e 7661 6c75 6573  [op_type].values
-00011e90: 2829 292c 0a20 2020 2020 2020 2020 2020  ()),.           
-00011ea0: 2072 6573 5b6f 705f 7479 7065 5d5b 2749   res[op_type]['I
-00011eb0: 4e54 3827 5d2c 2072 6573 5b6f 705f 7479  NT8'], res[op_ty
-00011ec0: 7065 5d5b 2742 4631 3627 5d2c 2072 6573  pe]['BF16'], res
-00011ed0: 5b6f 705f 7479 7065 5d5b 2746 5033 3227  [op_type]['FP32'
-00011ee0: 5d5d 0a20 2020 2020 2020 2066 6f72 206f  ]].        for o
-00011ef0: 705f 7479 7065 2069 6e20 7265 732e 6b65  p_type in res.ke
-00011f00: 7973 2829 5d0a 0a20 2020 2020 2020 2053  ys()]..        S
-00011f10: 7461 7469 7374 6963 7328 6f75 7470 7574  tatistics(output
-00011f20: 5f64 6174 612c 0a20 2020 2020 2020 2020  _data,.         
-00011f30: 2020 2020 2020 2020 2020 6865 6164 6572            header
-00011f40: 3d27 4d69 7865 6420 5072 6563 6973 696f  ='Mixed Precisio
-00011f50: 6e20 5374 6174 6973 7469 6373 272c 0a20  n Statistics',. 
-00011f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011f70: 2020 6669 656c 645f 6e61 6d65 733d 6669    field_names=fi
-00011f80: 656c 645f 6e61 6d65 7329 2e70 7269 6e74  eld_names).print
-00011f90: 5f73 7461 7428 290a 2020 2020 2020 2020  _stat().        
-00011fa0: 7365 6c66 2e6f 7074 7970 655f 7374 6174  self.optype_stat
-00011fb0: 6973 7469 6373 203d 2066 6965 6c64 5f6e  istics = field_n
-00011fc0: 616d 6573 2c20 6f75 7470 7574 5f64 6174  ames, output_dat
-00011fd0: 610a 0a0a 2020 2020 6465 6620 5f67 6574  a...    def _get
-00011fe0: 5f71 7561 6e74 697a 6162 6c65 5f6f 7073  _quantizable_ops
-00011ff0: 5f72 6563 7572 7369 7665 6c79 2873 656c  _recursively(sel
-00012000: 662c 206d 6f64 656c 2c20 7072 6566 6978  f, model, prefix
-00012010: 2c20 7175 616e 7469 7a61 626c 655f 6f70  , quantizable_op
-00012020: 7329 3a0a 2020 2020 2020 2020 2222 2254  s):.        """T
-00012030: 6869 7320 6973 2061 2068 656c 7065 7220  his is a helper 
-00012040: 6675 6e63 7469 6f6e 2066 6f72 2060 7175  function for `qu
-00012050: 6572 795f 6677 5f63 6170 6162 696c 6974  ery_fw_capabilit
-00012060: 7960 2c0a 2020 2020 2020 2020 2020 2061  y`,.           a
-00012070: 6e64 2069 7420 7769 6c6c 2067 6574 2061  nd it will get a
-00012080: 6c6c 2071 7561 6e74 697a 6162 6c65 206f  ll quantizable o
-00012090: 7073 2066 726f 6d20 6d6f 6465 6c2e 0a0a  ps from model...
-000120a0: 2020 2020 2020 2020 4172 6773 3a0a 2020          Args:.  
-000120b0: 2020 2020 2020 2020 2020 6d6f 6465 6c20            model 
-000120c0: 286f 626a 6563 7429 3a20 696e 7075 7420  (object): input 
-000120d0: 6d6f 6465 6c0a 2020 2020 2020 2020 2020  model.          
-000120e0: 2020 7072 6566 6978 2028 7374 7269 6e67    prefix (string
-000120f0: 293a 2070 7265 6669 7820 6f66 206f 7020  ): prefix of op 
-00012100: 6e61 6d65 0a20 2020 2020 2020 2020 2020  name.           
-00012110: 2071 7561 6e74 697a 6162 6c65 5f6f 7073   quantizable_ops
-00012120: 2028 6c69 7374 293a 206c 6973 7420 6f66   (list): list of
-00012130: 2071 7561 6e74 697a 6162 6c65 206f 7073   quantizable ops
-00012140: 2066 726f 6d20 6d6f 6465 6c20 696e 636c   from model incl
-00012150: 7564 6520 6f70 206e 616d 6520 616e 6420  ude op name and 
-00012160: 7479 7065 2e0a 0a20 2020 2020 2020 2052  type...        R
-00012170: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
-00012180: 2020 2020 4e6f 6e65 0a20 2020 2020 2020      None.       
-00012190: 2022 2222 0a0a 2020 2020 2020 2020 6d6f   """..        mo
-000121a0: 6475 6c65 5f64 6963 7420 3d20 6469 6374  dule_dict = dict
-000121b0: 286d 6f64 656c 2e6e 616d 6564 5f6d 6f64  (model.named_mod
-000121c0: 756c 6573 2829 290a 2020 2020 2020 2020  ules()).        
-000121d0: 666f 7220 6f70 5f6e 616d 652c 2063 6869  for op_name, chi
-000121e0: 6c64 2069 6e20 6d6f 6465 6c2e 6e61 6d65  ld in model.name
-000121f0: 645f 6d6f 6475 6c65 7328 293a 0a20 2020  d_modules():.   
-00012200: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00012210: 2e69 735f 6675 7365 645f 6d6f 6475 6c65  .is_fused_module
-00012220: 2863 6869 6c64 293a 0a20 2020 2020 2020  (child):.       
-00012230: 2020 2020 2020 2020 2066 6f72 206e 616d           for nam
-00012240: 652c 205f 2069 6e20 6368 696c 642e 6e61  e, _ in child.na
-00012250: 6d65 645f 6368 696c 6472 656e 2829 3a0a  med_children():.
-00012260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012270: 2020 2020 6d6f 6475 6c65 5f70 7265 6669      module_prefi
-00012280: 7820 3d20 6f70 5f6e 616d 6520 2b20 272e  x = op_name + '.
-00012290: 2720 2b20 6e61 6d65 0a20 2020 2020 2020  ' + name.       
-000122a0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-000122b0: 6d6f 6475 6c65 5f70 7265 6669 7820 696e  module_prefix in
-000122c0: 206d 6f64 756c 655f 6469 6374 3a0a 2020   module_dict:.  
-000122d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000122e0: 2020 2020 2020 6d6f 6475 6c65 5f64 6963        module_dic
-000122f0: 742e 706f 7028 6d6f 6475 6c65 5f70 7265  t.pop(module_pre
-00012300: 6669 7829 2020 2320 7265 6d6f 7665 2073  fix)  # remove s
-00012310: 7562 2d6d 6f64 756c 6573 206f 6620 6675  ub-modules of fu
-00012320: 7365 6420 6d6f 6475 6c65 730a 2020 2020  sed modules.    
-00012330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012340: 6966 206f 705f 6e61 6d65 2069 6e20 7365  if op_name in se
-00012350: 6c66 2e66 7573 6564 5f64 6963 743a 0a20  lf.fused_dict:. 
-00012360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012370: 2020 2020 2020 2073 656c 662e 6675 7365         self.fuse
-00012380: 645f 6469 6374 5b6f 705f 6e61 6d65 5d20  d_dict[op_name] 
-00012390: 3d20 5b73 656c 662e 6675 7365 645f 6469  = [self.fused_di
-000123a0: 6374 5b6f 705f 6e61 6d65 5d2c 206d 6f64  ct[op_name], mod
-000123b0: 756c 655f 7072 6566 6978 5d0a 2020 2020  ule_prefix].    
-000123c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000123d0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-000123e0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-000123f0: 6c66 2e66 7573 6564 5f64 6963 745b 6f70  lf.fused_dict[op
-00012400: 5f6e 616d 655d 203d 206d 6f64 756c 655f  _name] = module_
-00012410: 7072 6566 6978 0a20 2020 2020 2020 2066  prefix.        f
-00012420: 6f72 206f 705f 6e61 6d65 2c20 6368 696c  or op_name, chil
-00012430: 6420 696e 206d 6f64 756c 655f 6469 6374  d in module_dict
-00012440: 2e69 7465 6d73 2829 3a0a 2020 2020 2020  .items():.      
-00012450: 2020 2020 2020 2320 7468 6572 6520 6973        # there is
-00012460: 2061 6363 7572 6163 7920 6973 7375 6520   accuracy issue 
-00012470: 696e 2071 7561 6e74 697a 6564 204c 6179  in quantized Lay
-00012480: 6572 4e6f 726d 206f 7020 696e 2070 7974  erNorm op in pyt
-00012490: 6f72 6368 203c 312e 382e 312c 0a20 2020  orch <1.8.1,.   
-000124a0: 2020 2020 2020 2020 2023 2073 6f20 7265           # so re
-000124b0: 6d6f 7665 2069 7420 6865 7265 0a20 2020  move it here.   
-000124c0: 2020 2020 2020 2020 2069 6620 6f70 5f6e           if op_n
-000124d0: 616d 6520 696e 2073 656c 662e 6e6f 6e5f  ame in self.non_
-000124e0: 7175 616e 745f 6469 6374 5b27 736b 6970  quant_dict['skip
-000124f0: 7065 645f 6d6f 6475 6c65 5f6e 616d 6573  ped_module_names
-00012500: 275d 206f 7220 5c0a 2020 2020 2020 2020  '] or \.        
-00012510: 2020 2020 2020 7374 7228 6368 696c 642e        str(child.
-00012520: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
-00012530: 5f5f 2920 696e 205c 0a20 2020 2020 2020  __) in \.       
-00012540: 2020 2020 2020 2073 656c 662e 6e6f 6e5f         self.non_
-00012550: 7175 616e 745f 6469 6374 5b27 736b 6970  quant_dict['skip
-00012560: 7065 645f 6d6f 6475 6c65 5f63 6c61 7373  ped_module_class
-00012570: 6573 275d 3a0a 2020 2020 2020 2020 2020  es']:.          
-00012580: 2020 2020 2020 636f 6e74 696e 7565 0a20        continue. 
-00012590: 2020 2020 2020 2020 2020 2069 6620 7479             if ty
-000125a0: 7065 2863 6869 6c64 2920 696e 2073 656c  pe(child) in sel
-000125b0: 662e 7768 6974 655f 6c69 7374 2061 6e64  f.white_list and
-000125c0: 2074 7970 6528 6368 696c 6429 2021 3d20   type(child) != 
-000125d0: 746f 7263 682e 6e6e 2e53 6571 7565 6e74  torch.nn.Sequent
-000125e0: 6961 6c20 616e 6420 5c0a 2020 2020 2020  ial and \.      
-000125f0: 2020 2020 2020 2020 7479 7065 2863 6869          type(chi
-00012600: 6c64 2920 213d 2074 6f72 6368 2e71 7561  ld) != torch.qua
-00012610: 6e74 697a 6174 696f 6e2e 7374 7562 732e  ntization.stubs.
-00012620: 4465 5175 616e 7453 7475 623a 0a20 2020  DeQuantStub:.   
-00012630: 2020 2020 2020 2020 2020 2020 2071 7561               qua
-00012640: 6e74 697a 6162 6c65 5f6f 7073 2e61 7070  ntizable_ops.app
-00012650: 656e 6428 0a20 2020 2020 2020 2020 2020  end(.           
-00012660: 2020 2020 2020 2020 2028 6f70 5f6e 616d           (op_nam
-00012670: 652c 2075 6e69 6679 5f6f 705f 7479 7065  e, unify_op_type
-00012680: 5f6d 6170 7069 6e67 5b73 7472 2863 6869  _mapping[str(chi
-00012690: 6c64 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e  ld.__class__.__n
-000126a0: 616d 655f 5f29 5d0a 2020 2020 2020 2020  ame__)].        
-000126b0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-000126c0: 7374 7228 6368 696c 642e 5f5f 636c 6173  str(child.__clas
-000126d0: 735f 5f2e 5f5f 6e61 6d65 5f5f 2920 696e  s__.__name__) in
-000126e0: 2075 6e69 6679 5f6f 705f 7479 7065 5f6d   unify_op_type_m
-000126f0: 6170 7069 6e67 2065 6c73 6520 7374 7228  apping else str(
-00012700: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00012710: 2020 2020 2020 2020 2020 6368 696c 642e            child.
-00012720: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
-00012730: 5f5f 2929 290a 0a20 2020 2064 6566 205f  __)))..    def _
-00012740: 6765 745f 7363 616c 655f 7a65 726f 706f  get_scale_zeropo
-00012750: 696e 7428 7365 6c66 2c20 6d6f 6465 6c2c  int(self, model,
-00012760: 2074 756e 655f 6366 6729 3a0a 2020 2020   tune_cfg):.    
-00012770: 2020 2020 2222 2267 6574 2061 6374 6976      """get activ
-00012780: 6174 696f 6e20 7363 616c 6520 616e 6420  ation scale and 
-00012790: 7a65 726f 5f70 6f69 6e74 2066 6f72 2063  zero_point for c
-000127a0: 6f6e 7665 7274 6564 206d 6f64 656c 2e0a  onverted model..
-000127b0: 0a20 2020 2020 2020 2041 7267 733a 0a20  .        Args:. 
-000127c0: 2020 2020 2020 2020 2020 206d 6f64 656c             model
-000127d0: 2028 6469 7229 3a20 496e 7438 206d 6f64   (dir): Int8 mod
-000127e0: 656c 2063 6f6e 7665 7274 6564 2066 726f  el converted fro
-000127f0: 6d20 6670 3332 206d 6f64 656c 2e0a 2020  m fp32 model..  
-00012800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012810: 2020 2020 2020 7363 616c 6520 616e 6420        scale and 
-00012820: 7a65 726f 5f70 6f69 6e74 2069 7320 7365  zero_point is se
-00012830: 7420 7769 7468 2063 616c 6962 7261 7469  t with calibrati
-00012840: 6f6e 2066 6f72 2065 6163 6820 6d6f 6475  on for each modu
-00012850: 6c65 0a20 2020 2020 2020 2020 2020 2074  le.            t
-00012860: 756e 655f 6366 6720 286f 626a 6563 7429  une_cfg (object)
-00012870: 3a20 5468 6973 2066 696c 6520 7361 7665  : This file save
-00012880: 7320 7363 616c 6520 616e 6420 7a65 726f  s scale and zero
-00012890: 5f70 6f69 6e74 206f 6620 5c0a 2020 2020  _point of \.    
-000128a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000128b0: 2020 2020 2020 2020 6f75 7470 7574 2061          output a
-000128c0: 6374 6976 6174 696f 6e20 6f66 2065 6163  ctivation of eac
-000128d0: 6820 7175 616e 7469 7a65 6420 6d6f 6475  h quantized modu
-000128e0: 6c65 2e0a 0a20 2020 2020 2020 2052 6574  le...        Ret
-000128f0: 7572 6e73 3a0a 2020 2020 2020 2020 2020  urns:.          
-00012900: 2020 4e6f 6e65 0a20 2020 2020 2020 2022    None.        "
-00012910: 2222 0a20 2020 2020 2020 206d 6f64 756c  "".        modul
-00012920: 6573 203d 2064 6963 7428 6d6f 6465 6c2e  es = dict(model.
-00012930: 6e61 6d65 645f 6d6f 6475 6c65 7328 2929  named_modules())
-00012940: 0a20 2020 2020 2020 2066 6f72 206b 6579  .        for key
-00012950: 2c20 7661 6c75 6520 696e 2074 756e 655f  , value in tune_
-00012960: 6366 675b 276f 7027 5d2e 6974 656d 7328  cfg['op'].items(
-00012970: 293a 0a20 2020 2020 2020 2020 2020 2069  ):.            i
-00012980: 6620 6861 7361 7474 7228 6d6f 6475 6c65  f hasattr(module
-00012990: 735b 6b65 795b 305d 5d2c 2027 7363 616c  s[key[0]], 'scal
-000129a0: 6527 293a 0a20 2020 2020 2020 2020 2020  e'):.           
-000129b0: 2020 2020 2076 616c 7565 5b27 6163 7469       value['acti
-000129c0: 7661 7469 6f6e 275d 5b27 7363 616c 6527  vation']['scale'
-000129d0: 5d20 3d20 666c 6f61 7428 6d6f 6475 6c65  ] = float(module
-000129e0: 735b 6b65 795b 305d 5d2e 7363 616c 6529  s[key[0]].scale)
-000129f0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00012a00: 6861 7361 7474 7228 6d6f 6475 6c65 735b  hasattr(modules[
-00012a10: 6b65 795b 305d 5d2c 2027 7a65 726f 5f70  key[0]], 'zero_p
-00012a20: 6f69 6e74 2729 3a0a 2020 2020 2020 2020  oint'):.        
-00012a30: 2020 2020 2020 2020 7661 6c75 655b 2761          value['a
-00012a40: 6374 6976 6174 696f 6e27 5d5b 277a 6572  ctivation']['zer
-00012a50: 6f5f 706f 696e 7427 5d20 3d20 696e 7428  o_point'] = int(
-00012a60: 6d6f 6475 6c65 735b 6b65 795b 305d 5d2e  modules[key[0]].
-00012a70: 7a65 726f 5f70 6f69 6e74 290a 0a20 2020  zero_point)..   
-00012a80: 2064 6566 205f 7072 655f 6576 616c 5f68   def _pre_eval_h
-00012a90: 6f6f 6b28 7365 6c66 2c20 6d6f 6465 6c2c  ook(self, model,
-00012aa0: 206f 705f 6c69 7374 3d4e 6f6e 652c 2069   op_list=None, i
-00012ab0: 7465 7261 7469 6f6e 5f6c 6973 743d 4e6f  teration_list=No
-00012ac0: 6e65 293a 0a20 2020 2020 2020 2022 2222  ne):.        """
-00012ad0: 5468 6520 6675 6e63 7469 6f6e 2069 7320  The function is 
-00012ae0: 7573 6564 2074 6f20 646f 2073 6f6d 6520  used to do some 
-00012af0: 7072 6570 726f 6365 7373 696f 6e20 6265  preprocession be
-00012b00: 666f 7265 2065 7661 6c75 6174 696f 6e20  fore evaluation 
-00012b10: 7068 6173 652e 0a20 2020 2020 2020 2020  phase..         
-00012b20: 2020 4865 7265 2c20 6974 2075 7365 6420    Here, it used 
-00012b30: 746f 2061 6464 2068 6f6f 6b20 666f 7220  to add hook for 
-00012b40: 6475 6d70 206f 7574 7075 7420 7465 6e73  dump output tens
-00012b50: 6f72 2066 6f72 2071 7561 6e74 697a 6162  or for quantizab
-00012b60: 6c65 206f 7073 2e0a 0a20 2020 2020 2020  le ops...       
-00012b70: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
-00012b80: 2020 2020 6d6f 6465 6c20 286f 626a 6563      model (objec
-00012b90: 7429 3a20 696e 7075 7420 6d6f 6465 6c0a  t): input model.
-00012ba0: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
-00012bb0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00012bc0: 6d6f 6465 6c20 286f 626a 6563 7429 3a20  model (object): 
-00012bd0: 6d6f 6465 6c20 7769 7468 2068 6f6f 6b0a  model with hook.
-00012be0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00012bf0: 2020 2020 6672 6f6d 2061 6263 2069 6d70      from abc imp
-00012c00: 6f72 7420 4142 434d 6574 610a 0a20 2020  ort ABCMeta..   
-00012c10: 2020 2020 2064 6566 205f 7769 7468 5f61       def _with_a
-00012c20: 7267 7328 636c 735f 6f72 5f73 656c 662c  rgs(cls_or_self,
-00012c30: 202a 2a6b 7761 7267 7329 3a0a 2020 2020   **kwargs):.    
-00012c40: 2020 2020 2020 2020 7222 2222 5772 6170          r"""Wrap
-00012c50: 7065 7220 7468 6174 2061 6c6c 6f77 7320  per that allows 
-00012c60: 6372 6561 7469 6f6e 206f 6620 636c 6173  creation of clas
-00012c70: 7320 6661 6374 6f72 6965 732e 0a0a 2020  s factories...  
-00012c80: 2020 2020 2020 2020 2020 5468 6973 2063            This c
-00012c90: 616e 2062 6520 7573 6566 756c 2077 6865  an be useful whe
-00012ca0: 6e20 7468 6572 6520 6973 2061 206e 6565  n there is a nee
-00012cb0: 6420 746f 2063 7265 6174 6520 636c 6173  d to create clas
-00012cc0: 7365 7320 7769 7468 2074 6865 2073 616d  ses with the sam
-00012cd0: 650a 2020 2020 2020 2020 2020 2020 636f  e.            co
-00012ce0: 6e73 7472 7563 746f 7220 6172 6775 6d65  nstructor argume
-00012cf0: 6e74 732c 2062 7574 2064 6966 6665 7265  nts, but differe
-00012d00: 6e74 2069 6e73 7461 6e63 6573 2e0a 0a20  nt instances... 
-00012d10: 2020 2020 2020 2020 2020 2045 7861 6d70             Examp
-00012d20: 6c65 3a3a 0a0a 2020 2020 2020 2020 2020  le::..          
-00012d30: 2020 2020 2020 3e3e 3e20 466f 6f2e 7769        >>> Foo.wi
-00012d40: 7468 5f61 7267 7320 3d20 636c 6173 736d  th_args = classm
-00012d50: 6574 686f 6428 5f77 6974 685f 6172 6773  ethod(_with_args
-00012d60: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00012d70: 2020 3e3e 3e20 666f 6f5f 6275 696c 6465    >>> foo_builde
-00012d80: 7220 3d20 466f 6f2e 7769 7468 5f61 7267  r = Foo.with_arg
-00012d90: 7328 613d 332c 2062 3d34 292e 7769 7468  s(a=3, b=4).with
-00012da0: 5f61 7267 7328 616e 7377 6572 3d34 3229  _args(answer=42)
-00012db0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00012dc0: 203e 3e3e 2066 6f6f 5f69 6e73 7461 6e63   >>> foo_instanc
-00012dd0: 6531 203d 2066 6f6f 5f62 7569 6c64 6572  e1 = foo_builder
-00012de0: 2829 0a20 2020 2020 2020 2020 2020 2020  ().             
-00012df0: 2020 203e 3e3e 2066 6f6f 5f69 6e73 7461     >>> foo_insta
-00012e00: 6e63 6532 203d 2066 6f6f 5f62 7569 6c64  nce2 = foo_build
-00012e10: 6572 2829 0a20 2020 2020 2020 2020 2020  er().           
-00012e20: 2020 2020 203e 3e3e 2069 6428 666f 6f5f       >>> id(foo_
-00012e30: 696e 7374 616e 6365 3129 203d 3d20 6964  instance1) == id
-00012e40: 2866 6f6f 5f69 6e73 7461 6e63 6532 290a  (foo_instance2).
-00012e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012e60: 4661 6c73 650a 2020 2020 2020 2020 2020  False.          
-00012e70: 2020 2222 220a 2020 2020 2020 2020 2020    """.          
-00012e80: 2020 636c 6173 7320 5f50 6172 7469 616c    class _Partial
-00012e90: 5772 6170 7065 7228 6f62 6a65 6374 293a  Wrapper(object):
-00012ea0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00012eb0: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
-00012ec0: 6c66 2c20 7029 3a0a 2020 2020 2020 2020  lf, p):.        
-00012ed0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00012ee0: 2e70 203d 2070 0a0a 2020 2020 2020 2020  .p = p..        
-00012ef0: 2020 2020 2020 2020 6465 6620 5f5f 6361          def __ca
-00012f00: 6c6c 5f5f 2873 656c 662c 202a 6172 6773  ll__(self, *args
-00012f10: 2c20 2a2a 6b65 7977 6f72 6473 293a 0a20  , **keywords):. 
-00012f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012f30: 2020 2072 6574 7572 6e20 7365 6c66 2e70     return self.p
-00012f40: 282a 6172 6773 2c20 2a2a 6b65 7977 6f72  (*args, **keywor
-00012f50: 6473 290a 0a20 2020 2020 2020 2020 2020  ds)..           
-00012f60: 2020 2020 2064 6566 205f 5f72 6570 725f       def __repr_
-00012f70: 5f28 7365 6c66 293a 0a20 2020 2020 2020  _(self):.       
-00012f80: 2020 2020 2020 2020 2020 2020 2072 6574               ret
-00012f90: 7572 6e20 7365 6c66 2e70 2e5f 5f72 6570  urn self.p.__rep
-00012fa0: 725f 5f28 290a 0a20 2020 2020 2020 2020  r__()..         
-00012fb0: 2020 2020 2020 2077 6974 685f 6172 6773         with_args
-00012fc0: 203d 205f 7769 7468 5f61 7267 730a 0a20   = _with_args.. 
-00012fd0: 2020 2020 2020 2020 2020 2072 203d 205f             r = _
-00012fe0: 5061 7274 6961 6c57 7261 7070 6572 2870  PartialWrapper(p
-00012ff0: 6172 7469 616c 2863 6c73 5f6f 725f 7365  artial(cls_or_se
-00013000: 6c66 2c20 2a2a 6b77 6172 6773 2929 0a20  lf, **kwargs)). 
-00013010: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00013020: 6e20 720a 0a20 2020 2020 2020 2041 4243  n r..        ABC
-00013030: 203d 2041 4243 4d65 7461 2873 7472 2822   = ABCMeta(str("
-00013040: 4142 4322 292c 2028 6f62 6a65 6374 2c20  ABC"), (object, 
-00013050: 292c 207b 7d29 2020 2320 636f 6d70 6174  ), {})  # compat
-00013060: 6962 6c65 2077 6974 6820 5079 7468 6f6e  ible with Python
-00013070: 2032 202a 616e 642a 2033 3a0a 0a20 2020   2 *and* 3:..   
-00013080: 2020 2020 2063 6c61 7373 205f 5265 636f       class _Reco
-00013090: 7264 696e 674f 6273 6572 7665 7228 4142  rdingObserver(AB
-000130a0: 432c 2074 6f72 6368 2e6e 6e2e 4d6f 6475  C, torch.nn.Modu
-000130b0: 6c65 293a 0a20 2020 2020 2020 2020 2020  le):.           
-000130c0: 2022 2222 5468 6520 6d6f 6475 6c65 2069   """The module i
-000130d0: 7320 6d61 696e 6c79 2066 6f72 2064 6562  s mainly for deb
-000130e0: 7567 2061 6e64 2072 6563 6f72 6473 2074  ug and records t
-000130f0: 6865 2074 656e 736f 7220 7661 6c75 6573  he tensor values
-00013100: 2064 7572 696e 6720 7275 6e74 696d 652e   during runtime.
-00013110: 0a0a 2020 2020 2020 2020 2020 2020 4172  ..            Ar
-00013120: 6773 3a0a 2020 2020 2020 2020 2020 2020  gs:.            
-00013130: 2020 2020 6974 6572 6174 696f 6e5f 6c69      iteration_li
-00013140: 7374 2028 6c69 7374 2c20 6f70 7469 6f6e  st (list, option
-00013150: 616c 293a 2069 6e64 6578 7320 6f66 2069  al): indexs of i
-00013160: 7465 7261 7469 6f6e 2077 6869 6368 2074  teration which t
-00013170: 6f20 6475 6d70 2074 656e 736f 722e 0a20  o dump tensor.. 
-00013180: 2020 2020 2020 2020 2020 2022 2222 0a20             """. 
-00013190: 2020 2020 2020 2020 2020 2064 6566 205f             def _
-000131a0: 5f69 6e69 745f 5f28 7365 6c66 2c20 6974  _init__(self, it
-000131b0: 6572 6174 696f 6e5f 6c69 7374 3d4e 6f6e  eration_list=Non
-000131c0: 652c 202a 2a6b 7761 7267 7329 3a0a 2020  e, **kwargs):.  
-000131d0: 2020 2020 2020 2020 2020 2020 2020 7375                su
-000131e0: 7065 7228 5f52 6563 6f72 6469 6e67 4f62  per(_RecordingOb
-000131f0: 7365 7276 6572 2c20 7365 6c66 292e 5f5f  server, self).__
-00013200: 696e 6974 5f5f 282a 2a6b 7761 7267 7329  init__(**kwargs)
-00013210: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00013220: 2073 656c 662e 6f75 7470 7574 5f74 656e   self.output_ten
-00013230: 736f 7273 5f64 6963 7420 3d20 4f72 6465  sors_dict = Orde
-00013240: 7265 6444 6963 7428 290a 2020 2020 2020  redDict().      
-00013250: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
-00013260: 7572 7265 6e74 5f69 7465 7220 3d20 310a  urrent_iter = 1.
-00013270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013280: 7365 6c66 2e69 7465 7261 7469 6f6e 5f6c  self.iteration_l
-00013290: 6973 7420 3d20 6974 6572 6174 696f 6e5f  ist = iteration_
-000132a0: 6c69 7374 0a0a 2020 2020 2020 2020 2020  list..          
-000132b0: 2020 6465 6620 666f 7277 6172 6428 7365    def forward(se
-000132c0: 6c66 2c20 7829 3a0a 2020 2020 2020 2020  lf, x):.        
-000132d0: 2020 2020 2020 2020 6966 2028 7365 6c66          if (self
-000132e0: 2e69 7465 7261 7469 6f6e 5f6c 6973 7420  .iteration_list 
-000132f0: 6973 204e 6f6e 6520 616e 6420 7365 6c66  is None and self
-00013300: 2e63 7572 7265 6e74 5f69 7465 7220 3d3d  .current_iter ==
-00013310: 2031 2920 6f72 205c 0a20 2020 2020 2020   1) or \.       
-00013320: 2020 2020 2020 2020 2020 2020 2028 7365               (se
-00013330: 6c66 2e69 7465 7261 7469 6f6e 5f6c 6973  lf.iteration_lis
-00013340: 7420 6973 206e 6f74 204e 6f6e 6520 616e  t is not None an
-00013350: 640a 2020 2020 2020 2020 2020 2020 2020  d.              
-00013360: 2020 2020 2020 2073 656c 662e 6375 7272         self.curr
-00013370: 656e 745f 6974 6572 2069 6e20 7365 6c66  ent_iter in self
-00013380: 2e69 7465 7261 7469 6f6e 5f6c 6973 7429  .iteration_list)
-00013390: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000133a0: 2020 2020 2020 6966 2074 7970 6528 7829        if type(x)
-000133b0: 2069 7320 7475 706c 6520 6f72 2074 7970   is tuple or typ
-000133c0: 6528 7829 2069 7320 6c69 7374 3a0a 2020  e(x) is list:.  
-000133d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000133e0: 2020 2020 2020 7365 6c66 2e6f 7574 7075        self.outpu
-000133f0: 745f 7465 6e73 6f72 735f 6469 6374 5b73  t_tensors_dict[s
-00013400: 656c 662e 6375 7272 656e 745f 6974 6572  elf.current_iter
-00013410: 5d20 3d20 5c0a 2020 2020 2020 2020 2020  ] = \.          
-00013420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013430: 2020 5b69 2e74 6f28 2263 7075 2229 2069    [i.to("cpu") i
-00013440: 6620 692e 6465 7669 6365 2021 3d20 2763  f i.device != 'c
-00013450: 7075 2720 656c 7365 2069 2e63 6c6f 6e65  pu' else i.clone
-00013460: 2829 2066 6f72 2069 2069 6e20 785d 0a20  () for i in x]. 
-00013470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013480: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00013490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000134a0: 2073 656c 662e 6f75 7470 7574 5f74 656e   self.output_ten
-000134b0: 736f 7273 5f64 6963 745b 7365 6c66 2e63  sors_dict[self.c
-000134c0: 7572 7265 6e74 5f69 7465 725d 203d 205c  urrent_iter] = \
-000134d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000134e0: 2020 2020 2020 2020 2020 2020 2078 2e74               x.t
-000134f0: 6f28 2263 7075 2229 2069 6620 782e 6465  o("cpu") if x.de
-00013500: 7669 6365 2021 3d20 2263 7075 2220 656c  vice != "cpu" el
-00013510: 7365 2078 2e63 6c6f 6e65 2829 0a20 2020  se x.clone().   
-00013520: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-00013530: 662e 6375 7272 656e 745f 6974 6572 202b  f.current_iter +
-00013540: 3d20 310a 2020 2020 2020 2020 2020 2020  = 1.            
-00013550: 2020 2020 7265 7475 726e 2078 0a0a 2020      return x..  
-00013560: 2020 2020 2020 2020 2020 4074 6f72 6368            @torch
-00013570: 2e6a 6974 2e65 7870 6f72 740a 2020 2020  .jit.export.    
-00013580: 2020 2020 2020 2020 6465 6620 6765 745f          def get_
-00013590: 7465 6e73 6f72 5f76 616c 7565 2873 656c  tensor_value(sel
-000135a0: 6629 3a0a 2020 2020 2020 2020 2020 2020  f):.            
-000135b0: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-000135c0: 6f75 7470 7574 5f74 656e 736f 7273 5f64  output_tensors_d
-000135d0: 6963 740a 0a20 2020 2020 2020 2020 2020  ict..           
-000135e0: 2077 6974 685f 6172 6773 203d 2063 6c61   with_args = cla
-000135f0: 7373 6d65 7468 6f64 285f 7769 7468 5f61  ssmethod(_with_a
-00013600: 7267 7329 0a0a 2020 2020 2020 2020 6465  rgs)..        de
-00013610: 6620 5f6f 6273 6572 7665 725f 666f 7277  f _observer_forw
-00013620: 6172 645f 686f 6f6b 286d 6f64 756c 652c  ard_hook(module,
-00013630: 2069 6e70 7574 2c20 6f75 7470 7574 293a   input, output):
-00013640: 0a20 2020 2020 2020 2020 2020 2022 2222  .            """
-00013650: 466f 7277 6172 6420 686f 6f6b 2074 6861  Forward hook tha
-00013660: 7420 6361 6c6c 7320 6f62 7365 7276 6572  t calls observer
-00013670: 206f 6e20 7468 6520 6f75 7470 7574 0a0a   on the output..
-00013680: 2020 2020 2020 2020 2020 2020 4172 6773              Args
-00013690: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000136a0: 2020 6d6f 6475 6c65 2028 6f62 6a65 6374    module (object
-000136b0: 293a 2069 6e70 7574 206d 6f64 756c 650a  ): input module.
-000136c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000136d0: 696e 7075 7420 286f 626a 6563 7429 3a20  input (object): 
-000136e0: 6d6f 6475 6c65 2069 6e70 7574 0a20 2020  module input.   
-000136f0: 2020 2020 2020 2020 2020 2020 206f 7574               out
-00013700: 7075 7420 286f 626a 6563 7429 3a20 6d6f  put (object): mo
-00013710: 6475 6c65 206f 7574 7075 740a 0a20 2020  dule output..   
-00013720: 2020 2020 2020 2020 2052 6574 7572 6e73           Returns
-00013730: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00013740: 2020 6d6f 6475 6c65 206f 7574 7075 7420    module output 
-00013750: 7465 6e73 6f72 2028 6f62 6a65 6374 290a  tensor (object).
-00013760: 2020 2020 2020 2020 2020 2020 2222 220a              """.
-00013770: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00013780: 726e 206d 6f64 756c 652e 6163 7469 7661  rn module.activa
-00013790: 7469 6f6e 5f70 6f73 745f 7072 6f63 6573  tion_post_proces
-000137a0: 7328 6f75 7470 7574 290a 0a20 2020 2020  s(output)..     
-000137b0: 2020 2064 6566 205f 6164 645f 6f62 7365     def _add_obse
-000137c0: 7276 6572 5f28 6d6f 6475 6c65 2c20 6f70  rver_(module, op
-000137d0: 5f6c 6973 743d 4e6f 6e65 2c20 7072 6566  _list=None, pref
-000137e0: 6978 3d22 2229 3a0a 2020 2020 2020 2020  ix=""):.        
-000137f0: 2020 2020 2222 2241 6464 206f 6273 6572      """Add obser
-00013800: 7665 7220 666f 7220 7468 6520 6c65 6166  ver for the leaf
-00013810: 2063 6869 6c64 206f 6620 7468 6520 6d6f   child of the mo
-00013820: 6475 6c65 2e0a 0a20 2020 2020 2020 2020  dule...         
-00013830: 2020 2020 2020 5468 6973 2066 756e 6374        This funct
-00013840: 696f 6e20 696e 7365 7274 206f 6273 6572  ion insert obser
-00013850: 7665 7220 6d6f 6475 6c65 2074 6f20 616c  ver module to al
-00013860: 6c20 6c65 6166 2063 6869 6c64 206d 6f64  l leaf child mod
-00013870: 756c 6520 7468 6174 0a20 2020 2020 2020  ule that.       
-00013880: 2020 2020 2020 2020 6861 7320 6120 7661          has a va
-00013890: 6c69 6420 7163 6f6e 6669 6720 6174 7472  lid qconfig attr
-000138a0: 6962 7574 652e 0a0a 2020 2020 2020 2020  ibute...        
-000138b0: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
-000138c0: 2020 2020 2020 2020 2020 6d6f 6475 6c65            module
-000138d0: 2028 6f62 6a65 6374 293a 2069 6e70 7574   (object): input
-000138e0: 206d 6f64 756c 6520 7769 7468 2071 636f   module with qco
-000138f0: 6e66 6967 2061 7474 7269 6275 7465 7320  nfig attributes 
-00013900: 666f 7220 616c 6c20 7468 6520 6c65 6166  for all the leaf
-00013910: 206d 6f64 756c 6573 2074 6861 740a 2020   modules that.  
-00013920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013930: 2020 2020 2020 2020 2020 2020 2020 2077                 w
-00013940: 6520 7761 6e74 2074 6f20 6475 6d70 2074  e want to dump t
-00013950: 656e 736f 720a 2020 2020 2020 2020 2020  ensor.          
-00013960: 2020 2020 2020 6f70 5f6c 6973 7420 286c        op_list (l
-00013970: 6973 742c 206f 7074 696f 6e61 6c29 3a20  ist, optional): 
-00013980: 6c69 7374 206f 6620 6f70 7320 7768 6963  list of ops whic
-00013990: 6820 746f 2062 6520 6475 6d70 6564 2069  h to be dumped i
-000139a0: 6e20 6d6f 6475 6c65 0a20 2020 2020 2020  n module.       
-000139b0: 2020 2020 2020 2020 2070 7265 6669 7820           prefix 
-000139c0: 2873 7472 696e 6729 3a20 6e61 6d65 206f  (string): name o
-000139d0: 6620 6d6f 6475 6c65 0a0a 2020 2020 2020  f module..      
-000139e0: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
-000139f0: 2020 2020 2020 2020 2020 2020 2020 204e                 N
-00013a00: 6f6e 652c 206d 6f64 756c 6520 6973 206d  one, module is m
-00013a10: 6f64 6966 6965 6420 696e 706c 6163 6520  odified inplace 
-00013a20: 7769 7468 2061 6464 6564 206f 6273 6572  with added obser
-00013a30: 7665 7220 6d6f 6475 6c65 7320 616e 6420  ver modules and 
-00013a40: 666f 7277 6172 645f 686f 6f6b 730a 2020  forward_hooks.  
-00013a50: 2020 2020 2020 2020 2020 2222 220a 2020            """.  
-00013a60: 2020 2020 2020 2020 2020 666f 7220 6e61            for na
-00013a70: 6d65 2c20 6368 696c 6420 696e 206d 6f64  me, child in mod
-00013a80: 756c 652e 6e61 6d65 645f 6368 696c 6472  ule.named_childr
-00013a90: 656e 2829 3a0a 2020 2020 2020 2020 2020  en():.          
-00013aa0: 2020 2020 2020 6f70 5f6e 616d 6520 3d20        op_name = 
-00013ab0: 6e61 6d65 2069 6620 7072 6566 6978 203d  name if prefix =
-00013ac0: 3d20 2222 2065 6c73 6520 7072 6566 6978  = "" else prefix
-00013ad0: 202b 2022 2e22 202b 206e 616d 650a 2020   + "." + name.  
-00013ae0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00013af0: 2069 7369 6e73 7461 6e63 6528 6368 696c   isinstance(chil
-00013b00: 642c 2074 6f72 6368 2e6e 6e2e 7175 616e  d, torch.nn.quan
-00013b10: 7469 7a65 642e 466c 6f61 7446 756e 6374  tized.FloatFunct
-00013b20: 696f 6e61 6c29 2061 6e64 205c 0a20 2020  ional) and \.   
-00013b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013b40: 2020 2020 2020 2020 2020 286f 705f 6c69            (op_li
-00013b50: 7374 2069 7320 4e6f 6e65 206f 7220 6f70  st is None or op
-00013b60: 5f6e 616d 6520 696e 206f 705f 6c69 7374  _name in op_list
-00013b70: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00013b80: 2020 2020 2020 2069 6620 6861 7361 7474         if hasatt
-00013b90: 7228 6368 696c 642c 2027 7163 6f6e 6669  r(child, 'qconfi
-00013ba0: 6727 2920 616e 6420 6368 696c 642e 7163  g') and child.qc
-00013bb0: 6f6e 6669 6720 6973 206e 6f74 204e 6f6e  onfig is not Non
-00013bc0: 6520 616e 6420 280a 2020 2020 2020 2020  e and (.        
-00013bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013be0: 2020 2020 6f70 5f6c 6973 7420 6973 204e      op_list is N
-00013bf0: 6f6e 6520 6f72 206f 705f 6e61 6d65 2069  one or op_name i
-00013c00: 6e20 6f70 5f6c 6973 7429 3a0a 2020 2020  n op_list):.    
-00013c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013c20: 2020 2020 6368 696c 642e 6163 7469 7661      child.activa
-00013c30: 7469 6f6e 5f70 6f73 745f 7072 6f63 6573  tion_post_proces
-00013c40: 7320 3d20 5c0a 2020 2020 2020 2020 2020  s = \.          
-00013c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013c60: 2020 6368 696c 642e 7163 6f6e 6669 672e    child.qconfig.
-00013c70: 6163 7469 7661 7469 6f6e 2829 0a20 2020  activation().   
-00013c80: 2020 2020 2020 2020 2020 2020 2065 6c69               eli
-00013c90: 6620 6861 7361 7474 7228 6368 696c 642c  f hasattr(child,
-00013ca0: 2027 7163 6f6e 6669 6727 2920 616e 6420   'qconfig') and 
-00013cb0: 6368 696c 642e 7163 6f6e 6669 6720 6973  child.qconfig is
-00013cc0: 206e 6f74 204e 6f6e 6520 616e 6420 5c0a   not None and \.
-00013cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013ce0: 2020 2020 2020 2020 286f 705f 6c69 7374          (op_list
-00013cf0: 2069 7320 4e6f 6e65 206f 7220 6f70 5f6e   is None or op_n
-00013d00: 616d 6520 696e 206f 705f 6c69 7374 293a  ame in op_list):
-00013d10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00013d20: 2020 2020 2023 206f 6273 6572 7665 7220       # observer 
-00013d30: 616e 6420 686f 6f6b 2077 696c 6c20 6265  and hook will be
-00013d40: 2067 6f6e 6520 6166 7465 7220 7765 2073   gone after we s
-00013d50: 7761 7020 7468 6520 6d6f 6475 6c65 0a20  wap the module. 
+00010f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010fa0: 2020 2020 2020 2072 656d 6f76 655f 7163         remove_qc
+00010fb0: 6f6e 6669 673d 4661 6c73 6529 0a20 2020  onfig=False).   
+00010fc0: 2020 2020 2020 2020 2020 2020 205f 7072               _pr
+00010fd0: 6f70 6167 6174 655f 7163 6f6e 6669 6728  opagate_qconfig(
+00010fe0: 715f 6d6f 6465 6c2e 5f6d 6f64 656c 2c20  q_model._model, 
+00010ff0: 6f70 5f63 6667 7329 0a20 2020 2020 2020  op_cfgs).       
+00011000: 2020 2020 2020 2020 2061 6464 5f6f 6273           add_obs
+00011010: 6572 7665 725f 2871 5f6d 6f64 656c 2e5f  erver_(q_model._
+00011020: 6d6f 6465 6c2c 2073 656c 662e 7768 6974  model, self.whit
+00011030: 655f 6c69 7374 2c0a 2020 2020 2020 2020  e_list,.        
+00011040: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011060: 2020 2020 2020 2020 2073 6574 2873 656c           set(sel
+00011070: 662e 715f 6d61 7070 696e 672e 7661 6c75  f.q_mapping.valu
+00011080: 6573 2829 2929 0a20 2020 2020 2020 2020  es())).         
+00011090: 2020 2065 6c73 653a 2020 2320 7072 6167     else:  # prag
+000110a0: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
+000110b0: 2020 2020 2020 2020 2020 2020 2061 6464               add
+000110c0: 5f6f 6273 6572 7665 725f 2871 5f6d 6f64  _observer_(q_mod
+000110d0: 656c 2e5f 6d6f 6465 6c29 0a20 2020 2020  el._model).     
+000110e0: 2020 2020 2020 2020 2020 2074 6f72 6368             torch
+000110f0: 2e71 7561 6e74 697a 6174 696f 6e2e 636f  .quantization.co
+00011100: 6e76 6572 7428 715f 6d6f 6465 6c2e 5f6d  nvert(q_model._m
+00011110: 6f64 656c 2c20 7365 6c66 2e71 5f6d 6170  odel, self.q_map
+00011120: 7069 6e67 2c20 696e 706c 6163 653d 5472  ping, inplace=Tr
+00011130: 7565 290a 2020 2020 2020 2020 2020 2020  ue).            
+00011140: 2320 715f 6675 6e63 2063 616e 2062 6520  # q_func can be 
+00011150: 6372 6561 7465 6420 6279 206e 6575 7261  created by neura
+00011160: 6c5f 636f 6d70 7265 7373 6f72 2069 6e74  l_compressor int
+00011170: 6572 6e61 6c20 6f72 2070 6173 7365 6420  ernal or passed 
+00011180: 6279 2075 7365 722e 2049 7427 7320 6372  by user. It's cr
+00011190: 6974 6963 616c 2074 6f0a 2020 2020 2020  itical to.      
+000111a0: 2020 2020 2020 2320 6469 7374 696e 6775        # distingu
+000111b0: 6973 6820 686f 7720 715f 6675 6e63 2069  ish how q_func i
+000111c0: 7320 7061 7373 6564 2073 696e 6365 206e  s passed since n
+000111d0: 6575 7261 6c5f 636f 6d70 7265 7373 6f72  eural_compressor
+000111e0: 2062 7569 6c74 2d69 6e20 6675 6e63 7469   built-in functi
+000111f0: 6f6e 7320 6163 6365 7074 206e 6575 7261  ons accept neura
+00011200: 6c5f 636f 6d70 7265 7373 6f72 0a20 2020  l_compressor.   
+00011210: 2020 2020 2020 2020 2023 206d 6f64 656c           # model
+00011220: 2061 6e64 2075 7365 7220 6465 6669 6e65   and user define
+00011230: 6420 6675 6e63 2073 686f 756c 6420 6163  d func should ac
+00011240: 6365 7074 2066 7261 6d65 776f 726b 206d  cept framework m
+00011250: 6f64 656c 2e0a 2020 2020 2020 2020 2020  odel..          
+00011260: 2020 715f 6d6f 6465 6c2e 5f6d 6f64 656c    q_model._model
+00011270: 203d 2071 5f66 756e 6328 0a20 2020 2020   = q_func(.     
+00011280: 2020 2020 2020 2020 2020 2071 5f6d 6f64             q_mod
+00011290: 656c 2069 6620 6765 7461 7474 7228 715f  el if getattr(q_
+000112a0: 6675 6e63 2c20 2762 7569 6c74 696e 272c  func, 'builtin',
+000112b0: 204e 6f6e 6529 2065 6c73 6520 715f 6d6f   None) else q_mo
+000112c0: 6465 6c2e 5f6d 6f64 656c 290a 2020 2020  del._model).    
+000112d0: 2020 2020 2020 2020 6173 7365 7274 2071          assert q
+000112e0: 5f6d 6f64 656c 2e5f 6d6f 6465 6c20 6973  _model._model is
+000112f0: 206e 6f74 204e 6f6e 652c 2022 506c 6561   not None, "Plea
+00011300: 7365 2072 6574 7572 6e20 6120 7472 6169  se return a trai
+00011310: 6e65 6420 6d6f 6465 6c20 696e 2074 7261  ned model in tra
+00011320: 696e 2066 756e 6374 696f 6e21 220a 2020  in function!".  
+00011330: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
+00011340: 6c2e 5f6d 6f64 656c 2e65 7661 6c28 290a  l._model.eval().
+00011350: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00011360: 2e61 7070 726f 6163 6820 3d3d 2027 7175  .approach == 'qu
+00011370: 616e 745f 6177 6172 655f 7472 6169 6e69  ant_aware_traini
+00011380: 6e67 273a 0a20 2020 2020 2020 2020 2020  ng':.           
+00011390: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
+000113a0: 696f 6e2e 636f 6e76 6572 7428 715f 6d6f  ion.convert(q_mo
+000113b0: 6465 6c2e 5f6d 6f64 656c 2c20 696e 706c  del._model, inpl
+000113c0: 6163 653d 5472 7565 290a 2020 2020 2020  ace=True).      
+000113d0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+000113e0: 2020 2020 746f 7263 682e 7175 616e 7469      torch.quanti
+000113f0: 7a61 7469 6f6e 2e63 6f6e 7665 7274 2871  zation.convert(q
+00011400: 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c 206d  _model._model, m
+00011410: 6170 7069 6e67 3d73 656c 662e 715f 6d61  apping=self.q_ma
+00011420: 7070 696e 672c 2069 6e70 6c61 6365 3d54  pping, inplace=T
+00011430: 7275 6529 0a0a 2020 2020 2020 2020 6966  rue)..        if
+00011440: 206c 656e 2873 656c 662e 7475 6e65 5f63   len(self.tune_c
+00011450: 6667 5b27 6266 3136 5f6f 7073 5f6c 6973  fg['bf16_ops_lis
+00011460: 7427 5d29 203e 2030 2061 6e64 205c 0a20  t']) > 0 and \. 
+00011470: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
+00011480: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
+00011490: 203e 3d20 5665 7273 696f 6e28 2231 2e31   >= Version("1.1
+000114a0: 312e 3022 292e 7265 6c65 6173 6529 2061  1.0").release) a
+000114b0: 6e64 205c 0a20 2020 2020 2020 2020 2020  nd \.           
+000114c0: 2028 4370 7549 6e66 6f28 292e 6266 3136   (CpuInfo().bf16
+000114d0: 206f 7220 6f73 2e67 6574 656e 7628 2746   or os.getenv('F
+000114e0: 4f52 4345 5f42 4631 3627 2920 3d3d 2027  ORCE_BF16') == '
+000114f0: 3127 293a 2023 2070 7261 676d 613a 206e  1'): # pragma: n
+00011500: 6f20 636f 7665 720a 2020 2020 2020 2020  o cover.        
+00011510: 2020 2020 715f 6d6f 6465 6c2e 5f6d 6f64      q_model._mod
+00011520: 656c 203d 2074 6f72 6368 5f75 7469 6c73  el = torch_utils
+00011530: 2e62 6631 365f 636f 6e76 6572 742e 436f  .bf16_convert.Co
+00011540: 6e76 6572 7428 715f 6d6f 6465 6c2e 5f6d  nvert(q_model._m
+00011550: 6f64 656c 2c20 7365 6c66 2e74 756e 655f  odel, self.tune_
+00011560: 6366 6729 0a0a 2020 2020 2020 2020 715f  cfg)..        q_
+00011570: 6d6f 6465 6c2e 715f 636f 6e66 6967 203d  model.q_config =
+00011580: 2063 6f70 792e 6465 6570 636f 7079 2873   copy.deepcopy(s
+00011590: 656c 662e 7475 6e65 5f63 6667 290a 2020  elf.tune_cfg).  
+000115a0: 2020 2020 2020 6966 2073 656c 662e 6170        if self.ap
+000115b0: 7072 6f61 6368 2021 3d20 2770 6f73 745f  proach != 'post_
+000115c0: 7472 6169 6e69 6e67 5f64 796e 616d 6963  training_dynamic
+000115d0: 5f71 7561 6e74 273a 0a20 2020 2020 2020  _quant':.       
+000115e0: 2020 2020 2073 656c 662e 5f67 6574 5f73       self._get_s
+000115f0: 6361 6c65 5f7a 6572 6f70 6f69 6e74 2871  cale_zeropoint(q
+00011600: 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c 2071  _model._model, q
+00011610: 5f6d 6f64 656c 2e71 5f63 6f6e 6669 6729  _model.q_config)
+00011620: 0a20 2020 2020 2020 2071 5f6d 6f64 656c  .        q_model
+00011630: 2e69 735f 7175 616e 7469 7a65 6420 3d20  .is_quantized = 
+00011640: 5472 7565 0a0a 2020 2020 2020 2020 7365  True..        se
+00011650: 6c66 2e5f 6475 6d70 5f6d 6f64 656c 5f6f  lf._dump_model_o
+00011660: 705f 7374 6174 7328 715f 6d6f 6465 6c2e  p_stats(q_model.
+00011670: 5f6d 6f64 656c 2c20 715f 6d6f 6465 6c2e  _model, q_model.
+00011680: 715f 636f 6e66 6967 290a 2020 2020 2020  q_config).      
+00011690: 2020 746f 7263 685f 7574 696c 732e 7574    torch_utils.ut
+000116a0: 696c 2e67 6574 5f65 6d62 6564 6469 6e67  il.get_embedding
+000116b0: 5f63 6f6e 7469 6775 6f75 7328 715f 6d6f  _contiguous(q_mo
+000116c0: 6465 6c2e 5f6d 6f64 656c 290a 2020 2020  del._model).    
+000116d0: 2020 2020 7265 7475 726e 2071 5f6d 6f64      return q_mod
+000116e0: 656c 0a0a 2020 2020 6465 6620 6576 616c  el..    def eval
+000116f0: 7561 7465 2873 656c 662c 0a20 2020 2020  uate(self,.     
+00011700: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
+00011710: 6c2c 0a20 2020 2020 2020 2020 2020 2020  l,.             
+00011720: 2020 2020 6461 7461 6c6f 6164 6572 2c0a      dataloader,.
+00011730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011740: 2070 6f73 7470 726f 6365 7373 3d4e 6f6e   postprocess=Non
+00011750: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00011760: 2020 2020 6d65 7472 6963 733d 4e6f 6e65      metrics=None
+00011770: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00011780: 2020 206d 6561 7375 7265 723d 4e6f 6e65     measurer=None
+00011790: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000117a0: 2020 2069 7465 7261 7469 6f6e 3d2d 312c     iteration=-1,
+000117b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000117c0: 2020 7465 6e73 6f72 626f 6172 643d 4661    tensorboard=Fa
+000117d0: 6c73 652c 0a20 2020 2020 2020 2020 2020  lse,.           
+000117e0: 2020 2020 2020 6670 3332 5f62 6173 656c        fp32_basel
+000117f0: 696e 653d 4661 6c73 6529 3a0a 2020 2020  ine=False):.    
+00011800: 2020 2020 2222 2245 7865 6375 7465 2074      """Execute t
+00011810: 6865 2065 7661 6c75 6174 6520 7072 6f63  he evaluate proc
+00011820: 6573 7320 6f6e 2074 6865 2073 7065 6369  ess on the speci
+00011830: 6669 6564 206d 6f64 656c 2e0a 0a20 2020  fied model...   
+00011840: 2020 2020 2041 7267 733a 0a20 2020 2020       Args:.     
+00011850: 2020 2020 2020 206d 6f64 656c 2028 6f62         model (ob
+00011860: 6a65 6374 293a 206d 6f64 656c 2074 6f20  ject): model to 
+00011870: 7275 6e20 6576 616c 7561 7469 6f6e 2e0a  run evaluation..
+00011880: 2020 2020 2020 2020 2020 2020 6461 7461              data
+00011890: 6c6f 6164 6572 2028 6f62 6a65 6374 293a  loader (object):
+000118a0: 2065 7661 6c75 6174 696f 6e20 6461 7461   evaluation data
+000118b0: 7365 742e 0a20 2020 2020 2020 2020 2020  set..           
+000118c0: 2070 6f73 7470 726f 6365 7373 2028 6f62   postprocess (ob
+000118d0: 6a65 6374 2c20 6f70 7469 6f6e 616c 293a  ject, optional):
+000118e0: 2070 726f 6365 7373 2066 756e 6374 696f   process functio
+000118f0: 6e20 6166 7465 7220 6576 616c 7561 7469  n after evaluati
+00011900: 6f6e 2e0a 2020 2020 2020 2020 2020 2020  on..            
+00011910: 6d65 7472 6963 7320 286c 6973 742c 206f  metrics (list, o
+00011920: 7074 696f 6e61 6c29 3a20 6c69 7374 206f  ptional): list o
+00011930: 6620 6d65 7472 6963 2066 756e 6374 696f  f metric functio
+00011940: 6e2e 0a20 2020 2020 2020 2020 2020 206d  n..            m
+00011950: 6561 7375 7265 7220 286f 626a 6563 742c  easurer (object,
+00011960: 206f 7074 696f 6e61 6c29 3a20 6d65 6173   optional): meas
+00011970: 7572 6572 2066 756e 6374 696f 6e2e 0a20  urer function.. 
+00011980: 2020 2020 2020 2020 2020 2069 7465 7261             itera
+00011990: 7469 6f6e 2028 696e 742c 206f 7074 696f  tion (int, optio
+000119a0: 6e61 6c29 3a20 6e75 6d62 6572 206f 6620  nal): number of 
+000119b0: 6974 6572 6174 696f 6e73 2074 6f20 6576  iterations to ev
+000119c0: 616c 7561 7465 2e0a 2020 2020 2020 2020  aluate..        
+000119d0: 2020 2020 7465 6e73 6f72 626f 6172 6420      tensorboard 
+000119e0: 2862 6f6f 6c2c 206f 7074 696f 6e61 6c29  (bool, optional)
+000119f0: 3a20 6475 6d70 206f 7574 7075 7420 7465  : dump output te
+00011a00: 6e73 6f72 2074 6f20 7465 6e73 6f72 626f  nsor to tensorbo
+00011a10: 6172 6420 7375 6d6d 6172 7920 6669 6c65  ard summary file
+00011a20: 732e 0a20 2020 2020 2020 2020 2020 2066  s..            f
+00011a30: 7033 325f 6261 7365 6c69 6e65 2028 626f  p32_baseline (bo
+00011a40: 6f6c 656e 2c20 6f70 7469 6f6e 616c 293a  olen, optional):
+00011a50: 206f 6e6c 7920 666f 7220 636f 6d70 6172   only for compar
+00011a60: 655f 6c61 6265 6c3d 4661 6c73 6520 7069  e_label=False pi
+00011a70: 7065 6c69 6e65 0a0a 2020 2020 2020 2020  peline..        
+00011a80: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
+00011a90: 2020 2020 2028 6f62 6a65 6374 293a 2061       (object): a
+00011aa0: 6363 7572 6163 790a 2020 2020 2020 2020  ccuracy.        
+00011ab0: 2222 220a 2020 2020 2020 2020 7365 6c66  """.        self
+00011ac0: 2e69 735f 6261 7365 6c69 6e65 203d 2066  .is_baseline = f
+00011ad0: 7033 325f 6261 7365 6c69 6e65 0a20 2020  p32_baseline.   
+00011ae0: 2020 2020 2069 6620 7465 6e73 6f72 626f       if tensorbo
+00011af0: 6172 643a 0a20 2020 2020 2020 2020 2020  ard:.           
+00011b00: 206d 6f64 656c 203d 2073 656c 662e 5f70   model = self._p
+00011b10: 7265 5f65 7661 6c5f 686f 6f6b 286d 6f64  re_eval_hook(mod
+00011b20: 656c 290a 0a20 2020 2020 2020 206d 6f64  el)..        mod
+00011b30: 656c 5f20 3d20 6d6f 6465 6c2e 5f6d 6f64  el_ = model._mod
+00011b40: 656c 0a20 2020 2020 2020 2061 7373 6572  el.        asser
+00011b50: 7420 6973 696e 7374 616e 6365 280a 2020  t isinstance(.  
+00011b60: 2020 2020 2020 2020 2020 6d6f 6465 6c5f            model_
+00011b70: 2c20 746f 7263 682e 6e6e 2e4d 6f64 756c  , torch.nn.Modul
+00011b80: 6529 2c20 2254 6865 206d 6f64 656c 2070  e), "The model p
+00011b90: 6173 7365 6420 696e 2069 7320 6e6f 7420  assed in is not 
+00011ba0: 7468 6520 696e 7374 616e 6365 206f 6620  the instance of 
+00011bb0: 746f 7263 682e 6e6e 2e4d 6f64 756c 6522  torch.nn.Module"
+00011bc0: 0a20 2020 2020 2020 206d 6f64 656c 5f2e  .        model_.
+00011bd0: 6576 616c 2829 0a20 2020 2020 2020 2069  eval().        i
+00011be0: 6620 7365 6c66 2e64 6576 6963 6520 3d3d  f self.device ==
+00011bf0: 2022 6370 7522 3a0a 2020 2020 2020 2020   "cpu":.        
+00011c00: 2020 2020 6d6f 6465 6c5f 2e74 6f28 2263      model_.to("c
+00011c10: 7075 2229 0a20 2020 2020 2020 2065 6c69  pu").        eli
+00011c20: 6620 7365 6c66 2e64 6576 6963 6520 3d3d  f self.device ==
+00011c30: 2022 6770 7522 3a0a 2020 2020 2020 2020   "gpu":.        
+00011c40: 2020 2020 6966 2073 656c 662e 6973 5f62      if self.is_b
+00011c50: 6173 656c 696e 653a 0a20 2020 2020 2020  aseline:.       
+00011c60: 2020 2020 2020 2020 206d 6f64 656c 5f2e           model_.
+00011c70: 746f 2822 6470 6370 7022 290a 0a20 2020  to("dpcpp")..   
+00011c80: 2020 2020 2069 6620 6d65 7472 6963 733a       if metrics:
+00011c90: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00011ca0: 662e 6670 3332 5f70 7265 6473 5f61 735f  f.fp32_preds_as_
+00011cb0: 6c61 6265 6c20 3d20 616e 7928 5b68 6173  label = any([has
+00011cc0: 6174 7472 286d 6574 7269 632c 2022 636f  attr(metric, "co
+00011cd0: 6d70 6172 655f 6c61 6265 6c22 2920 616e  mpare_label") an
+00011ce0: 6420 5c0a 2020 2020 2020 2020 2020 2020  d \.            
+00011cf0: 2020 2020 6e6f 7420 6d65 7472 6963 2e63      not metric.c
+00011d00: 6f6d 7061 7265 5f6c 6162 656c 2066 6f72  ompare_label for
+00011d10: 206d 6574 7269 6320 696e 206d 6574 7269   metric in metri
+00011d20: 6373 5d29 0a20 2020 2020 2020 2061 6363  cs]).        acc
+00011d30: 203d 2073 656c 662e 6d6f 6465 6c5f 6576   = self.model_ev
+00011d40: 616c 286d 6f64 656c 5f2c 2064 6174 616c  al(model_, datal
+00011d50: 6f61 6465 722c 2070 6f73 7470 726f 6365  oader, postproce
+00011d60: 7373 2c20 6d65 7472 6963 732c 206d 6561  ss, metrics, mea
+00011d70: 7375 7265 722c 2069 7465 7261 7469 6f6e  surer, iteration
+00011d80: 290a 0a20 2020 2020 2020 2069 6620 7465  )..        if te
+00011d90: 6e73 6f72 626f 6172 643a 0a20 2020 2020  nsorboard:.     
+00011da0: 2020 2020 2020 2073 656c 662e 5f70 6f73         self._pos
+00011db0: 745f 6576 616c 5f68 6f6f 6b28 6d6f 6465  t_eval_hook(mode
+00011dc0: 6c2c 2061 6363 7572 6163 793d 6163 6329  l, accuracy=acc)
+00011dd0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00011de0: 6163 6320 6966 206e 6f74 2069 7369 6e73  acc if not isins
+00011df0: 7461 6e63 6528 6163 632c 206c 6973 7429  tance(acc, list)
+00011e00: 206f 7220 6c65 6e28 6163 6329 203e 2031   or len(acc) > 1
+00011e10: 2065 6c73 6520 6163 635b 305d 0a0a 2020   else acc[0]..  
+00011e20: 2020 6465 6620 5f70 7265 5f68 6f6f 6b5f    def _pre_hook_
+00011e30: 666f 725f 7161 7428 7365 6c66 2c20 6461  for_qat(self, da
+00011e40: 7461 6c6f 6164 6572 3d4e 6f6e 6529 3a0a  taloader=None):.
+00011e50: 2020 2020 2020 2020 2320 7365 6c66 2e6d          # self.m
+00011e60: 6f64 656c 2e5f 6d6f 6465 6c20 6973 206e  odel._model is n
+00011e70: 6565 6465 6420 6865 7265 2e0a 2020 2020  eeded here..    
+00011e80: 2020 2020 7365 6c66 2e6d 6f64 656c 2e5f      self.model._
+00011e90: 6d6f 6465 6c2e 7163 6f6e 6669 6720 3d20  model.qconfig = 
+00011ea0: 746f 7263 682e 7175 616e 7469 7a61 7469  torch.quantizati
+00011eb0: 6f6e 2e51 436f 6e66 6967 280a 2020 2020  on.QConfig(.    
+00011ec0: 2020 2020 2020 2020 6163 7469 7661 7469          activati
+00011ed0: 6f6e 3d74 6f72 6368 2e71 7561 6e74 697a  on=torch.quantiz
+00011ee0: 6174 696f 6e2e 4661 6b65 5175 616e 7469  ation.FakeQuanti
+00011ef0: 7a65 2e77 6974 685f 6172 6773 2864 7479  ze.with_args(dty
+00011f00: 7065 3d74 6f72 6368 2e71 7569 6e74 382c  pe=torch.quint8,
+00011f10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f50: 2020 7173 6368 656d 653d 746f 7263 682e    qscheme=torch.
+00011f60: 7065 725f 7465 6e73 6f72 5f61 6666 696e  per_tensor_affin
+00011f70: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00011f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011fb0: 2020 2020 7265 6475 6365 5f72 616e 6765      reduce_range
+00011fc0: 3d52 4544 5543 455f 5241 4e47 4529 2c0a  =REDUCE_RANGE),.
+00011fd0: 2020 2020 2020 2020 2020 2020 7765 6967              weig
+00011fe0: 6874 3d74 6f72 6368 2e71 7561 6e74 697a  ht=torch.quantiz
+00011ff0: 6174 696f 6e2e 6465 6661 756c 745f 7765  ation.default_we
+00012000: 6967 6874 5f66 616b 655f 7175 616e 7429  ight_fake_quant)
+00012010: 0a20 2020 2020 2020 2073 656c 662e 6e6f  .        self.no
+00012020: 6e5f 7175 616e 745f 6469 6374 203d 2073  n_quant_dict = s
+00012030: 656c 662e 6765 745f 6e6f 6e5f 7175 616e  elf.get_non_quan
+00012040: 745f 6d6f 6475 6c65 7328 7365 6c66 2e6d  t_modules(self.m
+00012050: 6f64 656c 2e6b 7761 7267 7329 0a20 2020  odel.kwargs).   
+00012060: 2020 2020 2071 7561 6e74 697a 6162 6c65       quantizable
+00012070: 5f6f 7073 203d 205b 5d0a 2020 2020 2020  _ops = [].      
+00012080: 2020 7365 6c66 2e5f 6765 745f 7175 616e    self._get_quan
+00012090: 7469 7a61 626c 655f 6f70 735f 7265 6375  tizable_ops_recu
+000120a0: 7273 6976 656c 7928 7365 6c66 2e6d 6f64  rsively(self.mod
+000120b0: 656c 2e5f 6d6f 6465 6c2c 2027 272c 2071  el._model, '', q
+000120c0: 7561 6e74 697a 6162 6c65 5f6f 7073 290a  uantizable_ops).
+000120d0: 2020 2020 2020 2020 6266 3136 5f6f 7073          bf16_ops
+000120e0: 203d 205b 5d0a 2020 2020 2020 2020 6966   = [].        if
+000120f0: 2073 656c 662e 7665 7273 696f 6e2e 7265   self.version.re
+00012100: 6c65 6173 6520 3e3d 2056 6572 7369 6f6e  lease >= Version
+00012110: 2822 312e 3131 2e30 2229 2e72 656c 6561  ("1.11.0").relea
+00012120: 7365 2061 6e64 2073 656c 662e 7573 655f  se and self.use_
+00012130: 6266 3136 2061 6e64 205c 0a20 2020 2020  bf16 and \.     
+00012140: 2020 2020 2020 2028 4370 7549 6e66 6f28         (CpuInfo(
+00012150: 292e 6266 3136 206f 7220 6f73 2e67 6574  ).bf16 or os.get
+00012160: 656e 7628 2746 4f52 4345 5f42 4631 3627  env('FORCE_BF16'
+00012170: 2920 3d3d 2027 3127 293a 2023 2070 7261  ) == '1'): # pra
+00012180: 676d 613a 206e 6f20 636f 7665 720a 2020  gma: no cover.  
+00012190: 2020 2020 2020 2020 2020 7365 6c66 2e62            self.b
+000121a0: 6631 365f 6f70 7320 3d20 7365 6c66 2e71  f16_ops = self.q
+000121b0: 7565 7279 5f68 616e 646c 6572 2e67 6574  uery_handler.get
+000121c0: 5f6f 705f 7479 7065 735f 6279 5f70 7265  _op_types_by_pre
+000121d0: 6369 7369 6f6e 2822 6266 3136 2229 0a20  cision("bf16"). 
+000121e0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000121f0: 5f67 6574 5f62 6631 365f 6f70 735f 7265  _get_bf16_ops_re
+00012200: 6375 7273 6976 656c 7928 7365 6c66 2e6d  cursively(self.m
+00012210: 6f64 656c 2e5f 6d6f 6465 6c2c 2027 272c  odel._model, '',
+00012220: 2062 6631 365f 6f70 7329 0a20 2020 2020   bf16_ops).     
+00012230: 2020 2062 6631 365f 6f70 735f 6c69 7374     bf16_ops_list
+00012240: 203d 205b 286f 7029 2066 6f72 206f 7020   = [(op) for op 
+00012250: 696e 2062 6631 365f 6f70 7320 6966 206f  in bf16_ops if o
+00012260: 7020 6e6f 7420 696e 2071 7561 6e74 697a  p not in quantiz
+00012270: 6162 6c65 5f6f 7073 5d0a 2020 2020 2020  able_ops].      
+00012280: 2020 7365 6c66 2e6d 6f64 656c 2e6d 6f64    self.model.mod
+00012290: 656c 2e74 7261 696e 696e 6720 3d20 5472  el.training = Tr
+000122a0: 7565 0a20 2020 2020 2020 2074 6f72 6368  ue.        torch
+000122b0: 2e71 7561 6e74 697a 6174 696f 6e2e 7072  .quantization.pr
+000122c0: 6570 6172 655f 7161 7428 7365 6c66 2e6d  epare_qat(self.m
+000122d0: 6f64 656c 2e5f 6d6f 6465 6c2c 2069 6e70  odel._model, inp
+000122e0: 6c61 6365 3d54 7275 6529 0a0a 2020 2020  lace=True)..    
+000122f0: 2020 2020 2320 5468 6973 2069 7320 6120      # This is a 
+00012300: 666c 6167 2066 6f72 2072 656c 6f61 6469  flag for reloadi
+00012310: 6e67 0a20 2020 2020 2020 2073 656c 662e  ng.        self.
+00012320: 6d6f 6465 6c2e 715f 636f 6e66 6967 203d  model.q_config =
+00012330: 207b 0a20 2020 2020 2020 2020 2020 2027   {.            '
+00012340: 6973 5f6f 6e65 7368 6f74 273a 2054 7275  is_oneshot': Tru
+00012350: 652c 0a20 2020 2020 2020 2020 2020 2027  e,.            '
+00012360: 6672 616d 6577 6f72 6b27 3a20 2770 7974  framework': 'pyt
+00012370: 6f72 6368 272c 0a20 2020 2020 2020 2020  orch',.         
+00012380: 2020 2027 7265 6475 6365 5f72 616e 6765     'reduce_range
+00012390: 273a 2052 4544 5543 455f 5241 4e47 452c  ': REDUCE_RANGE,
+000123a0: 0a20 2020 2020 2020 2020 2020 2027 6170  .            'ap
+000123b0: 7072 6f61 6368 273a 2027 7175 616e 745f  proach': 'quant_
+000123c0: 6177 6172 655f 7472 6169 6e69 6e67 272c  aware_training',
+000123d0: 0a20 2020 2020 2020 2020 2020 2027 6266  .            'bf
+000123e0: 3136 5f6f 7073 5f6c 6973 7427 3a20 6266  16_ops_list': bf
+000123f0: 3136 5f6f 7073 5f6c 6973 742c 0a20 2020  16_ops_list,.   
+00012400: 2020 2020 207d 0a0a 2020 2020 6465 6620       }..    def 
+00012410: 5f70 6f73 745f 686f 6f6b 5f66 6f72 5f71  _post_hook_for_q
+00012420: 6174 2873 656c 6629 3a0a 2020 2020 2020  at(self):.      
+00012430: 2020 746f 7263 682e 7175 616e 7469 7a61    torch.quantiza
+00012440: 7469 6f6e 2e63 6f6e 7665 7274 2873 656c  tion.convert(sel
+00012450: 662e 6d6f 6465 6c2e 5f6d 6f64 656c 2c20  f.model._model, 
+00012460: 696e 706c 6163 653d 5472 7565 290a 2020  inplace=True).  
+00012470: 2020 2020 2020 6966 2073 656c 662e 6d6f        if self.mo
+00012480: 6465 6c2e 715f 636f 6e66 6967 2069 7320  del.q_config is 
+00012490: 6e6f 7420 4e6f 6e65 2061 6e64 206c 656e  not None and len
+000124a0: 2873 656c 662e 6d6f 6465 6c2e 715f 636f  (self.model.q_co
+000124b0: 6e66 6967 5b27 6266 3136 5f6f 7073 5f6c  nfig['bf16_ops_l
+000124c0: 6973 7427 5d29 203e 2030 2061 6e64 205c  ist']) > 0 and \
+000124d0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+000124e0: 662e 7665 7273 696f 6e2e 7265 6c65 6173  f.version.releas
+000124f0: 6520 3e3d 2056 6572 7369 6f6e 2822 312e  e >= Version("1.
+00012500: 3131 2e30 2229 2e72 656c 6561 7365 2061  11.0").release a
+00012510: 6e64 2073 656c 662e 7573 655f 6266 3136  nd self.use_bf16
+00012520: 2061 6e64 205c 0a20 2020 2020 2020 2020   and \.         
+00012530: 2020 2028 4370 7549 6e66 6f28 292e 6266     (CpuInfo().bf
+00012540: 3136 206f 7220 6f73 2e67 6574 656e 7628  16 or os.getenv(
+00012550: 2746 4f52 4345 5f42 4631 3627 2920 3d3d  'FORCE_BF16') ==
+00012560: 2027 3127 293a 2023 2070 7261 676d 613a   '1'): # pragma:
+00012570: 206e 6f20 636f 7665 720a 2020 2020 2020   no cover.      
+00012580: 2020 2020 2020 7365 6c66 2e6d 6f64 656c        self.model
+00012590: 2e5f 6d6f 6465 6c20 3d20 746f 7263 685f  ._model = torch_
+000125a0: 7574 696c 732e 6266 3136 5f63 6f6e 7665  utils.bf16_conve
+000125b0: 7274 2e43 6f6e 7665 7274 2873 656c 662e  rt.Convert(self.
+000125c0: 6d6f 6465 6c2e 5f6d 6f64 656c 2c20 7365  model._model, se
+000125d0: 6c66 2e6d 6f64 656c 2e71 5f63 6f6e 6669  lf.model.q_confi
+000125e0: 6729 0a0a 2020 2020 6465 6620 5f70 7265  g)..    def _pre
+000125f0: 5f68 6f6f 6b5f 666f 725f 6876 6428 7365  _hook_for_hvd(se
+00012600: 6c66 2c20 6461 7461 6c6f 6164 6572 3d4e  lf, dataloader=N
+00012610: 6f6e 6529 3a0a 2020 2020 2020 2020 2320  one):.        # 
+00012620: 544f 444f 3a20 6c61 7a79 2069 6e69 7420  TODO: lazy init 
+00012630: 6865 7265 0a20 2020 2020 2020 2068 7664  here.        hvd
+00012640: 2e69 6e69 7428 290a 2020 2020 2020 2020  .init().        
+00012650: 6876 642e 6272 6f61 6463 6173 745f 7061  hvd.broadcast_pa
+00012660: 7261 6d65 7465 7273 2873 656c 662e 6d6f  rameters(self.mo
+00012670: 6465 6c2e 5f6d 6f64 656c 2e73 7461 7465  del._model.state
+00012680: 5f64 6963 7428 292c 2072 6f6f 745f 7261  _dict(), root_ra
+00012690: 6e6b 3d30 290a 2020 2020 2020 2020 6876  nk=0).        hv
+000126a0: 642e 6272 6f61 6463 6173 745f 6f70 7469  d.broadcast_opti
+000126b0: 6d69 7a65 725f 7374 6174 6528 7365 6c66  mizer_state(self
+000126c0: 2e6f 7074 696d 697a 6572 2c20 726f 6f74  .optimizer, root
+000126d0: 5f72 616e 6b3d 3029 0a20 2020 2020 2020  _rank=0).       
+000126e0: 2073 656c 662e 6f70 7469 6d69 7a65 7220   self.optimizer 
+000126f0: 3d20 6876 642e 4469 7374 7269 6275 7465  = hvd.Distribute
+00012700: 644f 7074 696d 697a 6572 280a 2020 2020  dOptimizer(.    
+00012710: 2020 2020 2020 2020 7365 6c66 2e6f 7074          self.opt
+00012720: 696d 697a 6572 2c20 6e61 6d65 645f 7061  imizer, named_pa
+00012730: 7261 6d65 7465 7273 3d73 656c 662e 6d6f  rameters=self.mo
+00012740: 6465 6c2e 5f6d 6f64 656c 2e6e 616d 6564  del._model.named
+00012750: 5f70 6172 616d 6574 6572 7328 2929 0a0a  _parameters())..
+00012760: 2020 2020 6465 6620 7472 6169 6e28 7365      def train(se
+00012770: 6c66 2c20 6d6f 6465 6c2c 2064 6174 616c  lf, model, datal
+00012780: 6f61 6465 722c 206f 7074 696d 697a 6572  oader, optimizer
+00012790: 5f74 7570 6c65 2c20 6372 6974 6572 696f  _tuple, criterio
+000127a0: 6e5f 7475 706c 652c 2068 6f6f 6b73 2c20  n_tuple, hooks, 
+000127b0: 2a2a 6b77 6172 6773 293a 0a20 2020 2020  **kwargs):.     
+000127c0: 2020 2022 2222 4578 6563 7574 6520 7468     """Execute th
+000127d0: 6520 7472 6169 6e20 7072 6f63 6573 7320  e train process 
+000127e0: 6f6e 2074 6865 2073 7065 6369 6669 6564  on the specified
+000127f0: 206d 6f64 656c 2e0a 0a20 2020 2020 2020   model...       
+00012800: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
+00012810: 2020 206d 6f64 656c 2028 6f62 6a65 6374     model (object
+00012820: 293a 206d 6f64 656c 2074 6f20 7275 6e20  ): model to run 
+00012830: 6576 616c 7561 7469 6f6e 2e0a 2020 2020  evaluation..    
+00012840: 2020 2020 2020 2020 6461 7461 6c6f 6164          dataload
+00012850: 6572 2028 6f62 6a65 6374 293a 2074 7261  er (object): tra
+00012860: 696e 696e 6720 6461 7461 7365 742e 0a20  ining dataset.. 
+00012870: 2020 2020 2020 2020 2020 206f 7074 696d             optim
+00012880: 697a 6572 2028 7475 706c 6529 3a20 4974  izer (tuple): It
+00012890: 2069 7320 6120 7475 706c 6520 6f66 2028   is a tuple of (
+000128a0: 636c 732c 2070 6172 616d 6574 6572 7329  cls, parameters)
+000128b0: 2066 6f72 206f 7074 696d 697a 6572 2e0a   for optimizer..
+000128c0: 2020 2020 2020 2020 2020 2020 6372 6974              crit
+000128d0: 6572 696f 6e20 2874 7570 6c65 293a 2049  erion (tuple): I
+000128e0: 7420 6973 2061 2074 7570 6c65 206f 6620  t is a tuple of 
+000128f0: 2863 6c73 2c20 7061 7261 6d65 7465 7273  (cls, parameters
+00012900: 2920 666f 7220 6372 6974 6572 696f 6e2e  ) for criterion.
+00012910: 0a20 2020 2020 2020 2020 2020 206b 7761  .            kwa
+00012920: 7267 7320 2864 6963 742c 206f 7074 696f  rgs (dict, optio
+00012930: 6e61 6c29 3a20 6f74 6865 7220 7061 7261  nal): other para
+00012940: 6d65 7465 7273 2e0a 0a20 2020 2020 2020  meters...       
+00012950: 2052 6574 7572 6e73 3a0a 2020 2020 2020   Returns:.      
+00012960: 2020 2020 2020 4e6f 6e65 0a20 2020 2020        None.     
+00012970: 2020 2022 2222 0a20 2020 2020 2020 206d     """.        m
+00012980: 6f64 656c 5f20 3d20 6d6f 6465 6c2e 5f6d  odel_ = model._m
+00012990: 6f64 656c 0a20 2020 2020 2020 2064 6576  odel.        dev
+000129a0: 6963 6520 3d20 2263 7564 613a 3022 2069  ice = "cuda:0" i
+000129b0: 6620 7365 6c66 2e64 6576 6963 6520 213d  f self.device !=
+000129c0: 2022 4750 5522 2061 6e64 2074 6f72 6368   "GPU" and torch
+000129d0: 2e63 7564 612e 6973 5f61 7661 696c 6162  .cuda.is_availab
+000129e0: 6c65 2829 2065 6c73 6520 7365 6c66 2e64  le() else self.d
+000129f0: 6576 6963 650a 2020 2020 2020 2020 2320  evice.        # 
+00012a00: 7365 6c66 2e6d 6f64 656c 2069 7320 7365  self.model is se
+00012a10: 7420 746f 206e 6575 7261 6c5f 636f 6d70  t to neural_comp
+00012a20: 7265 7373 6f72 206d 6f64 656c 2068 6572  ressor model her
+00012a30: 6520 746f 2068 6f6c 6420 7468 6520 696e  e to hold the in
+00012a40: 706c 6163 6520 6368 616e 6765 2069 6e20  place change in 
+00012a50: 4657 4b20 6d6f 6465 6c2e 0a20 2020 2020  FWK model..     
+00012a60: 2020 2073 656c 662e 6d6f 6465 6c20 3d20     self.model = 
+00012a70: 6d6f 6465 6c0a 2020 2020 2020 2020 6f70  model.        op
+00012a80: 7469 6d69 7a65 7220 3d20 6f70 7469 6d69  timizer = optimi
+00012a90: 7a65 725f 7475 706c 655b 305d 286d 6f64  zer_tuple[0](mod
+00012aa0: 656c 5f2e 7061 7261 6d65 7465 7273 2829  el_.parameters()
+00012ab0: 2c20 2a2a 6f70 7469 6d69 7a65 725f 7475  , **optimizer_tu
+00012ac0: 706c 655b 315d 290a 2020 2020 2020 2020  ple[1]).        
+00012ad0: 7365 6c66 2e6f 7074 696d 697a 6572 203d  self.optimizer =
+00012ae0: 206f 7074 696d 697a 6572 0a20 2020 2020   optimizer.     
+00012af0: 2020 2063 7269 7465 7269 6f6e 203d 2063     criterion = c
+00012b00: 7269 7465 7269 6f6e 5f74 7570 6c65 5b30  riterion_tuple[0
+00012b10: 5d28 2a2a 6372 6974 6572 696f 6e5f 7475  ](**criterion_tu
+00012b20: 706c 655b 315d 290a 2020 2020 2020 2020  ple[1]).        
+00012b30: 7374 6172 745f 6570 6f63 6873 203d 206b  start_epochs = k
+00012b40: 7761 7267 735b 276b 7761 7267 7327 5d5b  wargs['kwargs'][
+00012b50: 2773 7461 7274 5f65 706f 6368 275d 0a20  'start_epoch']. 
+00012b60: 2020 2020 2020 2065 6e64 5f65 706f 6368         end_epoch
+00012b70: 7320 3d20 6b77 6172 6773 5b27 6b77 6172  s = kwargs['kwar
+00012b80: 6773 275d 5b27 656e 645f 6570 6f63 6827  gs']['end_epoch'
+00012b90: 5d0a 2020 2020 2020 2020 6974 6572 7320  ].        iters 
+00012ba0: 3d20 6b77 6172 6773 5b27 6b77 6172 6773  = kwargs['kwargs
+00012bb0: 275d 5b27 6974 6572 6174 696f 6e27 5d0a  ']['iteration'].
+00012bc0: 2020 2020 2020 2020 6966 2068 6f6f 6b73          if hooks
+00012bd0: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+00012be0: 2020 2020 2020 2020 2020 6f6e 5f74 7261            on_tra
+00012bf0: 696e 5f62 6567 696e 203d 2068 6f6f 6b73  in_begin = hooks
+00012c00: 5b27 6f6e 5f74 7261 696e 5f62 6567 696e  ['on_train_begin
+00012c10: 275d 0a20 2020 2020 2020 2020 2020 206f  '].            o
+00012c20: 6e5f 7472 6169 6e5f 656e 6420 3d20 686f  n_train_end = ho
+00012c30: 6f6b 735b 276f 6e5f 7472 6169 6e5f 656e  oks['on_train_en
+00012c40: 6427 5d0a 2020 2020 2020 2020 2020 2020  d'].            
+00012c50: 6f6e 5f65 706f 6368 5f62 6567 696e 203d  on_epoch_begin =
+00012c60: 2068 6f6f 6b73 5b27 6f6e 5f65 706f 6368   hooks['on_epoch
+00012c70: 5f62 6567 696e 275d 0a20 2020 2020 2020  _begin'].       
+00012c80: 2020 2020 206f 6e5f 6570 6f63 685f 656e       on_epoch_en
+00012c90: 6420 3d20 686f 6f6b 735b 276f 6e5f 6570  d = hooks['on_ep
+00012ca0: 6f63 685f 656e 6427 5d0a 2020 2020 2020  och_end'].      
+00012cb0: 2020 2020 2020 6f6e 5f73 7465 705f 6265        on_step_be
+00012cc0: 6769 6e20 3d20 686f 6f6b 735b 276f 6e5f  gin = hooks['on_
+00012cd0: 7374 6570 5f62 6567 696e 275d 0a20 2020  step_begin'].   
+00012ce0: 2020 2020 2020 2020 206f 6e5f 7374 6570           on_step
+00012cf0: 5f65 6e64 203d 2068 6f6f 6b73 5b27 6f6e  _end = hooks['on
+00012d00: 5f73 7465 705f 656e 6427 5d0a 2020 2020  _step_end'].    
+00012d10: 2020 2020 2020 2020 6f6e 5f61 6674 6572          on_after
+00012d20: 5f63 6f6d 7075 7465 5f6c 6f73 7320 3d20  _compute_loss = 
+00012d30: 686f 6f6b 735b 276f 6e5f 6166 7465 725f  hooks['on_after_
+00012d40: 636f 6d70 7574 655f 6c6f 7373 275d 0a20  compute_loss']. 
+00012d50: 2020 2020 2020 2020 2020 206f 6e5f 6265             on_be
+00012d60: 666f 7265 5f6f 7074 696d 697a 6572 5f73  fore_optimizer_s
+00012d70: 7465 7020 3d20 686f 6f6b 735b 276f 6e5f  tep = hooks['on_
+00012d80: 6265 666f 7265 5f6f 7074 696d 697a 6572  before_optimizer
+00012d90: 5f73 7465 7027 5d0a 2020 2020 2020 2020  _step'].        
+00012da0: 6966 2068 6f6f 6b73 2069 7320 6e6f 7420  if hooks is not 
+00012db0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00012dc0: 2020 6f6e 5f74 7261 696e 5f62 6567 696e    on_train_begin
+00012dd0: 2829 0a20 2020 2020 2020 2066 6f72 206e  ().        for n
+00012de0: 6570 6f63 6820 696e 2072 616e 6765 2873  epoch in range(s
+00012df0: 7461 7274 5f65 706f 6368 732c 2065 6e64  tart_epochs, end
+00012e00: 5f65 706f 6368 7329 3a0a 2020 2020 2020  _epochs):.      
+00012e10: 2020 2020 2020 6d6f 6465 6c5f 2e74 6f28        model_.to(
+00012e20: 6465 7669 6365 290a 2020 2020 2020 2020  device).        
+00012e30: 2020 2020 6d6f 6465 6c5f 2e74 7261 696e      model_.train
+00012e40: 2829 0a20 2020 2020 2020 2020 2020 2063  ().            c
+00012e50: 6e74 203d 2030 0a20 2020 2020 2020 2020  nt = 0.         
+00012e60: 2020 2069 6620 686f 6f6b 7320 6973 206e     if hooks is n
+00012e70: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
+00012e80: 2020 2020 2020 2020 206f 6e5f 6570 6f63           on_epoc
+00012e90: 685f 6265 6769 6e28 6e65 706f 6368 290a  h_begin(nepoch).
+00012ea0: 2020 2020 2020 2020 2020 2020 6966 2067              if g
+00012eb0: 6574 6174 7472 2864 6174 616c 6f61 6465  etattr(dataloade
+00012ec0: 722c 2027 6469 7374 7269 6275 7465 6427  r, 'distributed'
+00012ed0: 2c20 4661 6c73 6529 205c 0a20 2020 2020  , False) \.     
+00012ee0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00012ef0: 7220 6973 696e 7374 616e 6365 2864 6174  r isinstance(dat
+00012f00: 616c 6f61 6465 722e 7361 6d70 6c65 722c  aloader.sampler,
+00012f10: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+00012f20: 2020 2020 2020 2074 6f72 6368 2e75 7469         torch.uti
+00012f30: 6c73 2e64 6174 612e 6469 7374 7269 6275  ls.data.distribu
+00012f40: 7465 642e 4469 7374 7269 6275 7465 6453  ted.DistributedS
+00012f50: 616d 706c 6572 293a 0a20 2020 2020 2020  ampler):.       
+00012f60: 2020 2020 2020 2020 2064 6174 616c 6f61           dataloa
+00012f70: 6465 722e 7361 6d70 6c65 722e 7365 745f  der.sampler.set_
+00012f80: 6570 6f63 6828 6e65 706f 6368 290a 2020  epoch(nepoch).  
+00012f90: 2020 2020 2020 2020 2020 666f 7220 696d            for im
+00012fa0: 6167 652c 2074 6172 6765 7420 696e 2064  age, target in d
+00012fb0: 6174 616c 6f61 6465 723a 0a20 2020 2020  ataloader:.     
+00012fc0: 2020 2020 2020 2020 2020 2023 2054 4f44             # TOD
+00012fd0: 4f3a 2074 6f20 7375 7070 6f72 7420 6164  O: to support ad
+00012fe0: 6a75 7374 206c 7220 7769 7468 2065 706f  just lr with epo
+00012ff0: 6368 0a20 2020 2020 2020 2020 2020 2020  ch.             
+00013000: 2020 2074 6172 6765 7420 3d20 7461 7267     target = targ
+00013010: 6574 2e74 6f28 6465 7669 6365 290a 2020  et.to(device).  
+00013020: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00013030: 2068 6f6f 6b73 2069 7320 6e6f 7420 4e6f   hooks is not No
+00013040: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00013050: 2020 2020 2020 2020 6f6e 5f73 7465 705f          on_step_
+00013060: 6265 6769 6e28 636e 7429 0a20 2020 2020  begin(cnt).     
+00013070: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+00013080: 2827 2e27 2c20 656e 643d 2727 2c20 666c  ('.', end='', fl
+00013090: 7573 683d 5472 7565 290a 2020 2020 2020  ush=True).      
+000130a0: 2020 2020 2020 2020 2020 636e 7420 2b3d            cnt +=
+000130b0: 2031 0a20 2020 2020 2020 2020 2020 2020   1.             
+000130c0: 2020 206f 7574 7075 7420 3d20 7079 746f     output = pyto
+000130d0: 7263 685f 666f 7277 6172 645f 7772 6170  rch_forward_wrap
+000130e0: 7065 7228 6d6f 6465 6c5f 2c20 696d 6167  per(model_, imag
+000130f0: 652c 2064 6576 6963 653d 6465 7669 6365  e, device=device
+00013100: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00013110: 2020 6c6f 7373 203d 2063 7269 7465 7269    loss = criteri
+00013120: 6f6e 286f 7574 7075 742c 2074 6172 6765  on(output, targe
+00013130: 7429 0a20 2020 2020 2020 2020 2020 2020  t).             
+00013140: 2020 2069 6620 686f 6f6b 7320 6973 206e     if hooks is n
+00013150: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
+00013160: 2020 2020 2020 2020 2020 2020 206c 6f73               los
+00013170: 7320 3d20 6f6e 5f61 6674 6572 5f63 6f6d  s = on_after_com
+00013180: 7075 7465 5f6c 6f73 7328 696d 6167 652c  pute_loss(image,
+00013190: 206f 7574 7075 742c 206c 6f73 7329 0a20   output, loss). 
+000131a0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000131b0: 656c 662e 6f70 7469 6d69 7a65 722e 7a65  elf.optimizer.ze
+000131c0: 726f 5f67 7261 6428 290a 2020 2020 2020  ro_grad().      
+000131d0: 2020 2020 2020 2020 2020 6c6f 7373 2e62            loss.b
+000131e0: 6163 6b77 6172 6428 290a 2020 2020 2020  ackward().      
+000131f0: 2020 2020 2020 2020 2020 6966 2068 6f6f            if hoo
+00013200: 6b73 2069 7320 6e6f 7420 4e6f 6e65 3a0a  ks is not None:.
+00013210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013220: 2020 2020 6f6e 5f62 6566 6f72 655f 6f70      on_before_op
+00013230: 7469 6d69 7a65 725f 7374 6570 2829 0a20  timizer_step(). 
+00013240: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00013250: 656c 662e 6f70 7469 6d69 7a65 722e 7374  elf.optimizer.st
+00013260: 6570 2829 0a20 2020 2020 2020 2020 2020  ep().           
+00013270: 2020 2020 2069 6620 686f 6f6b 7320 6973       if hooks is
+00013280: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+00013290: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+000132a0: 6e5f 7374 6570 5f65 6e64 2829 0a20 2020  n_step_end().   
+000132b0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000132c0: 636e 7420 3e3d 2069 7465 7273 3a0a 2020  cnt >= iters:.  
+000132d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000132e0: 2020 6272 6561 6b0a 2020 2020 2020 2020    break.        
+000132f0: 2020 2020 6966 2068 6f6f 6b73 2069 7320      if hooks is 
+00013300: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00013310: 2020 2020 2020 2020 2020 6f6e 5f65 706f            on_epo
+00013320: 6368 5f65 6e64 2829 0a0a 2020 2020 2020  ch_end()..      
+00013330: 2020 6966 2064 6576 6963 6520 213d 2073    if device != s
+00013340: 656c 662e 6465 7669 6365 3a20 2023 2070  elf.device:  # p
+00013350: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
+00013360: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
+00013370: 6c5f 2e74 6f28 7365 6c66 2e64 6576 6963  l_.to(self.devic
+00013380: 6529 0a0a 2020 2020 2020 2020 6966 2068  e)..        if h
+00013390: 6f6f 6b73 2069 7320 6e6f 7420 4e6f 6e65  ooks is not None
+000133a0: 3a0a 2020 2020 2020 2020 2020 2020 6f6e  :.            on
+000133b0: 5f74 7261 696e 5f65 6e64 2829 0a0a 2020  _train_end()..  
+000133c0: 2020 2020 2020 7265 7475 726e 206d 6f64        return mod
+000133d0: 656c 5f0a 0a20 2020 2064 6566 205f 6475  el_..    def _du
+000133e0: 6d70 5f6d 6f64 656c 5f6f 705f 7374 6174  mp_model_op_stat
+000133f0: 7328 7365 6c66 2c20 6d6f 6465 6c2c 2074  s(self, model, t
+00013400: 756e 655f 6366 6729 3a0a 2020 2020 2020  une_cfg):.      
+00013410: 2020 2222 2254 6869 7320 6973 2061 2066    """This is a f
+00013420: 756e 6374 696f 6e20 746f 2064 756d 7020  unction to dump 
+00013430: 7175 616e 7469 7a61 626c 6520 6f70 7320  quantizable ops 
+00013440: 6f66 206d 6f64 656c 2074 6f20 7573 6572  of model to user
+00013450: 2e0a 2020 2020 2020 2020 4172 6773 3a0a  ..        Args:.
+00013460: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
+00013470: 6c20 286f 626a 6563 7429 3a20 696e 7075  l (object): inpu
+00013480: 7420 6d6f 6465 6c0a 2020 2020 2020 2020  t model.        
+00013490: 2020 2020 7475 6e65 5f63 6667 2028 6469      tune_cfg (di
+000134a0: 6374 293a 2071 7561 6e74 697a 6174 696f  ct): quantizatio
+000134b0: 6e20 636f 6e66 6967 0a20 2020 2020 2020  n config.       
+000134c0: 2052 6574 7572 6e73 3a0a 2020 2020 2020   Returns:.      
+000134d0: 2020 2020 2020 4e6f 6e65 0a20 2020 2020        None.     
+000134e0: 2020 2022 2222 0a20 2020 2020 2020 2072     """.        r
+000134f0: 6573 203d 207b 7d0a 2020 2020 2020 2020  es = {}.        
+00013500: 6967 6e6f 7265 5f6c 6f67 203d 2046 616c  ignore_log = Fal
+00013510: 7365 0a20 2020 2020 2020 206d 6f64 756c  se.        modul
+00013520: 6573 203d 2064 6963 7428 6d6f 6465 6c2e  es = dict(model.
+00013530: 6e61 6d65 645f 6d6f 6475 6c65 7328 2929  named_modules())
+00013540: 0a20 2020 2020 2020 2023 2066 6574 6368  .        # fetch
+00013550: 2071 7561 6e74 697a 6162 6c65 206f 7073   quantizable ops
+00013560: 2073 7570 706f 7274 6564 2069 6e20 4e65   supported in Ne
+00013570: 7572 616c 2043 6f6d 7072 6573 736f 7220  ural Compressor 
+00013580: 6672 6f6d 2074 756e 655f 6366 670a 2020  from tune_cfg.  
+00013590: 2020 2020 2020 666f 7220 6b65 7920 696e        for key in
+000135a0: 2074 756e 655f 6366 675b 276f 7027 5d3a   tune_cfg['op']:
+000135b0: 0a20 2020 2020 2020 2020 2020 206f 705f  .            op_
+000135c0: 6e61 6d65 203d 206b 6579 5b30 5d0a 2020  name = key[0].  
+000135d0: 2020 2020 2020 2020 2020 6f70 5f74 7970            op_typ
+000135e0: 6520 3d20 7374 7228 7479 7065 286d 6f64  e = str(type(mod
+000135f0: 756c 6573 5b6f 705f 6e61 6d65 5d29 292e  ules[op_name])).
+00013600: 7273 7472 6970 2827 5c27 3e27 292e 7370  rstrip('\'>').sp
+00013610: 6c69 7428 272e 2729 5b2d 315d 0a20 2020  lit('.')[-1].   
+00013620: 2020 2020 2020 2020 2069 6620 6f70 5f74           if op_t
+00013630: 7970 6520 3d3d 2027 4246 3136 4d6f 6475  ype == 'BF16Modu
+00013640: 6c65 5772 6170 7065 7227 3a20 2023 2070  leWrapper':  # p
+00013650: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
+00013660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013670: 6f70 5f74 7970 6520 3d20 7374 7228 7479  op_type = str(ty
+00013680: 7065 286d 6f64 756c 6573 5b6f 705f 6e61  pe(modules[op_na
+00013690: 6d65 5d2e 6d6f 6475 6c65 2929 2e72 7374  me].module)).rst
+000136a0: 7269 7028 275c 273e 2729 2e73 706c 6974  rip('\'>').split
+000136b0: 2827 2e27 295b 2d31 5d0a 2020 2020 2020  ('.')[-1].      
+000136c0: 2020 2020 2020 6966 206f 705f 7479 7065        if op_type
+000136d0: 203d 3d20 2744 6571 7561 6e74 5175 616e   == 'DequantQuan
+000136e0: 7457 7261 7070 6572 273a 0a20 2020 2020  tWrapper':.     
+000136f0: 2020 2020 2020 2020 2020 206f 705f 7479             op_ty
+00013700: 7065 203d 2073 7472 2874 7970 6528 6d6f  pe = str(type(mo
+00013710: 6475 6c65 735b 6f70 5f6e 616d 655d 2e6d  dules[op_name].m
+00013720: 6f64 756c 6529 292e 7273 7472 6970 2827  odule)).rstrip('
+00013730: 5c27 3e27 292e 7370 6c69 7428 272e 2729  \'>').split('.')
+00013740: 5b2d 315d 0a20 2020 2020 2020 2020 2020  [-1].           
+00013750: 2069 6620 2746 756e 6374 696f 6e61 6c27   if 'Functional'
+00013760: 2069 6e20 6f70 5f74 7970 653a 0a20 2020   in op_type:.   
+00013770: 2020 2020 2020 2020 2020 2020 206f 705f               op_
+00013780: 7479 7065 203d 206f 705f 6e61 6d65 2e73  type = op_name.s
+00013790: 706c 6974 2827 2e27 295b 2d31 5d0a 2020  plit('.')[-1].  
+000137a0: 2020 2020 2020 2020 2020 6966 206f 705f            if op_
+000137b0: 7479 7065 206e 6f74 2069 6e20 7265 732e  type not in res.
+000137c0: 6b65 7973 2829 3a0a 2020 2020 2020 2020  keys():.        
+000137d0: 2020 2020 2020 2020 7265 735b 6f70 5f74          res[op_t
+000137e0: 7970 655d 203d 207b 2749 4e54 3827 3a20  ype] = {'INT8': 
+000137f0: 302c 2027 4246 3136 273a 2030 2c20 2746  0, 'BF16': 0, 'F
+00013800: 5033 3227 3a20 307d 0a20 2020 2020 2020  P32': 0}.       
+00013810: 2020 2020 2076 616c 7565 203d 2074 756e       value = tun
+00013820: 655f 6366 675b 276f 7027 5d5b 6b65 795d  e_cfg['op'][key]
+00013830: 0a20 2020 2020 2020 2020 2020 2023 2053  .            # S
+00013840: 7065 6369 616c 2063 6173 6573 3a20 5175  pecial cases: Qu
+00013850: 616e 7453 7475 622c 2045 6d62 6564 6469  antStub, Embeddi
+00013860: 6e67 0a20 2020 2020 2020 2020 2020 2069  ng.            i
+00013870: 6620 2827 7765 6967 6874 2720 696e 2076  f ('weight' in v
+00013880: 616c 7565 2061 6e64 2076 616c 7565 5b27  alue and value['
+00013890: 7765 6967 6874 275d 5b27 6474 7970 6527  weight']['dtype'
+000138a0: 5d20 3d3d 2027 6670 3332 2729 206f 7220  ] == 'fp32') or 
+000138b0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+000138c0: 2827 7765 6967 6874 2720 6e6f 7420 696e  ('weight' not in
+000138d0: 2076 616c 7565 2061 6e64 2076 616c 7565   value and value
+000138e0: 5b27 6163 7469 7661 7469 6f6e 275d 5b27  ['activation']['
+000138f0: 6474 7970 6527 5d20 3d3d 2027 6670 3332  dtype'] == 'fp32
+00013900: 2729 3a0a 2020 2020 2020 2020 2020 2020  '):.            
+00013910: 2020 2020 7265 735b 6f70 5f74 7970 655d      res[op_type]
+00013920: 5b27 4650 3332 275d 202b 3d20 310a 2020  ['FP32'] += 1.  
+00013930: 2020 2020 2020 2020 2020 656c 6966 2076            elif v
+00013940: 616c 7565 5b27 6163 7469 7661 7469 6f6e  alue['activation
+00013950: 275d 5b27 6474 7970 6527 5d20 3d3d 2027  ']['dtype'] == '
+00013960: 6266 3136 273a 2020 2320 7072 6167 6d61  bf16':  # pragma
+00013970: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
+00013980: 2020 2020 2020 2020 2020 2072 6573 5b6f             res[o
+00013990: 705f 7479 7065 5d5b 2742 4631 3627 5d20  p_type]['BF16'] 
+000139a0: 2b3d 2031 0a20 2020 2020 2020 2020 2020  += 1.           
+000139b0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+000139c0: 2020 2020 2020 2072 6573 5b6f 705f 7479         res[op_ty
+000139d0: 7065 5d5b 2749 4e54 3827 5d20 2b3d 2031  pe]['INT8'] += 1
+000139e0: 0a20 2020 2020 2020 2023 2066 6574 6368  .        # fetch
+000139f0: 206f 7468 6572 2071 7561 6e74 697a 6162   other quantizab
+00013a00: 6c65 206f 7073 2073 7570 706f 7274 6564  le ops supported
+00013a10: 2069 6e20 5079 546f 7263 6820 6672 6f6d   in PyTorch from
+00013a20: 206d 6f64 656c 0a20 2020 2020 2020 2066   model.        f
+00013a30: 6f72 206e 616d 652c 2063 6869 6c64 2069  or name, child i
+00013a40: 6e20 6d6f 6475 6c65 732e 6974 656d 7328  n modules.items(
+00013a50: 293a 0a20 2020 2020 2020 2020 2020 206f  ):.            o
+00013a60: 705f 7479 7065 203d 2073 7472 2874 7970  p_type = str(typ
+00013a70: 6528 6368 696c 6429 292e 7273 7472 6970  e(child)).rstrip
+00013a80: 2827 5c27 3e27 292e 7370 6c69 7428 272e  ('\'>').split('.
+00013a90: 2729 5b2d 315d 0a20 2020 2020 2020 2020  ')[-1].         
+00013aa0: 2020 2069 6620 7475 6e65 5f63 6667 5b27     if tune_cfg['
+00013ab0: 6170 7072 6f61 6368 275d 2021 3d20 2770  approach'] != 'p
+00013ac0: 6f73 745f 7472 6169 6e69 6e67 5f64 796e  ost_training_dyn
+00013ad0: 616d 6963 5f71 7561 6e74 273a 0a20 2020  amic_quant':.   
+00013ae0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00013af0: 6f70 5f74 7970 6520 3d3d 2027 4465 5175  op_type == 'DeQu
+00013b00: 616e 7469 7a65 273a 0a20 2020 2020 2020  antize':.       
+00013b10: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00013b20: 6f70 5f74 7970 6520 6e6f 7420 696e 2072  op_type not in r
+00013b30: 6573 2e6b 6579 7328 293a 0a20 2020 2020  es.keys():.     
+00013b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013b50: 2020 2072 6573 5b6f 705f 7479 7065 5d20     res[op_type] 
+00013b60: 3d20 7b27 494e 5438 273a 2030 2c20 2742  = {'INT8': 0, 'B
+00013b70: 4631 3627 3a20 302c 2027 4650 3332 273a  F16': 0, 'FP32':
+00013b80: 2030 7d0a 2020 2020 2020 2020 2020 2020   0}.            
+00013b90: 2020 2020 2020 2020 7265 735b 6f70 5f74          res[op_t
+00013ba0: 7970 655d 5b27 494e 5438 275d 202b 3d20  ype]['INT8'] += 
+00013bb0: 310a 2020 2020 2020 2020 2020 2020 2020  1.              
+00013bc0: 2020 6966 206f 705f 7479 7065 2069 6e20    if op_type in 
+00013bd0: 7365 6c66 2e6e 6f6e 5f71 7561 6e74 5f64  self.non_quant_d
+00013be0: 6963 745b 2773 6b69 7070 6564 5f6d 6f64  ict['skipped_mod
+00013bf0: 756c 655f 636c 6173 7365 7327 5d3a 0a20  ule_classes']:. 
+00013c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013c10: 2020 2069 676e 6f72 655f 6c6f 6720 3d20     ignore_log = 
+00013c20: 5472 7565 0a20 2020 2020 2020 2020 2020  True.           
+00013c30: 2020 2020 2020 2020 2069 6620 6f70 5f74           if op_t
+00013c40: 7970 6520 6e6f 7420 696e 2072 6573 2e6b  ype not in res.k
+00013c50: 6579 7328 293a 0a20 2020 2020 2020 2020  eys():.         
+00013c60: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00013c70: 6573 5b6f 705f 7479 7065 5d20 3d20 7b27  es[op_type] = {'
+00013c80: 494e 5438 273a 2030 2c20 2742 4631 3627  INT8': 0, 'BF16'
+00013c90: 3a20 302c 2027 4650 3332 273a 2030 7d0a  : 0, 'FP32': 0}.
+00013ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013cb0: 2020 2020 7265 735b 6f70 5f74 7970 655d      res[op_type]
+00013cc0: 5b27 4650 3332 275d 202b 3d20 310a 2020  ['FP32'] += 1.  
+00013cd0: 2020 2020 2020 2320 7368 6f77 2072 6573        # show res
+00013ce0: 756c 7473 2074 6f20 7573 6572 730a 2020  ults to users.  
+00013cf0: 2020 2020 2020 6966 2069 676e 6f72 655f        if ignore_
+00013d00: 6c6f 673a 0a20 2020 2020 2020 2020 2020  log:.           
+00013d10: 206c 6f67 6765 722e 696e 666f 2822 4967   logger.info("Ig
+00013d20: 6e6f 7265 204c 6179 6572 4e6f 726d 2c20  nore LayerNorm, 
+00013d30: 496e 7374 616e 6365 4e6f 726d 3364 2061  InstanceNorm3d a
+00013d40: 6e64 2045 6d62 6564 6469 6e67 2071 7561  nd Embedding qua
+00013d50: 6e74 697a 6162 6c65 206f 7073 2220 5c0a  ntizable ops" \.
 00013d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013d70: 2020 2063 6869 6c64 2e61 6464 5f6d 6f64     child.add_mod
-00013d80: 756c 6528 2761 6374 6976 6174 696f 6e5f  ule('activation_
-00013d90: 706f 7374 5f70 726f 6365 7373 272c 2063  post_process', c
-00013da0: 6869 6c64 2e71 636f 6e66 6967 2e61 6374  hild.qconfig.act
-00013db0: 6976 6174 696f 6e28 2929 0a20 2020 2020  ivation()).     
-00013dc0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00013dd0: 6869 6c64 2e72 6567 6973 7465 725f 666f  hild.register_fo
-00013de0: 7277 6172 645f 686f 6f6b 285f 6f62 7365  rward_hook(_obse
-00013df0: 7276 6572 5f66 6f72 7761 7264 5f68 6f6f  rver_forward_hoo
-00013e00: 6b29 0a20 2020 2020 2020 2020 2020 2020  k).             
-00013e10: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00013e20: 2020 2020 2020 2020 2020 2020 205f 6164               _ad
-00013e30: 645f 6f62 7365 7276 6572 5f28 6368 696c  d_observer_(chil
-00013e40: 642c 206f 705f 6c69 7374 2c20 6f70 5f6e  d, op_list, op_n
-00013e50: 616d 6529 0a0a 2020 2020 2020 2020 6465  ame)..        de
-00013e60: 6620 5f70 726f 7061 6761 7465 5f71 636f  f _propagate_qco
-00013e70: 6e66 6967 5f68 656c 7065 7228 6d6f 6475  nfig_helper(modu
-00013e80: 6c65 2c0a 2020 2020 2020 2020 2020 2020  le,.            
-00013e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013ea0: 2020 2020 2020 2020 2020 7163 6f6e 6669            qconfi
-00013eb0: 675f 6469 6374 2c0a 2020 2020 2020 2020  g_dict,.        
-00013ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013ed0: 2020 2020 2020 2020 2020 2020 2020 7768                wh
-00013ee0: 6974 655f 6c69 7374 3d4e 6f6e 652c 0a20  ite_list=None,. 
-00013ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013f10: 2020 2020 2071 636f 6e66 6967 5f70 6172       qconfig_par
-00013f20: 656e 743d 4e6f 6e65 2c0a 2020 2020 2020  ent=None,.      
-00013f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013f50: 7072 6566 6978 3d27 272c 0a20 2020 2020  prefix='',.     
-00013f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013f80: 2066 7573 6564 3d46 616c 7365 293a 0a20   fused=False):. 
-00013f90: 2020 2020 2020 2020 2020 2022 2222 5468             """Th
-00013fa0: 6973 2069 7320 6120 6865 6c70 6572 2066  is is a helper f
-00013fb0: 756e 6374 696f 6e20 666f 7220 6070 726f  unction for `pro
-00013fc0: 7061 6761 7465 5f71 636f 6e66 6967 5f60  pagate_qconfig_`
-00013fd0: 0a0a 2020 2020 2020 2020 2020 2020 4172  ..            Ar
-00013fe0: 6773 3a0a 2020 2020 2020 2020 2020 2020  gs:.            
-00013ff0: 2020 2020 6d6f 6475 6c65 2028 6f62 6a65      module (obje
-00014000: 6374 293a 2069 6e70 7574 206d 6f64 756c  ct): input modul
-00014010: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
-00014020: 2020 7163 6f6e 6669 675f 6469 6374 2028    qconfig_dict (
-00014030: 6469 6374 696f 6e61 7279 293a 2064 6963  dictionary): dic
-00014040: 7469 6f6e 6172 7920 7468 6174 206d 6170  tionary that map
-00014050: 7320 6672 6f6d 206e 616d 6520 6f66 2073  s from name of s
-00014060: 7562 6d6f 6475 6c65 2074 6f0a 2020 2020  ubmodule to.    
-00014070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014090: 2020 2020 2020 2071 7561 6e74 697a 6174         quantizat
-000140a0: 696f 6e20 636f 6e66 6967 7572 6174 696f  ion configuratio
-000140b0: 6e0a 2020 2020 2020 2020 2020 2020 2020  n.              
-000140c0: 2020 7768 6974 655f 6c69 7374 2028 6c69    white_list (li
-000140d0: 7374 2c20 6f70 7469 6f6e 616c 293a 206c  st, optional): l
-000140e0: 6973 7420 6f66 2071 7561 6e74 697a 6162  ist of quantizab
-000140f0: 6c65 206d 6f64 756c 6573 0a20 2020 2020  le modules.     
-00014100: 2020 2020 2020 2020 2020 2071 636f 6e66             qconf
-00014110: 6967 5f70 6172 656e 7420 286f 626a 6563  ig_parent (objec
-00014120: 742c 206f 7074 696f 6e61 6c29 3a20 636f  t, optional): co
-00014130: 6e66 6967 206f 6620 7061 7265 6e74 206d  nfig of parent m
-00014140: 6f64 756c 652c 2077 6520 7769 6c6c 2066  odule, we will f
-00014150: 616c 6c62 6163 6b20 746f 0a20 2020 2020  allback to.     
-00014160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014180: 2020 2020 2020 2020 2020 2020 2020 7468                th
-00014190: 6973 2063 6f6e 6669 6720 7768 656e 2074  is config when t
-000141a0: 6865 7265 2069 7320 6e6f 2073 7065 6369  here is no speci
-000141b0: 6669 6564 2063 6f6e 6669 670a 2020 2020  fied config.    
-000141c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000141d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000141e0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-000141f0: 6f72 2063 7572 7265 6e74 206d 6f64 756c  or current modul
-00014200: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
-00014210: 2020 7072 6566 6978 2028 7374 7269 6e67    prefix (string
-00014220: 2c20 6f70 7469 6f6e 616c 293a 2063 6f72  , optional): cor
-00014230: 7265 7370 6f6e 6469 6e67 2070 7265 6669  responding prefi
-00014240: 7820 6f66 2074 6865 2063 7572 7265 6e74  x of the current
-00014250: 206d 6f64 756c 652c 0a20 2020 2020 2020   module,.       
-00014260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014280: 2020 2020 7573 6564 2061 7320 6b65 7920      used as key 
-00014290: 696e 2071 636f 6e66 6967 5f64 6963 740a  in qconfig_dict.
-000142a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000142b0: 6675 7365 6420 2862 6f6f 6c2c 206f 7074  fused (bool, opt
-000142c0: 696f 6e61 6c29 3a20 496e 6469 6361 7465  ional): Indicate
-000142d0: 7320 7768 6574 6865 7220 7468 6520 6d6f  s whether the mo
-000142e0: 6475 6c65 2069 7320 6675 7365 6420 6f72  dule is fused or
-000142f0: 206e 6f74 0a0a 2020 2020 2020 2020 2020   not..          
-00014300: 2020 5265 7475 726e 3a0a 2020 2020 2020    Return:.      
-00014310: 2020 2020 2020 2020 2020 4e6f 6e65 2c20            None, 
-00014320: 6d6f 6475 6c65 2069 7320 6d6f 6469 6669  module is modifi
-00014330: 6564 2069 6e70 6c61 6365 2077 6974 6820  ed inplace with 
-00014340: 7163 6f6e 6669 6720 6174 7461 6368 6564  qconfig attached
-00014350: 0a20 2020 2020 2020 2020 2020 2022 2222  .            """
-00014360: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00014370: 7768 6974 655f 6c69 7374 2069 7320 4e6f  white_list is No
-00014380: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00014390: 2020 2020 7768 6974 655f 6c69 7374 203d      white_list =
-000143a0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-000143b0: 2020 2020 2020 746f 7263 682e 7175 616e        torch.quan
-000143c0: 7469 7a61 7469 6f6e 2e64 6566 6175 6c74  tization.default
-000143d0: 5f6d 6170 7069 6e67 732e 4445 4641 554c  _mappings.DEFAUL
-000143e0: 545f 5143 4f4e 4649 475f 5052 4f50 4147  T_QCONFIG_PROPAG
-000143f0: 4154 455f 5748 4954 455f 4c49 5354 205c  ATE_WHITE_LIST \
-00014400: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014410: 2020 2020 6966 2073 656c 662e 7665 7273      if self.vers
-00014420: 696f 6e2e 7265 6c65 6173 6520 3c20 5665  ion.release < Ve
-00014430: 7273 696f 6e28 2231 2e37 2e30 2229 2e72  rsion("1.7.0").r
-00014440: 656c 6561 7365 2065 6c73 6520 5c0a 2020  elease else \.  
-00014450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014460: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
-00014470: 696f 6e2e 7175 616e 7469 7a61 7469 6f6e  ion.quantization
-00014480: 5f6d 6170 7069 6e67 732e 6765 745f 7163  _mappings.get_qc
-00014490: 6f6e 6669 675f 7072 6f70 6167 6174 696f  onfig_propagatio
-000144a0: 6e5f 6c69 7374 2829 0a0a 2020 2020 2020  n_list()..      
-000144b0: 2020 2020 2020 6966 2074 7970 6528 6d6f        if type(mo
-000144c0: 6475 6c65 2920 696e 2077 6869 7465 5f6c  dule) in white_l
-000144d0: 6973 7420 616e 6420 7479 7065 286d 6f64  ist and type(mod
-000144e0: 756c 6529 2021 3d20 746f 7263 682e 6e6e  ule) != torch.nn
-000144f0: 2e53 6571 7565 6e74 6961 6c3a 0a20 2020  .Sequential:.   
-00014500: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
-00014510: 756c 652e 7163 6f6e 6669 6720 3d20 7163  ule.qconfig = qc
-00014520: 6f6e 6669 675f 7061 7265 6e74 0a20 2020  onfig_parent.   
-00014530: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00014540: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-00014550: 6f64 756c 652e 7163 6f6e 6669 6720 3d20  odule.qconfig = 
-00014560: 4e6f 6e65 0a20 2020 2020 2020 2020 2020  None.           
-00014570: 2069 6620 6861 7361 7474 7228 6d6f 6475   if hasattr(modu
-00014580: 6c65 2c20 275f 6d6f 6475 6c65 7327 293a  le, '_modules'):
-00014590: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000145a0: 2066 6f72 206e 616d 652c 2063 6869 6c64   for name, child
-000145b0: 2069 6e20 6d6f 6475 6c65 2e6e 616d 6564   in module.named
-000145c0: 5f63 6869 6c64 7265 6e28 293a 0a20 2020  _children():.   
-000145d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000145e0: 206d 6f64 756c 655f 7072 6566 6978 203d   module_prefix =
-000145f0: 2070 7265 6669 7820 2b20 272e 2720 2b20   prefix + '.' + 
-00014600: 6e61 6d65 2069 6620 7072 6566 6978 2065  name if prefix e
-00014610: 6c73 6520 6e61 6d65 0a20 2020 2020 2020  lse name.       
-00014620: 2020 2020 2020 2020 2020 2020 205f 7072               _pr
-00014630: 6f70 6167 6174 655f 7163 6f6e 6669 675f  opagate_qconfig_
-00014640: 6865 6c70 6572 2863 6869 6c64 2c20 7163  helper(child, qc
-00014650: 6f6e 6669 675f 6469 6374 2c20 7768 6974  onfig_dict, whit
-00014660: 655f 6c69 7374 2c20 7163 6f6e 6669 675f  e_list, qconfig_
-00014670: 7061 7265 6e74 2c0a 2020 2020 2020 2020  parent,.        
-00014680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000146a0: 2020 2020 2020 6d6f 6475 6c65 5f70 7265        module_pre
-000146b0: 6669 7829 0a0a 2020 2020 2020 2020 6465  fix)..        de
-000146c0: 6620 5f70 7265 7061 7265 286d 6f64 656c  f _prepare(model
-000146d0: 2c20 696e 706c 6163 653d 5472 7565 2c20  , inplace=True, 
-000146e0: 6f70 5f6c 6973 743d 5b5d 2c20 7768 6974  op_list=[], whit
-000146f0: 655f 6c69 7374 3d4e 6f6e 6529 3a0a 2020  e_list=None):.  
-00014700: 2020 2020 2020 2020 2020 2222 2254 6865            """The
-00014710: 206d 6f64 656c 2077 696c 6c20 6265 2061   model will be a
-00014720: 7474 6163 6865 6420 7769 7468 206f 6273  ttached with obs
-00014730: 6572 7665 7220 6f72 2066 616b 6520 7175  erver or fake qu
-00014740: 616e 7420 6d6f 6475 6c65 732c 2061 6e64  ant modules, and
-00014750: 2071 636f 6e66 6967 0a20 2020 2020 2020   qconfig.       
-00014760: 2020 2020 2020 2020 7769 6c6c 2062 6520          will be 
-00014770: 7072 6f70 6167 6174 6564 2e0a 0a20 2020  propagated...   
-00014780: 2020 2020 2020 2020 2041 7267 733a 0a20           Args:. 
-00014790: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-000147a0: 6f64 656c 2028 6f62 6a65 6374 293a 2069  odel (object): i
-000147b0: 6e70 7574 206d 6f64 656c 2074 6f20 6265  nput model to be
-000147c0: 206d 6f64 6966 6965 6420 696e 2d70 6c61   modified in-pla
-000147d0: 6365 0a20 2020 2020 2020 2020 2020 2020  ce.             
-000147e0: 2020 2069 6e70 6c61 6365 2028 626f 6f6c     inplace (bool
-000147f0: 2c20 6f70 7469 6f6e 616c 293a 2063 6172  , optional): car
-00014800: 7279 206f 7574 206d 6f64 656c 2074 7261  ry out model tra
-00014810: 6e73 666f 726d 6174 696f 6e73 2069 6e2d  nsformations in-
-00014820: 706c 6163 652c 0a20 2020 2020 2020 2020  place,.         
-00014830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014850: 2074 6865 206f 7269 6769 6e61 6c20 6d6f   the original mo
-00014860: 6475 6c65 2069 7320 6d75 7461 7465 640a  dule is mutated.
-00014870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014880: 6f70 5f6c 6973 7420 286c 6973 742c 206f  op_list (list, o
-00014890: 7074 696f 6e61 6c29 3a20 6c69 7374 206f  ptional): list o
-000148a0: 6620 6f70 7320 7768 6963 6820 746f 2062  f ops which to b
-000148b0: 6520 6475 6d70 6564 2069 6e20 6d6f 6475  e dumped in modu
-000148c0: 6c65 0a20 2020 2020 2020 2020 2020 2020  le.             
-000148d0: 2020 2077 6869 7465 5f6c 6973 7420 286c     white_list (l
-000148e0: 6973 742c 206f 7074 696f 6e61 6c29 3a20  ist, optional): 
-000148f0: 6c69 7374 206f 6620 7175 616e 7469 7a61  list of quantiza
-00014900: 626c 6520 6d6f 6475 6c65 730a 0a20 2020  ble modules..   
-00014910: 2020 2020 2020 2020 2052 6574 7572 6e73           Returns
-00014920: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00014930: 2020 6d6f 6465 6c20 286f 626a 6563 7429    model (object)
-00014940: 3a20 6d6f 6465 6c20 7769 7468 2071 636f  : model with qco
-00014950: 6e66 6967 0a20 2020 2020 2020 2020 2020  nfig.           
-00014960: 2022 2222 0a20 2020 2020 2020 2020 2020   """.           
-00014970: 2069 6620 6e6f 7420 696e 706c 6163 653a   if not inplace:
-00014980: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014990: 206d 6f64 656c 203d 2063 6f70 792e 6465   model = copy.de
-000149a0: 6570 636f 7079 286d 6f64 656c 290a 2020  epcopy(model).  
-000149b0: 2020 2020 2020 2020 2020 5f70 726f 7061            _propa
-000149c0: 6761 7465 5f71 636f 6e66 6967 5f68 656c  gate_qconfig_hel
-000149d0: 7065 7228 6d6f 6465 6c2c 0a20 2020 2020  per(model,.     
-000149e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000149f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014a00: 2071 636f 6e66 6967 5f64 6963 743d 7b7d   qconfig_dict={}
-00014a10: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00014a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014a30: 2020 2020 2020 2020 7768 6974 655f 6c69          white_li
-00014a40: 7374 3d77 6869 7465 5f6c 6973 742c 0a20  st=white_list,. 
-00014a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014a70: 2020 2020 2071 636f 6e66 6967 5f70 6172       qconfig_par
-00014a80: 656e 743d 6d6f 6465 6c2e 7163 6f6e 6669  ent=model.qconfi
-00014a90: 6729 0a20 2020 2020 2020 2020 2020 2023  g).            #
-00014aa0: 2073 616e 6974 7920 6368 6563 6b20 636f   sanity check co
-00014ab0: 6d6d 6f6e 2041 5049 206d 6973 7573 6167  mmon API misusag
-00014ac0: 650a 2020 2020 2020 2020 2020 2020 6966  e.            if
-00014ad0: 206e 6f74 2061 6e79 2868 6173 6174 7472   not any(hasattr
-00014ae0: 286d 2c20 2771 636f 6e66 6967 2729 2061  (m, 'qconfig') a
-00014af0: 6e64 206d 2e71 636f 6e66 6967 2066 6f72  nd m.qconfig for
-00014b00: 206d 2069 6e20 6d6f 6465 6c2e 6d6f 6475   m in model.modu
-00014b10: 6c65 7328 2929 3a0a 2020 2020 2020 2020  les()):.        
-00014b20: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
-00014b30: 6172 6e28 224e 6f6e 6520 6f66 2074 6865  arn("None of the
-00014b40: 2073 7562 6d6f 6475 6c65 2067 6f74 2071   submodule got q
-00014b50: 636f 6e66 6967 2061 7070 6c69 6564 2e20  config applied. 
-00014b60: 4d61 6b65 2073 7572 6520 796f 7520 220a  Make sure you ".
-00014b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014b80: 2020 2020 2020 2020 2020 2020 2270 6173              "pas
-00014b90: 7365 6420 636f 7272 6563 7420 636f 6e66  sed correct conf
-00014ba0: 6967 7572 6174 696f 6e20 7468 726f 7567  iguration throug
-00014bb0: 6820 6071 636f 6e66 6967 5f64 6963 7460  h `qconfig_dict`
-00014bc0: 206f 7220 220a 2020 2020 2020 2020 2020   or ".          
-00014bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014be0: 2020 2262 7920 6173 7369 676e 696e 6720    "by assigning 
-00014bf0: 7468 6520 602e 7163 6f6e 6669 6760 2061  the `.qconfig` a
-00014c00: 7474 7269 6275 7465 2064 6972 6563 746c  ttribute directl
-00014c10: 7920 6f6e 2073 7562 6d6f 6475 6c65 7322  y on submodules"
-00014c20: 290a 2020 2020 2020 2020 2020 2020 5f61  ).            _a
-00014c30: 6464 5f6f 6273 6572 7665 725f 286d 6f64  dd_observer_(mod
-00014c40: 656c 2c20 6f70 5f6c 6973 743d 6f70 5f6c  el, op_list=op_l
-00014c50: 6973 7429 0a20 2020 2020 2020 2020 2020  ist).           
-00014c60: 2072 6574 7572 6e20 6d6f 6465 6c0a 0a20   return model.. 
-00014c70: 2020 2020 2020 2023 2063 7265 6174 6520         # create 
-00014c80: 7072 6f70 6572 7469 6573 0a20 2020 2020  properties.     
-00014c90: 2020 2069 6620 7365 6c66 2e76 6572 7369     if self.versi
-00014ca0: 6f6e 2e72 656c 6561 7365 203c 2056 6572  on.release < Ver
-00014cb0: 7369 6f6e 2822 312e 372e 3022 292e 7265  sion("1.7.0").re
-00014cc0: 6c65 6173 653a 2020 2320 7072 6167 6d61  lease:  # pragma
-00014cd0: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
-00014ce0: 2020 2020 2020 2077 6869 7465 5f6c 6973         white_lis
-00014cf0: 7420 3d20 7365 6c66 2e77 6869 7465 5f6c  t = self.white_l
-00014d00: 6973 7420 7c20 5c0a 2020 2020 2020 2020  ist | \.        
-00014d10: 2020 2020 2020 2020 2873 6574 2874 6f72          (set(tor
-00014d20: 6368 2e71 7561 6e74 697a 6174 696f 6e2e  ch.quantization.
-00014d30: 6465 6661 756c 745f 6d61 7070 696e 6773  default_mappings
-00014d40: 2e44 4546 4155 4c54 5f4d 4f44 554c 455f  .DEFAULT_MODULE_
-00014d50: 4d41 5050 494e 472e 7661 6c75 6573 2829  MAPPING.values()
-00014d60: 2920 7c0a 2020 2020 2020 2020 2020 2020  ) |.            
-00014d70: 2020 2020 2073 6574 2874 6f72 6368 2e71       set(torch.q
-00014d80: 7561 6e74 697a 6174 696f 6e2e 6465 6661  uantization.defa
-00014d90: 756c 745f 6d61 7070 696e 6773 2e44 4546  ult_mappings.DEF
-00014da0: 4155 4c54 5f51 4154 5f4d 4f44 554c 455f  AULT_QAT_MODULE_
-00014db0: 4d41 5050 494e 472e 7661 6c75 6573 2829  MAPPING.values()
-00014dc0: 2920 7c0a 2020 2020 2020 2020 2020 2020  ) |.            
-00014dd0: 2020 2020 2073 6574 2874 6f72 6368 2e71       set(torch.q
-00014de0: 7561 6e74 697a 6174 696f 6e2e 6465 6661  uantization.defa
-00014df0: 756c 745f 6d61 7070 696e 6773 2e44 4546  ult_mappings.DEF
-00014e00: 4155 4c54 5f44 594e 414d 4943 5f4d 4f44  AULT_DYNAMIC_MOD
-00014e10: 554c 455f 4d41 5050 494e 472e 7661 6c75  ULE_MAPPING.valu
-00014e20: 6573 2829 2929 0a20 2020 2020 2020 2065  es())).        e
-00014e30: 6c69 6620 7365 6c66 2e76 6572 7369 6f6e  lif self.version
-00014e40: 2e72 656c 6561 7365 203c 2056 6572 7369  .release < Versi
-00014e50: 6f6e 2822 312e 382e 3022 292e 7265 6c65  on("1.8.0").rele
-00014e60: 6173 653a 2020 2320 7072 6167 6d61 3a20  ase:  # pragma: 
-00014e70: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
-00014e80: 2020 2020 2077 6869 7465 5f6c 6973 7420       white_list 
-00014e90: 3d20 746f 7263 682e 7175 616e 7469 7a61  = torch.quantiza
-00014ea0: 7469 6f6e 2e67 6574 5f63 6f6d 7061 7265  tion.get_compare
-00014eb0: 5f6f 7574 7075 745f 6d6f 6475 6c65 5f6c  _output_module_l
-00014ec0: 6973 7428 290a 2020 2020 2020 2020 656c  ist().        el
-00014ed0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00014ee0: 7768 6974 655f 6c69 7374 203d 2074 6f72  white_list = tor
-00014ef0: 6368 2e71 7561 6e74 697a 6174 696f 6e2e  ch.quantization.
-00014f00: 6765 745f 6465 6661 756c 745f 636f 6d70  get_default_comp
-00014f10: 6172 655f 6f75 7470 7574 5f6d 6f64 756c  are_output_modul
-00014f20: 655f 6c69 7374 2829 0a0a 2020 2020 2020  e_list()..      
-00014f30: 2020 6d6f 6465 6c20 3d20 6d6f 6465 6c20    model = model 
-00014f40: 6966 206d 6f64 656c 2e69 735f 7175 616e  if model.is_quan
-00014f50: 7469 7a65 6420 656c 7365 2063 6f70 792e  tized else copy.
-00014f60: 6465 6570 636f 7079 286d 6f64 656c 290a  deepcopy(model).
-00014f70: 2020 2020 2020 2020 6d6f 6465 6c2e 5f6d          model._m
-00014f80: 6f64 656c 2e71 636f 6e66 6967 203d 2074  odel.qconfig = t
-00014f90: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
-00014fa0: 6e2e 5143 6f6e 6669 6728 0a20 2020 2020  n.QConfig(.     
-00014fb0: 2020 2020 2020 2077 6569 6768 743d 746f         weight=to
-00014fc0: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
-00014fd0: 2e64 6566 6175 6c74 5f64 6562 7567 5f6f  .default_debug_o
-00014fe0: 6273 6572 7665 722c 0a20 2020 2020 2020  bserver,.       
-00014ff0: 2020 2020 2061 6374 6976 6174 696f 6e3d       activation=
-00015000: 5f52 6563 6f72 6469 6e67 4f62 7365 7276  _RecordingObserv
-00015010: 6572 2e77 6974 685f 6172 6773 2869 7465  er.with_args(ite
-00015020: 7261 7469 6f6e 5f6c 6973 743d 6974 6572  ration_list=iter
-00015030: 6174 696f 6e5f 6c69 7374 2929 0a20 2020  ation_list)).   
-00015040: 2020 2020 205f 7072 6570 6172 6528 6d6f       _prepare(mo
-00015050: 6465 6c2e 5f6d 6f64 656c 2c20 6f70 5f6c  del._model, op_l
-00015060: 6973 743d 6f70 5f6c 6973 742c 2077 6869  ist=op_list, whi
-00015070: 7465 5f6c 6973 743d 7768 6974 655f 6c69  te_list=white_li
-00015080: 7374 290a 0a20 2020 2020 2020 2072 6574  st)..        ret
-00015090: 7572 6e20 6d6f 6465 6c0a 0a20 2020 2064  urn model..    d
-000150a0: 6566 2069 735f 6675 7365 645f 6368 696c  ef is_fused_chil
-000150b0: 6428 7365 6c66 2c20 6f70 5f6e 616d 6529  d(self, op_name)
-000150c0: 3a0a 2020 2020 2020 2020 2222 2254 6869  :.        """Thi
-000150d0: 7320 6973 2061 2068 656c 7065 7220 6675  s is a helper fu
-000150e0: 6e63 7469 6f6e 2066 6f72 2060 5f70 6f73  nction for `_pos
-000150f0: 745f 6576 616c 5f68 6f6f 6b60 0a0a 2020  t_eval_hook`..  
-00015100: 2020 2020 2020 4172 6773 3a0a 2020 2020        Args:.    
-00015110: 2020 2020 2020 2020 6f70 5f6e 616d 6520          op_name 
-00015120: 2873 7472 696e 6729 3a20 6f70 206e 616d  (string): op nam
-00015130: 650a 0a20 2020 2020 2020 2052 6574 7572  e..        Retur
-00015140: 6e73 3a0a 2020 2020 2020 2020 2020 2020  ns:.            
-00015150: 2862 6f6f 6c29 3a20 6966 2074 6869 7320  (bool): if this 
-00015160: 6f70 2069 7320 6675 7365 640a 0a20 2020  op is fused..   
-00015170: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00015180: 206f 7020 3d20 6f70 5f6e 616d 655b 3a6f   op = op_name[:o
-00015190: 705f 6e61 6d65 2e72 6669 6e64 2827 2e27  p_name.rfind('.'
-000151a0: 295d 0a20 2020 2020 2020 2069 6620 6f70  )].        if op
-000151b0: 2069 6e20 7365 6c66 2e66 7573 6564 5f64   in self.fused_d
-000151c0: 6963 7420 616e 6420 6f70 5f6e 616d 655b  ict and op_name[
-000151d0: 6f70 5f6e 616d 652e 7266 696e 6428 272e  op_name.rfind('.
-000151e0: 2729 202b 2031 3a5d 2e69 7364 6967 6974  ') + 1:].isdigit
-000151f0: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-00015200: 7265 7475 726e 2054 7275 650a 2020 2020  return True.    
-00015210: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00015220: 2020 2020 2020 7265 7475 726e 2046 616c        return Fal
-00015230: 7365 0a0a 2020 2020 6465 6620 6973 5f66  se..    def is_f
-00015240: 7573 6564 5f6f 7028 7365 6c66 2c20 6f70  used_op(self, op
-00015250: 5f6e 616d 6529 3a0a 2020 2020 2020 2020  _name):.        
-00015260: 2222 2254 6869 7320 6973 2061 2068 656c  """This is a hel
-00015270: 7065 7220 6675 6e63 7469 6f6e 2066 6f72  per function for
-00015280: 2060 5f70 6f73 745f 6576 616c 5f68 6f6f   `_post_eval_hoo
-00015290: 6b60 0a0a 2020 2020 2020 2020 4172 6773  k`..        Args
-000152a0: 3a0a 2020 2020 2020 2020 2020 2020 6f70  :.            op
-000152b0: 5f6e 616d 6520 2873 7472 696e 6729 3a20  _name (string): 
-000152c0: 6f70 206e 616d 650a 0a20 2020 2020 2020  op name..       
-000152d0: 2052 6574 7572 6e73 3a0a 2020 2020 2020   Returns:.      
-000152e0: 2020 2020 2020 2862 6f6f 6c29 3a20 6966        (bool): if
-000152f0: 2074 6869 7320 6f70 2069 7320 6675 7365   this op is fuse
-00015300: 640a 0a20 2020 2020 2020 2022 2222 0a20  d..        """. 
-00015310: 2020 2020 2020 206f 7020 3d20 6f70 5f6e         op = op_n
-00015320: 616d 655b 3a6f 705f 6e61 6d65 2e72 6669  ame[:op_name.rfi
-00015330: 6e64 2827 2e27 295d 0a20 2020 2020 2020  nd('.')].       
-00015340: 2069 6620 6f70 2069 6e20 7365 6c66 2e66   if op in self.f
-00015350: 7573 6564 5f64 6963 743a 0a20 2020 2020  used_dict:.     
-00015360: 2020 2020 2020 2072 6574 7572 6e20 5472         return Tr
-00015370: 7565 0a20 2020 2020 2020 2065 6c73 653a  ue.        else:
-00015380: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00015390: 7572 6e20 4661 6c73 650a 0a20 2020 2064  urn False..    d
-000153a0: 6566 2069 735f 6c61 7374 5f66 7573 6564  ef is_last_fused
-000153b0: 5f63 6869 6c64 2873 656c 662c 206f 705f  _child(self, op_
-000153c0: 6e61 6d65 293a 0a20 2020 2020 2020 2022  name):.        "
-000153d0: 2222 5468 6973 2069 7320 6120 6865 6c70  ""This is a help
-000153e0: 6572 2066 756e 6374 696f 6e20 666f 7220  er function for 
-000153f0: 605f 706f 7374 5f65 7661 6c5f 686f 6f6b  `_post_eval_hook
-00015400: 600a 0a20 2020 2020 2020 2041 7267 733a  `..        Args:
-00015410: 0a20 2020 2020 2020 2020 2020 206f 705f  .            op_
-00015420: 6e61 6d65 2028 7374 7269 6e67 293a 206f  name (string): o
-00015430: 7020 6e61 6d65 0a0a 2020 2020 2020 2020  p name..        
-00015440: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
-00015450: 2020 2020 2028 626f 6f6c 293a 2069 6620       (bool): if 
-00015460: 7468 6973 206f 7020 6973 206c 6173 7420  this op is last 
-00015470: 6675 7365 6420 6f70 0a0a 2020 2020 2020  fused op..      
-00015480: 2020 2222 220a 2020 2020 2020 2020 6f70    """.        op
-00015490: 203d 206f 705f 6e61 6d65 5b3a 6f70 5f6e   = op_name[:op_n
-000154a0: 616d 652e 7266 696e 6428 272e 2729 5d0a  ame.rfind('.')].
-000154b0: 2020 2020 2020 2020 6966 206f 705f 6e61          if op_na
-000154c0: 6d65 2069 6e20 7365 6c66 2e66 7573 6564  me in self.fused
-000154d0: 5f64 6963 745b 6f70 5d5b 2d31 5d3a 0a20  _dict[op][-1]:. 
-000154e0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-000154f0: 6e20 5472 7565 0a20 2020 2020 2020 2065  n True.        e
-00015500: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00015510: 2072 6574 7572 6e20 4661 6c73 650a 0a20   return False.. 
-00015520: 2020 2064 6566 205f 706f 7374 5f65 7661     def _post_eva
-00015530: 6c5f 686f 6f6b 2873 656c 662c 206d 6f64  l_hook(self, mod
-00015540: 656c 2c20 2a2a 6172 6773 293a 0a20 2020  el, **args):.   
-00015550: 2020 2020 2022 2222 5468 6520 6675 6e63       """The func
-00015560: 7469 6f6e 2069 7320 7573 6564 2074 6f20  tion is used to 
-00015570: 646f 2073 6f6d 6520 706f 7374 2070 726f  do some post pro
-00015580: 6365 7373 2061 6674 6572 2063 6f6d 706c  cess after compl
-00015590: 6574 6520 6576 616c 7561 7469 6f6e 2e0a  ete evaluation..
-000155a0: 2020 2020 2020 2020 2020 2048 6572 652c             Here,
-000155b0: 2069 7420 7573 6564 2074 6f20 6475 6d70   it used to dump
-000155c0: 2071 7561 6e74 697a 6162 6c65 206f 7027   quantizable op'
-000155d0: 7320 6f75 7470 7574 2074 656e 736f 722e  s output tensor.
-000155e0: 0a0a 2020 2020 2020 2020 4172 6773 3a0a  ..        Args:.
-000155f0: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
-00015600: 6c20 286f 626a 6563 7429 3a20 696e 7075  l (object): inpu
-00015610: 7420 6d6f 6465 6c0a 0a20 2020 2020 2020  t model..       
-00015620: 2052 6574 7572 6e73 3a0a 2020 2020 2020   Returns:.      
-00015630: 2020 2020 2020 4e6f 6e65 0a20 2020 2020        None.     
-00015640: 2020 2022 2222 0a20 2020 2020 2020 2066     """.        f
-00015650: 726f 6d20 746f 7263 682e 7574 696c 732e  rom torch.utils.
-00015660: 7465 6e73 6f72 626f 6172 6420 696d 706f  tensorboard impo
-00015670: 7274 2053 756d 6d61 7279 5772 6974 6572  rt SummaryWriter
-00015680: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-00015690: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
-000156a0: 203e 3d20 5665 7273 696f 6e28 2232 2e30   >= Version("2.0
-000156b0: 2e30 2229 2e72 656c 6561 7365 3a0a 2020  .0").release:.  
-000156c0: 2020 2020 2020 2020 2020 6672 6f6d 2074            from t
-000156d0: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
-000156e0: 6e2e 7175 616e 7469 7a65 2069 6d70 6f72  n.quantize impor
-000156f0: 7420 5f67 6574 5f6f 6273 6572 7665 725f  t _get_observer_
-00015700: 6469 6374 2061 7320 6765 745f 6f62 7365  dict as get_obse
-00015710: 7276 6572 5f64 6963 740a 2020 2020 2020  rver_dict.      
-00015720: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00015730: 2020 2020 6672 6f6d 2074 6f72 6368 2e71      from torch.q
-00015740: 7561 6e74 697a 6174 696f 6e20 696d 706f  uantization impo
-00015750: 7274 2067 6574 5f6f 6273 6572 7665 725f  rt get_observer_
-00015760: 6469 6374 0a0a 2020 2020 2020 2020 6d6f  dict..        mo
-00015770: 6465 6c20 3d20 6d6f 6465 6c2e 5f6d 6f64  del = model._mod
-00015780: 656c 0a0a 2020 2020 2020 2020 6966 2061  el..        if a
-00015790: 7267 7320 6973 206e 6f74 204e 6f6e 6520  rgs is not None 
-000157a0: 616e 6420 2761 6363 7572 6163 7927 2069  and 'accuracy' i
-000157b0: 6e20 6172 6773 3a0a 2020 2020 2020 2020  n args:.        
-000157c0: 2020 2020 6163 6375 7261 6379 203d 2061      accuracy = a
-000157d0: 7267 735b 2761 6363 7572 6163 7927 5d0a  rgs['accuracy'].
-000157e0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-000157f0: 2020 2020 2020 2020 2020 6163 6375 7261            accura
-00015800: 6379 203d 2027 270a 0a20 2020 2020 2020  cy = ''..       
-00015810: 2069 6620 7365 6c66 2e64 756d 705f 7469   if self.dump_ti
-00015820: 6d65 7320 3d3d 2030 3a0a 2020 2020 2020  mes == 0:.      
-00015830: 2020 2020 2020 7772 6974 6572 203d 2053        writer = S
-00015840: 756d 6d61 7279 5772 6974 6572 2827 7275  ummaryWriter('ru
-00015850: 6e73 2f65 7661 6c2f 6261 7365 6c69 6e65  ns/eval/baseline
-00015860: 2720 2b20 275f 6163 6327 202b 2073 7472  ' + '_acc' + str
-00015870: 2861 6363 7572 6163 7929 2c20 6d6f 6465  (accuracy), mode
-00015880: 6c29 0a20 2020 2020 2020 2065 6c73 653a  l).        else:
-00015890: 0a20 2020 2020 2020 2020 2020 2077 7269  .            wri
-000158a0: 7465 7220 3d20 5375 6d6d 6172 7957 7269  ter = SummaryWri
-000158b0: 7465 7228 0a20 2020 2020 2020 2020 2020  ter(.           
-000158c0: 2020 2020 2027 7275 6e73 2f65 7661 6c2f       'runs/eval/
-000158d0: 7475 6e65 5f27 202b 2073 7472 2873 656c  tune_' + str(sel
-000158e0: 662e 6475 6d70 5f74 696d 6573 2920 2b20  f.dump_times) + 
-000158f0: 275f 6163 6327 202b 2073 7472 2861 6363  '_acc' + str(acc
-00015900: 7572 6163 7929 2c20 6d6f 6465 6c29 0a0a  uracy), model)..
-00015910: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00015920: 6475 6d70 5f74 696d 6573 203d 3d20 303a  dump_times == 0:
-00015930: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-00015940: 2028 696e 7075 742c 205f 2920 696e 2073   (input, _) in s
-00015950: 656c 662e 715f 6461 7461 6c6f 6164 6572  elf.q_dataloader
-00015960: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00015970: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-00015980: 696e 7075 742c 2064 6963 7429 206f 7220  input, dict) or 
-00015990: 6973 696e 7374 616e 6365 2869 6e70 7574  isinstance(input
-000159a0: 2c20 5573 6572 4469 6374 293a 0a20 2020  , UserDict):.   
-000159b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000159c0: 2069 6620 7365 6c66 2e64 6576 6963 6520   if self.device 
-000159d0: 3d3d 2022 6770 7522 3a0a 2020 2020 2020  == "gpu":.      
-000159e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000159f0: 2020 666f 7220 696e 7020 696e 2069 6e70    for inp in inp
-00015a00: 7574 2e6b 6579 7328 293a 0a20 2020 2020  ut.keys():.     
-00015a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015a20: 2020 2020 2020 2069 6e70 7574 5b69 6e70         input[inp
-00015a30: 5d20 3d20 696e 7075 745b 696e 705d 2e74  ] = input[inp].t
-00015a40: 6f28 2264 7063 7070 2229 0a20 2020 2020  o("dpcpp").     
-00015a50: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-00015a60: 6973 696e 7374 616e 6365 2869 6e70 7574  isinstance(input
-00015a70: 2c20 6c69 7374 2920 6f72 2069 7369 6e73  , list) or isins
-00015a80: 7461 6e63 6528 696e 7075 742c 2074 7570  tance(input, tup
-00015a90: 6c65 293a 0a20 2020 2020 2020 2020 2020  le):.           
-00015aa0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00015ab0: 2e64 6576 6963 6520 3d3d 2022 6770 7522  .device == "gpu"
-00015ac0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00015ad0: 2020 2020 2020 2020 2020 696e 7075 7420            input 
-00015ae0: 3d20 5b69 6e70 2e74 6f28 2264 7063 7070  = [inp.to("dpcpp
-00015af0: 2229 2066 6f72 2069 6e70 2069 6e20 696e  ") for inp in in
-00015b00: 7075 745d 0a20 2020 2020 2020 2020 2020  put].           
-00015b10: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00015b20: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00015b30: 6620 7365 6c66 2e64 6576 6963 6520 3d3d  f self.device ==
-00015b40: 2022 6770 7522 3a0a 2020 2020 2020 2020   "gpu":.        
-00015b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015b60: 696e 7075 7420 3d20 696e 7075 742e 746f  input = input.to
-00015b70: 2822 6470 6370 7022 290a 2020 2020 2020  ("dpcpp").      
-00015b80: 2020 2020 2020 2020 2020 7772 6974 6572            writer
-00015b90: 2e61 6464 5f67 7261 7068 286d 6f64 656c  .add_graph(model
-00015ba0: 2c20 696e 7075 7429 0a20 2020 2020 2020  , input).       
-00015bb0: 2020 2020 2020 2020 2062 7265 616b 0a0a           break..
-00015bc0: 2020 2020 2020 2020 7375 6d6d 6172 7920          summary 
-00015bd0: 3d20 4f72 6465 7265 6444 6963 7428 290a  = OrderedDict().
-00015be0: 2020 2020 2020 2020 6f62 7365 7276 6572          observer
-00015bf0: 5f64 6963 7420 3d20 7b7d 0a20 2020 2020  _dict = {}.     
-00015c00: 2020 2067 6574 5f6f 6273 6572 7665 725f     get_observer_
-00015c10: 6469 6374 286d 6f64 656c 2c20 6f62 7365  dict(model, obse
-00015c20: 7276 6572 5f64 6963 7429 0a20 2020 2020  rver_dict).     
-00015c30: 2020 2066 6f72 206b 6579 2069 6e20 6f62     for key in ob
-00015c40: 7365 7276 6572 5f64 6963 743a 0a20 2020  server_dict:.   
-00015c50: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
-00015c60: 7374 616e 6365 286f 6273 6572 7665 725f  stance(observer_
-00015c70: 6469 6374 5b6b 6579 5d2c 2074 6f72 6368  dict[key], torch
-00015c80: 2e6e 6e2e 6d6f 6475 6c65 732e 6c69 6e65  .nn.modules.line
-00015c90: 6172 2e49 6465 6e74 6974 7929 3a0a 2020  ar.Identity):.  
-00015ca0: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00015cb0: 6e74 696e 7565 0a20 2020 2020 2020 2020  ntinue.         
-00015cc0: 2020 206f 705f 6e61 6d65 203d 206b 6579     op_name = key
-00015cd0: 2e73 7472 6970 2822 2e61 6374 6976 6174  .strip(".activat
-00015ce0: 696f 6e5f 706f 7374 5f70 726f 6365 7373  ion_post_process
-00015cf0: 2229 0a20 2020 2020 2020 2020 2020 2073  ").            s
-00015d00: 756d 6d61 7279 5b6f 705f 6e61 6d65 202b  ummary[op_name +
-00015d10: 2022 2e6f 7574 7075 7422 5d20 3d20 6f62   ".output"] = ob
-00015d20: 7365 7276 6572 5f64 6963 745b 6b65 795d  server_dict[key]
-00015d30: 2e67 6574 5f74 656e 736f 725f 7661 6c75  .get_tensor_valu
-00015d40: 6528 290a 2020 2020 2020 2020 2020 2020  e().            
-00015d50: 666f 7220 6974 6572 2069 6e20 7375 6d6d  for iter in summ
-00015d60: 6172 795b 6f70 5f6e 616d 6520 2b20 222e  ary[op_name + ".
-00015d70: 6f75 7470 7574 225d 3a0a 2020 2020 2020  output"]:.      
-00015d80: 2020 2020 2020 2020 2020 2320 4f6e 6c79            # Only
-00015d90: 2063 6f6c 6c65 6374 206c 6173 7420 6675   collect last fu
-00015da0: 7365 6420 6368 696c 6420 6f75 7470 7574  sed child output
-00015db0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015dc0: 206f 7020 3d20 6f70 5f6e 616d 650a 2020   op = op_name.  
-00015dd0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00015de0: 2073 656c 662e 6973 5f66 7573 6564 5f63   self.is_fused_c
-00015df0: 6869 6c64 286f 705f 6e61 6d65 2920 3d3d  hild(op_name) ==
-00015e00: 2054 7275 6520 616e 6420 5c0a 2020 2020   True and \.    
-00015e10: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00015e20: 656c 662e 6973 5f6c 6173 745f 6675 7365  elf.is_last_fuse
-00015e30: 645f 6368 696c 6428 6f70 5f6e 616d 6529  d_child(op_name)
-00015e40: 203d 3d20 5472 7565 3a0a 2020 2020 2020   == True:.      
-00015e50: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-00015e60: 203d 206f 705f 6e61 6d65 5b3a 6f70 5f6e   = op_name[:op_n
-00015e70: 616d 652e 7266 696e 6428 272e 2729 5d0a  ame.rfind('.')].
-00015e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015e90: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00015ea0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-00015eb0: 662e 6973 5f66 7573 6564 5f63 6869 6c64  f.is_fused_child
-00015ec0: 286f 705f 6e61 6d65 2920 3d3d 2054 7275  (op_name) == Tru
-00015ed0: 6520 616e 6420 5c0a 2020 2020 2020 2020  e and \.        
-00015ee0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00015ef0: 656c 662e 6973 5f6c 6173 745f 6675 7365  elf.is_last_fuse
-00015f00: 645f 6368 696c 6428 6f70 5f6e 616d 6529  d_child(op_name)
-00015f10: 203d 3d20 4661 6c73 653a 0a20 2020 2020   == False:.     
-00015f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015f30: 2020 2063 6f6e 7469 6e75 650a 2020 2020     continue.    
-00015f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015f50: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00015f60: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-00015f70: 203d 206f 705f 6e61 6d65 0a0a 2020 2020   = op_name..    
-00015f80: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-00015f90: 756d 6d61 7279 5b6f 705f 6e61 6d65 202b  ummary[op_name +
-00015fa0: 2022 2e6f 7574 7075 7422 5d5b 6974 6572   ".output"][iter
-00015fb0: 5d2e 6973 5f71 7561 6e74 697a 6564 3a0a  ].is_quantized:.
-00015fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015fd0: 2020 2020 7772 6974 6572 2e61 6464 5f68      writer.add_h
-00015fe0: 6973 746f 6772 616d 286f 7020 2b20 222f  istogram(op + "/
-00015ff0: 4f75 7470 7574 2f69 6e74 3822 2c0a 2020  Output/int8",.  
-00016000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013d70: 2020 2020 2020 2020 2220 6475 6520 746f          " due to
+00013d80: 2061 6363 7572 6163 7920 6973 7375 6520   accuracy issue 
+00013d90: 696e 2050 7954 6f72 6368 2e22 290a 0a20  in PyTorch.").. 
+00013da0: 2020 2020 2020 2066 6965 6c64 5f6e 616d         field_nam
+00013db0: 6573 3d5b 224f 7020 5479 7065 222c 2022  es=["Op Type", "
+00013dc0: 546f 7461 6c22 2c20 2249 4e54 3822 2c20  Total", "INT8", 
+00013dd0: 2242 4631 3622 2c20 2246 5033 3222 5d0a  "BF16", "FP32"].
+00013de0: 2020 2020 2020 2020 6f75 7470 7574 5f64          output_d
+00013df0: 6174 6120 3d20 5b5b 0a20 2020 2020 2020  ata = [[.       
+00013e00: 2020 2020 206f 705f 7479 7065 2c20 7375       op_type, su
+00013e10: 6d28 7265 735b 6f70 5f74 7970 655d 2e76  m(res[op_type].v
+00013e20: 616c 7565 7328 2929 2c0a 2020 2020 2020  alues()),.      
+00013e30: 2020 2020 2020 7265 735b 6f70 5f74 7970        res[op_typ
+00013e40: 655d 5b27 494e 5438 275d 2c20 7265 735b  e]['INT8'], res[
+00013e50: 6f70 5f74 7970 655d 5b27 4246 3136 275d  op_type]['BF16']
+00013e60: 2c20 7265 735b 6f70 5f74 7970 655d 5b27  , res[op_type]['
+00013e70: 4650 3332 275d 5d0a 2020 2020 2020 2020  FP32']].        
+00013e80: 666f 7220 6f70 5f74 7970 6520 696e 2072  for op_type in r
+00013e90: 6573 2e6b 6579 7328 295d 0a0a 2020 2020  es.keys()]..    
+00013ea0: 2020 2020 5374 6174 6973 7469 6373 286f      Statistics(o
+00013eb0: 7574 7075 745f 6461 7461 2c0a 2020 2020  utput_data,.    
+00013ec0: 2020 2020 2020 2020 2020 2020 2020 2068                 h
+00013ed0: 6561 6465 723d 274d 6978 6564 2050 7265  eader='Mixed Pre
+00013ee0: 6369 7369 6f6e 2053 7461 7469 7374 6963  cision Statistic
+00013ef0: 7327 2c0a 2020 2020 2020 2020 2020 2020  s',.            
+00013f00: 2020 2020 2020 2066 6965 6c64 5f6e 616d         field_nam
+00013f10: 6573 3d66 6965 6c64 5f6e 616d 6573 292e  es=field_names).
+00013f20: 7072 696e 745f 7374 6174 2829 0a20 2020  print_stat().   
+00013f30: 2020 2020 2073 656c 662e 6f70 7479 7065       self.optype
+00013f40: 5f73 7461 7469 7374 6963 7320 3d20 6669  _statistics = fi
+00013f50: 656c 645f 6e61 6d65 732c 206f 7574 7075  eld_names, outpu
+00013f60: 745f 6461 7461 0a0a 0a20 2020 2064 6566  t_data...    def
+00013f70: 205f 6765 745f 7175 616e 7469 7a61 626c   _get_quantizabl
+00013f80: 655f 6f70 735f 7265 6375 7273 6976 656c  e_ops_recursivel
+00013f90: 7928 7365 6c66 2c20 6d6f 6465 6c2c 2070  y(self, model, p
+00013fa0: 7265 6669 782c 2071 7561 6e74 697a 6162  refix, quantizab
+00013fb0: 6c65 5f6f 7073 293a 0a20 2020 2020 2020  le_ops):.       
+00013fc0: 2022 2222 5468 6973 2069 7320 6120 6865   """This is a he
+00013fd0: 6c70 6572 2066 756e 6374 696f 6e20 666f  lper function fo
+00013fe0: 7220 6071 7565 7279 5f66 775f 6361 7061  r `query_fw_capa
+00013ff0: 6269 6c69 7479 602c 0a20 2020 2020 2020  bility`,.       
+00014000: 2020 2020 616e 6420 6974 2077 696c 6c20      and it will 
+00014010: 6765 7420 616c 6c20 7175 616e 7469 7a61  get all quantiza
+00014020: 626c 6520 6f70 7320 6672 6f6d 206d 6f64  ble ops from mod
+00014030: 656c 2e0a 0a20 2020 2020 2020 2041 7267  el...        Arg
+00014040: 733a 0a20 2020 2020 2020 2020 2020 206d  s:.            m
+00014050: 6f64 656c 2028 6f62 6a65 6374 293a 2069  odel (object): i
+00014060: 6e70 7574 206d 6f64 656c 0a20 2020 2020  nput model.     
+00014070: 2020 2020 2020 2070 7265 6669 7820 2873         prefix (s
+00014080: 7472 696e 6729 3a20 7072 6566 6978 206f  tring): prefix o
+00014090: 6620 6f70 206e 616d 650a 2020 2020 2020  f op name.      
+000140a0: 2020 2020 2020 7175 616e 7469 7a61 626c        quantizabl
+000140b0: 655f 6f70 7320 286c 6973 7429 3a20 6c69  e_ops (list): li
+000140c0: 7374 206f 6620 7175 616e 7469 7a61 626c  st of quantizabl
+000140d0: 6520 6f70 7320 6672 6f6d 206d 6f64 656c  e ops from model
+000140e0: 2069 6e63 6c75 6465 206f 7020 6e61 6d65   include op name
+000140f0: 2061 6e64 2074 7970 652e 0a0a 2020 2020   and type...    
+00014100: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
+00014110: 2020 2020 2020 2020 204e 6f6e 650a 2020           None.  
+00014120: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
+00014130: 2020 206d 6f64 756c 655f 6469 6374 203d     module_dict =
+00014140: 2064 6963 7428 6d6f 6465 6c2e 6e61 6d65   dict(model.name
+00014150: 645f 6d6f 6475 6c65 7328 2929 0a20 2020  d_modules()).   
+00014160: 2020 2020 2066 6f72 206f 705f 6e61 6d65       for op_name
+00014170: 2c20 6368 696c 6420 696e 206d 6f64 656c  , child in model
+00014180: 2e6e 616d 6564 5f6d 6f64 756c 6573 2829  .named_modules()
+00014190: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+000141a0: 2073 656c 662e 6973 5f66 7573 6564 5f6d   self.is_fused_m
+000141b0: 6f64 756c 6528 6368 696c 6429 3a0a 2020  odule(child):.  
+000141c0: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+000141d0: 7220 6e61 6d65 2c20 5f20 696e 2063 6869  r name, _ in chi
+000141e0: 6c64 2e6e 616d 6564 5f63 6869 6c64 7265  ld.named_childre
+000141f0: 6e28 293a 0a20 2020 2020 2020 2020 2020  n():.           
+00014200: 2020 2020 2020 2020 206d 6f64 756c 655f           module_
+00014210: 7072 6566 6978 203d 206f 705f 6e61 6d65  prefix = op_name
+00014220: 202b 2027 2e27 202b 206e 616d 650a 2020   + '.' + name.  
+00014230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014240: 2020 6966 206d 6f64 756c 655f 7072 6566    if module_pref
+00014250: 6978 2069 6e20 6d6f 6475 6c65 5f64 6963  ix in module_dic
+00014260: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+00014270: 2020 2020 2020 2020 2020 206d 6f64 756c             modul
+00014280: 655f 6469 6374 2e70 6f70 286d 6f64 756c  e_dict.pop(modul
+00014290: 655f 7072 6566 6978 2920 2023 2072 656d  e_prefix)  # rem
+000142a0: 6f76 6520 7375 622d 6d6f 6475 6c65 7320  ove sub-modules 
+000142b0: 6f66 2066 7573 6564 206d 6f64 756c 6573  of fused modules
+000142c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000142d0: 2020 2020 2069 6620 6f70 5f6e 616d 6520       if op_name 
+000142e0: 696e 2073 656c 662e 6675 7365 645f 6469  in self.fused_di
+000142f0: 6374 3a0a 2020 2020 2020 2020 2020 2020  ct:.            
+00014300: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00014310: 2e66 7573 6564 5f64 6963 745b 6f70 5f6e  .fused_dict[op_n
+00014320: 616d 655d 203d 205b 7365 6c66 2e66 7573  ame] = [self.fus
+00014330: 6564 5f64 6963 745b 6f70 5f6e 616d 655d  ed_dict[op_name]
+00014340: 2c20 6d6f 6475 6c65 5f70 7265 6669 785d  , module_prefix]
+00014350: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014360: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00014370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014380: 2020 2073 656c 662e 6675 7365 645f 6469     self.fused_di
+00014390: 6374 5b6f 705f 6e61 6d65 5d20 3d20 6d6f  ct[op_name] = mo
+000143a0: 6475 6c65 5f70 7265 6669 780a 2020 2020  dule_prefix.    
+000143b0: 2020 2020 666f 7220 6f70 5f6e 616d 652c      for op_name,
+000143c0: 2063 6869 6c64 2069 6e20 6d6f 6475 6c65   child in module
+000143d0: 5f64 6963 742e 6974 656d 7328 293a 0a20  _dict.items():. 
+000143e0: 2020 2020 2020 2020 2020 2023 2074 6865             # the
+000143f0: 7265 2069 7320 6163 6375 7261 6379 2069  re is accuracy i
+00014400: 7373 7565 2069 6e20 7175 616e 7469 7a65  ssue in quantize
+00014410: 6420 4c61 7965 724e 6f72 6d20 6f70 2069  d LayerNorm op i
+00014420: 6e20 7079 746f 7263 6820 3c31 2e38 2e31  n pytorch <1.8.1
+00014430: 2c0a 2020 2020 2020 2020 2020 2020 2320  ,.            # 
+00014440: 736f 2072 656d 6f76 6520 6974 2068 6572  so remove it her
+00014450: 650a 2020 2020 2020 2020 2020 2020 6966  e.            if
+00014460: 206f 705f 6e61 6d65 2069 6e20 7365 6c66   op_name in self
+00014470: 2e6e 6f6e 5f71 7561 6e74 5f64 6963 745b  .non_quant_dict[
+00014480: 2773 6b69 7070 6564 5f6d 6f64 756c 655f  'skipped_module_
+00014490: 6e61 6d65 7327 5d20 6f72 205c 0a20 2020  names'] or \.   
+000144a0: 2020 2020 2020 2020 2020 2073 7472 2863             str(c
+000144b0: 6869 6c64 2e5f 5f63 6c61 7373 5f5f 2e5f  hild.__class__._
+000144c0: 5f6e 616d 655f 5f29 2069 6e20 5c0a 2020  _name__) in \.  
+000144d0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+000144e0: 2e6e 6f6e 5f71 7561 6e74 5f64 6963 745b  .non_quant_dict[
+000144f0: 2773 6b69 7070 6564 5f6d 6f64 756c 655f  'skipped_module_
+00014500: 636c 6173 7365 7327 5d3a 0a20 2020 2020  classes']:.     
+00014510: 2020 2020 2020 2020 2020 2063 6f6e 7469             conti
+00014520: 6e75 650a 2020 2020 2020 2020 2020 2020  nue.            
+00014530: 6966 2074 7970 6528 6368 696c 6429 2069  if type(child) i
+00014540: 6e20 7365 6c66 2e77 6869 7465 5f6c 6973  n self.white_lis
+00014550: 7420 616e 6420 7479 7065 2863 6869 6c64  t and type(child
+00014560: 2920 213d 2074 6f72 6368 2e6e 6e2e 5365  ) != torch.nn.Se
+00014570: 7175 656e 7469 616c 2061 6e64 205c 0a20  quential and \. 
+00014580: 2020 2020 2020 2020 2020 2020 2074 7970               typ
+00014590: 6528 6368 696c 6429 2021 3d20 746f 7263  e(child) != torc
+000145a0: 682e 7175 616e 7469 7a61 7469 6f6e 2e73  h.quantization.s
+000145b0: 7475 6273 2e44 6551 7561 6e74 5374 7562  tubs.DeQuantStub
+000145c0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000145d0: 2020 7175 616e 7469 7a61 626c 655f 6f70    quantizable_op
+000145e0: 732e 6170 7065 6e64 280a 2020 2020 2020  s.append(.      
+000145f0: 2020 2020 2020 2020 2020 2020 2020 286f                (o
+00014600: 705f 6e61 6d65 2c20 756e 6966 795f 6f70  p_name, unify_op
+00014610: 5f74 7970 655f 6d61 7070 696e 675b 7374  _type_mapping[st
+00014620: 7228 6368 696c 642e 5f5f 636c 6173 735f  r(child.__class_
+00014630: 5f2e 5f5f 6e61 6d65 5f5f 295d 0a20 2020  _.__name__)].   
+00014640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014650: 2020 6966 2073 7472 2863 6869 6c64 2e5f    if str(child._
+00014660: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
+00014670: 5f29 2069 6e20 756e 6966 795f 6f70 5f74  _) in unify_op_t
+00014680: 7970 655f 6d61 7070 696e 6720 656c 7365  ype_mapping else
+00014690: 2073 7472 280a 2020 2020 2020 2020 2020   str(.          
+000146a0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+000146b0: 6869 6c64 2e5f 5f63 6c61 7373 5f5f 2e5f  hild.__class__._
+000146c0: 5f6e 616d 655f 5f29 2929 0a0a 2020 2020  _name__)))..    
+000146d0: 6465 6620 5f67 6574 5f73 6361 6c65 5f7a  def _get_scale_z
+000146e0: 6572 6f70 6f69 6e74 2873 656c 662c 206d  eropoint(self, m
+000146f0: 6f64 656c 2c20 7475 6e65 5f63 6667 293a  odel, tune_cfg):
+00014700: 0a20 2020 2020 2020 2022 2222 6765 7420  .        """get 
+00014710: 6163 7469 7661 7469 6f6e 2073 6361 6c65  activation scale
+00014720: 2061 6e64 207a 6572 6f5f 706f 696e 7420   and zero_point 
+00014730: 666f 7220 636f 6e76 6572 7465 6420 6d6f  for converted mo
+00014740: 6465 6c2e 0a0a 2020 2020 2020 2020 4172  del...        Ar
+00014750: 6773 3a0a 2020 2020 2020 2020 2020 2020  gs:.            
+00014760: 6d6f 6465 6c20 2864 6972 293a 2049 6e74  model (dir): Int
+00014770: 3820 6d6f 6465 6c20 636f 6e76 6572 7465  8 model converte
+00014780: 6420 6672 6f6d 2066 7033 3220 6d6f 6465  d from fp32 mode
+00014790: 6c2e 0a20 2020 2020 2020 2020 2020 2020  l..             
+000147a0: 2020 2020 2020 2020 2020 2073 6361 6c65             scale
+000147b0: 2061 6e64 207a 6572 6f5f 706f 696e 7420   and zero_point 
+000147c0: 6973 2073 6574 2077 6974 6820 6361 6c69  is set with cali
+000147d0: 6272 6174 696f 6e20 666f 7220 6561 6368  bration for each
+000147e0: 206d 6f64 756c 650a 2020 2020 2020 2020   module.        
+000147f0: 2020 2020 7475 6e65 5f63 6667 2028 6f62      tune_cfg (ob
+00014800: 6a65 6374 293a 2054 6869 7320 6669 6c65  ject): This file
+00014810: 2073 6176 6573 2073 6361 6c65 2061 6e64   saves scale and
+00014820: 207a 6572 6f5f 706f 696e 7420 6f66 205c   zero_point of \
+00014830: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014840: 2020 2020 2020 2020 2020 2020 206f 7574               out
+00014850: 7075 7420 6163 7469 7661 7469 6f6e 206f  put activation o
+00014860: 6620 6561 6368 2071 7561 6e74 697a 6564  f each quantized
+00014870: 206d 6f64 756c 652e 0a0a 2020 2020 2020   module...      
+00014880: 2020 5265 7475 726e 733a 0a20 2020 2020    Returns:.     
+00014890: 2020 2020 2020 204e 6f6e 650a 2020 2020         None.    
+000148a0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+000148b0: 6d6f 6475 6c65 7320 3d20 6469 6374 286d  modules = dict(m
+000148c0: 6f64 656c 2e6e 616d 6564 5f6d 6f64 756c  odel.named_modul
+000148d0: 6573 2829 290a 2020 2020 2020 2020 666f  es()).        fo
+000148e0: 7220 6b65 792c 2076 616c 7565 2069 6e20  r key, value in 
+000148f0: 7475 6e65 5f63 6667 5b27 6f70 275d 2e69  tune_cfg['op'].i
+00014900: 7465 6d73 2829 3a0a 2020 2020 2020 2020  tems():.        
+00014910: 2020 2020 6966 2068 6173 6174 7472 286d      if hasattr(m
+00014920: 6f64 756c 6573 5b6b 6579 5b30 5d5d 2c20  odules[key[0]], 
+00014930: 2773 6361 6c65 2729 3a0a 2020 2020 2020  'scale'):.      
+00014940: 2020 2020 2020 2020 2020 7661 6c75 655b            value[
+00014950: 2761 6374 6976 6174 696f 6e27 5d5b 2773  'activation']['s
+00014960: 6361 6c65 275d 203d 2066 6c6f 6174 286d  cale'] = float(m
+00014970: 6f64 756c 6573 5b6b 6579 5b30 5d5d 2e73  odules[key[0]].s
+00014980: 6361 6c65 290a 2020 2020 2020 2020 2020  cale).          
+00014990: 2020 6966 2068 6173 6174 7472 286d 6f64    if hasattr(mod
+000149a0: 756c 6573 5b6b 6579 5b30 5d5d 2c20 277a  ules[key[0]], 'z
+000149b0: 6572 6f5f 706f 696e 7427 293a 0a20 2020  ero_point'):.   
+000149c0: 2020 2020 2020 2020 2020 2020 2076 616c               val
+000149d0: 7565 5b27 6163 7469 7661 7469 6f6e 275d  ue['activation']
+000149e0: 5b27 7a65 726f 5f70 6f69 6e74 275d 203d  ['zero_point'] =
+000149f0: 2069 6e74 286d 6f64 756c 6573 5b6b 6579   int(modules[key
+00014a00: 5b30 5d5d 2e7a 6572 6f5f 706f 696e 7429  [0]].zero_point)
+00014a10: 0a0a 2020 2020 6465 6620 5f70 7265 5f65  ..    def _pre_e
+00014a20: 7661 6c5f 686f 6f6b 2873 656c 662c 206d  val_hook(self, m
+00014a30: 6f64 656c 2c20 6f70 5f6c 6973 743d 4e6f  odel, op_list=No
+00014a40: 6e65 2c20 6974 6572 6174 696f 6e5f 6c69  ne, iteration_li
+00014a50: 7374 3d4e 6f6e 6529 3a0a 2020 2020 2020  st=None):.      
+00014a60: 2020 2222 2254 6865 2066 756e 6374 696f    """The functio
+00014a70: 6e20 6973 2075 7365 6420 746f 2064 6f20  n is used to do 
+00014a80: 736f 6d65 2070 7265 7072 6f63 6573 7369  some preprocessi
+00014a90: 6f6e 2062 6566 6f72 6520 6576 616c 7561  on before evalua
+00014aa0: 7469 6f6e 2070 6861 7365 2e0a 2020 2020  tion phase..    
+00014ab0: 2020 2020 2020 2048 6572 652c 2069 7420         Here, it 
+00014ac0: 7573 6564 2074 6f20 6164 6420 686f 6f6b  used to add hook
+00014ad0: 2066 6f72 2064 756d 7020 6f75 7470 7574   for dump output
+00014ae0: 2074 656e 736f 7220 666f 7220 7175 616e   tensor for quan
+00014af0: 7469 7a61 626c 6520 6f70 732e 0a0a 2020  tizable ops...  
+00014b00: 2020 2020 2020 4172 6773 3a0a 2020 2020        Args:.    
+00014b10: 2020 2020 2020 2020 206d 6f64 656c 2028           model (
+00014b20: 6f62 6a65 6374 293a 2069 6e70 7574 206d  object): input m
+00014b30: 6f64 656c 0a0a 2020 2020 2020 2020 5265  odel..        Re
+00014b40: 7475 726e 733a 0a20 2020 2020 2020 2020  turns:.         
+00014b50: 2020 2020 206d 6f64 656c 2028 6f62 6a65       model (obje
+00014b60: 6374 293a 206d 6f64 656c 2077 6974 6820  ct): model with 
+00014b70: 686f 6f6b 0a20 2020 2020 2020 2022 2222  hook.        """
+00014b80: 0a20 2020 2020 2020 2066 726f 6d20 6162  .        from ab
+00014b90: 6320 696d 706f 7274 2041 4243 4d65 7461  c import ABCMeta
+00014ba0: 0a0a 2020 2020 2020 2020 6465 6620 5f77  ..        def _w
+00014bb0: 6974 685f 6172 6773 2863 6c73 5f6f 725f  ith_args(cls_or_
+00014bc0: 7365 6c66 2c20 2a2a 6b77 6172 6773 293a  self, **kwargs):
+00014bd0: 0a20 2020 2020 2020 2020 2020 2072 2222  .            r""
+00014be0: 2257 7261 7070 6572 2074 6861 7420 616c  "Wrapper that al
+00014bf0: 6c6f 7773 2063 7265 6174 696f 6e20 6f66  lows creation of
+00014c00: 2063 6c61 7373 2066 6163 746f 7269 6573   class factories
+00014c10: 2e0a 0a20 2020 2020 2020 2020 2020 2054  ...            T
+00014c20: 6869 7320 6361 6e20 6265 2075 7365 6675  his can be usefu
+00014c30: 6c20 7768 656e 2074 6865 7265 2069 7320  l when there is 
+00014c40: 6120 6e65 6564 2074 6f20 6372 6561 7465  a need to create
+00014c50: 2063 6c61 7373 6573 2077 6974 6820 7468   classes with th
+00014c60: 6520 7361 6d65 0a20 2020 2020 2020 2020  e same.         
+00014c70: 2020 2063 6f6e 7374 7275 6374 6f72 2061     constructor a
+00014c80: 7267 756d 656e 7473 2c20 6275 7420 6469  rguments, but di
+00014c90: 6666 6572 656e 7420 696e 7374 616e 6365  fferent instance
+00014ca0: 732e 0a0a 2020 2020 2020 2020 2020 2020  s...            
+00014cb0: 4578 616d 706c 653a 3a0a 0a20 2020 2020  Example::..     
+00014cc0: 2020 2020 2020 2020 2020 203e 3e3e 2046             >>> F
+00014cd0: 6f6f 2e77 6974 685f 6172 6773 203d 2063  oo.with_args = c
+00014ce0: 6c61 7373 6d65 7468 6f64 285f 7769 7468  lassmethod(_with
+00014cf0: 5f61 7267 7329 0a20 2020 2020 2020 2020  _args).         
+00014d00: 2020 2020 2020 203e 3e3e 2066 6f6f 5f62         >>> foo_b
+00014d10: 7569 6c64 6572 203d 2046 6f6f 2e77 6974  uilder = Foo.wit
+00014d20: 685f 6172 6773 2861 3d33 2c20 623d 3429  h_args(a=3, b=4)
+00014d30: 2e77 6974 685f 6172 6773 2861 6e73 7765  .with_args(answe
+00014d40: 723d 3432 290a 2020 2020 2020 2020 2020  r=42).          
+00014d50: 2020 2020 2020 3e3e 3e20 666f 6f5f 696e        >>> foo_in
+00014d60: 7374 616e 6365 3120 3d20 666f 6f5f 6275  stance1 = foo_bu
+00014d70: 696c 6465 7228 290a 2020 2020 2020 2020  ilder().        
+00014d80: 2020 2020 2020 2020 3e3e 3e20 666f 6f5f          >>> foo_
+00014d90: 696e 7374 616e 6365 3220 3d20 666f 6f5f  instance2 = foo_
+00014da0: 6275 696c 6465 7228 290a 2020 2020 2020  builder().      
+00014db0: 2020 2020 2020 2020 2020 3e3e 3e20 6964            >>> id
+00014dc0: 2866 6f6f 5f69 6e73 7461 6e63 6531 2920  (foo_instance1) 
+00014dd0: 3d3d 2069 6428 666f 6f5f 696e 7374 616e  == id(foo_instan
+00014de0: 6365 3229 0a20 2020 2020 2020 2020 2020  ce2).           
+00014df0: 2020 2020 2046 616c 7365 0a20 2020 2020       False.     
+00014e00: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00014e10: 2020 2020 2020 2063 6c61 7373 205f 5061         class _Pa
+00014e20: 7274 6961 6c57 7261 7070 6572 286f 626a  rtialWrapper(obj
+00014e30: 6563 7429 3a0a 2020 2020 2020 2020 2020  ect):.          
+00014e40: 2020 2020 2020 6465 6620 5f5f 696e 6974        def __init
+00014e50: 5f5f 2873 656c 662c 2070 293a 0a20 2020  __(self, p):.   
+00014e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014e70: 2073 656c 662e 7020 3d20 700a 0a20 2020   self.p = p..   
+00014e80: 2020 2020 2020 2020 2020 2020 2064 6566               def
+00014e90: 205f 5f63 616c 6c5f 5f28 7365 6c66 2c20   __call__(self, 
+00014ea0: 2a61 7267 732c 202a 2a6b 6579 776f 7264  *args, **keyword
+00014eb0: 7329 3a0a 2020 2020 2020 2020 2020 2020  s):.            
+00014ec0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00014ed0: 656c 662e 7028 2a61 7267 732c 202a 2a6b  elf.p(*args, **k
+00014ee0: 6579 776f 7264 7329 0a0a 2020 2020 2020  eywords)..      
+00014ef0: 2020 2020 2020 2020 2020 6465 6620 5f5f            def __
+00014f00: 7265 7072 5f5f 2873 656c 6629 3a0a 2020  repr__(self):.  
+00014f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014f20: 2020 7265 7475 726e 2073 656c 662e 702e    return self.p.
+00014f30: 5f5f 7265 7072 5f5f 2829 0a0a 2020 2020  __repr__()..    
+00014f40: 2020 2020 2020 2020 2020 2020 7769 7468              with
+00014f50: 5f61 7267 7320 3d20 5f77 6974 685f 6172  _args = _with_ar
+00014f60: 6773 0a0a 2020 2020 2020 2020 2020 2020  gs..            
+00014f70: 7220 3d20 5f50 6172 7469 616c 5772 6170  r = _PartialWrap
+00014f80: 7065 7228 7061 7274 6961 6c28 636c 735f  per(partial(cls_
+00014f90: 6f72 5f73 656c 662c 202a 2a6b 7761 7267  or_self, **kwarg
+00014fa0: 7329 290a 2020 2020 2020 2020 2020 2020  s)).            
+00014fb0: 7265 7475 726e 2072 0a0a 2020 2020 2020  return r..      
+00014fc0: 2020 4142 4320 3d20 4142 434d 6574 6128    ABC = ABCMeta(
+00014fd0: 7374 7228 2241 4243 2229 2c20 286f 626a  str("ABC"), (obj
+00014fe0: 6563 742c 2029 2c20 7b7d 2920 2023 2063  ect, ), {})  # c
+00014ff0: 6f6d 7061 7469 626c 6520 7769 7468 2050  ompatible with P
+00015000: 7974 686f 6e20 3220 2a61 6e64 2a20 333a  ython 2 *and* 3:
+00015010: 0a0a 2020 2020 2020 2020 636c 6173 7320  ..        class 
+00015020: 5f52 6563 6f72 6469 6e67 4f62 7365 7276  _RecordingObserv
+00015030: 6572 2841 4243 2c20 746f 7263 682e 6e6e  er(ABC, torch.nn
+00015040: 2e4d 6f64 756c 6529 3a0a 2020 2020 2020  .Module):.      
+00015050: 2020 2020 2020 2222 2254 6865 206d 6f64        """The mod
+00015060: 756c 6520 6973 206d 6169 6e6c 7920 666f  ule is mainly fo
+00015070: 7220 6465 6275 6720 616e 6420 7265 636f  r debug and reco
+00015080: 7264 7320 7468 6520 7465 6e73 6f72 2076  rds the tensor v
+00015090: 616c 7565 7320 6475 7269 6e67 2072 756e  alues during run
+000150a0: 7469 6d65 2e0a 0a20 2020 2020 2020 2020  time...         
+000150b0: 2020 2041 7267 733a 0a20 2020 2020 2020     Args:.       
+000150c0: 2020 2020 2020 2020 2069 7465 7261 7469           iterati
+000150d0: 6f6e 5f6c 6973 7420 286c 6973 742c 206f  on_list (list, o
+000150e0: 7074 696f 6e61 6c29 3a20 696e 6465 7873  ptional): indexs
+000150f0: 206f 6620 6974 6572 6174 696f 6e20 7768   of iteration wh
+00015100: 6963 6820 746f 2064 756d 7020 7465 6e73  ich to dump tens
+00015110: 6f72 2e0a 2020 2020 2020 2020 2020 2020  or..            
+00015120: 2222 220a 2020 2020 2020 2020 2020 2020  """.            
+00015130: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00015140: 662c 2069 7465 7261 7469 6f6e 5f6c 6973  f, iteration_lis
+00015150: 743d 4e6f 6e65 2c20 2a2a 6b77 6172 6773  t=None, **kwargs
+00015160: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+00015170: 2020 2073 7570 6572 285f 5265 636f 7264     super(_Record
+00015180: 696e 674f 6273 6572 7665 722c 2073 656c  ingObserver, sel
+00015190: 6629 2e5f 5f69 6e69 745f 5f28 2a2a 6b77  f).__init__(**kw
+000151a0: 6172 6773 290a 2020 2020 2020 2020 2020  args).          
+000151b0: 2020 2020 2020 7365 6c66 2e6f 7574 7075        self.outpu
+000151c0: 745f 7465 6e73 6f72 735f 6469 6374 203d  t_tensors_dict =
+000151d0: 204f 7264 6572 6564 4469 6374 2829 0a20   OrderedDict(). 
+000151e0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000151f0: 656c 662e 6375 7272 656e 745f 6974 6572  elf.current_iter
+00015200: 203d 2031 0a20 2020 2020 2020 2020 2020   = 1.           
+00015210: 2020 2020 2073 656c 662e 6974 6572 6174       self.iterat
+00015220: 696f 6e5f 6c69 7374 203d 2069 7465 7261  ion_list = itera
+00015230: 7469 6f6e 5f6c 6973 740a 0a20 2020 2020  tion_list..     
+00015240: 2020 2020 2020 2064 6566 2066 6f72 7761         def forwa
+00015250: 7264 2873 656c 662c 2078 293a 0a20 2020  rd(self, x):.   
+00015260: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00015270: 2873 656c 662e 6974 6572 6174 696f 6e5f  (self.iteration_
+00015280: 6c69 7374 2069 7320 4e6f 6e65 2061 6e64  list is None and
+00015290: 2073 656c 662e 6375 7272 656e 745f 6974   self.current_it
+000152a0: 6572 203d 3d20 3129 206f 7220 5c0a 2020  er == 1) or \.  
+000152b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000152c0: 2020 2873 656c 662e 6974 6572 6174 696f    (self.iteratio
+000152d0: 6e5f 6c69 7374 2069 7320 6e6f 7420 4e6f  n_list is not No
+000152e0: 6e65 2061 6e64 0a20 2020 2020 2020 2020  ne and.         
+000152f0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00015300: 2e63 7572 7265 6e74 5f69 7465 7220 696e  .current_iter in
+00015310: 2073 656c 662e 6974 6572 6174 696f 6e5f   self.iteration_
+00015320: 6c69 7374 293a 0a20 2020 2020 2020 2020  list):.         
+00015330: 2020 2020 2020 2020 2020 2069 6620 7479             if ty
+00015340: 7065 2878 2920 6973 2074 7570 6c65 206f  pe(x) is tuple o
+00015350: 7220 7479 7065 2878 2920 6973 206c 6973  r type(x) is lis
+00015360: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+00015370: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00015380: 6f75 7470 7574 5f74 656e 736f 7273 5f64  output_tensors_d
+00015390: 6963 745b 7365 6c66 2e63 7572 7265 6e74  ict[self.current
+000153a0: 5f69 7465 725d 203d 205c 0a20 2020 2020  _iter] = \.     
+000153b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000153c0: 2020 2020 2020 205b 692e 746f 2822 6370         [i.to("cp
+000153d0: 7522 2920 6966 2069 2e64 6576 6963 6520  u") if i.device 
+000153e0: 213d 2027 6370 7527 2065 6c73 6520 692e  != 'cpu' else i.
+000153f0: 636c 6f6e 6528 2920 666f 7220 6920 696e  clone() for i in
+00015400: 2078 5d0a 2020 2020 2020 2020 2020 2020   x].            
+00015410: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00015420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015430: 2020 2020 2020 7365 6c66 2e6f 7574 7075        self.outpu
+00015440: 745f 7465 6e73 6f72 735f 6469 6374 5b73  t_tensors_dict[s
+00015450: 656c 662e 6375 7272 656e 745f 6974 6572  elf.current_iter
+00015460: 5d20 3d20 5c0a 2020 2020 2020 2020 2020  ] = \.          
+00015470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015480: 2020 782e 746f 2822 6370 7522 2920 6966    x.to("cpu") if
+00015490: 2078 2e64 6576 6963 6520 213d 2022 6370   x.device != "cp
+000154a0: 7522 2065 6c73 6520 782e 636c 6f6e 6528  u" else x.clone(
+000154b0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+000154c0: 2020 7365 6c66 2e63 7572 7265 6e74 5f69    self.current_i
+000154d0: 7465 7220 2b3d 2031 0a20 2020 2020 2020  ter += 1.       
+000154e0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+000154f0: 780a 0a20 2020 2020 2020 2020 2020 2040  x..            @
+00015500: 746f 7263 682e 6a69 742e 6578 706f 7274  torch.jit.export
+00015510: 0a20 2020 2020 2020 2020 2020 2064 6566  .            def
+00015520: 2067 6574 5f74 656e 736f 725f 7661 6c75   get_tensor_valu
+00015530: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
+00015540: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00015550: 7365 6c66 2e6f 7574 7075 745f 7465 6e73  self.output_tens
+00015560: 6f72 735f 6469 6374 0a0a 2020 2020 2020  ors_dict..      
+00015570: 2020 2020 2020 7769 7468 5f61 7267 7320        with_args 
+00015580: 3d20 636c 6173 736d 6574 686f 6428 5f77  = classmethod(_w
+00015590: 6974 685f 6172 6773 290a 0a20 2020 2020  ith_args)..     
+000155a0: 2020 2064 6566 205f 6f62 7365 7276 6572     def _observer
+000155b0: 5f66 6f72 7761 7264 5f68 6f6f 6b28 6d6f  _forward_hook(mo
+000155c0: 6475 6c65 2c20 696e 7075 742c 206f 7574  dule, input, out
+000155d0: 7075 7429 3a0a 2020 2020 2020 2020 2020  put):.          
+000155e0: 2020 2222 2246 6f72 7761 7264 2068 6f6f    """Forward hoo
+000155f0: 6b20 7468 6174 2063 616c 6c73 206f 6273  k that calls obs
+00015600: 6572 7665 7220 6f6e 2074 6865 206f 7574  erver on the out
+00015610: 7075 740a 0a20 2020 2020 2020 2020 2020  put..           
+00015620: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
+00015630: 2020 2020 2020 206d 6f64 756c 6520 286f         module (o
+00015640: 626a 6563 7429 3a20 696e 7075 7420 6d6f  bject): input mo
+00015650: 6475 6c65 0a20 2020 2020 2020 2020 2020  dule.           
+00015660: 2020 2020 2069 6e70 7574 2028 6f62 6a65       input (obje
+00015670: 6374 293a 206d 6f64 756c 6520 696e 7075  ct): module inpu
+00015680: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
+00015690: 2020 6f75 7470 7574 2028 6f62 6a65 6374    output (object
+000156a0: 293a 206d 6f64 756c 6520 6f75 7470 7574  ): module output
+000156b0: 0a0a 2020 2020 2020 2020 2020 2020 5265  ..            Re
+000156c0: 7475 726e 733a 0a20 2020 2020 2020 2020  turns:.         
+000156d0: 2020 2020 2020 206d 6f64 756c 6520 6f75         module ou
+000156e0: 7470 7574 2074 656e 736f 7220 286f 626a  tput tensor (obj
+000156f0: 6563 7429 0a20 2020 2020 2020 2020 2020  ect).           
+00015700: 2022 2222 0a20 2020 2020 2020 2020 2020   """.           
+00015710: 2072 6574 7572 6e20 6d6f 6475 6c65 2e61   return module.a
+00015720: 6374 6976 6174 696f 6e5f 706f 7374 5f70  ctivation_post_p
+00015730: 726f 6365 7373 286f 7574 7075 7429 0a0a  rocess(output)..
+00015740: 2020 2020 2020 2020 6465 6620 5f61 6464          def _add
+00015750: 5f6f 6273 6572 7665 725f 286d 6f64 756c  _observer_(modul
+00015760: 652c 206f 705f 6c69 7374 3d4e 6f6e 652c  e, op_list=None,
+00015770: 2070 7265 6669 783d 2222 293a 0a20 2020   prefix=""):.   
+00015780: 2020 2020 2020 2020 2022 2222 4164 6420           """Add 
+00015790: 6f62 7365 7276 6572 2066 6f72 2074 6865  observer for the
+000157a0: 206c 6561 6620 6368 696c 6420 6f66 2074   leaf child of t
+000157b0: 6865 206d 6f64 756c 652e 0a0a 2020 2020  he module...    
+000157c0: 2020 2020 2020 2020 2020 2054 6869 7320             This 
+000157d0: 6675 6e63 7469 6f6e 2069 6e73 6572 7420  function insert 
+000157e0: 6f62 7365 7276 6572 206d 6f64 756c 6520  observer module 
+000157f0: 746f 2061 6c6c 206c 6561 6620 6368 696c  to all leaf chil
+00015800: 6420 6d6f 6475 6c65 2074 6861 740a 2020  d module that.  
+00015810: 2020 2020 2020 2020 2020 2020 2068 6173               has
+00015820: 2061 2076 616c 6964 2071 636f 6e66 6967   a valid qconfig
+00015830: 2061 7474 7269 6275 7465 2e0a 0a20 2020   attribute...   
+00015840: 2020 2020 2020 2020 2041 7267 733a 0a20           Args:. 
+00015850: 2020 2020 2020 2020 2020 2020 2020 206d                 m
+00015860: 6f64 756c 6520 286f 626a 6563 7429 3a20  odule (object): 
+00015870: 696e 7075 7420 6d6f 6475 6c65 2077 6974  input module wit
+00015880: 6820 7163 6f6e 6669 6720 6174 7472 6962  h qconfig attrib
+00015890: 7574 6573 2066 6f72 2061 6c6c 2074 6865  utes for all the
+000158a0: 206c 6561 6620 6d6f 6475 6c65 7320 7468   leaf modules th
+000158b0: 6174 0a20 2020 2020 2020 2020 2020 2020  at.             
+000158c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000158d0: 2020 2020 7765 2077 616e 7420 746f 2064      we want to d
+000158e0: 756d 7020 7465 6e73 6f72 0a20 2020 2020  ump tensor.     
+000158f0: 2020 2020 2020 2020 2020 206f 705f 6c69             op_li
+00015900: 7374 2028 6c69 7374 2c20 6f70 7469 6f6e  st (list, option
+00015910: 616c 293a 206c 6973 7420 6f66 206f 7073  al): list of ops
+00015920: 2077 6869 6368 2074 6f20 6265 2064 756d   which to be dum
+00015930: 7065 6420 696e 206d 6f64 756c 650a 2020  ped in module.  
+00015940: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+00015950: 6566 6978 2028 7374 7269 6e67 293a 206e  efix (string): n
+00015960: 616d 6520 6f66 206d 6f64 756c 650a 0a20  ame of module.. 
+00015970: 2020 2020 2020 2020 2020 2052 6574 7572             Retur
+00015980: 6e73 3a0a 2020 2020 2020 2020 2020 2020  ns:.            
+00015990: 2020 2020 4e6f 6e65 2c20 6d6f 6475 6c65      None, module
+000159a0: 2069 7320 6d6f 6469 6669 6564 2069 6e70   is modified inp
+000159b0: 6c61 6365 2077 6974 6820 6164 6465 6420  lace with added 
+000159c0: 6f62 7365 7276 6572 206d 6f64 756c 6573  observer modules
+000159d0: 2061 6e64 2066 6f72 7761 7264 5f68 6f6f   and forward_hoo
+000159e0: 6b73 0a20 2020 2020 2020 2020 2020 2022  ks.            "
+000159f0: 2222 0a20 2020 2020 2020 2020 2020 2066  "".            f
+00015a00: 6f72 206e 616d 652c 2063 6869 6c64 2069  or name, child i
+00015a10: 6e20 6d6f 6475 6c65 2e6e 616d 6564 5f63  n module.named_c
+00015a20: 6869 6c64 7265 6e28 293a 0a20 2020 2020  hildren():.     
+00015a30: 2020 2020 2020 2020 2020 206f 705f 6e61             op_na
+00015a40: 6d65 203d 206e 616d 6520 6966 2070 7265  me = name if pre
+00015a50: 6669 7820 3d3d 2022 2220 656c 7365 2070  fix == "" else p
+00015a60: 7265 6669 7820 2b20 222e 2220 2b20 6e61  refix + "." + na
+00015a70: 6d65 0a20 2020 2020 2020 2020 2020 2020  me.             
+00015a80: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+00015a90: 2863 6869 6c64 2c20 746f 7263 682e 6e6e  (child, torch.nn
+00015aa0: 2e71 7561 6e74 697a 6564 2e46 6c6f 6174  .quantized.Float
+00015ab0: 4675 6e63 7469 6f6e 616c 2920 616e 6420  Functional) and 
+00015ac0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00015ad0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+00015ae0: 6f70 5f6c 6973 7420 6973 204e 6f6e 6520  op_list is None 
+00015af0: 6f72 206f 705f 6e61 6d65 2069 6e20 6f70  or op_name in op
+00015b00: 5f6c 6973 7429 3a0a 2020 2020 2020 2020  _list):.        
+00015b10: 2020 2020 2020 2020 2020 2020 6966 2068              if h
+00015b20: 6173 6174 7472 2863 6869 6c64 2c20 2771  asattr(child, 'q
+00015b30: 636f 6e66 6967 2729 2061 6e64 2063 6869  config') and chi
+00015b40: 6c64 2e71 636f 6e66 6967 2069 7320 6e6f  ld.qconfig is no
+00015b50: 7420 4e6f 6e65 2061 6e64 2028 0a20 2020  t None and (.   
+00015b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015b70: 2020 2020 2020 2020 206f 705f 6c69 7374           op_list
+00015b80: 2069 7320 4e6f 6e65 206f 7220 6f70 5f6e   is None or op_n
+00015b90: 616d 6520 696e 206f 705f 6c69 7374 293a  ame in op_list):
+00015ba0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00015bb0: 2020 2020 2020 2020 2063 6869 6c64 2e61           child.a
+00015bc0: 6374 6976 6174 696f 6e5f 706f 7374 5f70  ctivation_post_p
+00015bd0: 726f 6365 7373 203d 205c 0a20 2020 2020  rocess = \.     
+00015be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015bf0: 2020 2020 2020 2063 6869 6c64 2e71 636f         child.qco
+00015c00: 6e66 6967 2e61 6374 6976 6174 696f 6e28  nfig.activation(
+00015c10: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00015c20: 2020 656c 6966 2068 6173 6174 7472 2863    elif hasattr(c
+00015c30: 6869 6c64 2c20 2771 636f 6e66 6967 2729  hild, 'qconfig')
+00015c40: 2061 6e64 2063 6869 6c64 2e71 636f 6e66   and child.qconf
+00015c50: 6967 2069 7320 6e6f 7420 4e6f 6e65 2061  ig is not None a
+00015c60: 6e64 205c 0a20 2020 2020 2020 2020 2020  nd \.           
+00015c70: 2020 2020 2020 2020 2020 2020 2028 6f70               (op
+00015c80: 5f6c 6973 7420 6973 204e 6f6e 6520 6f72  _list is None or
+00015c90: 206f 705f 6e61 6d65 2069 6e20 6f70 5f6c   op_name in op_l
+00015ca0: 6973 7429 3a0a 2020 2020 2020 2020 2020  ist):.          
+00015cb0: 2020 2020 2020 2020 2020 2320 6f62 7365            # obse
+00015cc0: 7276 6572 2061 6e64 2068 6f6f 6b20 7769  rver and hook wi
+00015cd0: 6c6c 2062 6520 676f 6e65 2061 6674 6572  ll be gone after
+00015ce0: 2077 6520 7377 6170 2074 6865 206d 6f64   we swap the mod
+00015cf0: 756c 650a 2020 2020 2020 2020 2020 2020  ule.            
+00015d00: 2020 2020 2020 2020 6368 696c 642e 6164          child.ad
+00015d10: 645f 6d6f 6475 6c65 2827 6163 7469 7661  d_module('activa
+00015d20: 7469 6f6e 5f70 6f73 745f 7072 6f63 6573  tion_post_proces
+00015d30: 7327 2c20 6368 696c 642e 7163 6f6e 6669  s', child.qconfi
+00015d40: 672e 6163 7469 7661 7469 6f6e 2829 290a  g.activation()).
+00015d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015d60: 2020 2020 6368 696c 642e 7265 6769 7374      child.regist
+00015d70: 6572 5f66 6f72 7761 7264 5f68 6f6f 6b28  er_forward_hook(
+00015d80: 5f6f 6273 6572 7665 725f 666f 7277 6172  _observer_forwar
+00015d90: 645f 686f 6f6b 290a 2020 2020 2020 2020  d_hook).        
+00015da0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00015db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015dc0: 2020 5f61 6464 5f6f 6273 6572 7665 725f    _add_observer_
+00015dd0: 2863 6869 6c64 2c20 6f70 5f6c 6973 742c  (child, op_list,
+00015de0: 206f 705f 6e61 6d65 290a 0a20 2020 2020   op_name)..     
+00015df0: 2020 2064 6566 205f 7072 6f70 6167 6174     def _propagat
+00015e00: 655f 7163 6f6e 6669 675f 6865 6c70 6572  e_qconfig_helper
+00015e10: 286d 6f64 756c 652c 0a20 2020 2020 2020  (module,.       
+00015e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015e30: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+00015e40: 636f 6e66 6967 5f64 6963 742c 0a20 2020  config_dict,.   
+00015e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015e70: 2020 2077 6869 7465 5f6c 6973 743d 4e6f     white_list=No
+00015e80: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
+00015e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015ea0: 2020 2020 2020 2020 2020 7163 6f6e 6669            qconfi
+00015eb0: 675f 7061 7265 6e74 3d4e 6f6e 652c 0a20  g_parent=None,. 
+00015ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015ee0: 2020 2020 2070 7265 6669 783d 2727 2c0a       prefix='',.
+00015ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015f10: 2020 2020 2020 6675 7365 643d 4661 6c73        fused=Fals
+00015f20: 6529 3a0a 2020 2020 2020 2020 2020 2020  e):.            
+00015f30: 2222 2254 6869 7320 6973 2061 2068 656c  """This is a hel
+00015f40: 7065 7220 6675 6e63 7469 6f6e 2066 6f72  per function for
+00015f50: 2060 7072 6f70 6167 6174 655f 7163 6f6e   `propagate_qcon
+00015f60: 6669 675f 600a 0a20 2020 2020 2020 2020  fig_`..         
+00015f70: 2020 2041 7267 733a 0a20 2020 2020 2020     Args:.       
+00015f80: 2020 2020 2020 2020 206d 6f64 756c 6520           module 
+00015f90: 286f 626a 6563 7429 3a20 696e 7075 7420  (object): input 
+00015fa0: 6d6f 6475 6c65 0a20 2020 2020 2020 2020  module.         
+00015fb0: 2020 2020 2020 2071 636f 6e66 6967 5f64         qconfig_d
+00015fc0: 6963 7420 2864 6963 7469 6f6e 6172 7929  ict (dictionary)
+00015fd0: 3a20 6469 6374 696f 6e61 7279 2074 6861  : dictionary tha
+00015fe0: 7420 6d61 7073 2066 726f 6d20 6e61 6d65  t maps from name
+00015ff0: 206f 6620 7375 626d 6f64 756c 6520 746f   of submodule to
+00016000: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 00016010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016020: 2020 2020 2020 2074 6f72 6368 2e64 6571         torch.deq
-00016030: 7561 6e74 697a 6528 7375 6d6d 6172 795b  uantize(summary[
-00016040: 6f70 5f6e 616d 6520 2b20 222e 6f75 7470  op_name + ".outp
-00016050: 7574 225d 5b69 7465 725d 2929 0a20 2020  ut"][iter])).   
-00016060: 2020 2020 2020 2020 2020 2020 2065 6c73               els
-00016070: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-00016080: 2020 2020 2020 2077 7269 7465 722e 6164         writer.ad
-00016090: 645f 6869 7374 6f67 7261 6d28 6f70 202b  d_histogram(op +
-000160a0: 2022 2f4f 7574 7075 742f 6670 3332 222c   "/Output/fp32",
-000160b0: 2073 756d 6d61 7279 5b6f 705f 6e61 6d65   summary[op_name
-000160c0: 202b 2022 2e6f 7574 7075 7422 5d5b 6974   + ".output"][it
-000160d0: 6572 5d29 0a0a 2020 2020 2020 2020 7374  er])..        st
-000160e0: 6174 655f 6469 6374 203d 206d 6f64 656c  ate_dict = model
-000160f0: 2e73 7461 7465 5f64 6963 7428 290a 2020  .state_dict().  
-00016100: 2020 2020 2020 666f 7220 6b65 7920 696e        for key in
-00016110: 2073 7461 7465 5f64 6963 743a 0a20 2020   state_dict:.   
-00016120: 2020 2020 2020 2020 2069 6620 6e6f 7420           if not 
-00016130: 6973 696e 7374 616e 6365 2873 7461 7465  isinstance(state
-00016140: 5f64 6963 745b 6b65 795d 2c20 746f 7263  _dict[key], torc
-00016150: 682e 5465 6e73 6f72 293a 0a20 2020 2020  h.Tensor):.     
-00016160: 2020 2020 2020 2020 2020 2063 6f6e 7469             conti
-00016170: 6e75 650a 0a20 2020 2020 2020 2020 2020  nue..           
-00016180: 206f 7020 3d20 6b65 795b 3a6b 6579 2e72   op = key[:key.r
-00016190: 6669 6e64 2827 2e27 295d 0a20 2020 2020  find('.')].     
-000161a0: 2020 2020 2020 2069 6620 7365 6c66 2e69         if self.i
-000161b0: 735f 6675 7365 645f 6368 696c 6428 6f70  s_fused_child(op
-000161c0: 2920 6973 2054 7275 653a 0a20 2020 2020  ) is True:.     
-000161d0: 2020 2020 2020 2020 2020 2023 2066 7573             # fus
-000161e0: 6564 2063 6869 6c64 2074 656e 736f 7262  ed child tensorb
-000161f0: 6f61 7264 2074 6167 2077 696c 6c20 6265  oard tag will be
-00016200: 206d 6572 6765 0a20 2020 2020 2020 2020   merge.         
-00016210: 2020 2020 2020 2077 6569 6768 7420 3d20         weight = 
-00016220: 6b65 795b 6b65 792e 7266 696e 6428 272e  key[key.rfind('.
-00016230: 2729 202b 2031 3a5d 0a20 2020 2020 2020  ') + 1:].       
-00016240: 2020 2020 2020 2020 206f 7020 3d20 6f70           op = op
-00016250: 5b3a 6f70 2e72 6669 6e64 2827 2e27 295d  [:op.rfind('.')]
-00016260: 202b 2027 2f27 202b 2077 6569 6768 740a   + '/' + weight.
-00016270: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00016280: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00016290: 2020 7765 6967 6874 203d 206b 6579 5b6b    weight = key[k
-000162a0: 6579 2e72 6669 6e64 2827 2e27 2920 2b20  ey.rfind('.') + 
-000162b0: 313a 5d0a 2020 2020 2020 2020 2020 2020  1:].            
-000162c0: 2020 2020 6f70 203d 206b 6579 5b3a 6b65      op = key[:ke
-000162d0: 792e 7266 696e 6428 272e 2729 5d20 2b20  y.rfind('.')] + 
-000162e0: 272f 2720 2b20 7765 6967 6874 0a0a 2020  '/' + weight..  
-000162f0: 2020 2020 2020 2020 2020 2320 546f 206d            # To m
-00016300: 6572 6765 202e 5f70 6163 6b65 645f 7061  erge ._packed_pa
-00016310: 7261 6d73 0a20 2020 2020 2020 2020 2020  rams.           
-00016320: 206f 7020 3d20 6f70 2e72 6570 6c61 6365   op = op.replace
-00016330: 2827 2e5f 7061 636b 6564 5f70 6172 616d  ('._packed_param
-00016340: 7327 2c20 2727 290a 0a20 2020 2020 2020  s', '')..       
-00016350: 2020 2020 2069 6620 7374 6174 655f 6469       if state_di
-00016360: 6374 5b6b 6579 5d2e 6973 5f71 7561 6e74  ct[key].is_quant
-00016370: 697a 6564 3a0a 2020 2020 2020 2020 2020  ized:.          
-00016380: 2020 2020 2020 7772 6974 6572 2e61 6464        writer.add
-00016390: 5f68 6973 746f 6772 616d 286f 7020 2b20  _histogram(op + 
-000163a0: 222f 696e 7438 222c 2074 6f72 6368 2e64  "/int8", torch.d
-000163b0: 6571 7561 6e74 697a 6528 7374 6174 655f  equantize(state_
-000163c0: 6469 6374 5b6b 6579 5d29 290a 2020 2020  dict[key])).    
-000163d0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-000163e0: 2020 2020 2020 2020 2020 2020 2020 7772                wr
-000163f0: 6974 6572 2e61 6464 5f68 6973 746f 6772  iter.add_histogr
-00016400: 616d 286f 7020 2b20 222f 6670 3332 222c  am(op + "/fp32",
-00016410: 2073 7461 7465 5f64 6963 745b 6b65 795d   state_dict[key]
-00016420: 290a 0a20 2020 2020 2020 2077 7269 7465  )..        write
-00016430: 722e 636c 6f73 6528 290a 2020 2020 2020  r.close().      
-00016440: 2020 7365 6c66 2e64 756d 705f 7469 6d65    self.dump_time
-00016450: 7320 3d20 7365 6c66 2e64 756d 705f 7469  s = self.dump_ti
-00016460: 6d65 7320 2b20 310a 0a20 2020 2020 2020  mes + 1..       
-00016470: 2072 6574 7572 6e20 7375 6d6d 6172 790a   return summary.
-00016480: 0a20 2020 2040 6475 6d70 5f65 6c61 7073  .    @dump_elaps
-00016490: 6564 5f74 696d 6528 2250 6173 7320 7361  ed_time("Pass sa
-000164a0: 7665 2071 7561 6e74 697a 6564 206d 6f64  ve quantized mod
-000164b0: 656c 2229 0a20 2020 2064 6566 2073 6176  el").    def sav
-000164c0: 6528 7365 6c66 2c20 6d6f 6465 6c2c 2070  e(self, model, p
-000164d0: 6174 683d 4e6f 6e65 293a 0a20 2020 2020  ath=None):.     
-000164e0: 2020 2070 6173 730a 0a20 2020 2064 6566     pass..    def
-000164f0: 2069 6e73 7065 6374 5f74 656e 736f 7228   inspect_tensor(
-00016500: 7365 6c66 2c0a 2020 2020 2020 2020 2020  self,.          
-00016510: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
-00016520: 656c 2c0a 2020 2020 2020 2020 2020 2020  el,.            
-00016530: 2020 2020 2020 2020 2020 2064 6174 616c             datal
-00016540: 6f61 6465 722c 0a20 2020 2020 2020 2020  oader,.         
-00016550: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-00016560: 5f6c 6973 743d 4e6f 6e65 2c0a 2020 2020  _list=None,.    
-00016570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016580: 2020 2069 7465 7261 7469 6f6e 5f6c 6973     iteration_lis
-00016590: 743d 4e6f 6e65 2c0a 2020 2020 2020 2020  t=None,.        
-000165a0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-000165b0: 6e73 7065 6374 5f74 7970 653d 2761 6374  nspect_type='act
-000165c0: 6976 6174 696f 6e27 2c0a 2020 2020 2020  ivation',.      
-000165d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000165e0: 2073 6176 655f 746f 5f64 6973 6b3d 4661   save_to_disk=Fa
-000165f0: 6c73 6529 3a0a 2020 2020 2020 2020 6966  lse):.        if
-00016600: 2073 656c 662e 7665 7273 696f 6e2e 7265   self.version.re
-00016610: 6c65 6173 6520 3e3d 2056 6572 7369 6f6e  lease >= Version
-00016620: 2822 312e 382e 3022 292e 7265 6c65 6173  ("1.8.0").releas
-00016630: 653a 0a20 2020 2020 2020 2020 2020 2066  e:.            f
-00016640: 726f 6d20 746f 7263 682e 6678 2069 6d70  rom torch.fx imp
-00016650: 6f72 7420 4772 6170 684d 6f64 756c 650a  ort GraphModule.
-00016660: 2020 2020 2020 2020 2020 2020 6966 2074              if t
-00016670: 7970 6528 6d6f 6465 6c2e 5f6d 6f64 656c  ype(model._model
-00016680: 2920 3d3d 2047 7261 7068 4d6f 6475 6c65  ) == GraphModule
-00016690: 3a20 2023 2070 7261 676d 613a 206e 6f20  :  # pragma: no 
-000166a0: 636f 7665 720a 2020 2020 2020 2020 2020  cover.          
-000166b0: 2020 2020 2020 6173 7365 7274 2046 616c        assert Fal
-000166c0: 7365 2c20 2249 6e73 7065 6374 5f74 656e  se, "Inspect_ten
-000166d0: 736f 7220 6469 646e 2774 2073 7570 706f  sor didn't suppo
-000166e0: 7274 2066 7820 6772 6170 6820 6d6f 6465  rt fx graph mode
-000166f0: 6c20 6e6f 7721 220a 2020 2020 2020 2020  l now!".        
-00016700: 6672 6f6d 2074 6f72 6368 2069 6d70 6f72  from torch impor
-00016710: 7420 6465 7175 616e 7469 7a65 0a20 2020  t dequantize.   
-00016720: 2020 2020 2069 6d70 6f72 7420 6e75 6d70       import nump
-00016730: 7920 6173 206e 700a 2020 2020 2020 2020  y as np.        
-00016740: 6973 5f71 7561 6e74 697a 6564 203d 206d  is_quantized = m
-00016750: 6f64 656c 2e69 735f 7175 616e 7469 7a65  odel.is_quantize
-00016760: 640a 2020 2020 2020 2020 6f70 5f6c 6973  d.        op_lis
-00016770: 745f 203d 205b 5d0a 2020 2020 2020 2020  t_ = [].        
-00016780: 6670 3332 5f69 6e74 385f 6d61 7020 3d20  fp32_int8_map = 
-00016790: 7b7d 0a20 2020 2020 2020 2066 6f72 206f  {}.        for o
-000167a0: 705f 6e61 6d65 2069 6e20 6f70 5f6c 6973  p_name in op_lis
-000167b0: 743a 0a20 2020 2020 2020 2020 2020 206f  t:.            o
-000167c0: 705f 6c69 7374 5f2e 6170 7065 6e64 286f  p_list_.append(o
-000167d0: 705f 6e61 6d65 290a 2020 2020 2020 2020  p_name).        
-000167e0: 2020 2020 666f 7220 6b65 7920 696e 2073      for key in s
-000167f0: 656c 662e 6675 7365 645f 6469 6374 3a0a  elf.fused_dict:.
-00016800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016810: 6966 206f 705f 6e61 6d65 2069 6e20 7365  if op_name in se
-00016820: 6c66 2e66 7573 6564 5f64 6963 745b 6b65  lf.fused_dict[ke
-00016830: 795d 3a0a 2020 2020 2020 2020 2020 2020  y]:.            
-00016840: 2020 2020 2020 2020 6670 3332 5f69 6e74          fp32_int
-00016850: 385f 6d61 705b 6f70 5f6e 616d 655d 203d  8_map[op_name] =
-00016860: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00016870: 2020 2020 2020 2020 2020 207b 2761 6374             {'act
-00016880: 6976 6174 696f 6e27 3a20 7365 6c66 2e66  ivation': self.f
-00016890: 7573 6564 5f64 6963 745b 6b65 795d 5b2d  used_dict[key][-
-000168a0: 315d 2c20 2777 6569 6768 7427 3a20 6b65  1], 'weight': ke
-000168b0: 797d 0a20 2020 2020 2020 2020 2020 2020  y}.             
-000168c0: 2020 2020 2020 2069 6620 6973 5f71 7561         if is_qua
-000168d0: 6e74 697a 6564 3a0a 2020 2020 2020 2020  ntized:.        
-000168e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000168f0: 6f70 5f6c 6973 745f 2e61 7070 656e 6428  op_list_.append(
-00016900: 6b65 7929 0a20 2020 2020 2020 2020 2020  key).           
-00016910: 2020 2020 2020 2020 2020 2020 206f 705f               op_
-00016920: 6c69 7374 5f2e 7265 6d6f 7665 286f 705f  list_.remove(op_
-00016930: 6e61 6d65 290a 2020 2020 2020 2020 2020  name).          
-00016940: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00016950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016960: 2020 2020 2020 2020 6f70 5f6c 6973 745f          op_list_
-00016970: 2e61 7070 656e 6428 7365 6c66 2e66 7573  .append(self.fus
-00016980: 6564 5f64 6963 745b 6b65 795d 5b2d 315d  ed_dict[key][-1]
-00016990: 290a 0a20 2020 2020 2020 206e 6577 5f6d  )..        new_m
-000169a0: 6f64 656c 203d 206d 6f64 656c 2069 6620  odel = model if 
-000169b0: 6973 5f71 7561 6e74 697a 6564 2065 6c73  is_quantized els
-000169c0: 6520 636f 7079 2e64 6565 7063 6f70 7928  e copy.deepcopy(
-000169d0: 6d6f 6465 6c29 0a0a 2020 2020 2020 2020  model)..        
-000169e0: 6173 7365 7274 206d 696e 2869 7465 7261  assert min(itera
-000169f0: 7469 6f6e 5f6c 6973 7429 203e 2030 2c20  tion_list) > 0, 
-00016a00: 5c0a 2020 2020 2020 2020 2020 2020 2249  \.            "I
-00016a10: 7465 7261 7469 6f6e 206e 756d 6265 7220  teration number 
-00016a20: 7368 6f75 6c64 2067 7265 6174 207a 6572  should great zer
-00016a30: 6f2c 2031 206d 6561 6e73 2066 6972 7374  o, 1 means first
-00016a40: 2069 7465 7261 7469 6f6e 2e22 0a20 2020   iteration.".   
-00016a50: 2020 2020 2069 7465 7261 7469 6f6e 7320       iterations 
-00016a60: 3d20 6d61 7828 6974 6572 6174 696f 6e5f  = max(iteration_
-00016a70: 6c69 7374 2920 6966 2069 7465 7261 7469  list) if iterati
-00016a80: 6f6e 5f6c 6973 7420 6973 206e 6f74 204e  on_list is not N
-00016a90: 6f6e 6520 656c 7365 202d 310a 2020 2020  one else -1.    
-00016aa0: 2020 2020 6e65 775f 6d6f 6465 6c20 3d20      new_model = 
-00016ab0: 7365 6c66 2e5f 7072 655f 6576 616c 5f68  self._pre_eval_h
-00016ac0: 6f6f 6b28 6e65 775f 6d6f 6465 6c2c 206f  ook(new_model, o
-00016ad0: 705f 6c69 7374 3d6f 705f 6c69 7374 5f2c  p_list=op_list_,
-00016ae0: 2069 7465 7261 7469 6f6e 5f6c 6973 743d   iteration_list=
-00016af0: 6974 6572 6174 696f 6e5f 6c69 7374 290a  iteration_list).
-00016b00: 2020 2020 2020 2020 7365 6c66 2e65 7661          self.eva
-00016b10: 6c75 6174 6528 6e65 775f 6d6f 6465 6c2c  luate(new_model,
-00016b20: 2064 6174 616c 6f61 6465 722c 2069 7465   dataloader, ite
-00016b30: 7261 7469 6f6e 3d69 7465 7261 7469 6f6e  ration=iteration
-00016b40: 7329 0a20 2020 2020 2020 206f 6273 6572  s).        obser
-00016b50: 7665 725f 6469 6374 203d 207b 7d0a 2020  ver_dict = {}.  
-00016b60: 2020 2020 2020 7265 7420 3d20 7b7d 0a20        ret = {}. 
-00016b70: 2020 2020 2020 2069 6620 696e 7370 6563         if inspec
-00016b80: 745f 7479 7065 203d 3d20 2761 6374 6976  t_type == 'activ
-00016b90: 6174 696f 6e27 206f 7220 696e 7370 6563  ation' or inspec
-00016ba0: 745f 7479 7065 203d 3d20 2761 6c6c 273a  t_type == 'all':
-00016bb0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00016bc0: 7365 6c66 2e76 6572 7369 6f6e 2e72 656c  self.version.rel
-00016bd0: 6561 7365 203e 3d20 5665 7273 696f 6e28  ease >= Version(
-00016be0: 2232 2e30 2e30 2229 2e72 656c 6561 7365  "2.0.0").release
-00016bf0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00016c00: 2020 6672 6f6d 2074 6f72 6368 2e71 7561    from torch.qua
-00016c10: 6e74 697a 6174 696f 6e2e 7175 616e 7469  ntization.quanti
-00016c20: 7a65 2069 6d70 6f72 7420 5f67 6574 5f6f  ze import _get_o
-00016c30: 6273 6572 7665 725f 6469 6374 2061 7320  bserver_dict as 
-00016c40: 6765 745f 6f62 7365 7276 6572 5f64 6963  get_observer_dic
-00016c50: 740a 2020 2020 2020 2020 2020 2020 656c  t.            el
-00016c60: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00016c70: 2020 2020 6672 6f6d 2074 6f72 6368 2e71      from torch.q
-00016c80: 7561 6e74 697a 6174 696f 6e20 696d 706f  uantization impo
-00016c90: 7274 2067 6574 5f6f 6273 6572 7665 725f  rt get_observer_
-00016ca0: 6469 6374 0a20 2020 2020 2020 2020 2020  dict.           
-00016cb0: 2072 6574 5b27 6163 7469 7661 7469 6f6e   ret['activation
-00016cc0: 275d 203d 205b 5d0a 2020 2020 2020 2020  '] = [].        
-00016cd0: 2020 2020 6765 745f 6f62 7365 7276 6572      get_observer
-00016ce0: 5f64 6963 7428 6e65 775f 6d6f 6465 6c2e  _dict(new_model.
-00016cf0: 5f6d 6f64 656c 2c20 6f62 7365 7276 6572  _model, observer
-00016d00: 5f64 6963 7429 0a20 2020 2020 2020 2020  _dict).         
-00016d10: 2020 2069 6620 6974 6572 6174 696f 6e5f     if iteration_
-00016d20: 6c69 7374 2069 7320 4e6f 6e65 3a0a 2020  list is None:.  
-00016d30: 2020 2020 2020 2020 2020 2020 2020 6974                it
-00016d40: 6572 6174 696f 6e5f 6c69 7374 203d 205b  eration_list = [
-00016d50: 315d 0a20 2020 2020 2020 2020 2020 2066  1].            f
-00016d60: 6f72 2069 2069 6e20 6974 6572 6174 696f  or i in iteratio
-00016d70: 6e5f 6c69 7374 3a0a 2020 2020 2020 2020  n_list:.        
-00016d80: 2020 2020 2020 2020 7375 6d6d 6172 7920          summary 
-00016d90: 3d20 4f72 6465 7265 6444 6963 7428 290a  = OrderedDict().
-00016da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016db0: 666f 7220 6b65 7920 696e 206f 6273 6572  for key in obser
-00016dc0: 7665 725f 6469 6374 3a0a 2020 2020 2020  ver_dict:.      
-00016dd0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00016de0: 2069 7369 6e73 7461 6e63 6528 6f62 7365   isinstance(obse
-00016df0: 7276 6572 5f64 6963 745b 6b65 795d 2c20  rver_dict[key], 
-00016e00: 746f 7263 682e 6e6e 2e6d 6f64 756c 6573  torch.nn.modules
-00016e10: 2e6c 696e 6561 722e 4964 656e 7469 7479  .linear.Identity
-00016e20: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00016e30: 2020 2020 2020 2020 2020 2063 6f6e 7469             conti
-00016e40: 6e75 650a 2020 2020 2020 2020 2020 2020  nue.            
-00016e50: 2020 2020 2020 2020 6f70 5f6e 616d 6520          op_name 
-00016e60: 3d20 6b65 792e 7265 706c 6163 6528 222e  = key.replace(".
-00016e70: 6163 7469 7661 7469 6f6e 5f70 6f73 745f  activation_post_
-00016e80: 7072 6f63 6573 7322 2c20 2222 290a 2020  process", "").  
-00016e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016ea0: 2020 7661 6c75 6520 3d20 6f62 7365 7276    value = observ
-00016eb0: 6572 5f64 6963 745b 6b65 795d 2e67 6574  er_dict[key].get
-00016ec0: 5f74 656e 736f 725f 7661 6c75 6528 295b  _tensor_value()[
-00016ed0: 695d 0a20 2020 2020 2020 2020 2020 2020  i].             
-00016ee0: 2020 2020 2020 2069 6620 6f70 5f6e 616d         if op_nam
-00016ef0: 6520 696e 206f 705f 6c69 7374 3a0a 2020  e in op_list:.  
-00016f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016f10: 2020 2020 2020 6966 2074 7970 6528 7661        if type(va
-00016f20: 6c75 6529 2069 7320 6c69 7374 3a0a 2020  lue) is list:.  
-00016f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016f40: 2020 2020 2020 2020 2020 7375 6d6d 6172            summar
-00016f50: 795b 6f70 5f6e 616d 655d 203d 207b 7d0a  y[op_name] = {}.
-00016f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016f70: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00016f80: 696e 6465 7820 696e 2072 616e 6765 286c  index in range(l
-00016f90: 656e 2876 616c 7565 2929 3a0a 2020 2020  en(value)):.    
-00016fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016fb0: 2020 2020 2020 2020 2020 2020 7375 6d6d              summ
-00016fc0: 6172 795b 6f70 5f6e 616d 655d 2e75 7064  ary[op_name].upd
-00016fd0: 6174 6528 7b0a 2020 2020 2020 2020 2020  ate({.          
-00016fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016ff0: 2020 2020 2020 2020 2020 6f70 5f6e 616d            op_nam
-00017000: 6520 2b20 222e 6f75 7470 7574 2220 2b20  e + ".output" + 
-00017010: 7374 7228 696e 6465 7829 3a0a 2020 2020  str(index):.    
-00017020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017040: 6465 7175 616e 7469 7a65 2876 616c 7565  dequantize(value
-00017050: 5b69 6e64 6578 5d29 2e6e 756d 7079 2829  [index]).numpy()
-00017060: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017080: 2020 2020 2069 6620 7661 6c75 655b 696e       if value[in
-00017090: 6465 785d 2e69 735f 7175 616e 7469 7a65  dex].is_quantize
-000170a0: 6420 656c 7365 2076 616c 7565 5b69 6e64  d else value[ind
-000170b0: 6578 5d2e 6e75 6d70 7928 290a 2020 2020  ex].numpy().    
-000170c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000170d0: 2020 2020 2020 2020 2020 2020 7d29 0a20              }). 
-000170e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000170f0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-00017100: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017110: 2020 2020 2020 2020 2073 756d 6d61 7279           summary
-00017120: 5b6f 705f 6e61 6d65 5d20 3d20 7b0a 2020  [op_name] = {.  
-00017130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017140: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-00017150: 5f6e 616d 6520 2b20 222e 6f75 7470 7574  _name + ".output
-00017160: 3022 3a0a 2020 2020 2020 2020 2020 2020  0":.            
-00017170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017180: 2020 2020 6465 7175 616e 7469 7a65 2876      dequantize(v
-00017190: 616c 7565 292e 6e75 6d70 7928 2920 6966  alue).numpy() if
-000171a0: 2076 616c 7565 2e69 735f 7175 616e 7469   value.is_quanti
-000171b0: 7a65 6420 656c 7365 2076 616c 7565 2e6e  zed else value.n
-000171c0: 756d 7079 2829 0a20 2020 2020 2020 2020  umpy().         
-000171d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000171e0: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
-000171f0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00017200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017210: 2020 2020 2020 2069 6620 626f 6f6c 2873         if bool(s
-00017220: 656c 662e 6675 7365 645f 6469 6374 293a  elf.fused_dict):
-00017230: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017240: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00017250: 6973 5f71 7561 6e74 697a 6564 3a0a 2020  is_quantized:.  
-00017260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017270: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-00017280: 7220 6120 696e 2066 7033 325f 696e 7438  r a in fp32_int8
-00017290: 5f6d 6170 3a0a 2020 2020 2020 2020 2020  _map:.          
-000172a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000172b0: 2020 2020 2020 2020 2020 6966 206f 705f            if op_
-000172c0: 6e61 6d65 203d 3d20 6670 3332 5f69 6e74  name == fp32_int
-000172d0: 385f 6d61 705b 615d 5b27 7765 6967 6874  8_map[a]['weight
-000172e0: 275d 3a0a 2020 2020 2020 2020 2020 2020  ']:.            
-000172f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017300: 2020 2020 2020 2020 2020 2020 6966 2074              if t
-00017310: 7970 6528 7661 6c75 6529 2069 7320 6c69  ype(value) is li
-00017320: 7374 3a0a 2020 2020 2020 2020 2020 2020  st:.            
-00017330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017350: 7375 6d6d 6172 795b 615d 203d 207b 7d0a  summary[a] = {}.
-00017360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017380: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00017390: 696e 6465 7820 696e 2072 616e 6765 286c  index in range(l
-000173a0: 656e 2876 616c 7565 2929 3a0a 2020 2020  en(value)):.    
-000173b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000173c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000173d0: 2020 2020 2020 2020 2020 2020 7375 6d6d              summ
-000173e0: 6172 795b 615d 2e75 7064 6174 6528 7b0a  ary[a].update({.
-000173f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017420: 2020 2020 6f70 5f6e 616d 6520 2b20 222e      op_name + ".
-00017430: 6f75 7470 7574 2220 2b20 7374 7228 696e  output" + str(in
-00017440: 6465 7829 3a0a 2020 2020 2020 2020 2020  dex):.          
-00017450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017470: 2020 2020 2020 2020 2020 6465 7175 616e            dequan
-00017480: 7469 7a65 2876 616c 7565 5b69 6e64 6578  tize(value[index
-00017490: 5d29 2e6e 756d 7079 2829 0a20 2020 2020  ]).numpy().     
-000174a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000174b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000174c0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-000174d0: 6620 7661 6c75 655b 696e 6465 785d 2e69  f value[index].i
-000174e0: 735f 7175 616e 7469 7a65 6420 656c 7365  s_quantized else
-000174f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017520: 2020 2020 2076 616c 7565 5b69 6e64 6578       value[index
-00017530: 5d2e 6e75 6d70 7928 290a 2020 2020 2020  ].numpy().      
-00017540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017560: 2020 2020 2020 2020 2020 7d29 0a20 2020            }).   
-00017570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017590: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-000175a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000175b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000175c0: 2020 2020 2020 2073 756d 6d61 7279 5b61         summary[a
-000175d0: 5d20 3d20 7b0a 2020 2020 2020 2020 2020  ] = {.          
-000175e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000175f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017600: 2020 2020 2020 6f70 5f6e 616d 6520 2b20        op_name + 
-00017610: 222e 6f75 7470 7574 3022 3a0a 2020 2020  ".output0":.    
-00017620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017640: 2020 2020 2020 2020 2020 2020 6465 7175              dequ
-00017650: 616e 7469 7a65 2876 616c 7565 292e 6e75  antize(value).nu
-00017660: 6d70 7928 290a 2020 2020 2020 2020 2020  mpy().          
-00017670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017690: 2020 2020 2020 6966 2076 616c 7565 2e69        if value.i
-000176a0: 735f 7175 616e 7469 7a65 6420 656c 7365  s_quantized else
-000176b0: 2076 616c 7565 2e6e 756d 7079 2829 0a20   value.numpy(). 
-000176c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000176d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000176e0: 2020 2020 2020 2020 2020 207d 0a20 2020             }.   
-000176f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017700: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00017710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017720: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00017730: 6f72 2061 2069 6e20 6670 3332 5f69 6e74  or a in fp32_int
-00017740: 385f 6d61 703a 2020 2320 7072 6167 6d61  8_map:  # pragma
-00017750: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
-00017760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017770: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00017780: 6620 6f70 5f6e 616d 6520 3d3d 2066 7033  f op_name == fp3
-00017790: 325f 696e 7438 5f6d 6170 5b61 5d5b 2761  2_int8_map[a]['a
-000177a0: 6374 6976 6174 696f 6e27 5d3a 0a20 2020  ctivation']:.   
-000177b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000177c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000177d0: 2020 2020 2069 6620 7479 7065 2876 616c       if type(val
-000177e0: 7565 2920 6973 206c 6973 743a 0a20 2020  ue) is list:.   
-000177f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017810: 2020 2020 2020 2020 2073 756d 6d61 7279           summary
-00017820: 5b61 5d20 3d20 7b7d 0a20 2020 2020 2020  [a] = {}.       
-00017830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017850: 2020 2020 2066 6f72 2069 6e64 6578 2069       for index i
-00017860: 6e20 7261 6e67 6528 6c65 6e28 7661 6c75  n range(len(valu
-00017870: 6529 293a 0a20 2020 2020 2020 2020 2020  e)):.           
-00017880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000178a0: 2020 2020 2073 756d 6d61 7279 5b61 5d2e       summary[a].
-000178b0: 7570 6461 7465 287b 0a20 2020 2020 2020  update({.       
-000178c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000178d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000178e0: 2020 2020 2020 2020 2020 2020 206f 705f               op_
-000178f0: 6e61 6d65 202b 2022 2e6f 7574 7075 7422  name + ".output"
-00017900: 202b 2073 7472 2869 6e64 6578 293a 0a20   + str(index):. 
-00017910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017940: 2020 2064 6571 7561 6e74 697a 6528 7661     dequantize(va
-00017950: 6c75 655b 696e 6465 785d 292e 6e75 6d70  lue[index]).nump
-00017960: 7928 290a 2020 2020 2020 2020 2020 2020  y().            
+00016020: 2020 2020 2020 2020 2020 2020 7175 616e              quan
+00016030: 7469 7a61 7469 6f6e 2063 6f6e 6669 6775  tization configu
+00016040: 7261 7469 6f6e 0a20 2020 2020 2020 2020  ration.         
+00016050: 2020 2020 2020 2077 6869 7465 5f6c 6973         white_lis
+00016060: 7420 286c 6973 742c 206f 7074 696f 6e61  t (list, optiona
+00016070: 6c29 3a20 6c69 7374 206f 6620 7175 616e  l): list of quan
+00016080: 7469 7a61 626c 6520 6d6f 6475 6c65 730a  tizable modules.
+00016090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000160a0: 7163 6f6e 6669 675f 7061 7265 6e74 2028  qconfig_parent (
+000160b0: 6f62 6a65 6374 2c20 6f70 7469 6f6e 616c  object, optional
+000160c0: 293a 2063 6f6e 6669 6720 6f66 2070 6172  ): config of par
+000160d0: 656e 7420 6d6f 6475 6c65 2c20 7765 2077  ent module, we w
+000160e0: 696c 6c20 6661 6c6c 6261 636b 2074 6f0a  ill fallback to.
+000160f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016120: 2020 2074 6869 7320 636f 6e66 6967 2077     this config w
+00016130: 6865 6e20 7468 6572 6520 6973 206e 6f20  hen there is no 
+00016140: 7370 6563 6966 6965 6420 636f 6e66 6967  specified config
+00016150: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00016160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016180: 2020 2020 666f 7220 6375 7272 656e 7420      for current 
+00016190: 6d6f 6475 6c65 0a20 2020 2020 2020 2020  module.         
+000161a0: 2020 2020 2020 2070 7265 6669 7820 2873         prefix (s
+000161b0: 7472 696e 672c 206f 7074 696f 6e61 6c29  tring, optional)
+000161c0: 3a20 636f 7272 6573 706f 6e64 696e 6720  : corresponding 
+000161d0: 7072 6566 6978 206f 6620 7468 6520 6375  prefix of the cu
+000161e0: 7272 656e 7420 6d6f 6475 6c65 2c0a 2020  rrent module,.  
+000161f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016210: 2020 2020 2020 2020 2075 7365 6420 6173           used as
+00016220: 206b 6579 2069 6e20 7163 6f6e 6669 675f   key in qconfig_
+00016230: 6469 6374 0a20 2020 2020 2020 2020 2020  dict.           
+00016240: 2020 2020 2066 7573 6564 2028 626f 6f6c       fused (bool
+00016250: 2c20 6f70 7469 6f6e 616c 293a 2049 6e64  , optional): Ind
+00016260: 6963 6174 6573 2077 6865 7468 6572 2074  icates whether t
+00016270: 6865 206d 6f64 756c 6520 6973 2066 7573  he module is fus
+00016280: 6564 206f 7220 6e6f 740a 0a20 2020 2020  ed or not..     
+00016290: 2020 2020 2020 2052 6574 7572 6e3a 0a20         Return:. 
+000162a0: 2020 2020 2020 2020 2020 2020 2020 204e                 N
+000162b0: 6f6e 652c 206d 6f64 756c 6520 6973 206d  one, module is m
+000162c0: 6f64 6966 6965 6420 696e 706c 6163 6520  odified inplace 
+000162d0: 7769 7468 2071 636f 6e66 6967 2061 7474  with qconfig att
+000162e0: 6163 6865 640a 2020 2020 2020 2020 2020  ached.          
+000162f0: 2020 2222 220a 2020 2020 2020 2020 2020    """.          
+00016300: 2020 6966 2077 6869 7465 5f6c 6973 7420    if white_list 
+00016310: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+00016320: 2020 2020 2020 2020 2077 6869 7465 5f6c           white_l
+00016330: 6973 7420 3d20 5c0a 2020 2020 2020 2020  ist = \.        
+00016340: 2020 2020 2020 2020 2020 2074 6f72 6368             torch
+00016350: 2e71 7561 6e74 697a 6174 696f 6e2e 6465  .quantization.de
+00016360: 6661 756c 745f 6d61 7070 696e 6773 2e44  fault_mappings.D
+00016370: 4546 4155 4c54 5f51 434f 4e46 4947 5f50  EFAULT_QCONFIG_P
+00016380: 524f 5041 4741 5445 5f57 4849 5445 5f4c  ROPAGATE_WHITE_L
+00016390: 4953 5420 5c0a 2020 2020 2020 2020 2020  IST \.          
+000163a0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+000163b0: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
+000163c0: 203c 2056 6572 7369 6f6e 2822 312e 372e   < Version("1.7.
+000163d0: 3022 292e 7265 6c65 6173 6520 656c 7365  0").release else
+000163e0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+000163f0: 2020 2020 2020 746f 7263 682e 7175 616e        torch.quan
+00016400: 7469 7a61 7469 6f6e 2e71 7561 6e74 697a  tization.quantiz
+00016410: 6174 696f 6e5f 6d61 7070 696e 6773 2e67  ation_mappings.g
+00016420: 6574 5f71 636f 6e66 6967 5f70 726f 7061  et_qconfig_propa
+00016430: 6761 7469 6f6e 5f6c 6973 7428 290a 0a20  gation_list().. 
+00016440: 2020 2020 2020 2020 2020 2069 6620 7479             if ty
+00016450: 7065 286d 6f64 756c 6529 2069 6e20 7768  pe(module) in wh
+00016460: 6974 655f 6c69 7374 2061 6e64 2074 7970  ite_list and typ
+00016470: 6528 6d6f 6475 6c65 2920 213d 2074 6f72  e(module) != tor
+00016480: 6368 2e6e 6e2e 5365 7175 656e 7469 616c  ch.nn.Sequential
+00016490: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000164a0: 2020 6d6f 6475 6c65 2e71 636f 6e66 6967    module.qconfig
+000164b0: 203d 2071 636f 6e66 6967 5f70 6172 656e   = qconfig_paren
+000164c0: 740a 2020 2020 2020 2020 2020 2020 656c  t.            el
+000164d0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+000164e0: 2020 2020 6d6f 6475 6c65 2e71 636f 6e66      module.qconf
+000164f0: 6967 203d 204e 6f6e 650a 2020 2020 2020  ig = None.      
+00016500: 2020 2020 2020 6966 2068 6173 6174 7472        if hasattr
+00016510: 286d 6f64 756c 652c 2027 5f6d 6f64 756c  (module, '_modul
+00016520: 6573 2729 3a0a 2020 2020 2020 2020 2020  es'):.          
+00016530: 2020 2020 2020 666f 7220 6e61 6d65 2c20        for name, 
+00016540: 6368 696c 6420 696e 206d 6f64 756c 652e  child in module.
+00016550: 6e61 6d65 645f 6368 696c 6472 656e 2829  named_children()
+00016560: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00016570: 2020 2020 2020 6d6f 6475 6c65 5f70 7265        module_pre
+00016580: 6669 7820 3d20 7072 6566 6978 202b 2027  fix = prefix + '
+00016590: 2e27 202b 206e 616d 6520 6966 2070 7265  .' + name if pre
+000165a0: 6669 7820 656c 7365 206e 616d 650a 2020  fix else name.  
+000165b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000165c0: 2020 5f70 726f 7061 6761 7465 5f71 636f    _propagate_qco
+000165d0: 6e66 6967 5f68 656c 7065 7228 6368 696c  nfig_helper(chil
+000165e0: 642c 2071 636f 6e66 6967 5f64 6963 742c  d, qconfig_dict,
+000165f0: 2077 6869 7465 5f6c 6973 742c 2071 636f   white_list, qco
+00016600: 6e66 6967 5f70 6172 656e 742c 0a20 2020  nfig_parent,.   
+00016610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016630: 2020 2020 2020 2020 2020 206d 6f64 756c             modul
+00016640: 655f 7072 6566 6978 290a 0a20 2020 2020  e_prefix)..     
+00016650: 2020 2064 6566 205f 7072 6570 6172 6528     def _prepare(
+00016660: 6d6f 6465 6c2c 2069 6e70 6c61 6365 3d54  model, inplace=T
+00016670: 7275 652c 206f 705f 6c69 7374 3d5b 5d2c  rue, op_list=[],
+00016680: 2077 6869 7465 5f6c 6973 743d 4e6f 6e65   white_list=None
+00016690: 293a 0a20 2020 2020 2020 2020 2020 2022  ):.            "
+000166a0: 2222 5468 6520 6d6f 6465 6c20 7769 6c6c  ""The model will
+000166b0: 2062 6520 6174 7461 6368 6564 2077 6974   be attached wit
+000166c0: 6820 6f62 7365 7276 6572 206f 7220 6661  h observer or fa
+000166d0: 6b65 2071 7561 6e74 206d 6f64 756c 6573  ke quant modules
+000166e0: 2c20 616e 6420 7163 6f6e 6669 670a 2020  , and qconfig.  
+000166f0: 2020 2020 2020 2020 2020 2020 2077 696c               wil
+00016700: 6c20 6265 2070 726f 7061 6761 7465 642e  l be propagated.
+00016710: 0a0a 2020 2020 2020 2020 2020 2020 4172  ..            Ar
+00016720: 6773 3a0a 2020 2020 2020 2020 2020 2020  gs:.            
+00016730: 2020 2020 6d6f 6465 6c20 286f 626a 6563      model (objec
+00016740: 7429 3a20 696e 7075 7420 6d6f 6465 6c20  t): input model 
+00016750: 746f 2062 6520 6d6f 6469 6669 6564 2069  to be modified i
+00016760: 6e2d 706c 6163 650a 2020 2020 2020 2020  n-place.        
+00016770: 2020 2020 2020 2020 696e 706c 6163 6520          inplace 
+00016780: 2862 6f6f 6c2c 206f 7074 696f 6e61 6c29  (bool, optional)
+00016790: 3a20 6361 7272 7920 6f75 7420 6d6f 6465  : carry out mode
+000167a0: 6c20 7472 616e 7366 6f72 6d61 7469 6f6e  l transformation
+000167b0: 7320 696e 2d70 6c61 6365 2c0a 2020 2020  s in-place,.    
+000167c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000167d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000167e0: 2020 2020 2020 7468 6520 6f72 6967 696e        the origin
+000167f0: 616c 206d 6f64 756c 6520 6973 206d 7574  al module is mut
+00016800: 6174 6564 0a20 2020 2020 2020 2020 2020  ated.           
+00016810: 2020 2020 206f 705f 6c69 7374 2028 6c69       op_list (li
+00016820: 7374 2c20 6f70 7469 6f6e 616c 293a 206c  st, optional): l
+00016830: 6973 7420 6f66 206f 7073 2077 6869 6368  ist of ops which
+00016840: 2074 6f20 6265 2064 756d 7065 6420 696e   to be dumped in
+00016850: 206d 6f64 756c 650a 2020 2020 2020 2020   module.        
+00016860: 2020 2020 2020 2020 7768 6974 655f 6c69          white_li
+00016870: 7374 2028 6c69 7374 2c20 6f70 7469 6f6e  st (list, option
+00016880: 616c 293a 206c 6973 7420 6f66 2071 7561  al): list of qua
+00016890: 6e74 697a 6162 6c65 206d 6f64 756c 6573  ntizable modules
+000168a0: 0a0a 2020 2020 2020 2020 2020 2020 5265  ..            Re
+000168b0: 7475 726e 733a 0a20 2020 2020 2020 2020  turns:.         
+000168c0: 2020 2020 2020 206d 6f64 656c 2028 6f62         model (ob
+000168d0: 6a65 6374 293a 206d 6f64 656c 2077 6974  ject): model wit
+000168e0: 6820 7163 6f6e 6669 670a 2020 2020 2020  h qconfig.      
+000168f0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00016900: 2020 2020 2020 6966 206e 6f74 2069 6e70        if not inp
+00016910: 6c61 6365 3a0a 2020 2020 2020 2020 2020  lace:.          
+00016920: 2020 2020 2020 6d6f 6465 6c20 3d20 636f        model = co
+00016930: 7079 2e64 6565 7063 6f70 7928 6d6f 6465  py.deepcopy(mode
+00016940: 6c29 0a20 2020 2020 2020 2020 2020 205f  l).            _
+00016950: 7072 6f70 6167 6174 655f 7163 6f6e 6669  propagate_qconfi
+00016960: 675f 6865 6c70 6572 286d 6f64 656c 2c0a  g_helper(model,.
+00016970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016990: 2020 2020 2020 7163 6f6e 6669 675f 6469        qconfig_di
+000169a0: 6374 3d7b 7d2c 0a20 2020 2020 2020 2020  ct={},.         
+000169b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000169c0: 2020 2020 2020 2020 2020 2020 2077 6869               whi
+000169d0: 7465 5f6c 6973 743d 7768 6974 655f 6c69  te_list=white_li
+000169e0: 7374 2c0a 2020 2020 2020 2020 2020 2020  st,.            
+000169f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016a00: 2020 2020 2020 2020 2020 7163 6f6e 6669            qconfi
+00016a10: 675f 7061 7265 6e74 3d6d 6f64 656c 2e71  g_parent=model.q
+00016a20: 636f 6e66 6967 290a 2020 2020 2020 2020  config).        
+00016a30: 2020 2020 2320 7361 6e69 7479 2063 6865      # sanity che
+00016a40: 636b 2063 6f6d 6d6f 6e20 4150 4920 6d69  ck common API mi
+00016a50: 7375 7361 6765 0a20 2020 2020 2020 2020  susage.         
+00016a60: 2020 2069 6620 6e6f 7420 616e 7928 6861     if not any(ha
+00016a70: 7361 7474 7228 6d2c 2027 7163 6f6e 6669  sattr(m, 'qconfi
+00016a80: 6727 2920 616e 6420 6d2e 7163 6f6e 6669  g') and m.qconfi
+00016a90: 6720 666f 7220 6d20 696e 206d 6f64 656c  g for m in model
+00016aa0: 2e6d 6f64 756c 6573 2829 293a 0a20 2020  .modules()):.   
+00016ab0: 2020 2020 2020 2020 2020 2020 206c 6f67               log
+00016ac0: 6765 722e 7761 726e 2822 4e6f 6e65 206f  ger.warn("None o
+00016ad0: 6620 7468 6520 7375 626d 6f64 756c 6520  f the submodule 
+00016ae0: 676f 7420 7163 6f6e 6669 6720 6170 706c  got qconfig appl
+00016af0: 6965 642e 204d 616b 6520 7375 7265 2079  ied. Make sure y
+00016b00: 6f75 2022 0a20 2020 2020 2020 2020 2020  ou ".           
+00016b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016b20: 2022 7061 7373 6564 2063 6f72 7265 6374   "passed correct
+00016b30: 2063 6f6e 6669 6775 7261 7469 6f6e 2074   configuration t
+00016b40: 6872 6f75 6768 2060 7163 6f6e 6669 675f  hrough `qconfig_
+00016b50: 6469 6374 6020 6f72 2022 0a20 2020 2020  dict` or ".     
+00016b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016b70: 2020 2020 2020 2022 6279 2061 7373 6967         "by assig
+00016b80: 6e69 6e67 2074 6865 2060 2e71 636f 6e66  ning the `.qconf
+00016b90: 6967 6020 6174 7472 6962 7574 6520 6469  ig` attribute di
+00016ba0: 7265 6374 6c79 206f 6e20 7375 626d 6f64  rectly on submod
+00016bb0: 756c 6573 2229 0a20 2020 2020 2020 2020  ules").         
+00016bc0: 2020 205f 6164 645f 6f62 7365 7276 6572     _add_observer
+00016bd0: 5f28 6d6f 6465 6c2c 206f 705f 6c69 7374  _(model, op_list
+00016be0: 3d6f 705f 6c69 7374 290a 2020 2020 2020  =op_list).      
+00016bf0: 2020 2020 2020 7265 7475 726e 206d 6f64        return mod
+00016c00: 656c 0a0a 2020 2020 2020 2020 2320 6372  el..        # cr
+00016c10: 6561 7465 2070 726f 7065 7274 6965 730a  eate properties.
+00016c20: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00016c30: 7665 7273 696f 6e2e 7265 6c65 6173 6520  version.release 
+00016c40: 3c20 5665 7273 696f 6e28 2231 2e37 2e30  < Version("1.7.0
+00016c50: 2229 2e72 656c 6561 7365 3a20 2023 2070  ").release:  # p
+00016c60: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
+00016c70: 2020 2020 2020 2020 2020 2020 7768 6974              whit
+00016c80: 655f 6c69 7374 203d 2073 656c 662e 7768  e_list = self.wh
+00016c90: 6974 655f 6c69 7374 207c 205c 0a20 2020  ite_list | \.   
+00016ca0: 2020 2020 2020 2020 2020 2020 2028 7365               (se
+00016cb0: 7428 746f 7263 682e 7175 616e 7469 7a61  t(torch.quantiza
+00016cc0: 7469 6f6e 2e64 6566 6175 6c74 5f6d 6170  tion.default_map
+00016cd0: 7069 6e67 732e 4445 4641 554c 545f 4d4f  pings.DEFAULT_MO
+00016ce0: 4455 4c45 5f4d 4150 5049 4e47 2e76 616c  DULE_MAPPING.val
+00016cf0: 7565 7328 2929 207c 0a20 2020 2020 2020  ues()) |.       
+00016d00: 2020 2020 2020 2020 2020 7365 7428 746f            set(to
+00016d10: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+00016d20: 2e64 6566 6175 6c74 5f6d 6170 7069 6e67  .default_mapping
+00016d30: 732e 4445 4641 554c 545f 5141 545f 4d4f  s.DEFAULT_QAT_MO
+00016d40: 4455 4c45 5f4d 4150 5049 4e47 2e76 616c  DULE_MAPPING.val
+00016d50: 7565 7328 2929 207c 0a20 2020 2020 2020  ues()) |.       
+00016d60: 2020 2020 2020 2020 2020 7365 7428 746f            set(to
+00016d70: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+00016d80: 2e64 6566 6175 6c74 5f6d 6170 7069 6e67  .default_mapping
+00016d90: 732e 4445 4641 554c 545f 4459 4e41 4d49  s.DEFAULT_DYNAMI
+00016da0: 435f 4d4f 4455 4c45 5f4d 4150 5049 4e47  C_MODULE_MAPPING
+00016db0: 2e76 616c 7565 7328 2929 290a 2020 2020  .values())).    
+00016dc0: 2020 2020 656c 6966 2073 656c 662e 7665      elif self.ve
+00016dd0: 7273 696f 6e2e 7265 6c65 6173 6520 3c20  rsion.release < 
+00016de0: 5665 7273 696f 6e28 2231 2e38 2e30 2229  Version("1.8.0")
+00016df0: 2e72 656c 6561 7365 3a20 2023 2070 7261  .release:  # pra
+00016e00: 676d 613a 206e 6f20 636f 7665 720a 2020  gma: no cover.  
+00016e10: 2020 2020 2020 2020 2020 7768 6974 655f            white_
+00016e20: 6c69 7374 203d 2074 6f72 6368 2e71 7561  list = torch.qua
+00016e30: 6e74 697a 6174 696f 6e2e 6765 745f 636f  ntization.get_co
+00016e40: 6d70 6172 655f 6f75 7470 7574 5f6d 6f64  mpare_output_mod
+00016e50: 756c 655f 6c69 7374 2829 0a20 2020 2020  ule_list().     
+00016e60: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00016e70: 2020 2020 2077 6869 7465 5f6c 6973 7420       white_list 
+00016e80: 3d20 746f 7263 682e 7175 616e 7469 7a61  = torch.quantiza
+00016e90: 7469 6f6e 2e67 6574 5f64 6566 6175 6c74  tion.get_default
+00016ea0: 5f63 6f6d 7061 7265 5f6f 7574 7075 745f  _compare_output_
+00016eb0: 6d6f 6475 6c65 5f6c 6973 7428 290a 0a20  module_list().. 
+00016ec0: 2020 2020 2020 206d 6f64 656c 203d 206d         model = m
+00016ed0: 6f64 656c 2069 6620 6d6f 6465 6c2e 6973  odel if model.is
+00016ee0: 5f71 7561 6e74 697a 6564 2065 6c73 6520  _quantized else 
+00016ef0: 636f 7079 2e64 6565 7063 6f70 7928 6d6f  copy.deepcopy(mo
+00016f00: 6465 6c29 0a20 2020 2020 2020 206d 6f64  del).        mod
+00016f10: 656c 2e5f 6d6f 6465 6c2e 7163 6f6e 6669  el._model.qconfi
+00016f20: 6720 3d20 746f 7263 682e 7175 616e 7469  g = torch.quanti
+00016f30: 7a61 7469 6f6e 2e51 436f 6e66 6967 280a  zation.QConfig(.
+00016f40: 2020 2020 2020 2020 2020 2020 7765 6967              weig
+00016f50: 6874 3d74 6f72 6368 2e71 7561 6e74 697a  ht=torch.quantiz
+00016f60: 6174 696f 6e2e 6465 6661 756c 745f 6465  ation.default_de
+00016f70: 6275 675f 6f62 7365 7276 6572 2c0a 2020  bug_observer,.  
+00016f80: 2020 2020 2020 2020 2020 6163 7469 7661            activa
+00016f90: 7469 6f6e 3d5f 5265 636f 7264 696e 674f  tion=_RecordingO
+00016fa0: 6273 6572 7665 722e 7769 7468 5f61 7267  bserver.with_arg
+00016fb0: 7328 6974 6572 6174 696f 6e5f 6c69 7374  s(iteration_list
+00016fc0: 3d69 7465 7261 7469 6f6e 5f6c 6973 7429  =iteration_list)
+00016fd0: 290a 2020 2020 2020 2020 5f70 7265 7061  ).        _prepa
+00016fe0: 7265 286d 6f64 656c 2e5f 6d6f 6465 6c2c  re(model._model,
+00016ff0: 206f 705f 6c69 7374 3d6f 705f 6c69 7374   op_list=op_list
+00017000: 2c20 7768 6974 655f 6c69 7374 3d77 6869  , white_list=whi
+00017010: 7465 5f6c 6973 7429 0a0a 2020 2020 2020  te_list)..      
+00017020: 2020 7265 7475 726e 206d 6f64 656c 0a0a    return model..
+00017030: 2020 2020 6465 6620 6973 5f66 7573 6564      def is_fused
+00017040: 5f63 6869 6c64 2873 656c 662c 206f 705f  _child(self, op_
+00017050: 6e61 6d65 293a 0a20 2020 2020 2020 2022  name):.        "
+00017060: 2222 5468 6973 2069 7320 6120 6865 6c70  ""This is a help
+00017070: 6572 2066 756e 6374 696f 6e20 666f 7220  er function for 
+00017080: 605f 706f 7374 5f65 7661 6c5f 686f 6f6b  `_post_eval_hook
+00017090: 600a 0a20 2020 2020 2020 2041 7267 733a  `..        Args:
+000170a0: 0a20 2020 2020 2020 2020 2020 206f 705f  .            op_
+000170b0: 6e61 6d65 2028 7374 7269 6e67 293a 206f  name (string): o
+000170c0: 7020 6e61 6d65 0a0a 2020 2020 2020 2020  p name..        
+000170d0: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
+000170e0: 2020 2020 2028 626f 6f6c 293a 2069 6620       (bool): if 
+000170f0: 7468 6973 206f 7020 6973 2066 7573 6564  this op is fused
+00017100: 0a0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
+00017110: 2020 2020 2020 6f70 203d 206f 705f 6e61        op = op_na
+00017120: 6d65 5b3a 6f70 5f6e 616d 652e 7266 696e  me[:op_name.rfin
+00017130: 6428 272e 2729 5d0a 2020 2020 2020 2020  d('.')].        
+00017140: 6966 206f 7020 696e 2073 656c 662e 6675  if op in self.fu
+00017150: 7365 645f 6469 6374 2061 6e64 206f 705f  sed_dict and op_
+00017160: 6e61 6d65 5b6f 705f 6e61 6d65 2e72 6669  name[op_name.rfi
+00017170: 6e64 2827 2e27 2920 2b20 313a 5d2e 6973  nd('.') + 1:].is
+00017180: 6469 6769 7428 293a 0a20 2020 2020 2020  digit():.       
+00017190: 2020 2020 2072 6574 7572 6e20 5472 7565       return True
+000171a0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+000171b0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+000171c0: 6e20 4661 6c73 650a 0a20 2020 2064 6566  n False..    def
+000171d0: 2069 735f 6675 7365 645f 6f70 2873 656c   is_fused_op(sel
+000171e0: 662c 206f 705f 6e61 6d65 293a 0a20 2020  f, op_name):.   
+000171f0: 2020 2020 2022 2222 5468 6973 2069 7320       """This is 
+00017200: 6120 6865 6c70 6572 2066 756e 6374 696f  a helper functio
+00017210: 6e20 666f 7220 605f 706f 7374 5f65 7661  n for `_post_eva
+00017220: 6c5f 686f 6f6b 600a 0a20 2020 2020 2020  l_hook`..       
+00017230: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
+00017240: 2020 206f 705f 6e61 6d65 2028 7374 7269     op_name (stri
+00017250: 6e67 293a 206f 7020 6e61 6d65 0a0a 2020  ng): op name..  
+00017260: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
+00017270: 2020 2020 2020 2020 2020 2028 626f 6f6c             (bool
+00017280: 293a 2069 6620 7468 6973 206f 7020 6973  ): if this op is
+00017290: 2066 7573 6564 0a0a 2020 2020 2020 2020   fused..        
+000172a0: 2222 220a 2020 2020 2020 2020 6f70 203d  """.        op =
+000172b0: 206f 705f 6e61 6d65 5b3a 6f70 5f6e 616d   op_name[:op_nam
+000172c0: 652e 7266 696e 6428 272e 2729 5d0a 2020  e.rfind('.')].  
+000172d0: 2020 2020 2020 6966 206f 7020 696e 2073        if op in s
+000172e0: 656c 662e 6675 7365 645f 6469 6374 3a0a  elf.fused_dict:.
+000172f0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00017300: 726e 2054 7275 650a 2020 2020 2020 2020  rn True.        
+00017310: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00017320: 2020 7265 7475 726e 2046 616c 7365 0a0a    return False..
+00017330: 2020 2020 6465 6620 6973 5f6c 6173 745f      def is_last_
+00017340: 6675 7365 645f 6368 696c 6428 7365 6c66  fused_child(self
+00017350: 2c20 6f70 5f6e 616d 6529 3a0a 2020 2020  , op_name):.    
+00017360: 2020 2020 2222 2254 6869 7320 6973 2061      """This is a
+00017370: 2068 656c 7065 7220 6675 6e63 7469 6f6e   helper function
+00017380: 2066 6f72 2060 5f70 6f73 745f 6576 616c   for `_post_eval
+00017390: 5f68 6f6f 6b60 0a0a 2020 2020 2020 2020  _hook`..        
+000173a0: 4172 6773 3a0a 2020 2020 2020 2020 2020  Args:.          
+000173b0: 2020 6f70 5f6e 616d 6520 2873 7472 696e    op_name (strin
+000173c0: 6729 3a20 6f70 206e 616d 650a 0a20 2020  g): op name..   
+000173d0: 2020 2020 2052 6574 7572 6e73 3a0a 2020       Returns:.  
+000173e0: 2020 2020 2020 2020 2020 2862 6f6f 6c29            (bool)
+000173f0: 3a20 6966 2074 6869 7320 6f70 2069 7320  : if this op is 
+00017400: 6c61 7374 2066 7573 6564 206f 700a 0a20  last fused op.. 
+00017410: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00017420: 2020 206f 7020 3d20 6f70 5f6e 616d 655b     op = op_name[
+00017430: 3a6f 705f 6e61 6d65 2e72 6669 6e64 2827  :op_name.rfind('
+00017440: 2e27 295d 0a20 2020 2020 2020 2069 6620  .')].        if 
+00017450: 6f70 5f6e 616d 6520 696e 2073 656c 662e  op_name in self.
+00017460: 6675 7365 645f 6469 6374 5b6f 705d 5b2d  fused_dict[op][-
+00017470: 315d 3a0a 2020 2020 2020 2020 2020 2020  1]:.            
+00017480: 7265 7475 726e 2054 7275 650a 2020 2020  return True.    
+00017490: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000174a0: 2020 2020 2020 7265 7475 726e 2046 616c        return Fal
+000174b0: 7365 0a0a 2020 2020 6465 6620 5f70 6f73  se..    def _pos
+000174c0: 745f 6576 616c 5f68 6f6f 6b28 7365 6c66  t_eval_hook(self
+000174d0: 2c20 6d6f 6465 6c2c 202a 2a61 7267 7329  , model, **args)
+000174e0: 3a0a 2020 2020 2020 2020 2222 2254 6865  :.        """The
+000174f0: 2066 756e 6374 696f 6e20 6973 2075 7365   function is use
+00017500: 6420 746f 2064 6f20 736f 6d65 2070 6f73  d to do some pos
+00017510: 7420 7072 6f63 6573 7320 6166 7465 7220  t process after 
+00017520: 636f 6d70 6c65 7465 2065 7661 6c75 6174  complete evaluat
+00017530: 696f 6e2e 0a20 2020 2020 2020 2020 2020  ion..           
+00017540: 4865 7265 2c20 6974 2075 7365 6420 746f  Here, it used to
+00017550: 2064 756d 7020 7175 616e 7469 7a61 626c   dump quantizabl
+00017560: 6520 6f70 2773 206f 7574 7075 7420 7465  e op's output te
+00017570: 6e73 6f72 2e0a 0a20 2020 2020 2020 2041  nsor...        A
+00017580: 7267 733a 0a20 2020 2020 2020 2020 2020  rgs:.           
+00017590: 206d 6f64 656c 2028 6f62 6a65 6374 293a   model (object):
+000175a0: 2069 6e70 7574 206d 6f64 656c 0a0a 2020   input model..  
+000175b0: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
+000175c0: 2020 2020 2020 2020 2020 204e 6f6e 650a             None.
+000175d0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+000175e0: 2020 2020 6672 6f6d 2074 6f72 6368 2e75      from torch.u
+000175f0: 7469 6c73 2e74 656e 736f 7262 6f61 7264  tils.tensorboard
+00017600: 2069 6d70 6f72 7420 5375 6d6d 6172 7957   import SummaryW
+00017610: 7269 7465 720a 2020 2020 2020 2020 6966  riter.        if
+00017620: 2073 656c 662e 7665 7273 696f 6e2e 7265   self.version.re
+00017630: 6c65 6173 6520 3e3d 2056 6572 7369 6f6e  lease >= Version
+00017640: 2822 322e 302e 3022 292e 7265 6c65 6173  ("2.0.0").releas
+00017650: 653a 0a20 2020 2020 2020 2020 2020 2066  e:.            f
+00017660: 726f 6d20 746f 7263 682e 7175 616e 7469  rom torch.quanti
+00017670: 7a61 7469 6f6e 2e71 7561 6e74 697a 6520  zation.quantize 
+00017680: 696d 706f 7274 205f 6765 745f 6f62 7365  import _get_obse
+00017690: 7276 6572 5f64 6963 7420 6173 2067 6574  rver_dict as get
+000176a0: 5f6f 6273 6572 7665 725f 6469 6374 0a20  _observer_dict. 
+000176b0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+000176c0: 2020 2020 2020 2020 2066 726f 6d20 746f           from to
+000176d0: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+000176e0: 2069 6d70 6f72 7420 6765 745f 6f62 7365   import get_obse
+000176f0: 7276 6572 5f64 6963 740a 0a20 2020 2020  rver_dict..     
+00017700: 2020 206d 6f64 656c 203d 206d 6f64 656c     model = model
+00017710: 2e5f 6d6f 6465 6c0a 0a20 2020 2020 2020  ._model..       
+00017720: 2069 6620 6172 6773 2069 7320 6e6f 7420   if args is not 
+00017730: 4e6f 6e65 2061 6e64 2027 6163 6375 7261  None and 'accura
+00017740: 6379 2720 696e 2061 7267 733a 0a20 2020  cy' in args:.   
+00017750: 2020 2020 2020 2020 2061 6363 7572 6163           accurac
+00017760: 7920 3d20 6172 6773 5b27 6163 6375 7261  y = args['accura
+00017770: 6379 275d 0a20 2020 2020 2020 2065 6c73  cy'].        els
+00017780: 653a 0a20 2020 2020 2020 2020 2020 2061  e:.            a
+00017790: 6363 7572 6163 7920 3d20 2727 0a0a 2020  ccuracy = ''..  
+000177a0: 2020 2020 2020 6966 2073 656c 662e 6475        if self.du
+000177b0: 6d70 5f74 696d 6573 203d 3d20 303a 0a20  mp_times == 0:. 
+000177c0: 2020 2020 2020 2020 2020 2077 7269 7465             write
+000177d0: 7220 3d20 5375 6d6d 6172 7957 7269 7465  r = SummaryWrite
+000177e0: 7228 2772 756e 732f 6576 616c 2f62 6173  r('runs/eval/bas
+000177f0: 656c 696e 6527 202b 2027 5f61 6363 2720  eline' + '_acc' 
+00017800: 2b20 7374 7228 6163 6375 7261 6379 292c  + str(accuracy),
+00017810: 206d 6f64 656c 290a 2020 2020 2020 2020   model).        
+00017820: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00017830: 2020 7772 6974 6572 203d 2053 756d 6d61    writer = Summa
+00017840: 7279 5772 6974 6572 280a 2020 2020 2020  ryWriter(.      
+00017850: 2020 2020 2020 2020 2020 2772 756e 732f            'runs/
+00017860: 6576 616c 2f74 756e 655f 2720 2b20 7374  eval/tune_' + st
+00017870: 7228 7365 6c66 2e64 756d 705f 7469 6d65  r(self.dump_time
+00017880: 7329 202b 2027 5f61 6363 2720 2b20 7374  s) + '_acc' + st
+00017890: 7228 6163 6375 7261 6379 292c 206d 6f64  r(accuracy), mod
+000178a0: 656c 290a 0a20 2020 2020 2020 2069 6620  el)..        if 
+000178b0: 7365 6c66 2e64 756d 705f 7469 6d65 7320  self.dump_times 
+000178c0: 3d3d 2030 3a0a 2020 2020 2020 2020 2020  == 0:.          
+000178d0: 2020 666f 7220 2869 6e70 7574 2c20 5f29    for (input, _)
+000178e0: 2069 6e20 7365 6c66 2e71 5f64 6174 616c   in self.q_datal
+000178f0: 6f61 6465 723a 0a20 2020 2020 2020 2020  oader:.         
+00017900: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+00017910: 616e 6365 2869 6e70 7574 2c20 6469 6374  ance(input, dict
+00017920: 2920 6f72 2069 7369 6e73 7461 6e63 6528  ) or isinstance(
+00017930: 696e 7075 742c 2055 7365 7244 6963 7429  input, UserDict)
+00017940: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00017950: 2020 2020 2020 6966 2073 656c 662e 6465        if self.de
+00017960: 7669 6365 203d 3d20 2267 7075 223a 0a20  vice == "gpu":. 
 00017970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017990: 2020 2020 2020 2020 6966 2076 616c 7565          if value
-000179a0: 5b69 6e64 6578 5d2e 6973 5f71 7561 6e74  [index].is_quant
-000179b0: 697a 6564 2065 6c73 650a 2020 2020 2020  ized else.      
-000179c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000179d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000179e0: 2020 2020 2020 2020 2020 2020 2020 7661                va
-000179f0: 6c75 655b 696e 6465 785d 2e6e 756d 7079  lue[index].numpy
-00017a00: 2829 0a20 2020 2020 2020 2020 2020 2020  ().             
-00017a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017a30: 2020 207d 290a 2020 2020 2020 2020 2020     }).          
-00017a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017a50: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00017a60: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00017a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017a90: 7375 6d6d 6172 795b 615d 203d 207b 0a20  summary[a] = {. 
-00017aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017980: 2020 2020 2020 2066 6f72 2069 6e70 2069         for inp i
+00017990: 6e20 696e 7075 742e 6b65 7973 2829 3a0a  n input.keys():.
+000179a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000179b0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+000179c0: 745b 696e 705d 203d 2069 6e70 7574 5b69  t[inp] = input[i
+000179d0: 6e70 5d2e 746f 2822 6470 6370 7022 290a  np].to("dpcpp").
+000179e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000179f0: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
+00017a00: 696e 7075 742c 206c 6973 7429 206f 7220  input, list) or 
+00017a10: 6973 696e 7374 616e 6365 2869 6e70 7574  isinstance(input
+00017a20: 2c20 7475 706c 6529 3a0a 2020 2020 2020  , tuple):.      
+00017a30: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00017a40: 2073 656c 662e 6465 7669 6365 203d 3d20   self.device == 
+00017a50: 2267 7075 223a 0a20 2020 2020 2020 2020  "gpu":.         
+00017a60: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00017a70: 6e70 7574 203d 205b 696e 702e 746f 2822  nput = [inp.to("
+00017a80: 6470 6370 7022 2920 666f 7220 696e 7020  dpcpp") for inp 
+00017a90: 696e 2069 6e70 7574 5d0a 2020 2020 2020  in input].      
+00017aa0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
 00017ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ac0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00017ad0: 705f 6e61 6d65 202b 2022 2e6f 7574 7075  p_name + ".outpu
-00017ae0: 7430 223a 0a20 2020 2020 2020 2020 2020  t0":.           
-00017af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b10: 2020 2020 2064 6571 7561 6e74 697a 6528       dequantize(
-00017b20: 7661 6c75 6529 2e6e 756d 7079 2829 0a20  value).numpy(). 
-00017b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b50: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00017b60: 6620 7661 6c75 652e 6973 5f71 7561 6e74  f value.is_quant
-00017b70: 697a 6564 2065 6c73 6520 7661 6c75 652e  ized else value.
-00017b80: 6e75 6d70 7928 290a 2020 2020 2020 2020  numpy().        
-00017b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017bb0: 2020 2020 7d0a 0a20 2020 2020 2020 2020      }..         
-00017bc0: 2020 2020 2020 2069 6620 7361 7665 5f74         if save_t
-00017bd0: 6f5f 6469 736b 3a0a 2020 2020 2020 2020  o_disk:.        
-00017be0: 2020 2020 2020 2020 2020 2020 6475 6d70              dump
-00017bf0: 5f64 6972 203d 206f 732e 7061 7468 2e6a  _dir = os.path.j
-00017c00: 6f69 6e28 7365 6c66 2e77 6f72 6b73 7061  oin(self.workspa
-00017c10: 6365 5f70 6174 682c 2027 6475 6d70 5f74  ce_path, 'dump_t
-00017c20: 656e 736f 7227 290a 2020 2020 2020 2020  ensor').        
-00017c30: 2020 2020 2020 2020 2020 2020 6f73 2e6d              os.m
-00017c40: 616b 6564 6972 7328 6475 6d70 5f64 6972  akedirs(dump_dir
-00017c50: 2c20 6578 6973 745f 6f6b 3d54 7275 6529  , exist_ok=True)
-00017c60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017c70: 2020 2020 206e 702e 7361 7665 7a28 6f73       np.savez(os
-00017c80: 2e70 6174 682e 6a6f 696e 2864 756d 705f  .path.join(dump_
-00017c90: 6469 722c 2027 6163 7469 7661 7469 6f6e  dir, 'activation
-00017ca0: 5f69 7465 727b 7d2e 6e70 7a27 2e66 6f72  _iter{}.npz'.for
-00017cb0: 6d61 7428 6929 292c 202a 2a73 756d 6d61  mat(i)), **summa
-00017cc0: 7279 290a 0a20 2020 2020 2020 2020 2020  ry)..           
-00017cd0: 2020 2020 2072 6574 5b27 6163 7469 7661       ret['activa
-00017ce0: 7469 6f6e 275d 2e61 7070 656e 6428 7375  tion'].append(su
-00017cf0: 6d6d 6172 7929 0a0a 2020 2020 2020 2020  mmary)..        
-00017d00: 6966 2069 6e73 7065 6374 5f74 7970 6520  if inspect_type 
-00017d10: 3d3d 2027 7765 6967 6874 2720 6f72 2069  == 'weight' or i
-00017d20: 6e73 7065 6374 5f74 7970 6520 3d3d 2027  nspect_type == '
-00017d30: 616c 6c27 3a0a 2020 2020 2020 2020 2020  all':.          
-00017d40: 2020 7265 745b 2777 6569 6768 7427 5d20    ret['weight'] 
-00017d50: 3d20 7b7d 0a20 2020 2020 2020 2020 2020  = {}.           
-00017d60: 2073 7461 7465 5f64 6963 7420 3d20 6e65   state_dict = ne
-00017d70: 775f 6d6f 6465 6c2e 5f6d 6f64 656c 2e73  w_model._model.s
-00017d80: 7461 7465 5f64 6963 7428 290a 0a20 2020  tate_dict()..   
-00017d90: 2020 2020 2020 2020 2066 6f72 206b 6579           for key
-00017da0: 2069 6e20 7374 6174 655f 6469 6374 3a0a   in state_dict:.
-00017db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017dc0: 6966 206e 6f74 2069 7369 6e73 7461 6e63  if not isinstanc
-00017dd0: 6528 7374 6174 655f 6469 6374 5b6b 6579  e(state_dict[key
-00017de0: 5d2c 2074 6f72 6368 2e54 656e 736f 7229  ], torch.Tensor)
-00017df0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00017e00: 2020 2020 2020 636f 6e74 696e 7565 0a20        continue. 
-00017e10: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00017e20: 6620 2777 6569 6768 7427 206e 6f74 2069  f 'weight' not i
-00017e30: 6e20 6b65 7920 616e 6420 2762 6961 7327  n key and 'bias'
-00017e40: 206e 6f74 2069 6e20 6b65 793a 0a20 2020   not in key:.   
-00017e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017e60: 2063 6f6e 7469 6e75 650a 0a20 2020 2020   continue..     
-00017e70: 2020 2020 2020 2020 2020 206f 7020 3d20             op = 
-00017e80: 6b65 795b 3a6b 6579 2e72 6669 6e64 2827  key[:key.rfind('
-00017e90: 2e27 295d 0a20 2020 2020 2020 2020 2020  .')].           
-00017ea0: 2020 2020 206f 7020 3d20 6f70 2e72 6570       op = op.rep
-00017eb0: 6c61 6365 2827 2e5f 7061 636b 6564 5f70  lace('._packed_p
-00017ec0: 6172 616d 7327 2c20 2727 290a 0a20 2020  arams', '')..   
-00017ed0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00017ee0: 6f70 2069 6e20 6f70 5f6c 6973 743a 0a20  op in op_list:. 
+00017ac0: 2020 2020 6966 2073 656c 662e 6465 7669      if self.devi
+00017ad0: 6365 203d 3d20 2267 7075 223a 0a20 2020  ce == "gpu":.   
+00017ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017af0: 2020 2020 2069 6e70 7574 203d 2069 6e70       input = inp
+00017b00: 7574 2e74 6f28 2264 7063 7070 2229 0a20  ut.to("dpcpp"). 
+00017b10: 2020 2020 2020 2020 2020 2020 2020 2077                 w
+00017b20: 7269 7465 722e 6164 645f 6772 6170 6828  riter.add_graph(
+00017b30: 6d6f 6465 6c2c 2069 6e70 7574 290a 2020  model, input).  
+00017b40: 2020 2020 2020 2020 2020 2020 2020 6272                br
+00017b50: 6561 6b0a 0a20 2020 2020 2020 2073 756d  eak..        sum
+00017b60: 6d61 7279 203d 204f 7264 6572 6564 4469  mary = OrderedDi
+00017b70: 6374 2829 0a20 2020 2020 2020 206f 6273  ct().        obs
+00017b80: 6572 7665 725f 6469 6374 203d 207b 7d0a  erver_dict = {}.
+00017b90: 2020 2020 2020 2020 6765 745f 6f62 7365          get_obse
+00017ba0: 7276 6572 5f64 6963 7428 6d6f 6465 6c2c  rver_dict(model,
+00017bb0: 206f 6273 6572 7665 725f 6469 6374 290a   observer_dict).
+00017bc0: 2020 2020 2020 2020 666f 7220 6b65 7920          for key 
+00017bd0: 696e 206f 6273 6572 7665 725f 6469 6374  in observer_dict
+00017be0: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+00017bf0: 2069 7369 6e73 7461 6e63 6528 6f62 7365   isinstance(obse
+00017c00: 7276 6572 5f64 6963 745b 6b65 795d 2c20  rver_dict[key], 
+00017c10: 746f 7263 682e 6e6e 2e6d 6f64 756c 6573  torch.nn.modules
+00017c20: 2e6c 696e 6561 722e 4964 656e 7469 7479  .linear.Identity
+00017c30: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+00017c40: 2020 2063 6f6e 7469 6e75 650a 2020 2020     continue.    
+00017c50: 2020 2020 2020 2020 6f70 5f6e 616d 6520          op_name 
+00017c60: 3d20 6b65 792e 7374 7269 7028 222e 6163  = key.strip(".ac
+00017c70: 7469 7661 7469 6f6e 5f70 6f73 745f 7072  tivation_post_pr
+00017c80: 6f63 6573 7322 290a 2020 2020 2020 2020  ocess").        
+00017c90: 2020 2020 7375 6d6d 6172 795b 6f70 5f6e      summary[op_n
+00017ca0: 616d 6520 2b20 222e 6f75 7470 7574 225d  ame + ".output"]
+00017cb0: 203d 206f 6273 6572 7665 725f 6469 6374   = observer_dict
+00017cc0: 5b6b 6579 5d2e 6765 745f 7465 6e73 6f72  [key].get_tensor
+00017cd0: 5f76 616c 7565 2829 0a20 2020 2020 2020  _value().       
+00017ce0: 2020 2020 2066 6f72 2069 7465 7220 696e       for iter in
+00017cf0: 2073 756d 6d61 7279 5b6f 705f 6e61 6d65   summary[op_name
+00017d00: 202b 2022 2e6f 7574 7075 7422 5d3a 0a20   + ".output"]:. 
+00017d10: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+00017d20: 204f 6e6c 7920 636f 6c6c 6563 7420 6c61   Only collect la
+00017d30: 7374 2066 7573 6564 2063 6869 6c64 206f  st fused child o
+00017d40: 7574 7075 740a 2020 2020 2020 2020 2020  utput.          
+00017d50: 2020 2020 2020 6f70 203d 206f 705f 6e61        op = op_na
+00017d60: 6d65 0a20 2020 2020 2020 2020 2020 2020  me.             
+00017d70: 2020 2069 6620 7365 6c66 2e69 735f 6675     if self.is_fu
+00017d80: 7365 645f 6368 696c 6428 6f70 5f6e 616d  sed_child(op_nam
+00017d90: 6529 203d 3d20 5472 7565 2061 6e64 205c  e) == True and \
+00017da0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00017db0: 2020 2020 7365 6c66 2e69 735f 6c61 7374      self.is_last
+00017dc0: 5f66 7573 6564 5f63 6869 6c64 286f 705f  _fused_child(op_
+00017dd0: 6e61 6d65 2920 3d3d 2054 7275 653a 0a20  name) == True:. 
+00017de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017df0: 2020 206f 7020 3d20 6f70 5f6e 616d 655b     op = op_name[
+00017e00: 3a6f 705f 6e61 6d65 2e72 6669 6e64 2827  :op_name.rfind('
+00017e10: 2e27 295d 0a20 2020 2020 2020 2020 2020  .')].           
+00017e20: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00017e30: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00017e40: 6620 7365 6c66 2e69 735f 6675 7365 645f  f self.is_fused_
+00017e50: 6368 696c 6428 6f70 5f6e 616d 6529 203d  child(op_name) =
+00017e60: 3d20 5472 7565 2061 6e64 205c 0a20 2020  = True and \.   
+00017e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017e80: 2020 2020 7365 6c66 2e69 735f 6c61 7374      self.is_last
+00017e90: 5f66 7573 6564 5f63 6869 6c64 286f 705f  _fused_child(op_
+00017ea0: 6e61 6d65 2920 3d3d 2046 616c 7365 3a0a  name) == False:.
+00017eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017ec0: 2020 2020 2020 2020 636f 6e74 696e 7565          continue
+00017ed0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00017ee0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
 00017ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017f00: 2020 2069 6620 6f70 2069 6e20 7265 745b     if op in ret[
-00017f10: 2777 6569 6768 7427 5d3a 0a20 2020 2020  'weight']:.     
-00017f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017f30: 2020 2072 6574 5b27 7765 6967 6874 275d     ret['weight']
-00017f40: 5b6f 705d 2e75 7064 6174 6528 7b0a 2020  [op].update({.  
-00017f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017f60: 2020 2020 2020 2020 2020 6b65 793a 0a20            key:. 
-00017f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017f80: 2020 2020 2020 2020 2020 2064 6571 7561             dequa
-00017f90: 6e74 697a 6528 7374 6174 655f 6469 6374  ntize(state_dict
-00017fa0: 5b6b 6579 5d29 2e6e 756d 7079 2829 0a20  [key]).numpy(). 
-00017fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017fc0: 2020 2020 2020 2020 2020 2069 6620 7374             if st
-00017fd0: 6174 655f 6469 6374 5b6b 6579 5d2e 6973  ate_dict[key].is
-00017fe0: 5f71 7561 6e74 697a 6564 2065 6c73 6520  _quantized else 
-00017ff0: 7374 6174 655f 6469 6374 5b6b 6579 5d2e  state_dict[key].
-00018000: 6465 7461 6368 2829 2e6e 756d 7079 2829  detach().numpy()
-00018010: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018020: 2020 2020 2020 2020 207d 290a 2020 2020           }).    
-00018030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018040: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00018050: 2020 2020 2020 2020 2020 2020 2020 7265                re
-00018060: 745b 2777 6569 6768 7427 5d5b 6f70 5d20  t['weight'][op] 
-00018070: 3d20 7b0a 2020 2020 2020 2020 2020 2020  = {.            
-00018080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018090: 6b65 793a 0a20 2020 2020 2020 2020 2020  key:.           
-000180a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000180b0: 2064 6571 7561 6e74 697a 6528 7374 6174   dequantize(stat
-000180c0: 655f 6469 6374 5b6b 6579 5d29 2e6e 756d  e_dict[key]).num
-000180d0: 7079 2829 0a20 2020 2020 2020 2020 2020  py().           
-000180e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000180f0: 2069 6620 7374 6174 655f 6469 6374 5b6b   if state_dict[k
-00018100: 6579 5d2e 6973 5f71 7561 6e74 697a 6564  ey].is_quantized
-00018110: 2065 6c73 6520 7374 6174 655f 6469 6374   else state_dict
-00018120: 5b6b 6579 5d2e 6465 7461 6368 2829 2e6e  [key].detach().n
-00018130: 756d 7079 2829 0a20 2020 2020 2020 2020  umpy().         
-00018140: 2020 2020 2020 2020 2020 2020 2020 207d                 }
-00018150: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018160: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00018170: 2020 2020 2020 2020 2020 2069 6620 626f             if bo
-00018180: 6f6c 2873 656c 662e 6675 7365 645f 6469  ol(self.fused_di
-00018190: 6374 293a 0a20 2020 2020 2020 2020 2020  ct):.           
-000181a0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-000181b0: 6973 5f71 7561 6e74 697a 6564 3a0a 2020  is_quantized:.  
-000181c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000181d0: 2020 2020 2020 2020 2020 666f 7220 6120            for a 
-000181e0: 696e 2066 7033 325f 696e 7438 5f6d 6170  in fp32_int8_map
-000181f0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00018200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018210: 2020 6966 206f 7020 3d3d 2066 7033 325f    if op == fp32_
-00018220: 696e 7438 5f6d 6170 5b61 5d5b 2777 6569  int8_map[a]['wei
-00018230: 6768 7427 5d3a 0a20 2020 2020 2020 2020  ght']:.         
-00018240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018250: 2020 2020 2020 2020 2020 2069 6620 6120             if a 
-00018260: 696e 2072 6574 5b27 7765 6967 6874 275d  in ret['weight']
-00018270: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00018280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018290: 2020 2020 2020 2020 2020 7265 745b 2777            ret['w
-000182a0: 6569 6768 7427 5d5b 615d 2e75 7064 6174  eight'][a].updat
-000182b0: 6528 7b0a 2020 2020 2020 2020 2020 2020  e({.            
-000182c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000182d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000182e0: 6b65 793a 0a20 2020 2020 2020 2020 2020  key:.           
-000182f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018310: 2064 6571 7561 6e74 697a 6528 7374 6174   dequantize(stat
-00018320: 655f 6469 6374 5b6b 6579 5d29 2e6e 756d  e_dict[key]).num
-00018330: 7079 2829 0a20 2020 2020 2020 2020 2020  py().           
-00018340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018360: 2069 6620 7374 6174 655f 6469 6374 5b6b   if state_dict[k
-00018370: 6579 5d2e 6973 5f71 7561 6e74 697a 6564  ey].is_quantized
-00018380: 2065 6c73 650a 2020 2020 2020 2020 2020   else.          
-00018390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000183a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000183b0: 2020 7374 6174 655f 6469 6374 5b6b 6579    state_dict[key
-000183c0: 5d2e 6465 7461 6368 2829 2e6e 756d 7079  ].detach().numpy
-000183d0: 2829 0a20 2020 2020 2020 2020 2020 2020  ().             
-000183e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000183f0: 2020 2020 2020 2020 2020 207d 290a 2020             }).  
-00018400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018420: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00018430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018450: 7265 745b 2777 6569 6768 7427 5d5b 615d  ret['weight'][a]
-00018460: 203d 205c 0a20 2020 2020 2020 2020 2020   = \.           
-00018470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018490: 207b 6b65 793a 2064 6571 7561 6e74 697a   {key: dequantiz
-000184a0: 6528 7374 6174 655f 6469 6374 5b6b 6579  e(state_dict[key
-000184b0: 5d29 2e6e 756d 7079 2829 0a20 2020 2020  ]).numpy().     
+00017f00: 2020 206f 7020 3d20 6f70 5f6e 616d 650a     op = op_name.
+00017f10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00017f20: 2069 6620 7375 6d6d 6172 795b 6f70 5f6e   if summary[op_n
+00017f30: 616d 6520 2b20 222e 6f75 7470 7574 225d  ame + ".output"]
+00017f40: 5b69 7465 725d 2e69 735f 7175 616e 7469  [iter].is_quanti
+00017f50: 7a65 643a 0a20 2020 2020 2020 2020 2020  zed:.           
+00017f60: 2020 2020 2020 2020 2077 7269 7465 722e           writer.
+00017f70: 6164 645f 6869 7374 6f67 7261 6d28 6f70  add_histogram(op
+00017f80: 202b 2022 2f4f 7574 7075 742f 696e 7438   + "/Output/int8
+00017f90: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00017fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017fb0: 2020 2020 2020 2020 2020 2020 746f 7263              torc
+00017fc0: 682e 6465 7175 616e 7469 7a65 2873 756d  h.dequantize(sum
+00017fd0: 6d61 7279 5b6f 705f 6e61 6d65 202b 2022  mary[op_name + "
+00017fe0: 2e6f 7574 7075 7422 5d5b 6974 6572 5d29  .output"][iter])
+00017ff0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00018000: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00018010: 2020 2020 2020 2020 2020 2020 7772 6974              writ
+00018020: 6572 2e61 6464 5f68 6973 746f 6772 616d  er.add_histogram
+00018030: 286f 7020 2b20 222f 4f75 7470 7574 2f66  (op + "/Output/f
+00018040: 7033 3222 2c20 7375 6d6d 6172 795b 6f70  p32", summary[op
+00018050: 5f6e 616d 6520 2b20 222e 6f75 7470 7574  _name + ".output
+00018060: 225d 5b69 7465 725d 290a 0a20 2020 2020  "][iter])..     
+00018070: 2020 2073 7461 7465 5f64 6963 7420 3d20     state_dict = 
+00018080: 6d6f 6465 6c2e 7374 6174 655f 6469 6374  model.state_dict
+00018090: 2829 0a20 2020 2020 2020 2066 6f72 206b  ().        for k
+000180a0: 6579 2069 6e20 7374 6174 655f 6469 6374  ey in state_dict
+000180b0: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+000180c0: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
+000180d0: 7374 6174 655f 6469 6374 5b6b 6579 5d2c  state_dict[key],
+000180e0: 2074 6f72 6368 2e54 656e 736f 7229 3a0a   torch.Tensor):.
+000180f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018100: 636f 6e74 696e 7565 0a0a 2020 2020 2020  continue..      
+00018110: 2020 2020 2020 6f70 203d 206b 6579 5b3a        op = key[:
+00018120: 6b65 792e 7266 696e 6428 272e 2729 5d0a  key.rfind('.')].
+00018130: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00018140: 656c 662e 6973 5f66 7573 6564 5f63 6869  elf.is_fused_chi
+00018150: 6c64 286f 7029 2069 7320 5472 7565 3a0a  ld(op) is True:.
+00018160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018170: 2320 6675 7365 6420 6368 696c 6420 7465  # fused child te
+00018180: 6e73 6f72 626f 6172 6420 7461 6720 7769  nsorboard tag wi
+00018190: 6c6c 2062 6520 6d65 7267 650a 2020 2020  ll be merge.    
+000181a0: 2020 2020 2020 2020 2020 2020 7765 6967              weig
+000181b0: 6874 203d 206b 6579 5b6b 6579 2e72 6669  ht = key[key.rfi
+000181c0: 6e64 2827 2e27 2920 2b20 313a 5d0a 2020  nd('.') + 1:].  
+000181d0: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+000181e0: 203d 206f 705b 3a6f 702e 7266 696e 6428   = op[:op.rfind(
+000181f0: 272e 2729 5d20 2b20 272f 2720 2b20 7765  '.')] + '/' + we
+00018200: 6967 6874 0a20 2020 2020 2020 2020 2020  ight.           
+00018210: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00018220: 2020 2020 2020 2077 6569 6768 7420 3d20         weight = 
+00018230: 6b65 795b 6b65 792e 7266 696e 6428 272e  key[key.rfind('.
+00018240: 2729 202b 2031 3a5d 0a20 2020 2020 2020  ') + 1:].       
+00018250: 2020 2020 2020 2020 206f 7020 3d20 6b65           op = ke
+00018260: 795b 3a6b 6579 2e72 6669 6e64 2827 2e27  y[:key.rfind('.'
+00018270: 295d 202b 2027 2f27 202b 2077 6569 6768  )] + '/' + weigh
+00018280: 740a 0a20 2020 2020 2020 2020 2020 2023  t..            #
+00018290: 2054 6f20 6d65 7267 6520 2e5f 7061 636b   To merge ._pack
+000182a0: 6564 5f70 6172 616d 730a 2020 2020 2020  ed_params.      
+000182b0: 2020 2020 2020 6f70 203d 206f 702e 7265        op = op.re
+000182c0: 706c 6163 6528 272e 5f70 6163 6b65 645f  place('._packed_
+000182d0: 7061 7261 6d73 272c 2027 2729 0a0a 2020  params', '')..  
+000182e0: 2020 2020 2020 2020 2020 6966 2073 7461            if sta
+000182f0: 7465 5f64 6963 745b 6b65 795d 2e69 735f  te_dict[key].is_
+00018300: 7175 616e 7469 7a65 643a 0a20 2020 2020  quantized:.     
+00018310: 2020 2020 2020 2020 2020 2077 7269 7465             write
+00018320: 722e 6164 645f 6869 7374 6f67 7261 6d28  r.add_histogram(
+00018330: 6f70 202b 2022 2f69 6e74 3822 2c20 746f  op + "/int8", to
+00018340: 7263 682e 6465 7175 616e 7469 7a65 2873  rch.dequantize(s
+00018350: 7461 7465 5f64 6963 745b 6b65 795d 2929  tate_dict[key]))
+00018360: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
+00018370: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00018380: 2020 2077 7269 7465 722e 6164 645f 6869     writer.add_hi
+00018390: 7374 6f67 7261 6d28 6f70 202b 2022 2f66  stogram(op + "/f
+000183a0: 7033 3222 2c20 7374 6174 655f 6469 6374  p32", state_dict
+000183b0: 5b6b 6579 5d29 0a0a 2020 2020 2020 2020  [key])..        
+000183c0: 7772 6974 6572 2e63 6c6f 7365 2829 0a20  writer.close(). 
+000183d0: 2020 2020 2020 2073 656c 662e 6475 6d70         self.dump
+000183e0: 5f74 696d 6573 203d 2073 656c 662e 6475  _times = self.du
+000183f0: 6d70 5f74 696d 6573 202b 2031 0a0a 2020  mp_times + 1..  
+00018400: 2020 2020 2020 7265 7475 726e 2073 756d        return sum
+00018410: 6d61 7279 0a0a 2020 2020 4064 756d 705f  mary..    @dump_
+00018420: 656c 6170 7365 645f 7469 6d65 2822 5061  elapsed_time("Pa
+00018430: 7373 2073 6176 6520 7175 616e 7469 7a65  ss save quantize
+00018440: 6420 6d6f 6465 6c22 290a 2020 2020 6465  d model").    de
+00018450: 6620 7361 7665 2873 656c 662c 206d 6f64  f save(self, mod
+00018460: 656c 2c20 7061 7468 3d4e 6f6e 6529 3a0a  el, path=None):.
+00018470: 2020 2020 2020 2020 7061 7373 0a0a 2020          pass..  
+00018480: 2020 6465 6620 696e 7370 6563 745f 7465    def inspect_te
+00018490: 6e73 6f72 2873 656c 662c 0a20 2020 2020  nsor(self,.     
+000184a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000184b0: 2020 6d6f 6465 6c2c 0a20 2020 2020 2020    model,.       
 000184c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000184d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000184e0: 2020 2020 2020 2020 2020 2069 6620 7374             if st
-000184f0: 6174 655f 6469 6374 5b6b 6579 5d2e 6973  ate_dict[key].is
-00018500: 5f71 7561 6e74 697a 6564 2065 6c73 650a  _quantized else.
-00018510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000184d0: 6461 7461 6c6f 6164 6572 2c0a 2020 2020  dataloader,.    
+000184e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000184f0: 2020 206f 705f 6c69 7374 3d4e 6f6e 652c     op_list=None,
+00018500: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018510: 2020 2020 2020 2020 6974 6572 6174 696f          iteratio
+00018520: 6e5f 6c69 7374 3d4e 6f6e 652c 0a20 2020  n_list=None,.   
 00018530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018540: 2020 2020 7374 6174 655f 6469 6374 5b6b      state_dict[k
-00018550: 6579 5d2e 6465 7461 6368 2829 2e6e 756d  ey].detach().num
-00018560: 7079 2829 7d0a 2020 2020 2020 2020 2020  py()}.          
-00018570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018580: 2020 2020 2020 2020 2020 6272 6561 6b0a            break.
-00018590: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-000185a0: 7361 7665 5f74 6f5f 6469 736b 3a0a 2020  save_to_disk:.  
-000185b0: 2020 2020 2020 2020 2020 2020 2020 6e70                np
-000185c0: 2e73 6176 657a 286f 732e 7061 7468 2e6a  .savez(os.path.j
-000185d0: 6f69 6e28 6475 6d70 5f64 6972 2c20 2777  oin(dump_dir, 'w
-000185e0: 6569 6768 742e 6e70 7a27 292c 202a 2a72  eight.npz'), **r
-000185f0: 6574 5b27 7765 6967 6874 275d 290a 2020  et['weight']).  
-00018600: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00018610: 2020 2020 2020 2020 7265 745b 2777 6569          ret['wei
-00018620: 6768 7427 5d20 3d20 4e6f 6e65 0a0a 2020  ght'] = None..  
-00018630: 2020 2020 2020 7265 7475 726e 2072 6574        return ret
-00018640: 0a0a 2020 2020 6465 6620 7365 745f 7465  ..    def set_te
-00018650: 6e73 6f72 2873 656c 662c 206d 6f64 656c  nsor(self, model
-00018660: 2c20 7465 6e73 6f72 5f64 6963 7429 3a0a  , tensor_dict):.
-00018670: 2020 2020 2020 2020 7374 6174 655f 6469          state_di
-00018680: 6374 203d 206d 6f64 656c 2e5f 6d6f 6465  ct = model._mode
-00018690: 6c2e 7374 6174 655f 6469 6374 2829 0a20  l.state_dict(). 
-000186a0: 2020 2020 2020 2074 656e 736f 725f 6e61         tensor_na
-000186b0: 6d65 203d 204e 6f6e 650a 2020 2020 2020  me = None.      
-000186c0: 2020 666f 7220 6b65 7920 696e 2074 656e    for key in ten
-000186d0: 736f 725f 6469 6374 2e6b 6579 7328 293a  sor_dict.keys():
-000186e0: 0a20 2020 2020 2020 2020 2020 2065 6e64  .            end
-000186f0: 203d 206b 6579 2e72 6669 6e64 2827 2e27   = key.rfind('.'
-00018700: 290a 2020 2020 2020 2020 2020 2020 6f70  ).            op
-00018710: 5f6e 616d 6520 3d20 6b65 795b 3a65 6e64  _name = key[:end
-00018720: 5d0a 2020 2020 2020 2020 2020 2020 7374  ].            st
-00018730: 6174 655f 6f70 5f6e 616d 6520 3d20 4e6f  ate_op_name = No
-00018740: 6e65 0a20 2020 2020 2020 2020 2020 2077  ne.            w
-00018750: 6569 6768 745f 6269 6173 203d 206b 6579  eight_bias = key
-00018760: 5b65 6e64 202b 2031 3a5d 0a20 2020 2020  [end + 1:].     
-00018770: 2020 2020 2020 2066 6f72 206f 7020 696e         for op in
-00018780: 2073 656c 662e 6675 7365 645f 6469 6374   self.fused_dict
-00018790: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000187a0: 2020 6966 206f 705f 6e61 6d65 2069 6e20    if op_name in 
-000187b0: 7365 6c66 2e66 7573 6564 5f64 6963 745b  self.fused_dict[
-000187c0: 6f70 5d3a 0a20 2020 2020 2020 2020 2020  op]:.           
-000187d0: 2020 2020 2020 2020 2073 7461 7465 5f6f           state_o
-000187e0: 705f 6e61 6d65 203d 206f 700a 2020 2020  p_name = op.    
-000187f0: 2020 2020 2020 2020 6966 2073 7461 7465          if state
-00018800: 5f6f 705f 6e61 6d65 2069 7320 4e6f 6e65  _op_name is None
-00018810: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00018820: 2020 7374 6174 655f 6f70 5f6e 616d 6520    state_op_name 
-00018830: 3d20 6f70 5f6e 616d 650a 2020 2020 2020  = op_name.      
-00018840: 2020 2020 2020 666f 7220 7374 6174 655f        for state_
-00018850: 6469 6374 5f6b 6579 2069 6e20 7374 6174  dict_key in stat
-00018860: 655f 6469 6374 2e6b 6579 7328 293a 0a20  e_dict.keys():. 
-00018870: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00018880: 7461 7465 5f6b 6579 5f65 6e64 203d 2073  tate_key_end = s
-00018890: 7461 7465 5f64 6963 745f 6b65 792e 7266  tate_dict_key.rf
-000188a0: 696e 6428 272e 2729 0a20 2020 2020 2020  ind('.').       
-000188b0: 2020 2020 2020 2020 2073 7461 7465 5f6b           state_k
-000188c0: 6579 203d 2073 7461 7465 5f64 6963 745f  ey = state_dict_
-000188d0: 6b65 795b 3a73 7461 7465 5f6b 6579 5f65  key[:state_key_e
-000188e0: 6e64 5d2e 7265 706c 6163 6528 272e 5f70  nd].replace('._p
-000188f0: 6163 6b65 645f 7061 7261 6d73 272c 2027  acked_params', '
-00018900: 2729 0a20 2020 2020 2020 2020 2020 2020  ').             
-00018910: 2020 2069 6620 7765 6967 6874 5f62 6961     if weight_bia
-00018920: 7320 696e 2073 7461 7465 5f64 6963 745f  s in state_dict_
-00018930: 6b65 7920 616e 6420 7374 6174 655f 6f70  key and state_op
-00018940: 5f6e 616d 6520 3d3d 2073 7461 7465 5f6b  _name == state_k
-00018950: 6579 3a0a 2020 2020 2020 2020 2020 2020  ey:.            
-00018960: 2020 2020 2020 2020 7465 6e73 6f72 5f6e          tensor_n
-00018970: 616d 6520 3d20 7374 6174 655f 6469 6374  ame = state_dict
-00018980: 5f6b 6579 0a20 2020 2020 2020 2020 2020  _key.           
-00018990: 2061 7373 6572 7420 7465 6e73 6f72 5f6e   assert tensor_n
-000189a0: 616d 6520 6973 206e 6f74 204e 6f6e 652c  ame is not None,
-000189b0: 206b 6579 202b 2022 2069 7320 6e6f 7420   key + " is not 
-000189c0: 696e 2074 6865 2073 7461 7465 2064 6963  in the state dic
-000189d0: 7422 0a20 2020 2020 2020 2020 2020 2074  t".            t
-000189e0: 656e 736f 7220 3d20 746f 7263 682e 6672  ensor = torch.fr
-000189f0: 6f6d 5f6e 756d 7079 2874 656e 736f 725f  om_numpy(tensor_
-00018a00: 6469 6374 5b6b 6579 5d29 0a20 2020 2020  dict[key]).     
-00018a10: 2020 2020 2020 2064 7479 7065 203d 2073         dtype = s
-00018a20: 7461 7465 5f64 6963 745b 7465 6e73 6f72  tate_dict[tensor
-00018a30: 5f6e 616d 655d 2e64 7479 7065 0a20 2020  _name].dtype.   
-00018a40: 2020 2020 2020 2020 2069 6620 7374 6174           if stat
-00018a50: 655f 6469 6374 5b74 656e 736f 725f 6e61  e_dict[tensor_na
-00018a60: 6d65 5d2e 6973 5f71 7561 6e74 697a 6564  me].is_quantized
-00018a70: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00018a80: 2020 6966 2027 6368 616e 6e65 6c27 2069    if 'channel' i
-00018a90: 6e20 7374 7228 7374 6174 655f 6469 6374  n str(state_dict
-00018aa0: 5b74 656e 736f 725f 6e61 6d65 5d2e 7173  [tensor_name].qs
-00018ab0: 6368 656d 6528 2929 3a0a 2020 2020 2020  cheme()):.      
-00018ac0: 2020 2020 2020 2020 2020 2020 2020 7363                sc
-00018ad0: 616c 6573 203d 2073 7461 7465 5f64 6963  ales = state_dic
-00018ae0: 745b 7465 6e73 6f72 5f6e 616d 655d 2e71  t[tensor_name].q
-00018af0: 5f70 6572 5f63 6861 6e6e 656c 5f73 6361  _per_channel_sca
-00018b00: 6c65 7328 290a 2020 2020 2020 2020 2020  les().          
-00018b10: 2020 2020 2020 2020 2020 7a65 726f 5f70            zero_p
-00018b20: 6f69 6e74 7320 3d20 7374 6174 655f 6469  oints = state_di
-00018b30: 6374 5b74 656e 736f 725f 6e61 6d65 5d2e  ct[tensor_name].
-00018b40: 715f 7065 725f 6368 616e 6e65 6c5f 7a65  q_per_channel_ze
-00018b50: 726f 5f70 6f69 6e74 7328 290a 2020 2020  ro_points().    
-00018b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018b70: 6178 6973 203d 2073 7461 7465 5f64 6963  axis = state_dic
-00018b80: 745b 7465 6e73 6f72 5f6e 616d 655d 2e71  t[tensor_name].q
-00018b90: 5f70 6572 5f63 6861 6e6e 656c 5f61 7869  _per_channel_axi
-00018ba0: 7328 290a 2020 2020 2020 2020 2020 2020  s().            
-00018bb0: 2020 2020 2020 2020 7374 6174 655f 6469          state_di
-00018bc0: 6374 5b74 656e 736f 725f 6e61 6d65 5d20  ct[tensor_name] 
-00018bd0: 3d20 746f 7263 682e 7175 616e 7469 7a65  = torch.quantize
-00018be0: 5f70 6572 5f63 6861 6e6e 656c 2874 656e  _per_channel(ten
-00018bf0: 736f 722c 0a20 2020 2020 2020 2020 2020  sor,.           
-00018c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018c30: 2020 2020 2020 2020 2020 2020 2020 7363                sc
-00018c40: 616c 6573 2c0a 2020 2020 2020 2020 2020  ales,.          
-00018c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018c80: 2020 2020 2020 2020 2020 2020 2020 207a                 z
-00018c90: 6572 6f5f 706f 696e 7473 2c0a 2020 2020  ero_points,.    
-00018ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018ce0: 2020 2020 2061 7869 732c 0a20 2020 2020       axis,.     
-00018cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018d30: 2020 2020 6474 7970 653d 6474 7970 6529      dtype=dtype)
-00018d40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018d50: 2065 6c69 6620 2774 656e 736f 7227 2069   elif 'tensor' i
-00018d60: 6e20 7374 7228 7374 6174 655f 6469 6374  n str(state_dict
-00018d70: 5b74 656e 736f 725f 6e61 6d65 5d2e 7173  [tensor_name].qs
-00018d80: 6368 656d 6528 2929 3a0a 2020 2020 2020  cheme()):.      
-00018d90: 2020 2020 2020 2020 2020 2020 2020 7363                sc
-00018da0: 616c 6573 203d 2073 7461 7465 5f64 6963  ales = state_dic
-00018db0: 745b 7465 6e73 6f72 5f6e 616d 655d 2e71  t[tensor_name].q
-00018dc0: 5f73 6361 6c65 2829 0a20 2020 2020 2020  _scale().       
-00018dd0: 2020 2020 2020 2020 2020 2020 207a 6572               zer
-00018de0: 6f5f 706f 696e 7473 203d 2073 7461 7465  o_points = state
-00018df0: 5f64 6963 745b 7465 6e73 6f72 5f6e 616d  _dict[tensor_nam
-00018e00: 655d 2e71 5f7a 6572 6f5f 706f 696e 7428  e].q_zero_point(
-00018e10: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00018e20: 2020 2020 2020 7374 6174 655f 6469 6374        state_dict
-00018e30: 5b74 656e 736f 725f 6e61 6d65 5d20 3d20  [tensor_name] = 
-00018e40: 746f 7263 682e 7175 616e 7469 7a65 5f70  torch.quantize_p
-00018e50: 6572 5f74 656e 736f 7228 0a20 2020 2020  er_tensor(.     
-00018e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018e70: 2020 2074 656e 736f 722c 2073 6361 6c65     tensor, scale
-00018e80: 732c 207a 6572 6f5f 706f 696e 7473 2c20  s, zero_points, 
-00018e90: 6474 7970 6529 0a20 2020 2020 2020 2020  dtype).         
-00018ea0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00018eb0: 2020 2020 2020 2020 2073 7461 7465 5f64           state_d
-00018ec0: 6963 745b 7465 6e73 6f72 5f6e 616d 655d  ict[tensor_name]
-00018ed0: 203d 2074 656e 736f 720a 2020 2020 2020   = tensor.      
-00018ee0: 2020 6d6f 6465 6c2e 5f6d 6f64 656c 2e6c    model._model.l
-00018ef0: 6f61 645f 7374 6174 655f 6469 6374 2873  oad_state_dict(s
-00018f00: 7461 7465 5f64 6963 7429 0a0a 2020 2020  tate_dict)..    
-00018f10: 4064 756d 705f 656c 6170 7365 645f 7469  @dump_elapsed_ti
-00018f20: 6d65 2822 5061 7373 2071 7565 7279 2066  me("Pass query f
-00018f30: 7261 6d65 776f 726b 2063 6170 6162 696c  ramework capabil
-00018f40: 6974 7922 290a 2020 2020 6465 6620 7175  ity").    def qu
-00018f50: 6572 795f 6677 5f63 6170 6162 696c 6974  ery_fw_capabilit
-00018f60: 7928 7365 6c66 2c20 6d6f 6465 6c29 3a0a  y(self, model):.
-00018f70: 2020 2020 2020 2020 2222 2254 6869 7320          """This 
-00018f80: 6973 2061 2068 656c 7065 7220 6675 6e63  is a helper func
-00018f90: 7469 6f6e 2074 6f20 6765 7420 616c 6c20  tion to get all 
-00018fa0: 7175 616e 7469 7a61 626c 6520 6f70 7320  quantizable ops 
-00018fb0: 6672 6f6d 206d 6f64 656c 2e0a 0a20 2020  from model...   
-00018fc0: 2020 2020 2041 7267 733a 0a20 2020 2020       Args:.     
-00018fd0: 2020 2020 2020 206d 6f64 656c 2028 6f62         model (ob
-00018fe0: 6a65 6374 293a 2069 6e70 7574 206d 6f64  ject): input mod
-00018ff0: 656c 2077 6869 6368 2069 7320 4e65 7572  el which is Neur
-00019000: 616c 2043 6f6d 7072 6573 736f 7220 6d6f  al Compressor mo
-00019010: 6465 6c0a 0a20 2020 2020 2020 2052 6574  del..        Ret
-00019020: 7572 6e73 3a0a 2020 2020 2020 2020 2020  urns:.          
-00019030: 2020 715f 6361 7061 6269 6c69 7479 2028    q_capability (
-00019040: 6469 6374 696f 6e61 7279 293a 2074 756e  dictionary): tun
-00019050: 696e 6720 6361 7061 6269 6c69 7479 2066  ing capability f
-00019060: 6f72 2065 6163 6820 6f70 2066 726f 6d20  or each op from 
-00019070: 6d6f 6465 6c2e 0a20 2020 2020 2020 2022  model..        "
-00019080: 2222 0a20 2020 2020 2020 2073 656c 662e  "".        self.
-00019090: 7072 655f 6f70 7469 6d69 7a65 645f 6d6f  pre_optimized_mo
-000190a0: 6465 6c20 3d20 6d6f 6465 6c0a 2020 2020  del = model.    
-000190b0: 2020 2020 7365 6c66 2e6e 6f6e 5f71 7561      self.non_qua
-000190c0: 6e74 5f64 6963 7420 3d20 7365 6c66 2e67  nt_dict = self.g
-000190d0: 6574 5f6e 6f6e 5f71 7561 6e74 5f6d 6f64  et_non_quant_mod
-000190e0: 756c 6573 286d 6f64 656c 2e6b 7761 7267  ules(model.kwarg
-000190f0: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
-00019100: 6e20 7365 6c66 2e5f 6765 745f 7175 616e  n self._get_quan
-00019110: 7469 7a61 626c 655f 6f70 7328 6d6f 6465  tizable_ops(mode
-00019120: 6c2e 6d6f 6465 6c29 0a0a 2020 2020 6465  l.model)..    de
-00019130: 6620 6765 745f 6e6f 6e5f 7175 616e 745f  f get_non_quant_
-00019140: 6d6f 6475 6c65 7328 7365 6c66 2c20 6d6f  modules(self, mo
-00019150: 6465 6c5f 6b77 6172 6773 293a 0a20 2020  del_kwargs):.   
-00019160: 2020 2020 2022 2222 5468 6973 2069 7320       """This is 
-00019170: 6120 6865 6c70 6572 2066 756e 6374 696f  a helper functio
-00019180: 6e20 746f 2067 6574 2061 6c6c 206e 6f6e  n to get all non
-00019190: 5f71 7561 6e74 5f6d 6f64 756c 6573 2066  _quant_modules f
-000191a0: 726f 6d20 6375 7374 6f6d 6572 2061 6e64  rom customer and
-000191b0: 2064 6566 6175 6c74 2e0a 0a20 2020 2020   default...     
-000191c0: 2020 2041 7267 733a 0a20 2020 2020 2020     Args:.       
-000191d0: 2020 2020 206d 6f64 656c 5f6b 7761 7267       model_kwarg
-000191e0: 7320 2864 6963 7469 6f6e 6172 7929 3a20  s (dictionary): 
-000191f0: 6b65 7977 6f72 6420 6172 6773 2066 726f  keyword args fro
-00019200: 6d20 4e65 7572 616c 2043 6f6d 7072 6573  m Neural Compres
-00019210: 736f 7220 6d6f 6465 6c0a 0a20 2020 2020  sor model..     
-00019220: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
-00019230: 2020 2020 2020 2020 6375 7374 6f6d 5f6e          custom_n
-00019240: 6f6e 5f71 7561 6e74 5f64 6963 7420 2864  on_quant_dict (d
-00019250: 6963 7469 6f6e 6172 7929 3a20 6e6f 6e5f  ictionary): non_
-00019260: 7175 616e 745f 6d6f 6475 6c65 7320 666f  quant_modules fo
-00019270: 7220 6d6f 6465 6c2e 0a20 2020 2020 2020  r model..       
-00019280: 2022 2222 0a20 2020 2020 2020 2069 6620   """.        if 
-00019290: 6d6f 6465 6c5f 6b77 6172 6773 2069 7320  model_kwargs is 
-000192a0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-000192b0: 2020 6d6f 6465 6c5f 6b77 6172 6773 203d    model_kwargs =
-000192c0: 207b 7d0a 2020 2020 2020 2020 736b 6970   {}.        skip
-000192d0: 7065 645f 6d6f 6475 6c65 5f6e 616d 6573  ped_module_names
-000192e0: 203d 206d 6f64 656c 5f6b 7761 7267 732e   = model_kwargs.
-000192f0: 6765 7428 226e 6f6e 5f71 7561 6e74 5f6d  get("non_quant_m
-00019300: 6f64 756c 655f 6e61 6d65 222c 205b 5d29  odule_name", [])
-00019310: 0a20 2020 2020 2020 2073 6b69 7070 6564  .        skipped
-00019320: 5f6d 6f64 756c 655f 636c 6173 7365 7320  _module_classes 
-00019330: 3d20 6d6f 6465 6c5f 6b77 6172 6773 2e67  = model_kwargs.g
-00019340: 6574 2822 6e6f 6e5f 7175 616e 745f 6d6f  et("non_quant_mo
-00019350: 6475 6c65 5f63 6c61 7373 222c 205b 5d29  dule_class", [])
-00019360: 0a20 2020 2020 2020 2063 7573 746f 6d5f  .        custom_
-00019370: 6e6f 6e5f 7175 616e 745f 6469 6374 203d  non_quant_dict =
-00019380: 207b 0a20 2020 2020 2020 2020 2020 2027   {.            '
-00019390: 736b 6970 7065 645f 6d6f 6475 6c65 5f6e  skipped_module_n
-000193a0: 616d 6573 273a 2073 6b69 7070 6564 5f6d  ames': skipped_m
-000193b0: 6f64 756c 655f 6e61 6d65 732c 0a20 2020  odule_names,.   
-000193c0: 2020 2020 2020 2020 2027 736b 6970 7065           'skippe
-000193d0: 645f 6d6f 6475 6c65 5f63 6c61 7373 6573  d_module_classes
-000193e0: 273a 2073 6b69 7070 6564 5f6d 6f64 756c  ': skipped_modul
-000193f0: 655f 636c 6173 7365 730a 2020 2020 2020  e_classes.      
-00019400: 2020 7d0a 2020 2020 2020 2020 2320 4967    }.        # Ig
-00019410: 6e6f 7265 204c 6179 6572 4e6f 726d 2c20  nore LayerNorm, 
-00019420: 496e 7374 616e 6365 4e6f 726d 3364 2061  InstanceNorm3d a
-00019430: 6e64 2045 6d62 6564 6469 6e67 2071 7561  nd Embedding qua
-00019440: 6e74 697a 6162 6c65 206f 7073 2c0a 2020  ntizable ops,.  
-00019450: 2020 2020 2020 2320 6475 6520 746f 2068        # due to h
-00019460: 7567 6520 6163 6375 7261 6379 2072 6567  uge accuracy reg
-00019470: 7265 7373 696f 6e20 696e 2050 7954 6f72  ression in PyTor
-00019480: 6368 2e0a 2020 2020 2020 2020 6164 6469  ch..        addi
-00019490: 7469 6f6e 616c 5f73 6b69 7070 6564 5f6d  tional_skipped_m
-000194a0: 6f64 756c 655f 636c 6173 7365 7320 3d20  odule_classes = 
-000194b0: 5b27 4c61 7965 724e 6f72 6d27 2c20 2749  ['LayerNorm', 'I
-000194c0: 6e73 7461 6e63 654e 6f72 6d33 6427 2c20  nstanceNorm3d', 
-000194d0: 2745 6d62 6564 6469 6e67 272c 2027 4472  'Embedding', 'Dr
-000194e0: 6f70 6f75 7427 5d0a 2020 2020 2020 2020  opout'].        
-000194f0: 6966 2073 656c 662e 6170 7072 6f61 6368  if self.approach
-00019500: 203d 3d20 2770 6f73 745f 7472 6169 6e69   == 'post_traini
-00019510: 6e67 5f64 796e 616d 6963 5f71 7561 6e74  ng_dynamic_quant
-00019520: 273a 0a20 2020 2020 2020 2020 2020 2061  ':.            a
-00019530: 6464 6974 696f 6e61 6c5f 736b 6970 7065  dditional_skippe
-00019540: 645f 6d6f 6475 6c65 5f63 6c61 7373 6573  d_module_classes
-00019550: 2e72 656d 6f76 6528 2745 6d62 6564 6469  .remove('Embeddi
-00019560: 6e67 2729 0a20 2020 2020 2020 2063 7573  ng').        cus
-00019570: 746f 6d5f 6e6f 6e5f 7175 616e 745f 6469  tom_non_quant_di
-00019580: 6374 5b27 736b 6970 7065 645f 6d6f 6475  ct['skipped_modu
-00019590: 6c65 5f63 6c61 7373 6573 275d 202b 3d20  le_classes'] += 
-000195a0: 6164 6469 7469 6f6e 616c 5f73 6b69 7070  additional_skipp
-000195b0: 6564 5f6d 6f64 756c 655f 636c 6173 7365  ed_module_classe
-000195c0: 730a 2020 2020 2020 2020 7265 7475 726e  s.        return
-000195d0: 2063 7573 746f 6d5f 6e6f 6e5f 7175 616e   custom_non_quan
-000195e0: 745f 6469 6374 0a0a 0a75 6e69 6679 5f6f  t_dict...unify_o
-000195f0: 705f 7479 7065 5f6d 6170 7069 6e67 5f69  p_type_mapping_i
-00019600: 7065 7820 3d20 7b0a 2020 2020 2243 6f6e  pex = {.    "Con
-00019610: 766f 6c75 7469 6f6e 5f52 656c 7522 3a20  volution_Relu": 
-00019620: 2263 6f6e 7632 6422 2c0a 2020 2020 2243  "conv2d",.    "C
-00019630: 6f6e 766f 6c75 7469 6f6e 5f53 756d 5f52  onvolution_Sum_R
-00019640: 656c 7522 3a20 2263 6f6e 7632 6422 2c0a  elu": "conv2d",.
-00019650: 2020 2020 2243 6f6e 766f 6c75 7469 6f6e      "Convolution
-00019660: 5f42 6174 6368 4e6f 726d 223a 2022 636f  _BatchNorm": "co
-00019670: 6e76 3264 222c 0a20 2020 2022 3c63 6c61  nv2d",.    "<cla
-00019680: 7373 2027 746f 7263 682e 6e6e 2e6d 6f64  ss 'torch.nn.mod
-00019690: 756c 6573 2e63 6f6e 762e 436f 6e76 3164  ules.conv.Conv1d
-000196a0: 273e 223a 2022 636f 6e76 3164 222c 0a20  '>": "conv1d",. 
-000196b0: 2020 2022 3c63 6c61 7373 2027 746f 7263     "<class 'torc
-000196c0: 682e 6e6e 2e6d 6f64 756c 6573 2e63 6f6e  h.nn.modules.con
-000196d0: 762e 436f 6e76 3264 273e 223a 2022 636f  v.Conv2d'>": "co
-000196e0: 6e76 3264 222c 0a20 2020 2022 3c63 6c61  nv2d",.    "<cla
-000196f0: 7373 2027 746f 7263 682e 6e6e 2e6d 6f64  ss 'torch.nn.mod
-00019700: 756c 6573 2e63 6f6e 762e 436f 6e76 3364  ules.conv.Conv3d
-00019710: 273e 223a 2022 636f 6e76 3364 222c 0a20  '>": "conv3d",. 
-00019720: 2020 2022 3c63 6c61 7373 2027 746f 7263     "<class 'torc
-00019730: 682e 6e6e 2e6d 6f64 756c 6573 2e61 6374  h.nn.modules.act
-00019740: 6976 6174 696f 6e2e 5265 4c55 273e 223a  ivation.ReLU'>":
-00019750: 2022 7265 6c75 222c 0a20 2020 2022 3c6d   "relu",.    "<m
-00019760: 6574 686f 6420 2761 6464 2720 6f66 2027  ethod 'add' of '
-00019770: 746f 7263 682e 5f43 2e5f 5465 6e73 6f72  torch._C._Tensor
-00019780: 4261 7365 2720 6f62 6a65 6374 733e 223a  Base' objects>":
-00019790: 2022 6164 6422 2c0a 2020 2020 223c 636c   "add",.    "<cl
-000197a0: 6173 7320 2774 6f72 6368 2e6e 6e2e 6d6f  ass 'torch.nn.mo
-000197b0: 6475 6c65 732e 706f 6f6c 696e 672e 4164  dules.pooling.Ad
-000197c0: 6170 7469 7665 4176 6750 6f6f 6c32 6427  aptiveAvgPool2d'
-000197d0: 3e22 3a20 2261 6461 7074 6976 6561 7667  >": "adaptiveavg
-000197e0: 706f 6f6c 3264 222c 0a20 2020 2022 4c69  pool2d",.    "Li
-000197f0: 6e65 6172 5f52 656c 7522 3a20 226c 696e  near_Relu": "lin
-00019800: 6561 7222 2c0a 2020 2020 223c 636c 6173  ear",.    "<clas
-00019810: 7320 2774 6f72 6368 2e6e 6e2e 6d6f 6475  s 'torch.nn.modu
-00019820: 6c65 732e 6c69 6e65 6172 2e4c 696e 6561  les.linear.Linea
-00019830: 7227 3e22 3a20 226c 696e 6561 7222 2c0a  r'>": "linear",.
-00019840: 2020 2020 223c 636c 6173 7320 2774 6f72      "<class 'tor
-00019850: 6368 2e6e 6e2e 6d6f 6475 6c65 732e 706f  ch.nn.modules.po
-00019860: 6f6c 696e 672e 4d61 7850 6f6f 6c32 6427  oling.MaxPool2d'
-00019870: 3e22 3a20 226d 6178 706f 6f6c 3264 220a  >": "maxpool2d".
-00019880: 7d0a 0a0a 4061 6461 7074 6f72 5f72 6567  }...@adaptor_reg
-00019890: 6973 7472 790a 636c 6173 7320 5079 546f  istry.class PyTo
-000198a0: 7263 685f 4950 4558 4164 6170 746f 7228  rch_IPEXAdaptor(
-000198b0: 5465 6d70 6c61 7465 4164 6170 746f 7229  TemplateAdaptor)
-000198c0: 3a20 2023 2070 7261 676d 613a 206e 6f20  :  # pragma: no 
-000198d0: 636f 7665 720a 2020 2020 2222 2241 6461  cover.    """Ada
-000198e0: 7074 6f72 206f 6620 5079 546f 7263 6820  ptor of PyTorch 
-000198f0: 6672 616d 6577 6f72 6b20 7769 7468 2049  framework with I
-00019900: 6e74 656c 2050 7954 6f72 6368 2045 7874  ntel PyTorch Ext
-00019910: 656e 7369 6f6e 2c0a 2020 2020 2020 2061  ension,.       a
-00019920: 6c6c 2050 7954 6f72 6368 2049 5045 5820  ll PyTorch IPEX 
-00019930: 4150 4920 6973 2069 6e20 7468 6973 2063  API is in this c
-00019940: 6c61 7373 2e0a 0a20 2020 2041 7267 733a  lass...    Args:
-00019950: 0a20 2020 2020 2020 2066 7261 6d65 776f  .        framewo
-00019960: 726b 5f73 7065 6369 6669 635f 696e 666f  rk_specific_info
-00019970: 2028 6469 6374 293a 2064 6963 7469 6f6e   (dict): diction
-00019980: 6172 7920 6f66 2074 756e 696e 6720 636f  ary of tuning co
-00019990: 6e66 6967 7572 6520 6672 6f6d 2079 616d  nfigure from yam
-000199a0: 6c20 6669 6c65 2e0a 2020 2020 2222 220a  l file..    """.
-000199b0: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
-000199c0: 2873 656c 662c 2066 7261 6d65 776f 726b  (self, framework
-000199d0: 5f73 7065 6369 6669 635f 696e 666f 293a  _specific_info):
-000199e0: 0a20 2020 2020 2020 2073 7570 6572 2850  .        super(P
-000199f0: 7954 6f72 6368 5f49 5045 5841 6461 7074  yTorch_IPEXAdapt
-00019a00: 6f72 2c20 7365 6c66 292e 5f5f 696e 6974  or, self).__init
-00019a10: 5f5f 2866 7261 6d65 776f 726b 5f73 7065  __(framework_spe
-00019a20: 6369 6669 635f 696e 666f 290a 2020 2020  cific_info).    
-00019a30: 2020 2020 7365 6c66 2e76 6572 7369 6f6e      self.version
-00019a40: 203d 2067 6574 5f74 6f72 6368 5f76 6572   = get_torch_ver
-00019a50: 7369 6f6e 2829 0a20 2020 2020 2020 2071  sion().        q
-00019a60: 7565 7279 5f63 6f6e 6669 675f 6669 6c65  uery_config_file
-00019a70: 203d 2022 7079 746f 7263 685f 6970 6578   = "pytorch_ipex
-00019a80: 2e79 616d 6c22 0a20 2020 2020 2020 2073  .yaml".        s
-00019a90: 656c 662e 7175 6572 795f 6861 6e64 6c65  elf.query_handle
-00019aa0: 7220 3d20 5079 546f 7263 6851 7565 7279  r = PyTorchQuery
-00019ab0: 280a 2020 2020 2020 2020 2020 2020 6c6f  (.            lo
-00019ac0: 6361 6c5f 636f 6e66 6967 5f66 696c 653d  cal_config_file=
-00019ad0: 6f73 2e70 6174 682e 6a6f 696e 286f 732e  os.path.join(os.
-00019ae0: 7061 7468 2e64 6972 6e61 6d65 285f 5f66  path.dirname(__f
-00019af0: 696c 655f 5f29 2c20 7175 6572 795f 636f  ile__), query_co
-00019b00: 6e66 6967 5f66 696c 6529 290a 2020 2020  nfig_file)).    
-00019b10: 2020 2020 7365 6c66 2e63 6667 7320 3d20      self.cfgs = 
-00019b20: 4e6f 6e65 0a20 2020 2020 2020 2073 656c  None.        sel
-00019b30: 662e 6675 7365 5f6f 7073 203d 204e 6f6e  f.fuse_ops = Non
-00019b40: 650a 2020 2020 2020 2020 7365 6c66 2e6f  e.        self.o
-00019b50: 705f 696e 666f 735f 6672 6f6d 5f63 6667  p_infos_from_cfg
-00019b60: 7320 3d20 4e6f 6e65 0a20 2020 2020 2020  s = None.       
-00019b70: 2073 656c 662e 6f75 7470 7574 5f74 656e   self.output_ten
-00019b80: 736f 725f 6964 5f6f 705f 6e61 6d65 203d  sor_id_op_name =
-00019b90: 204e 6f6e 650a 2020 2020 2020 2020 7365   None.        se
-00019ba0: 6c66 2e69 7065 785f 636f 6e66 6967 5f70  lf.ipex_config_p
-00019bb0: 6174 6820 3d20 5c0a 2020 2020 2020 2020  ath = \.        
-00019bc0: 2020 2020 6f73 2e70 6174 682e 6a6f 696e      os.path.join
-00019bd0: 2873 656c 662e 776f 726b 7370 6163 655f  (self.workspace_
-00019be0: 7061 7468 2c20 2769 7065 785f 636f 6e66  path, 'ipex_conf
-00019bf0: 6967 5f74 6d70 2e6a 736f 6e27 290a 0a20  ig_tmp.json').. 
-00019c00: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-00019c10: 2020 2020 2020 2020 6f73 2e72 656d 6f76          os.remov
-00019c20: 6528 7365 6c66 2e69 7065 785f 636f 6e66  e(self.ipex_conf
-00019c30: 6967 5f70 6174 6829 0a20 2020 2020 2020  ig_path).       
-00019c40: 2065 7863 6570 743a 0a20 2020 2020 2020   except:.       
-00019c50: 2020 2020 206c 6f67 6765 722e 7761 726e       logger.warn
-00019c60: 696e 6728 2746 6169 6c20 746f 2072 656d  ing('Fail to rem
-00019c70: 6f76 6520 7b7d 2e27 2e66 6f72 6d61 7428  ove {}.'.format(
-00019c80: 7365 6c66 2e69 7065 785f 636f 6e66 6967  self.ipex_config
-00019c90: 5f70 6174 6829 290a 2020 2020 2020 2020  _path)).        
-00019ca0: 7365 6c66 2e64 6576 6963 6520 3d20 2769  self.device = 'i
-00019cb0: 7065 7827 0a20 2020 2020 2020 2073 656c  pex'.        sel
-00019cc0: 662e 746d 705f 6d6f 6465 6c20 3d20 4e6f  f.tmp_model = No
-00019cd0: 6e65 0a0a 2020 2020 4064 756d 705f 656c  ne..    @dump_el
-00019ce0: 6170 7365 645f 7469 6d65 2822 5061 7373  apsed_time("Pass
-00019cf0: 2071 7561 6e74 697a 6520 6d6f 6465 6c22   quantize model"
-00019d00: 290a 2020 2020 6465 6620 7175 616e 7469  ).    def quanti
-00019d10: 7a65 2873 656c 662c 2074 756e 655f 6366  ze(self, tune_cf
-00019d20: 672c 206d 6f64 656c 2c20 6461 7461 6c6f  g, model, datalo
-00019d30: 6164 6572 2c20 715f 6675 6e63 3d4e 6f6e  ader, q_func=Non
-00019d40: 6529 3a0a 2020 2020 2020 2020 2222 2245  e):.        """E
-00019d50: 7865 6375 7465 2074 6865 2071 7561 6e74  xecute the quant
-00019d60: 697a 6520 7072 6f63 6573 7320 6f6e 2074  ize process on t
-00019d70: 6865 2073 7065 6369 6669 6564 206d 6f64  he specified mod
-00019d80: 656c 2e0a 0a20 2020 2020 2020 2041 7267  el...        Arg
-00019d90: 733a 0a20 2020 2020 2020 2020 2020 2074  s:.            t
-00019da0: 756e 655f 6366 6720 2864 6963 7429 3a20  une_cfg (dict): 
-00019db0: 7175 616e 7469 7a61 7469 6f6e 2063 6f6e  quantization con
-00019dc0: 6669 672e 0a20 2020 2020 2020 2020 2020  fig..           
-00019dd0: 206d 6f64 656c 2028 6f62 6a65 6374 293a   model (object):
-00019de0: 206d 6f64 656c 206e 6565 6420 746f 2064   model need to d
-00019df0: 6f20 7175 616e 7469 7a61 7469 6f6e 2c20  o quantization, 
-00019e00: 6974 2069 7320 4e65 7572 616c 2043 6f6d  it is Neural Com
-00019e10: 7072 6573 736f 7220 6d6f 6465 6c2e 0a20  pressor model.. 
-00019e20: 2020 2020 2020 2020 2020 2064 6174 616c             datal
-00019e30: 6f61 6465 7220 286f 626a 6563 7429 3a20  oader (object): 
-00019e40: 6361 6c69 6272 6174 696f 6e20 6461 7461  calibration data
-00019e50: 7365 742e 0a20 2020 2020 2020 2020 2020  set..           
-00019e60: 2071 5f66 756e 6320 286f 626a 6578 742c   q_func (objext,
-00019e70: 206f 7074 696f 6e61 6c29 3a20 7472 6169   optional): trai
-00019e80: 6e69 6e67 2066 756e 6374 696f 6e20 666f  ning function fo
-00019e90: 7220 7175 616e 7469 7a61 7469 6f6e 2061  r quantization a
-00019ea0: 7761 7265 2074 7261 696e 696e 6720 6d6f  ware training mo
-00019eb0: 6465 2e0a 0a20 2020 2020 2020 2052 6574  de...        Ret
-00019ec0: 7572 6e73 3a0a 2020 2020 2020 2020 2020  urns:.          
-00019ed0: 2020 2864 6963 7429 3a20 7175 616e 7469    (dict): quanti
-00019ee0: 7a65 6420 6d6f 6465 6c0a 2020 2020 2020  zed model.      
-00019ef0: 2020 2222 220a 0a20 2020 2020 2020 2061    """..        a
-00019f00: 7373 6572 7420 7365 6c66 2e61 7070 726f  ssert self.appro
-00019f10: 6163 6820 213d 2027 7175 616e 745f 6177  ach != 'quant_aw
-00019f20: 6172 655f 7472 6169 6e69 6e67 272c 205c  are_training', \
-00019f30: 0a20 2020 2020 2020 2020 2020 2022 496e  .            "In
-00019f40: 7465 6c20 5079 546f 7263 6820 4578 7465  tel PyTorch Exte
-00019f50: 6e73 696f 6e20 6469 646e 2774 2073 7570  nsion didn't sup
-00019f60: 706f 7274 2071 7561 6e74 697a 6174 696f  port quantizatio
-00019f70: 6e20 6177 6172 6520 7472 6169 6e69 6e67  n aware training
-00019f80: 206d 6f64 6522 0a20 2020 2020 2020 2061   mode".        a
-00019f90: 7373 6572 7420 6e6f 7420 7365 6c66 2e76  ssert not self.v
-00019fa0: 6572 7369 6f6e 2e72 656c 6561 7365 203c  ersion.release <
-00019fb0: 2056 6572 7369 6f6e 2822 312e 3130 2e30   Version("1.10.0
-00019fc0: 2229 2e72 656c 6561 7365 2c20 5c0a 2020  ").release, \.  
-00019fd0: 2020 2020 2020 2020 2020 2020 2020 2249                "I
-00019fe0: 4e43 2073 7570 706f 7274 2049 5045 5820  NC support IPEX 
-00019ff0: 7665 7273 696f 6e20 3e3d 2031 2e31 302e  version >= 1.10.
-0001a000: 3022 0a0a 2020 2020 2020 2020 7173 6368  0"..        qsch
-0001a010: 656d 6520 3d20 7365 6c66 2e5f 6366 675f  eme = self._cfg_
-0001a020: 746f 5f71 636f 6e66 6967 2874 756e 655f  to_qconfig(tune_
-0001a030: 6366 6729 0a20 2020 2020 2020 2069 7465  cfg).        ite
-0001a040: 7261 7469 6f6e 7320 3d20 7475 6e65 5f63  rations = tune_c
-0001a050: 6667 2e67 6574 2827 6361 6c69 625f 6974  fg.get('calib_it
-0001a060: 6572 6174 696f 6e27 2c20 3129 0a20 2020  eration', 1).   
-0001a070: 2020 2020 206d 6f64 656c 2e6d 6f64 656c       model.model
-0001a080: 2e65 7661 6c28 290a 0a20 2020 2020 2020  .eval()..       
-0001a090: 2069 6620 7365 6c66 2e70 6572 666f 726d   if self.perform
-0001a0a0: 616e 6365 5f6f 6e6c 793a 0a20 2020 2020  ance_only:.     
-0001a0b0: 2020 2020 2020 2069 6620 6861 7361 7474         if hasatt
-0001a0c0: 7228 6d6f 6465 6c2e 6d6f 6465 6c2c 2022  r(model.model, "
-0001a0d0: 7361 7665 5f71 636f 6e66 5f73 756d 6d61  save_qconf_summa
-0001a0e0: 7279 2229 3a0a 2020 2020 2020 2020 2020  ry"):.          
-0001a0f0: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
-0001a100: 6d6f 6465 6c2e 6d6f 6465 6c0a 2020 2020  model.model.    
-0001a110: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
-0001a120: 6465 6c2e 6c6f 6164 5f71 636f 6e66 5f73  del.load_qconf_s
-0001a130: 756d 6d61 7279 2871 636f 6e66 5f73 756d  ummary(qconf_sum
-0001a140: 6d61 7279 3d73 656c 662e 6970 6578 5f63  mary=self.ipex_c
-0001a150: 6f6e 6669 675f 7061 7468 290a 2020 2020  onfig_path).    
-0001a160: 2020 2020 2020 2020 2020 2020 6966 2071              if q
-0001a170: 5f66 756e 6320 6973 206e 6f74 204e 6f6e  _func is not Non
-0001a180: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-0001a190: 2020 2020 2020 2071 5f66 756e 6328 715f         q_func(q_
-0001a1a0: 6d6f 6465 6c29 0a20 2020 2020 2020 2020  model).         
-0001a1b0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0001a1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a1d0: 2073 656c 662e 6d6f 6465 6c5f 6361 6c69   self.model_cali
-0001a1e0: 6272 6174 696f 6e28 715f 6d6f 6465 6c2c  bration(q_model,
-0001a1f0: 2064 6174 616c 6f61 6465 722c 2069 7465   dataloader, ite
-0001a200: 7261 7469 6f6e 732c 204e 6f6e 652c 0a20  rations, None,. 
+00018540: 2020 2020 696e 7370 6563 745f 7479 7065      inspect_type
+00018550: 3d27 6163 7469 7661 7469 6f6e 272c 0a20  ='activation',. 
+00018560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018570: 2020 2020 2020 7361 7665 5f74 6f5f 6469        save_to_di
+00018580: 736b 3d46 616c 7365 293a 0a20 2020 2020  sk=False):.     
+00018590: 2020 2069 6620 7365 6c66 2e76 6572 7369     if self.versi
+000185a0: 6f6e 2e72 656c 6561 7365 203e 3d20 5665  on.release >= Ve
+000185b0: 7273 696f 6e28 2231 2e38 2e30 2229 2e72  rsion("1.8.0").r
+000185c0: 656c 6561 7365 3a0a 2020 2020 2020 2020  elease:.        
+000185d0: 2020 2020 6672 6f6d 2074 6f72 6368 2e66      from torch.f
+000185e0: 7820 696d 706f 7274 2047 7261 7068 4d6f  x import GraphMo
+000185f0: 6475 6c65 0a20 2020 2020 2020 2020 2020  dule.           
+00018600: 2069 6620 7479 7065 286d 6f64 656c 2e5f   if type(model._
+00018610: 6d6f 6465 6c29 203d 3d20 4772 6170 684d  model) == GraphM
+00018620: 6f64 756c 653a 2020 2320 7072 6167 6d61  odule:  # pragma
+00018630: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
+00018640: 2020 2020 2020 2020 2020 2061 7373 6572             asser
+00018650: 7420 4661 6c73 652c 2022 496e 7370 6563  t False, "Inspec
+00018660: 745f 7465 6e73 6f72 2064 6964 6e27 7420  t_tensor didn't 
+00018670: 7375 7070 6f72 7420 6678 2067 7261 7068  support fx graph
+00018680: 206d 6f64 656c 206e 6f77 2122 0a20 2020   model now!".   
+00018690: 2020 2020 2066 726f 6d20 746f 7263 6820       from torch 
+000186a0: 696d 706f 7274 2064 6571 7561 6e74 697a  import dequantiz
+000186b0: 650a 2020 2020 2020 2020 696d 706f 7274  e.        import
+000186c0: 206e 756d 7079 2061 7320 6e70 0a20 2020   numpy as np.   
+000186d0: 2020 2020 2069 735f 7175 616e 7469 7a65       is_quantize
+000186e0: 6420 3d20 6d6f 6465 6c2e 6973 5f71 7561  d = model.is_qua
+000186f0: 6e74 697a 6564 0a20 2020 2020 2020 206f  ntized.        o
+00018700: 705f 6c69 7374 5f20 3d20 5b5d 0a20 2020  p_list_ = [].   
+00018710: 2020 2020 2066 7033 325f 696e 7438 5f6d       fp32_int8_m
+00018720: 6170 203d 207b 7d0a 2020 2020 2020 2020  ap = {}.        
+00018730: 666f 7220 6f70 5f6e 616d 6520 696e 206f  for op_name in o
+00018740: 705f 6c69 7374 3a0a 2020 2020 2020 2020  p_list:.        
+00018750: 2020 2020 6f70 5f6c 6973 745f 2e61 7070      op_list_.app
+00018760: 656e 6428 6f70 5f6e 616d 6529 0a20 2020  end(op_name).   
+00018770: 2020 2020 2020 2020 2066 6f72 206b 6579           for key
+00018780: 2069 6e20 7365 6c66 2e66 7573 6564 5f64   in self.fused_d
+00018790: 6963 743a 0a20 2020 2020 2020 2020 2020  ict:.           
+000187a0: 2020 2020 2069 6620 6f70 5f6e 616d 6520       if op_name 
+000187b0: 696e 2073 656c 662e 6675 7365 645f 6469  in self.fused_di
+000187c0: 6374 5b6b 6579 5d3a 0a20 2020 2020 2020  ct[key]:.       
+000187d0: 2020 2020 2020 2020 2020 2020 2066 7033               fp3
+000187e0: 325f 696e 7438 5f6d 6170 5b6f 705f 6e61  2_int8_map[op_na
+000187f0: 6d65 5d20 3d20 5c0a 2020 2020 2020 2020  me] = \.        
+00018800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018810: 7b27 6163 7469 7661 7469 6f6e 273a 2073  {'activation': s
+00018820: 656c 662e 6675 7365 645f 6469 6374 5b6b  elf.fused_dict[k
+00018830: 6579 5d5b 2d31 5d2c 2027 7765 6967 6874  ey][-1], 'weight
+00018840: 273a 206b 6579 7d0a 2020 2020 2020 2020  ': key}.        
+00018850: 2020 2020 2020 2020 2020 2020 6966 2069              if i
+00018860: 735f 7175 616e 7469 7a65 643a 0a20 2020  s_quantized:.   
+00018870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018880: 2020 2020 206f 705f 6c69 7374 5f2e 6170       op_list_.ap
+00018890: 7065 6e64 286b 6579 290a 2020 2020 2020  pend(key).      
+000188a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000188b0: 2020 6f70 5f6c 6973 745f 2e72 656d 6f76    op_list_.remov
+000188c0: 6528 6f70 5f6e 616d 6529 0a20 2020 2020  e(op_name).     
+000188d0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+000188e0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+000188f0: 2020 2020 2020 2020 2020 2020 206f 705f               op_
+00018900: 6c69 7374 5f2e 6170 7065 6e64 2873 656c  list_.append(sel
+00018910: 662e 6675 7365 645f 6469 6374 5b6b 6579  f.fused_dict[key
+00018920: 5d5b 2d31 5d29 0a0a 2020 2020 2020 2020  ][-1])..        
+00018930: 6e65 775f 6d6f 6465 6c20 3d20 6d6f 6465  new_model = mode
+00018940: 6c20 6966 2069 735f 7175 616e 7469 7a65  l if is_quantize
+00018950: 6420 656c 7365 2063 6f70 792e 6465 6570  d else copy.deep
+00018960: 636f 7079 286d 6f64 656c 290a 0a20 2020  copy(model)..   
+00018970: 2020 2020 2061 7373 6572 7420 6d69 6e28       assert min(
+00018980: 6974 6572 6174 696f 6e5f 6c69 7374 2920  iteration_list) 
+00018990: 3e20 302c 205c 0a20 2020 2020 2020 2020  > 0, \.         
+000189a0: 2020 2022 4974 6572 6174 696f 6e20 6e75     "Iteration nu
+000189b0: 6d62 6572 2073 686f 756c 6420 6772 6561  mber should grea
+000189c0: 7420 7a65 726f 2c20 3120 6d65 616e 7320  t zero, 1 means 
+000189d0: 6669 7273 7420 6974 6572 6174 696f 6e2e  first iteration.
+000189e0: 220a 2020 2020 2020 2020 6974 6572 6174  ".        iterat
+000189f0: 696f 6e73 203d 206d 6178 2869 7465 7261  ions = max(itera
+00018a00: 7469 6f6e 5f6c 6973 7429 2069 6620 6974  tion_list) if it
+00018a10: 6572 6174 696f 6e5f 6c69 7374 2069 7320  eration_list is 
+00018a20: 6e6f 7420 4e6f 6e65 2065 6c73 6520 2d31  not None else -1
+00018a30: 0a20 2020 2020 2020 206e 6577 5f6d 6f64  .        new_mod
+00018a40: 656c 203d 2073 656c 662e 5f70 7265 5f65  el = self._pre_e
+00018a50: 7661 6c5f 686f 6f6b 286e 6577 5f6d 6f64  val_hook(new_mod
+00018a60: 656c 2c20 6f70 5f6c 6973 743d 6f70 5f6c  el, op_list=op_l
+00018a70: 6973 745f 2c20 6974 6572 6174 696f 6e5f  ist_, iteration_
+00018a80: 6c69 7374 3d69 7465 7261 7469 6f6e 5f6c  list=iteration_l
+00018a90: 6973 7429 0a20 2020 2020 2020 2073 656c  ist).        sel
+00018aa0: 662e 6576 616c 7561 7465 286e 6577 5f6d  f.evaluate(new_m
+00018ab0: 6f64 656c 2c20 6461 7461 6c6f 6164 6572  odel, dataloader
+00018ac0: 2c20 6974 6572 6174 696f 6e3d 6974 6572  , iteration=iter
+00018ad0: 6174 696f 6e73 290a 2020 2020 2020 2020  ations).        
+00018ae0: 6f62 7365 7276 6572 5f64 6963 7420 3d20  observer_dict = 
+00018af0: 7b7d 0a20 2020 2020 2020 2072 6574 203d  {}.        ret =
+00018b00: 207b 7d0a 2020 2020 2020 2020 6966 2069   {}.        if i
+00018b10: 6e73 7065 6374 5f74 7970 6520 3d3d 2027  nspect_type == '
+00018b20: 6163 7469 7661 7469 6f6e 2720 6f72 2069  activation' or i
+00018b30: 6e73 7065 6374 5f74 7970 6520 3d3d 2027  nspect_type == '
+00018b40: 616c 6c27 3a0a 2020 2020 2020 2020 2020  all':.          
+00018b50: 2020 6966 2073 656c 662e 7665 7273 696f    if self.versio
+00018b60: 6e2e 7265 6c65 6173 6520 3e3d 2056 6572  n.release >= Ver
+00018b70: 7369 6f6e 2822 322e 302e 3022 292e 7265  sion("2.0.0").re
+00018b80: 6c65 6173 653a 0a20 2020 2020 2020 2020  lease:.         
+00018b90: 2020 2020 2020 2066 726f 6d20 746f 7263         from torc
+00018ba0: 682e 7175 616e 7469 7a61 7469 6f6e 2e71  h.quantization.q
+00018bb0: 7561 6e74 697a 6520 696d 706f 7274 205f  uantize import _
+00018bc0: 6765 745f 6f62 7365 7276 6572 5f64 6963  get_observer_dic
+00018bd0: 7420 6173 2067 6574 5f6f 6273 6572 7665  t as get_observe
+00018be0: 725f 6469 6374 0a20 2020 2020 2020 2020  r_dict.         
+00018bf0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00018c00: 2020 2020 2020 2020 2066 726f 6d20 746f           from to
+00018c10: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+00018c20: 2069 6d70 6f72 7420 6765 745f 6f62 7365   import get_obse
+00018c30: 7276 6572 5f64 6963 740a 2020 2020 2020  rver_dict.      
+00018c40: 2020 2020 2020 7265 745b 2761 6374 6976        ret['activ
+00018c50: 6174 696f 6e27 5d20 3d20 5b5d 0a20 2020  ation'] = [].   
+00018c60: 2020 2020 2020 2020 2067 6574 5f6f 6273           get_obs
+00018c70: 6572 7665 725f 6469 6374 286e 6577 5f6d  erver_dict(new_m
+00018c80: 6f64 656c 2e5f 6d6f 6465 6c2c 206f 6273  odel._model, obs
+00018c90: 6572 7665 725f 6469 6374 290a 2020 2020  erver_dict).    
+00018ca0: 2020 2020 2020 2020 6966 2069 7465 7261          if itera
+00018cb0: 7469 6f6e 5f6c 6973 7420 6973 204e 6f6e  tion_list is Non
+00018cc0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00018cd0: 2020 2069 7465 7261 7469 6f6e 5f6c 6973     iteration_lis
+00018ce0: 7420 3d20 5b31 5d0a 2020 2020 2020 2020  t = [1].        
+00018cf0: 2020 2020 666f 7220 6920 696e 2069 7465      for i in ite
+00018d00: 7261 7469 6f6e 5f6c 6973 743a 0a20 2020  ration_list:.   
+00018d10: 2020 2020 2020 2020 2020 2020 2073 756d               sum
+00018d20: 6d61 7279 203d 204f 7264 6572 6564 4469  mary = OrderedDi
+00018d30: 6374 2829 0a20 2020 2020 2020 2020 2020  ct().           
+00018d40: 2020 2020 2066 6f72 206b 6579 2069 6e20       for key in 
+00018d50: 6f62 7365 7276 6572 5f64 6963 743a 0a20  observer_dict:. 
+00018d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018d70: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+00018d80: 286f 6273 6572 7665 725f 6469 6374 5b6b  (observer_dict[k
+00018d90: 6579 5d2c 2074 6f72 6368 2e6e 6e2e 6d6f  ey], torch.nn.mo
+00018da0: 6475 6c65 732e 6c69 6e65 6172 2e49 6465  dules.linear.Ide
+00018db0: 6e74 6974 7929 3a0a 2020 2020 2020 2020  ntity):.        
+00018dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018dd0: 636f 6e74 696e 7565 0a20 2020 2020 2020  continue.       
+00018de0: 2020 2020 2020 2020 2020 2020 206f 705f               op_
+00018df0: 6e61 6d65 203d 206b 6579 2e72 6570 6c61  name = key.repla
+00018e00: 6365 2822 2e61 6374 6976 6174 696f 6e5f  ce(".activation_
+00018e10: 706f 7374 5f70 726f 6365 7373 222c 2022  post_process", "
+00018e20: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+00018e30: 2020 2020 2020 2076 616c 7565 203d 206f         value = o
+00018e40: 6273 6572 7665 725f 6469 6374 5b6b 6579  bserver_dict[key
+00018e50: 5d2e 6765 745f 7465 6e73 6f72 5f76 616c  ].get_tensor_val
+00018e60: 7565 2829 5b69 5d0a 2020 2020 2020 2020  ue()[i].        
+00018e70: 2020 2020 2020 2020 2020 2020 6966 206f              if o
+00018e80: 705f 6e61 6d65 2069 6e20 6f70 5f6c 6973  p_name in op_lis
+00018e90: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+00018ea0: 2020 2020 2020 2020 2020 2069 6620 7479             if ty
+00018eb0: 7065 2876 616c 7565 2920 6973 206c 6973  pe(value) is lis
+00018ec0: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+00018ed0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00018ee0: 756d 6d61 7279 5b6f 705f 6e61 6d65 5d20  ummary[op_name] 
+00018ef0: 3d20 7b7d 0a20 2020 2020 2020 2020 2020  = {}.           
+00018f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018f10: 2066 6f72 2069 6e64 6578 2069 6e20 7261   for index in ra
+00018f20: 6e67 6528 6c65 6e28 7661 6c75 6529 293a  nge(len(value)):
+00018f30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018f50: 2073 756d 6d61 7279 5b6f 705f 6e61 6d65   summary[op_name
+00018f60: 5d2e 7570 6461 7465 287b 0a20 2020 2020  ].update({.     
+00018f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018f80: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00018f90: 705f 6e61 6d65 202b 2022 2e6f 7574 7075  p_name + ".outpu
+00018fa0: 7422 202b 2073 7472 2869 6e64 6578 293a  t" + str(index):
+00018fb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018fd0: 2020 2020 2064 6571 7561 6e74 697a 6528       dequantize(
+00018fe0: 7661 6c75 655b 696e 6465 785d 292e 6e75  value[index]).nu
+00018ff0: 6d70 7928 290a 2020 2020 2020 2020 2020  mpy().          
+00019000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019010: 2020 2020 2020 2020 2020 6966 2076 616c            if val
+00019020: 7565 5b69 6e64 6578 5d2e 6973 5f71 7561  ue[index].is_qua
+00019030: 6e74 697a 6564 2065 6c73 6520 7661 6c75  ntized else valu
+00019040: 655b 696e 6465 785d 2e6e 756d 7079 2829  e[index].numpy()
+00019050: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019070: 207d 290a 2020 2020 2020 2020 2020 2020   }).            
+00019080: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00019090: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000190a0: 2020 2020 2020 2020 2020 2020 2020 7375                su
+000190b0: 6d6d 6172 795b 6f70 5f6e 616d 655d 203d  mmary[op_name] =
+000190c0: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
+000190d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000190e0: 2020 206f 705f 6e61 6d65 202b 2022 2e6f     op_name + ".o
+000190f0: 7574 7075 7430 223a 0a20 2020 2020 2020  utput0":.       
+00019100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019110: 2020 2020 2020 2020 2064 6571 7561 6e74           dequant
+00019120: 697a 6528 7661 6c75 6529 2e6e 756d 7079  ize(value).numpy
+00019130: 2829 2069 6620 7661 6c75 652e 6973 5f71  () if value.is_q
+00019140: 7561 6e74 697a 6564 2065 6c73 6520 7661  uantized else va
+00019150: 6c75 652e 6e75 6d70 7928 290a 2020 2020  lue.numpy().    
+00019160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019170: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00019180: 2020 2020 2020 2020 2020 2020 2020 656c                el
+00019190: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+000191a0: 2020 2020 2020 2020 2020 2020 6966 2062              if b
+000191b0: 6f6f 6c28 7365 6c66 2e66 7573 6564 5f64  ool(self.fused_d
+000191c0: 6963 7429 3a0a 2020 2020 2020 2020 2020  ict):.          
+000191d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000191e0: 2020 6966 2069 735f 7175 616e 7469 7a65    if is_quantize
+000191f0: 643a 0a20 2020 2020 2020 2020 2020 2020  d:.             
+00019200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019210: 2020 2066 6f72 2061 2069 6e20 6670 3332     for a in fp32
+00019220: 5f69 6e74 385f 6d61 703a 0a20 2020 2020  _int8_map:.     
+00019230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019240: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00019250: 6620 6f70 5f6e 616d 6520 3d3d 2066 7033  f op_name == fp3
+00019260: 325f 696e 7438 5f6d 6170 5b61 5d5b 2777  2_int8_map[a]['w
+00019270: 6569 6768 7427 5d3a 0a20 2020 2020 2020  eight']:.       
+00019280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000192a0: 2069 6620 7479 7065 2876 616c 7565 2920   if type(value) 
+000192b0: 6973 206c 6973 743a 0a20 2020 2020 2020  is list:.       
+000192c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000192d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000192e0: 2020 2020 2073 756d 6d61 7279 5b61 5d20       summary[a] 
+000192f0: 3d20 7b7d 0a20 2020 2020 2020 2020 2020  = {}.           
+00019300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019320: 2066 6f72 2069 6e64 6578 2069 6e20 7261   for index in ra
+00019330: 6e67 6528 6c65 6e28 7661 6c75 6529 293a  nge(len(value)):
+00019340: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019370: 2073 756d 6d61 7279 5b61 5d2e 7570 6461   summary[a].upda
+00019380: 7465 287b 0a20 2020 2020 2020 2020 2020  te({.           
+00019390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000193a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000193b0: 2020 2020 2020 2020 206f 705f 6e61 6d65           op_name
+000193c0: 202b 2022 2e6f 7574 7075 7422 202b 2073   + ".output" + s
+000193d0: 7472 2869 6e64 6578 293a 0a20 2020 2020  tr(index):.     
+000193e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000193f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019400: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00019410: 6571 7561 6e74 697a 6528 7661 6c75 655b  equantize(value[
+00019420: 696e 6465 785d 292e 6e75 6d70 7928 290a  index]).numpy().
+00019430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019460: 2020 2020 6966 2076 616c 7565 5b69 6e64      if value[ind
+00019470: 6578 5d2e 6973 5f71 7561 6e74 697a 6564  ex].is_quantized
+00019480: 2065 6c73 650a 2020 2020 2020 2020 2020   else.          
+00019490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000194a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000194b0: 2020 2020 2020 2020 2020 7661 6c75 655b            value[
+000194c0: 696e 6465 785d 2e6e 756d 7079 2829 0a20  index].numpy(). 
+000194d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000194e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000194f0: 2020 2020 2020 2020 2020 2020 2020 207d                 }
+00019500: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00019510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019520: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+00019530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019550: 2020 2020 2020 2020 2020 2020 7375 6d6d              summ
+00019560: 6172 795b 615d 203d 207b 0a20 2020 2020  ary[a] = {.     
+00019570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019590: 2020 2020 2020 2020 2020 206f 705f 6e61             op_na
+000195a0: 6d65 202b 2022 2e6f 7574 7075 7430 223a  me + ".output0":
+000195b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000195c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000195d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000195e0: 2064 6571 7561 6e74 697a 6528 7661 6c75   dequantize(valu
+000195f0: 6529 2e6e 756d 7079 2829 0a20 2020 2020  e).numpy().     
+00019600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019620: 2020 2020 2020 2020 2020 2069 6620 7661             if va
+00019630: 6c75 652e 6973 5f71 7561 6e74 697a 6564  lue.is_quantized
+00019640: 2065 6c73 6520 7661 6c75 652e 6e75 6d70   else value.nump
+00019650: 7928 290a 2020 2020 2020 2020 2020 2020  y().            
+00019660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019680: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
+00019690: 2020 2020 2020 2020 2020 2020 2020 656c                el
+000196a0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+000196b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000196c0: 2020 2020 666f 7220 6120 696e 2066 7033      for a in fp3
+000196d0: 325f 696e 7438 5f6d 6170 3a20 2023 2070  2_int8_map:  # p
+000196e0: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
+000196f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019710: 2020 2020 6966 206f 705f 6e61 6d65 203d      if op_name =
+00019720: 3d20 6670 3332 5f69 6e74 385f 6d61 705b  = fp32_int8_map[
+00019730: 615d 5b27 6163 7469 7661 7469 6f6e 275d  a]['activation']
+00019740: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00019750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019760: 2020 2020 2020 2020 2020 6966 2074 7970            if typ
+00019770: 6528 7661 6c75 6529 2069 7320 6c69 7374  e(value) is list
+00019780: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00019790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000197a0: 2020 2020 2020 2020 2020 2020 2020 7375                su
+000197b0: 6d6d 6172 795b 615d 203d 207b 7d0a 2020  mmary[a] = {}.  
+000197c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000197d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000197e0: 2020 2020 2020 2020 2020 666f 7220 696e            for in
+000197f0: 6465 7820 696e 2072 616e 6765 286c 656e  dex in range(len
+00019800: 2876 616c 7565 2929 3a0a 2020 2020 2020  (value)):.      
+00019810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019830: 2020 2020 2020 2020 2020 7375 6d6d 6172            summar
+00019840: 795b 615d 2e75 7064 6174 6528 7b0a 2020  y[a].update({.  
+00019850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019880: 2020 6f70 5f6e 616d 6520 2b20 222e 6f75    op_name + ".ou
+00019890: 7470 7574 2220 2b20 7374 7228 696e 6465  tput" + str(inde
+000198a0: 7829 3a0a 2020 2020 2020 2020 2020 2020  x):.            
+000198b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000198c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000198d0: 2020 2020 2020 2020 6465 7175 616e 7469          dequanti
+000198e0: 7a65 2876 616c 7565 5b69 6e64 6578 5d29  ze(value[index])
+000198f0: 2e6e 756d 7079 2829 0a20 2020 2020 2020  .numpy().       
+00019900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019920: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00019930: 7661 6c75 655b 696e 6465 785d 2e69 735f  value[index].is_
+00019940: 7175 616e 7469 7a65 6420 656c 7365 0a20  quantized else. 
+00019950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019980: 2020 2076 616c 7565 5b69 6e64 6578 5d2e     value[index].
+00019990: 6e75 6d70 7928 290a 2020 2020 2020 2020  numpy().        
+000199a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000199b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000199c0: 2020 2020 2020 2020 7d29 0a20 2020 2020          }).     
+000199d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000199e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000199f0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00019a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019a20: 2020 2020 2073 756d 6d61 7279 5b61 5d20       summary[a] 
+00019a30: 3d20 7b0a 2020 2020 2020 2020 2020 2020  = {.            
+00019a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019a60: 2020 2020 6f70 5f6e 616d 6520 2b20 222e      op_name + ".
+00019a70: 6f75 7470 7574 3022 3a0a 2020 2020 2020  output0":.      
+00019a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019aa0: 2020 2020 2020 2020 2020 6465 7175 616e            dequan
+00019ab0: 7469 7a65 2876 616c 7565 292e 6e75 6d70  tize(value).nump
+00019ac0: 7928 290a 2020 2020 2020 2020 2020 2020  y().            
+00019ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019af0: 2020 2020 6966 2076 616c 7565 2e69 735f      if value.is_
+00019b00: 7175 616e 7469 7a65 6420 656c 7365 2076  quantized else v
+00019b10: 616c 7565 2e6e 756d 7079 2829 0a20 2020  alue.numpy().   
+00019b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019b40: 2020 2020 2020 2020 207d 0a0a 2020 2020           }..    
+00019b50: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00019b60: 6176 655f 746f 5f64 6973 6b3a 0a20 2020  ave_to_disk:.   
+00019b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019b80: 2064 756d 705f 6469 7220 3d20 6f73 2e70   dump_dir = os.p
+00019b90: 6174 682e 6a6f 696e 2873 656c 662e 776f  ath.join(self.wo
+00019ba0: 726b 7370 6163 655f 7061 7468 2c20 2764  rkspace_path, 'd
+00019bb0: 756d 705f 7465 6e73 6f72 2729 0a20 2020  ump_tensor').   
+00019bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019bd0: 206f 732e 6d61 6b65 6469 7273 2864 756d   os.makedirs(dum
+00019be0: 705f 6469 722c 2065 7869 7374 5f6f 6b3d  p_dir, exist_ok=
+00019bf0: 5472 7565 290a 2020 2020 2020 2020 2020  True).          
+00019c00: 2020 2020 2020 2020 2020 6e70 2e73 6176            np.sav
+00019c10: 657a 286f 732e 7061 7468 2e6a 6f69 6e28  ez(os.path.join(
+00019c20: 6475 6d70 5f64 6972 2c20 2761 6374 6976  dump_dir, 'activ
+00019c30: 6174 696f 6e5f 6974 6572 7b7d 2e6e 707a  ation_iter{}.npz
+00019c40: 272e 666f 726d 6174 2869 2929 2c20 2a2a  '.format(i)), **
+00019c50: 7375 6d6d 6172 7929 0a0a 2020 2020 2020  summary)..      
+00019c60: 2020 2020 2020 2020 2020 7265 745b 2761            ret['a
+00019c70: 6374 6976 6174 696f 6e27 5d2e 6170 7065  ctivation'].appe
+00019c80: 6e64 2873 756d 6d61 7279 290a 0a20 2020  nd(summary)..   
+00019c90: 2020 2020 2069 6620 696e 7370 6563 745f       if inspect_
+00019ca0: 7479 7065 203d 3d20 2777 6569 6768 7427  type == 'weight'
+00019cb0: 206f 7220 696e 7370 6563 745f 7479 7065   or inspect_type
+00019cc0: 203d 3d20 2761 6c6c 273a 0a20 2020 2020   == 'all':.     
+00019cd0: 2020 2020 2020 2072 6574 5b27 7765 6967         ret['weig
+00019ce0: 6874 275d 203d 207b 7d0a 2020 2020 2020  ht'] = {}.      
+00019cf0: 2020 2020 2020 7374 6174 655f 6469 6374        state_dict
+00019d00: 203d 206e 6577 5f6d 6f64 656c 2e5f 6d6f   = new_model._mo
+00019d10: 6465 6c2e 7374 6174 655f 6469 6374 2829  del.state_dict()
+00019d20: 0a0a 2020 2020 2020 2020 2020 2020 666f  ..            fo
+00019d30: 7220 6b65 7920 696e 2073 7461 7465 5f64  r key in state_d
+00019d40: 6963 743a 0a20 2020 2020 2020 2020 2020  ict:.           
+00019d50: 2020 2020 2069 6620 6e6f 7420 6973 696e       if not isin
+00019d60: 7374 616e 6365 2873 7461 7465 5f64 6963  stance(state_dic
+00019d70: 745b 6b65 795d 2c20 746f 7263 682e 5465  t[key], torch.Te
+00019d80: 6e73 6f72 293a 0a20 2020 2020 2020 2020  nsor):.         
+00019d90: 2020 2020 2020 2020 2020 2063 6f6e 7469             conti
+00019da0: 6e75 650a 2020 2020 2020 2020 2020 2020  nue.            
+00019db0: 2020 2020 6966 2027 7765 6967 6874 2720      if 'weight' 
+00019dc0: 6e6f 7420 696e 206b 6579 2061 6e64 2027  not in key and '
+00019dd0: 6269 6173 2720 6e6f 7420 696e 206b 6579  bias' not in key
+00019de0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00019df0: 2020 2020 2020 636f 6e74 696e 7565 0a0a        continue..
+00019e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019e10: 6f70 203d 206b 6579 5b3a 6b65 792e 7266  op = key[:key.rf
+00019e20: 696e 6428 272e 2729 5d0a 2020 2020 2020  ind('.')].      
+00019e30: 2020 2020 2020 2020 2020 6f70 203d 206f            op = o
+00019e40: 702e 7265 706c 6163 6528 272e 5f70 6163  p.replace('._pac
+00019e50: 6b65 645f 7061 7261 6d73 272c 2027 2729  ked_params', '')
+00019e60: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00019e70: 2020 6966 206f 7020 696e 206f 705f 6c69    if op in op_li
+00019e80: 7374 3a0a 2020 2020 2020 2020 2020 2020  st:.            
+00019e90: 2020 2020 2020 2020 6966 206f 7020 696e          if op in
+00019ea0: 2072 6574 5b27 7765 6967 6874 275d 3a0a   ret['weight']:.
+00019eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019ec0: 2020 2020 2020 2020 7265 745b 2777 6569          ret['wei
+00019ed0: 6768 7427 5d5b 6f70 5d2e 7570 6461 7465  ght'][op].update
+00019ee0: 287b 0a20 2020 2020 2020 2020 2020 2020  ({.             
+00019ef0: 2020 2020 2020 2020 2020 2020 2020 206b                 k
+00019f00: 6579 3a0a 2020 2020 2020 2020 2020 2020  ey:.            
+00019f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019f20: 6465 7175 616e 7469 7a65 2873 7461 7465  dequantize(state
+00019f30: 5f64 6963 745b 6b65 795d 292e 6e75 6d70  _dict[key]).nump
+00019f40: 7928 290a 2020 2020 2020 2020 2020 2020  y().            
+00019f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019f60: 6966 2073 7461 7465 5f64 6963 745b 6b65  if state_dict[ke
+00019f70: 795d 2e69 735f 7175 616e 7469 7a65 6420  y].is_quantized 
+00019f80: 656c 7365 2073 7461 7465 5f64 6963 745b  else state_dict[
+00019f90: 6b65 795d 2e64 6574 6163 6828 292e 6e75  key].detach().nu
+00019fa0: 6d70 7928 290a 2020 2020 2020 2020 2020  mpy().          
+00019fb0: 2020 2020 2020 2020 2020 2020 2020 7d29                })
+00019fc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019fd0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00019fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019ff0: 2020 2072 6574 5b27 7765 6967 6874 275d     ret['weight']
+0001a000: 5b6f 705d 203d 207b 0a20 2020 2020 2020  [op] = {.       
+0001a010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a020: 2020 2020 206b 6579 3a0a 2020 2020 2020       key:.      
+0001a030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a040: 2020 2020 2020 6465 7175 616e 7469 7a65        dequantize
+0001a050: 2873 7461 7465 5f64 6963 745b 6b65 795d  (state_dict[key]
+0001a060: 292e 6e75 6d70 7928 290a 2020 2020 2020  ).numpy().      
+0001a070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a080: 2020 2020 2020 6966 2073 7461 7465 5f64        if state_d
+0001a090: 6963 745b 6b65 795d 2e69 735f 7175 616e  ict[key].is_quan
+0001a0a0: 7469 7a65 6420 656c 7365 2073 7461 7465  tized else state
+0001a0b0: 5f64 6963 745b 6b65 795d 2e64 6574 6163  _dict[key].detac
+0001a0c0: 6828 292e 6e75 6d70 7928 290a 2020 2020  h().numpy().    
+0001a0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a0e0: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
+0001a0f0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+0001a100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a110: 6966 2062 6f6f 6c28 7365 6c66 2e66 7573  if bool(self.fus
+0001a120: 6564 5f64 6963 7429 3a0a 2020 2020 2020  ed_dict):.      
+0001a130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a140: 2020 6966 2069 735f 7175 616e 7469 7a65    if is_quantize
+0001a150: 643a 0a20 2020 2020 2020 2020 2020 2020  d:.             
+0001a160: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0001a170: 6f72 2061 2069 6e20 6670 3332 5f69 6e74  or a in fp32_int
+0001a180: 385f 6d61 703a 0a20 2020 2020 2020 2020  8_map:.         
+0001a190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a1a0: 2020 2020 2020 2069 6620 6f70 203d 3d20         if op == 
+0001a1b0: 6670 3332 5f69 6e74 385f 6d61 705b 615d  fp32_int8_map[a]
+0001a1c0: 5b27 7765 6967 6874 275d 3a0a 2020 2020  ['weight']:.    
+0001a1d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a1f0: 6966 2061 2069 6e20 7265 745b 2777 6569  if a in ret['wei
+0001a200: 6768 7427 5d3a 0a20 2020 2020 2020 2020  ght']:.         
 0001a210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a230: 2020 2020 2020 2020 2020 7475 6e65 5f63            tune_c
-0001a240: 6667 2e67 6574 2827 6361 6c69 625f 7361  fg.get('calib_sa
-0001a250: 6d70 6c69 6e67 5f73 697a 6527 2c20 3129  mpling_size', 1)
-0001a260: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-0001a270: 2020 715f 6d6f 6465 6c2e 7361 7665 5f71    q_model.save_q
-0001a280: 636f 6e66 5f73 756d 6d61 7279 2871 636f  conf_summary(qco
-0001a290: 6e66 5f73 756d 6d61 7279 3d73 656c 662e  nf_summary=self.
-0001a2a0: 6970 6578 5f63 6f6e 6669 675f 7061 7468  ipex_config_path
-0001a2b0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-0001a2c0: 2020 6966 2073 656c 662e 7573 655f 6266    if self.use_bf
-0001a2d0: 3136 2061 6e64 2028 4370 7549 6e66 6f28  16 and (CpuInfo(
-0001a2e0: 292e 6266 3136 206f 7220 6f73 2e67 6574  ).bf16 or os.get
-0001a2f0: 656e 7628 2746 4f52 4345 5f42 4631 3627  env('FORCE_BF16'
-0001a300: 2920 3d3d 2027 3127 2920 616e 6420 5c0a  ) == '1') and \.
-0001a310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a320: 2020 2020 2873 656c 662e 7665 7273 696f      (self.versio
-0001a330: 6e2e 7265 6c65 6173 6520 3e3d 2056 6572  n.release >= Ver
-0001a340: 7369 6f6e 2822 312e 3131 2e30 2229 2e72  sion("1.11.0").r
-0001a350: 656c 6561 7365 293a 0a20 2020 2020 2020  elease):.       
-0001a360: 2020 2020 2020 2020 2020 2020 2077 6974               wit
-0001a370: 6820 746f 7263 682e 6e6f 5f67 7261 6428  h torch.no_grad(
-0001a380: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0001a390: 2020 2020 2020 2020 2020 2077 6974 6820             with 
-0001a3a0: 746f 7263 682e 6370 752e 616d 702e 6175  torch.cpu.amp.au
-0001a3b0: 746f 6361 7374 2829 3a0a 2020 2020 2020  tocast():.      
+0001a220: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+0001a230: 6574 5b27 7765 6967 6874 275d 5b61 5d2e  et['weight'][a].
+0001a240: 7570 6461 7465 287b 0a20 2020 2020 2020  update({.       
+0001a250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a270: 2020 2020 206b 6579 3a0a 2020 2020 2020       key:.      
+0001a280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a2a0: 2020 2020 2020 6465 7175 616e 7469 7a65        dequantize
+0001a2b0: 2873 7461 7465 5f64 6963 745b 6b65 795d  (state_dict[key]
+0001a2c0: 292e 6e75 6d70 7928 290a 2020 2020 2020  ).numpy().      
+0001a2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a2f0: 2020 2020 2020 6966 2073 7461 7465 5f64        if state_d
+0001a300: 6963 745b 6b65 795d 2e69 735f 7175 616e  ict[key].is_quan
+0001a310: 7469 7a65 6420 656c 7365 0a20 2020 2020  tized else.     
+0001a320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a340: 2020 2020 2020 2073 7461 7465 5f64 6963         state_dic
+0001a350: 745b 6b65 795d 2e64 6574 6163 6828 292e  t[key].detach().
+0001a360: 6e75 6d70 7928 290a 2020 2020 2020 2020  numpy().        
+0001a370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a390: 7d29 0a20 2020 2020 2020 2020 2020 2020  }).             
+0001a3a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a3b0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
 0001a3c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a3d0: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
-0001a3e0: 6970 6578 2e71 7561 6e74 697a 6174 696f  ipex.quantizatio
-0001a3f0: 6e2e 636f 6e76 6572 7428 715f 6d6f 6465  n.convert(q_mode
-0001a400: 6c2c 2069 6e70 6c61 6365 3d54 7275 6529  l, inplace=True)
-0001a410: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001a420: 2020 2020 2020 2020 2020 2020 2074 7279               try
-0001a430: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001a440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a450: 2020 715f 6d6f 6465 6c20 3d20 746f 7263    q_model = torc
-0001a460: 682e 6a69 742e 7472 6163 6528 715f 6d6f  h.jit.trace(q_mo
-0001a470: 6465 6c2c 2073 656c 662e 6578 616d 706c  del, self.exampl
-0001a480: 655f 696e 7075 7473 290a 2020 2020 2020  e_inputs).      
-0001a490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a4a0: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
-0001a4b0: 6c20 3d20 746f 7263 682e 6a69 742e 6672  l = torch.jit.fr
-0001a4c0: 6565 7a65 2871 5f6d 6f64 656c 2e65 7661  eeze(q_model.eva
-0001a4d0: 6c28 2929 0a20 2020 2020 2020 2020 2020  l()).           
-0001a4e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a4f0: 2065 7863 6570 743a 0a20 2020 2020 2020   except:.       
+0001a3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a3e0: 2020 2020 2072 6574 5b27 7765 6967 6874       ret['weight
+0001a3f0: 275d 5b61 5d20 3d20 5c0a 2020 2020 2020  '][a] = \.      
+0001a400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a420: 2020 2020 2020 7b6b 6579 3a20 6465 7175        {key: dequ
+0001a430: 616e 7469 7a65 2873 7461 7465 5f64 6963  antize(state_dic
+0001a440: 745b 6b65 795d 292e 6e75 6d70 7928 290a  t[key]).numpy().
+0001a450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a460: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a480: 6966 2073 7461 7465 5f64 6963 745b 6b65  if state_dict[ke
+0001a490: 795d 2e69 735f 7175 616e 7469 7a65 6420  y].is_quantized 
+0001a4a0: 656c 7365 0a20 2020 2020 2020 2020 2020  else.           
+0001a4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a4d0: 2020 2020 2020 2020 2073 7461 7465 5f64           state_d
+0001a4e0: 6963 745b 6b65 795d 2e64 6574 6163 6828  ict[key].detach(
+0001a4f0: 292e 6e75 6d70 7928 297d 0a20 2020 2020  ).numpy()}.     
 0001a500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a510: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
-0001a520: 203d 2074 6f72 6368 2e6a 6974 2e74 7261   = torch.jit.tra
-0001a530: 6365 2871 5f6d 6f64 656c 2c20 7365 6c66  ce(q_model, self
-0001a540: 2e65 7861 6d70 6c65 5f69 6e70 7574 732c  .example_inputs,
-0001a550: 2073 7472 6963 743d 4661 6c73 6529 0a20   strict=False). 
-0001a560: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a570: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-0001a580: 5f6d 6f64 656c 203d 2074 6f72 6368 2e6a  _model = torch.j
-0001a590: 6974 2e66 7265 657a 6528 715f 6d6f 6465  it.freeze(q_mode
-0001a5a0: 6c2e 6576 616c 2829 290a 2020 2020 2020  l.eval()).      
-0001a5b0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-0001a5c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a5d0: 2020 2020 715f 6d6f 6465 6c20 3d20 6970      q_model = ip
-0001a5e0: 6578 2e71 7561 6e74 697a 6174 696f 6e2e  ex.quantization.
-0001a5f0: 636f 6e76 6572 7428 715f 6d6f 6465 6c2c  convert(q_model,
-0001a600: 2069 6e70 6c61 6365 3d54 7275 6529 0a20   inplace=True). 
-0001a610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a620: 2020 2077 6974 6820 746f 7263 682e 6e6f     with torch.no
-0001a630: 5f67 7261 6428 293a 0a20 2020 2020 2020  _grad():.       
-0001a640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a650: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
-0001a660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a670: 2020 715f 6d6f 6465 6c20 3d20 746f 7263    q_model = torc
-0001a680: 682e 6a69 742e 7472 6163 6528 715f 6d6f  h.jit.trace(q_mo
-0001a690: 6465 6c2c 2073 656c 662e 6578 616d 706c  del, self.exampl
-0001a6a0: 655f 696e 7075 7473 290a 2020 2020 2020  e_inputs).      
-0001a6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a6c0: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
-0001a6d0: 746f 7263 682e 6a69 742e 6672 6565 7a65  torch.jit.freeze
-0001a6e0: 2871 5f6d 6f64 656c 2e65 7661 6c28 2929  (q_model.eval())
-0001a6f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001a700: 2020 2020 2020 2020 2065 7863 6570 743a           except:
-0001a710: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001a720: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
-0001a730: 6f64 656c 203d 2074 6f72 6368 2e6a 6974  odel = torch.jit
-0001a740: 2e74 7261 6365 2871 5f6d 6f64 656c 2c20  .trace(q_model, 
-0001a750: 7365 6c66 2e65 7861 6d70 6c65 5f69 6e70  self.example_inp
-0001a760: 7574 732c 2073 7472 6963 743d 4661 6c73  uts, strict=Fals
-0001a770: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
-0001a780: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-0001a790: 5f6d 6f64 656c 203d 2074 6f72 6368 2e6a  _model = torch.j
-0001a7a0: 6974 2e66 7265 657a 6528 715f 6d6f 6465  it.freeze(q_mode
-0001a7b0: 6c2e 6576 616c 2829 290a 2020 2020 2020  l.eval()).      
-0001a7c0: 2020 2020 2020 2020 2020 2320 4166 7465            # Afte
-0001a7d0: 7220 6672 6565 7a69 6e67 2c20 7275 6e20  r freezing, run 
-0001a7e0: 3120 7469 6d65 2074 6f20 7761 726d 2075  1 time to warm u
-0001a7f0: 7020 7468 6520 7072 6f66 696c 696e 6720  p the profiling 
-0001a800: 6772 6170 6820 6578 6563 7574 6f72 2074  graph executor t
-0001a810: 6f20 696e 7365 7274 2070 7269 6d3a 3a70  o insert prim::p
-0001a820: 726f 6669 6c65 0a20 2020 2020 2020 2020  rofile.         
-0001a830: 2020 2020 2020 2023 2041 7420 7468 6520         # At the 
-0001a840: 326e 6420 7275 6e2c 2074 6865 206c 6c67  2nd run, the llg
-0001a850: 6120 7061 7373 2077 696c 6c20 6265 2074  a pass will be t
-0001a860: 7269 6767 6572 6564 2061 6e64 2074 6865  riggered and the
-0001a870: 206d 6f64 656c 2069 7320 7475 726e 6564   model is turned
-0001a880: 2069 6e74 6f0a 2020 2020 2020 2020 2020   into.          
-0001a890: 2020 2020 2020 2320 616e 2069 6e74 3820        # an int8 
-0001a8a0: 6d6f 6465 6c3a 2070 7269 6d3a 3a70 726f  model: prim::pro
-0001a8b0: 6669 6c65 2077 696c 6c20 6265 2072 656d  file will be rem
-0001a8c0: 6f76 6564 2061 6e64 2077 696c 6c20 6861  oved and will ha
-0001a8d0: 7665 204c 6c67 6146 7573 696f 6e47 726f  ve LlgaFusionGro
-0001a8e0: 7570 2069 6e20 7468 6520 6772 6170 680a  up in the graph.
-0001a8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a900: 7365 6c66 2e63 616c 6962 5f66 756e 6328  self.calib_func(
-0001a910: 715f 6d6f 6465 6c2c 2064 6174 616c 6f61  q_model, dataloa
-0001a920: 6465 722c 2074 6d70 5f69 7465 7261 7469  der, tmp_iterati
-0001a930: 6f6e 733d 3229 0a20 2020 2020 2020 2020  ons=2).         
-0001a940: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0001a950: 2020 2020 2020 2020 2061 7373 6572 7420           assert 
-0001a960: 6e6f 7420 7365 6c66 2e76 6572 7369 6f6e  not self.version
-0001a970: 2e72 656c 6561 7365 203c 2056 6572 7369  .release < Versi
-0001a980: 6f6e 2822 312e 3130 2e30 2229 2e72 656c  on("1.10.0").rel
-0001a990: 6561 7365 2c20 5c0a 2020 2020 2020 2020  ease, \.        
-0001a9a0: 2020 2020 2020 2020 2020 2020 2249 4e43              "INC
-0001a9b0: 2073 7570 706f 7274 2049 5045 5820 7665   support IPEX ve
-0001a9c0: 7273 696f 6e20 3e3d 2031 2e31 302e 3022  rsion >= 1.10.0"
-0001a9d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001a9e0: 2069 6620 7365 6c66 2e61 7070 726f 6163   if self.approac
-0001a9f0: 6820 696e 205b 2770 6f73 745f 7472 6169  h in ['post_trai
-0001aa00: 6e69 6e67 5f73 7461 7469 635f 7175 616e  ning_static_quan
-0001aa10: 7427 2c20 2770 6f73 745f 7472 6169 6e69  t', 'post_traini
-0001aa20: 6e67 5f61 7574 6f5f 7175 616e 7427 5d3a  ng_auto_quant']:
-0001aa30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001aa40: 2020 2020 2071 5f6d 6f64 656c 203d 206d       q_model = m
-0001aa50: 6f64 656c 2e6d 6f64 656c 0a20 2020 2020  odel.model.     
-0001aa60: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0001aa70: 6620 7365 6c66 2e76 6572 7369 6f6e 2e72  f self.version.r
-0001aa80: 656c 6561 7365 203c 2056 6572 7369 6f6e  elease < Version
-0001aa90: 2822 312e 3132 2e30 2229 2e72 656c 6561  ("1.12.0").relea
-0001aaa0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0001aab0: 2020 2020 2020 2020 2020 2020 6970 6578              ipex
-0001aac0: 5f63 6f6e 6620 3d20 6970 6578 2e71 7561  _conf = ipex.qua
-0001aad0: 6e74 697a 6174 696f 6e2e 5175 616e 7443  ntization.QuantC
-0001aae0: 6f6e 6628 636f 6e66 6967 7572 655f 6669  onf(configure_fi
-0001aaf0: 6c65 3d73 656c 662e 6970 6578 5f63 6f6e  le=self.ipex_con
-0001ab00: 6669 675f 7061 7468 2c20 2023 2070 796c  fig_path,  # pyl
-0001ab10: 696e 743a 2064 6973 6162 6c65 3d45 3131  int: disable=E11
-0001ab20: 3031 0a20 2020 2020 2020 2020 2020 2020  01.             
-0001ab30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ab40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ab50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ab60: 2020 2071 7363 6865 6d65 3d71 7363 6865     qscheme=qsche
-0001ab70: 6d65 290a 2020 2020 2020 2020 2020 2020  me).            
-0001ab80: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0001ab90: 2e6d 6f64 656c 5f63 616c 6962 7261 7469  .model_calibrati
-0001aba0: 6f6e 2871 5f6d 6f64 656c 2c20 6461 7461  on(q_model, data
-0001abb0: 6c6f 6164 6572 2c20 6974 6572 6174 696f  loader, iteratio
-0001abc0: 6e73 2c20 6970 6578 5f63 6f6e 662c 0a20  ns, ipex_conf,. 
-0001abd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a510: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+0001a520: 7265 616b 0a0a 2020 2020 2020 2020 2020  reak..          
+0001a530: 2020 6966 2073 6176 655f 746f 5f64 6973    if save_to_dis
+0001a540: 6b3a 0a20 2020 2020 2020 2020 2020 2020  k:.             
+0001a550: 2020 206e 702e 7361 7665 7a28 6f73 2e70     np.savez(os.p
+0001a560: 6174 682e 6a6f 696e 2864 756d 705f 6469  ath.join(dump_di
+0001a570: 722c 2027 7765 6967 6874 2e6e 707a 2729  r, 'weight.npz')
+0001a580: 2c20 2a2a 7265 745b 2777 6569 6768 7427  , **ret['weight'
+0001a590: 5d29 0a20 2020 2020 2020 2065 6c73 653a  ]).        else:
+0001a5a0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+0001a5b0: 5b27 7765 6967 6874 275d 203d 204e 6f6e  ['weight'] = Non
+0001a5c0: 650a 0a20 2020 2020 2020 2072 6574 7572  e..        retur
+0001a5d0: 6e20 7265 740a 0a20 2020 2064 6566 2073  n ret..    def s
+0001a5e0: 6574 5f74 656e 736f 7228 7365 6c66 2c20  et_tensor(self, 
+0001a5f0: 6d6f 6465 6c2c 2074 656e 736f 725f 6469  model, tensor_di
+0001a600: 6374 293a 0a20 2020 2020 2020 2073 7461  ct):.        sta
+0001a610: 7465 5f64 6963 7420 3d20 6d6f 6465 6c2e  te_dict = model.
+0001a620: 5f6d 6f64 656c 2e73 7461 7465 5f64 6963  _model.state_dic
+0001a630: 7428 290a 2020 2020 2020 2020 7465 6e73  t().        tens
+0001a640: 6f72 5f6e 616d 6520 3d20 4e6f 6e65 0a20  or_name = None. 
+0001a650: 2020 2020 2020 2066 6f72 206b 6579 2069         for key i
+0001a660: 6e20 7465 6e73 6f72 5f64 6963 742e 6b65  n tensor_dict.ke
+0001a670: 7973 2829 3a0a 2020 2020 2020 2020 2020  ys():.          
+0001a680: 2020 656e 6420 3d20 6b65 792e 7266 696e    end = key.rfin
+0001a690: 6428 272e 2729 0a20 2020 2020 2020 2020  d('.').         
+0001a6a0: 2020 206f 705f 6e61 6d65 203d 206b 6579     op_name = key
+0001a6b0: 5b3a 656e 645d 0a20 2020 2020 2020 2020  [:end].         
+0001a6c0: 2020 2073 7461 7465 5f6f 705f 6e61 6d65     state_op_name
+0001a6d0: 203d 204e 6f6e 650a 2020 2020 2020 2020   = None.        
+0001a6e0: 2020 2020 7765 6967 6874 5f62 6961 7320      weight_bias 
+0001a6f0: 3d20 6b65 795b 656e 6420 2b20 313a 5d0a  = key[end + 1:].
+0001a700: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+0001a710: 6f70 2069 6e20 7365 6c66 2e66 7573 6564  op in self.fused
+0001a720: 5f64 6963 743a 0a20 2020 2020 2020 2020  _dict:.         
+0001a730: 2020 2020 2020 2069 6620 6f70 5f6e 616d         if op_nam
+0001a740: 6520 696e 2073 656c 662e 6675 7365 645f  e in self.fused_
+0001a750: 6469 6374 5b6f 705d 3a0a 2020 2020 2020  dict[op]:.      
+0001a760: 2020 2020 2020 2020 2020 2020 2020 7374                st
+0001a770: 6174 655f 6f70 5f6e 616d 6520 3d20 6f70  ate_op_name = op
+0001a780: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0001a790: 7374 6174 655f 6f70 5f6e 616d 6520 6973  state_op_name is
+0001a7a0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+0001a7b0: 2020 2020 2020 2073 7461 7465 5f6f 705f         state_op_
+0001a7c0: 6e61 6d65 203d 206f 705f 6e61 6d65 0a20  name = op_name. 
+0001a7d0: 2020 2020 2020 2020 2020 2066 6f72 2073             for s
+0001a7e0: 7461 7465 5f64 6963 745f 6b65 7920 696e  tate_dict_key in
+0001a7f0: 2073 7461 7465 5f64 6963 742e 6b65 7973   state_dict.keys
+0001a800: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+0001a810: 2020 2020 7374 6174 655f 6b65 795f 656e      state_key_en
+0001a820: 6420 3d20 7374 6174 655f 6469 6374 5f6b  d = state_dict_k
+0001a830: 6579 2e72 6669 6e64 2827 2e27 290a 2020  ey.rfind('.').  
+0001a840: 2020 2020 2020 2020 2020 2020 2020 7374                st
+0001a850: 6174 655f 6b65 7920 3d20 7374 6174 655f  ate_key = state_
+0001a860: 6469 6374 5f6b 6579 5b3a 7374 6174 655f  dict_key[:state_
+0001a870: 6b65 795f 656e 645d 2e72 6570 6c61 6365  key_end].replace
+0001a880: 2827 2e5f 7061 636b 6564 5f70 6172 616d  ('._packed_param
+0001a890: 7327 2c20 2727 290a 2020 2020 2020 2020  s', '').        
+0001a8a0: 2020 2020 2020 2020 6966 2077 6569 6768          if weigh
+0001a8b0: 745f 6269 6173 2069 6e20 7374 6174 655f  t_bias in state_
+0001a8c0: 6469 6374 5f6b 6579 2061 6e64 2073 7461  dict_key and sta
+0001a8d0: 7465 5f6f 705f 6e61 6d65 203d 3d20 7374  te_op_name == st
+0001a8e0: 6174 655f 6b65 793a 0a20 2020 2020 2020  ate_key:.       
+0001a8f0: 2020 2020 2020 2020 2020 2020 2074 656e               ten
+0001a900: 736f 725f 6e61 6d65 203d 2073 7461 7465  sor_name = state
+0001a910: 5f64 6963 745f 6b65 790a 2020 2020 2020  _dict_key.      
+0001a920: 2020 2020 2020 6173 7365 7274 2074 656e        assert ten
+0001a930: 736f 725f 6e61 6d65 2069 7320 6e6f 7420  sor_name is not 
+0001a940: 4e6f 6e65 2c20 6b65 7920 2b20 2220 6973  None, key + " is
+0001a950: 206e 6f74 2069 6e20 7468 6520 7374 6174   not in the stat
+0001a960: 6520 6469 6374 220a 2020 2020 2020 2020  e dict".        
+0001a970: 2020 2020 7465 6e73 6f72 203d 2074 6f72      tensor = tor
+0001a980: 6368 2e66 726f 6d5f 6e75 6d70 7928 7465  ch.from_numpy(te
+0001a990: 6e73 6f72 5f64 6963 745b 6b65 795d 290a  nsor_dict[key]).
+0001a9a0: 2020 2020 2020 2020 2020 2020 6474 7970              dtyp
+0001a9b0: 6520 3d20 7374 6174 655f 6469 6374 5b74  e = state_dict[t
+0001a9c0: 656e 736f 725f 6e61 6d65 5d2e 6474 7970  ensor_name].dtyp
+0001a9d0: 650a 2020 2020 2020 2020 2020 2020 6966  e.            if
+0001a9e0: 2073 7461 7465 5f64 6963 745b 7465 6e73   state_dict[tens
+0001a9f0: 6f72 5f6e 616d 655d 2e69 735f 7175 616e  or_name].is_quan
+0001aa00: 7469 7a65 643a 0a20 2020 2020 2020 2020  tized:.         
+0001aa10: 2020 2020 2020 2069 6620 2763 6861 6e6e         if 'chann
+0001aa20: 656c 2720 696e 2073 7472 2873 7461 7465  el' in str(state
+0001aa30: 5f64 6963 745b 7465 6e73 6f72 5f6e 616d  _dict[tensor_nam
+0001aa40: 655d 2e71 7363 6865 6d65 2829 293a 0a20  e].qscheme()):. 
+0001aa50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001aa60: 2020 2073 6361 6c65 7320 3d20 7374 6174     scales = stat
+0001aa70: 655f 6469 6374 5b74 656e 736f 725f 6e61  e_dict[tensor_na
+0001aa80: 6d65 5d2e 715f 7065 725f 6368 616e 6e65  me].q_per_channe
+0001aa90: 6c5f 7363 616c 6573 2829 0a20 2020 2020  l_scales().     
+0001aaa0: 2020 2020 2020 2020 2020 2020 2020 207a                 z
+0001aab0: 6572 6f5f 706f 696e 7473 203d 2073 7461  ero_points = sta
+0001aac0: 7465 5f64 6963 745b 7465 6e73 6f72 5f6e  te_dict[tensor_n
+0001aad0: 616d 655d 2e71 5f70 6572 5f63 6861 6e6e  ame].q_per_chann
+0001aae0: 656c 5f7a 6572 6f5f 706f 696e 7473 2829  el_zero_points()
+0001aaf0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001ab00: 2020 2020 2061 7869 7320 3d20 7374 6174       axis = stat
+0001ab10: 655f 6469 6374 5b74 656e 736f 725f 6e61  e_dict[tensor_na
+0001ab20: 6d65 5d2e 715f 7065 725f 6368 616e 6e65  me].q_per_channe
+0001ab30: 6c5f 6178 6973 2829 0a20 2020 2020 2020  l_axis().       
+0001ab40: 2020 2020 2020 2020 2020 2020 2073 7461               sta
+0001ab50: 7465 5f64 6963 745b 7465 6e73 6f72 5f6e  te_dict[tensor_n
+0001ab60: 616d 655d 203d 2074 6f72 6368 2e71 7561  ame] = torch.qua
+0001ab70: 6e74 697a 655f 7065 725f 6368 616e 6e65  ntize_per_channe
+0001ab80: 6c28 7465 6e73 6f72 2c0a 2020 2020 2020  l(tensor,.      
+0001ab90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001aba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001abb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001abc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001abd0: 2020 2073 6361 6c65 732c 0a20 2020 2020     scales,.     
 0001abe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001abf0: 2020 2020 2020 2020 2020 2020 2020 7475                tu
-0001ac00: 6e65 5f63 6667 2e67 6574 2827 6361 6c69  ne_cfg.get('cali
-0001ac10: 625f 7361 6d70 6c69 6e67 5f73 697a 6527  b_sampling_size'
-0001ac20: 2c20 3129 290a 2020 2020 2020 2020 2020  , 1)).          
-0001ac30: 2020 2020 2020 2020 2020 2020 2020 6970                ip
-0001ac40: 6578 5f63 6f6e 662e 7361 7665 2873 656c  ex_conf.save(sel
-0001ac50: 662e 6970 6578 5f63 6f6e 6669 675f 7061  f.ipex_config_pa
-0001ac60: 7468 290a 2020 2020 2020 2020 2020 2020  th).            
-0001ac70: 2020 2020 2020 2020 2020 2020 6970 6578              ipex
-0001ac80: 5f63 6f6e 6620 3d20 6970 6578 2e71 7561  _conf = ipex.qua
-0001ac90: 6e74 697a 6174 696f 6e2e 5175 616e 7443  ntization.QuantC
-0001aca0: 6f6e 6628 7365 6c66 2e69 7065 785f 636f  onf(self.ipex_co
-0001acb0: 6e66 6967 5f70 6174 6829 2020 2023 2070  nfig_path)   # p
-0001acc0: 796c 696e 743a 2064 6973 6162 6c65 3d45  ylint: disable=E
-0001acd0: 3131 3031 0a20 2020 2020 2020 2020 2020  1101.           
-0001ace0: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
-0001acf0: 6f64 656c 203d 2069 7065 782e 7175 616e  odel = ipex.quan
-0001ad00: 7469 7a61 7469 6f6e 2e63 6f6e 7665 7274  tization.convert
-0001ad10: 2871 5f6d 6f64 656c 2c0a 2020 2020 2020  (q_model,.      
+0001abf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ac00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ac10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ac20: 2020 2020 7a65 726f 5f70 6f69 6e74 732c      zero_points,
+0001ac30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001ac40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ac50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ac60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ac70: 2020 2020 2020 2020 2020 6178 6973 2c0a            axis,.
+0001ac80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ac90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001aca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001acb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001acc0: 2020 2020 2020 2020 2064 7479 7065 3d64           dtype=d
+0001acd0: 7479 7065 290a 2020 2020 2020 2020 2020  type).          
+0001ace0: 2020 2020 2020 656c 6966 2027 7465 6e73        elif 'tens
+0001acf0: 6f72 2720 696e 2073 7472 2873 7461 7465  or' in str(state
+0001ad00: 5f64 6963 745b 7465 6e73 6f72 5f6e 616d  _dict[tensor_nam
+0001ad10: 655d 2e71 7363 6865 6d65 2829 293a 0a20  e].qscheme()):. 
 0001ad20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ad30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ad40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ad50: 2020 2020 2020 6970 6578 5f63 6f6e 662c        ipex_conf,
-0001ad60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001ad70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ad80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ad90: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-0001ada0: 662e 6578 616d 706c 655f 696e 7075 7473  f.example_inputs
-0001adb0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0001adc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001add0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ade0: 2020 2020 2020 2020 2020 2020 2020 696e                in
-0001adf0: 706c 6163 653d 5472 7565 2920 2023 2070  place=True)  # p
-0001ae00: 796c 696e 743a 2064 6973 6162 6c65 3d45  ylint: disable=E
-0001ae10: 3131 3231 0a20 2020 2020 2020 2020 2020  1121.           
-0001ae20: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-0001ae30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ae40: 2020 2020 2020 2066 726f 6d20 746f 7263         from torc
-0001ae50: 682e 616f 2e71 7561 6e74 697a 6174 696f  h.ao.quantizatio
-0001ae60: 6e20 696d 706f 7274 204d 696e 4d61 784f  n import MinMaxO
-0001ae70: 6273 6572 7665 722c 2050 6572 4368 616e  bserver, PerChan
-0001ae80: 6e65 6c4d 696e 4d61 784f 6273 6572 7665  nelMinMaxObserve
-0001ae90: 722c 2051 436f 6e66 6967 0a20 2020 2020  r, QConfig.     
-0001aea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001aeb0: 2020 2073 7461 7469 635f 7163 6f6e 6669     static_qconfi
-0001aec0: 6720 3d20 5143 6f6e 6669 6728 6163 7469  g = QConfig(acti
-0001aed0: 7661 7469 6f6e 3d4d 696e 4d61 784f 6273  vation=MinMaxObs
-0001aee0: 6572 7665 722e 7769 7468 5f61 7267 7328  erver.with_args(
-0001aef0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001af00: 2020 2020 2020 2020 2020 2020 2071 7363               qsc
-0001af10: 6865 6d65 3d74 6f72 6368 2e70 6572 5f74  heme=torch.per_t
-0001af20: 656e 736f 725f 6166 6669 6e65 2c20 6474  ensor_affine, dt
-0001af30: 7970 653d 746f 7263 682e 7175 696e 7438  ype=torch.quint8
-0001af40: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
-0001af50: 2020 2020 2020 2020 2020 2020 2020 2077                 w
-0001af60: 6569 6768 743d 5065 7243 6861 6e6e 656c  eight=PerChannel
-0001af70: 4d69 6e4d 6178 4f62 7365 7276 6572 2e77  MinMaxObserver.w
-0001af80: 6974 685f 6172 6773 2864 7479 7065 3d74  ith_args(dtype=t
-0001af90: 6f72 6368 2e71 696e 7438 2c20 5c0a 2020  orch.qint8, \.  
-0001afa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001afb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001afc0: 2020 2020 2020 7173 6368 656d 653d 746f        qscheme=to
-0001afd0: 7263 682e 7065 725f 6368 616e 6e65 6c5f  rch.per_channel_
-0001afe0: 7379 6d6d 6574 7269 6329 290a 0a20 2020  symmetric))..   
-0001aff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b000: 2020 2020 2071 5f6d 6f64 656c 203d 2069       q_model = i
-0001b010: 7065 782e 7175 616e 7469 7a61 7469 6f6e  pex.quantization
-0001b020: 2e70 7265 7061 7265 286d 6f64 656c 2e5f  .prepare(model._
-0001b030: 6d6f 6465 6c2c 2073 7461 7469 635f 7163  model, static_qc
-0001b040: 6f6e 6669 672c 205c 0a20 2020 2020 2020  onfig, \.       
-0001b050: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b070: 2020 2020 2020 2020 2065 7861 6d70 6c65           example
-0001b080: 5f69 6e70 7574 733d 7365 6c66 2e65 7861  _inputs=self.exa
-0001b090: 6d70 6c65 5f69 6e70 7574 732c 2069 6e70  mple_inputs, inp
-0001b0a0: 6c61 6365 3d54 7275 6529 0a20 2020 2020  lace=True).     
-0001b0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b0c0: 2020 2071 5f6d 6f64 656c 2e6c 6f61 645f     q_model.load_
-0001b0d0: 7163 6f6e 665f 7375 6d6d 6172 7928 7163  qconf_summary(qc
-0001b0e0: 6f6e 665f 7375 6d6d 6172 793d 7365 6c66  onf_summary=self
-0001b0f0: 2e69 7065 785f 636f 6e66 6967 5f70 6174  .ipex_config_pat
-0001b100: 6829 0a20 2020 2020 2020 2020 2020 2020  h).             
-0001b110: 2020 2020 2020 2020 2020 2069 6620 715f             if q_
-0001b120: 6675 6e63 2069 7320 6e6f 7420 4e6f 6e65  func is not None
-0001b130: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001b140: 2020 2020 2020 2020 2020 2020 2020 715f                q_
-0001b150: 6675 6e63 2871 5f6d 6f64 656c 290a 2020  func(q_model).  
-0001b160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b170: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-0001b180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b190: 2020 2020 2020 2020 7365 6c66 2e6d 6f64          self.mod
-0001b1a0: 656c 5f63 616c 6962 7261 7469 6f6e 2871  el_calibration(q
-0001b1b0: 5f6d 6f64 656c 2c20 6461 7461 6c6f 6164  _model, dataload
-0001b1c0: 6572 2c20 6974 6572 6174 696f 6e73 2c20  er, iterations, 
-0001b1d0: 4e6f 6e65 2c0a 2020 2020 2020 2020 2020  None,.          
-0001b1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b200: 2020 2020 2020 2020 2074 756e 655f 6366           tune_cf
-0001b210: 672e 6765 7428 2763 616c 6962 5f73 616d  g.get('calib_sam
-0001b220: 706c 696e 675f 7369 7a65 272c 2031 2929  pling_size', 1))
-0001b230: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b240: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
-0001b250: 2e73 6176 655f 7163 6f6e 665f 7375 6d6d  .save_qconf_summ
-0001b260: 6172 7928 7163 6f6e 665f 7375 6d6d 6172  ary(qconf_summar
-0001b270: 793d 7365 6c66 2e69 7065 785f 636f 6e66  y=self.ipex_conf
-0001b280: 6967 5f70 6174 6829 0a20 2020 2020 2020  ig_path).       
-0001b290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b2a0: 2069 6620 7365 6c66 2e75 7365 5f62 6631   if self.use_bf1
-0001b2b0: 3620 616e 6420 2843 7075 496e 666f 2829  6 and (CpuInfo()
-0001b2c0: 2e62 6631 3620 6f72 206f 732e 6765 7465  .bf16 or os.gete
-0001b2d0: 6e76 2827 464f 5243 455f 4246 3136 2729  nv('FORCE_BF16')
-0001b2e0: 203d 3d20 2731 2729 2061 6e64 205c 0a20   == '1') and \. 
-0001b2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b300: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
-0001b310: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
-0001b320: 203e 3d20 5665 7273 696f 6e28 2231 2e31   >= Version("1.1
-0001b330: 312e 3022 292e 7265 6c65 6173 6529 3a0a  1.0").release):.
-0001b340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b350: 2020 2020 2020 2020 2020 2020 7769 7468              with
-0001b360: 2074 6f72 6368 2e6e 6f5f 6772 6164 2829   torch.no_grad()
-0001b370: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001b380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b390: 2020 7769 7468 2074 6f72 6368 2e63 7075    with torch.cpu
-0001b3a0: 2e61 6d70 2e61 7574 6f63 6173 7428 293a  .amp.autocast():
-0001b3b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b3c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b3d0: 2020 2020 2071 5f6d 6f64 656c 203d 2069       q_model = i
-0001b3e0: 7065 782e 7175 616e 7469 7a61 7469 6f6e  pex.quantization
-0001b3f0: 2e63 6f6e 7665 7274 2871 5f6d 6f64 656c  .convert(q_model
-0001b400: 2c20 696e 706c 6163 653d 5472 7565 290a  , inplace=True).
-0001b410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b430: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0001b440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b460: 2071 5f6d 6f64 656c 203d 2074 6f72 6368   q_model = torch
-0001b470: 2e6a 6974 2e74 7261 6365 2871 5f6d 6f64  .jit.trace(q_mod
-0001b480: 656c 2c20 7365 6c66 2e65 7861 6d70 6c65  el, self.example
-0001b490: 5f69 6e70 7574 7329 0a20 2020 2020 2020  _inputs).       
-0001b4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b4c0: 2071 5f6d 6f64 656c 203d 2074 6f72 6368   q_model = torch
-0001b4d0: 2e6a 6974 2e66 7265 657a 6528 715f 6d6f  .jit.freeze(q_mo
-0001b4e0: 6465 6c2e 6576 616c 2829 290a 2020 2020  del.eval()).    
-0001b4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b510: 6578 6365 7074 3a0a 2020 2020 2020 2020  except:.        
-0001b520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b540: 715f 6d6f 6465 6c20 3d20 746f 7263 682e  q_model = torch.
-0001b550: 6a69 742e 7472 6163 6528 715f 6d6f 6465  jit.trace(q_mode
-0001b560: 6c2c 2073 656c 662e 6578 616d 706c 655f  l, self.example_
-0001b570: 696e 7075 7473 2c20 7374 7269 6374 3d46  inputs, strict=F
-0001b580: 616c 7365 290a 2020 2020 2020 2020 2020  alse).          
-0001b590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5a0: 2020 2020 2020 2020 2020 2020 2020 715f                q_
-0001b5b0: 6d6f 6465 6c20 3d20 746f 7263 682e 6a69  model = torch.ji
-0001b5c0: 742e 6672 6565 7a65 2871 5f6d 6f64 656c  t.freeze(q_model
-0001b5d0: 2e65 7661 6c28 2929 0a20 2020 2020 2020  .eval()).       
-0001b5e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5f0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-0001b600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b610: 2020 2071 5f6d 6f64 656c 203d 2069 7065     q_model = ipe
-0001b620: 782e 7175 616e 7469 7a61 7469 6f6e 2e63  x.quantization.c
-0001b630: 6f6e 7665 7274 2871 5f6d 6f64 656c 2c20  onvert(q_model, 
-0001b640: 696e 706c 6163 653d 5472 7565 290a 2020  inplace=True).  
-0001b650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b660: 2020 2020 2020 2020 2020 7769 7468 2074            with t
-0001b670: 6f72 6368 2e6e 6f5f 6772 6164 2829 3a0a  orch.no_grad():.
-0001b680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b6a0: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
-0001b6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b6c0: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
-0001b6d0: 203d 2074 6f72 6368 2e6a 6974 2e74 7261   = torch.jit.tra
-0001b6e0: 6365 2871 5f6d 6f64 656c 2c20 7365 6c66  ce(q_model, self
-0001b6f0: 2e65 7861 6d70 6c65 5f69 6e70 7574 7329  .example_inputs)
-0001b700: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b720: 2020 2020 2071 5f6d 6f64 656c 203d 2074       q_model = t
-0001b730: 6f72 6368 2e6a 6974 2e66 7265 657a 6528  orch.jit.freeze(
-0001b740: 715f 6d6f 6465 6c2e 6576 616c 2829 290a  q_model.eval()).
-0001b750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b770: 6578 6365 7074 3a0a 2020 2020 2020 2020  except:.        
-0001b780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b790: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
-0001b7a0: 6465 6c20 3d20 746f 7263 682e 6a69 742e  del = torch.jit.
-0001b7b0: 7472 6163 6528 715f 6d6f 6465 6c2c 2073  trace(q_model, s
-0001b7c0: 656c 662e 6578 616d 706c 655f 696e 7075  elf.example_inpu
-0001b7d0: 7473 2c20 7374 7269 6374 3d46 616c 7365  ts, strict=False
-0001b7e0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-0001b7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b800: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
-0001b810: 746f 7263 682e 6a69 742e 6672 6565 7a65  torch.jit.freeze
-0001b820: 2871 5f6d 6f64 656c 2e65 7661 6c28 2929  (q_model.eval())
-0001b830: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b840: 2020 2020 2020 2020 2023 2041 6674 6572           # After
-0001b850: 2066 7265 657a 696e 672c 2072 756e 2031   freezing, run 1
-0001b860: 2074 696d 6520 746f 2077 6172 6d20 7570   time to warm up
-0001b870: 2074 6865 2070 726f 6669 6c69 6e67 2067   the profiling g
-0001b880: 7261 7068 2065 7865 6375 746f 7220 746f  raph executor to
-0001b890: 2069 6e73 6572 7420 7072 696d 3a3a 7072   insert prim::pr
-0001b8a0: 6f66 696c 650a 2020 2020 2020 2020 2020  ofile.          
-0001b8b0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0001b8c0: 4174 2074 6865 2032 6e64 2072 756e 2c20  At the 2nd run, 
-0001b8d0: 7468 6520 6c6c 6761 2070 6173 7320 7769  the llga pass wi
-0001b8e0: 6c6c 2062 6520 7472 6967 6765 7265 6420  ll be triggered 
-0001b8f0: 616e 6420 7468 6520 6d6f 6465 6c20 6973  and the model is
-0001b900: 2074 7572 6e65 6420 696e 746f 0a20 2020   turned into.   
-0001b910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b920: 2020 2020 2023 2061 6e20 696e 7438 206d       # an int8 m
-0001b930: 6f64 656c 3a20 7072 696d 3a3a 7072 6f66  odel: prim::prof
-0001b940: 696c 6520 7769 6c6c 2062 6520 7265 6d6f  ile will be remo
-0001b950: 7665 6420 616e 6420 7769 6c6c 2068 6176  ved and will hav
-0001b960: 6520 4c6c 6761 4675 7369 6f6e 4772 6f75  e LlgaFusionGrou
-0001b970: 7020 696e 2074 6865 2067 7261 7068 0a20  p in the graph. 
-0001b980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b990: 2020 2020 2020 2073 656c 662e 6361 6c69         self.cali
-0001b9a0: 625f 6675 6e63 2871 5f6d 6f64 656c 2c20  b_func(q_model, 
-0001b9b0: 6461 7461 6c6f 6164 6572 2c20 746d 705f  dataloader, tmp_
-0001b9c0: 6974 6572 6174 696f 6e73 3d32 290a 2020  iterations=2).  
-0001b9d0: 2020 2020 2020 2020 2020 6d6f 6465 6c2e            model.
-0001b9e0: 5f6d 6f64 656c 203d 2071 5f6d 6f64 656c  _model = q_model
-0001b9f0: 0a20 2020 2020 2020 2020 2020 2077 6974  .            wit
-0001ba00: 6820 6f70 656e 2873 656c 662e 6970 6578  h open(self.ipex
-0001ba10: 5f63 6f6e 6669 675f 7061 7468 2c20 2772  _config_path, 'r
-0001ba20: 2729 2061 7320 663a 0a20 2020 2020 2020  ') as f:.       
-0001ba30: 2020 2020 2020 2020 206d 6f64 656c 2e74           model.t
-0001ba40: 756e 655f 6366 6720 3d20 6a73 6f6e 2e6c  une_cfg = json.l
-0001ba50: 6f61 6428 6629 0a20 2020 2020 2020 2020  oad(f).         
-0001ba60: 2020 206d 6f64 656c 2e69 7065 785f 636f     model.ipex_co
-0001ba70: 6e66 6967 5f70 6174 6820 3d20 7365 6c66  nfig_path = self
-0001ba80: 2e69 7065 785f 636f 6e66 6967 5f70 6174  .ipex_config_pat
-0001ba90: 680a 2020 2020 2020 2020 2020 2020 7265  h.            re
-0001baa0: 7475 726e 206d 6f64 656c 0a20 2020 2020  turn model.     
-0001bab0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0001bac0: 2020 2020 2069 6620 7365 6c66 2e74 6d70       if self.tmp
-0001bad0: 5f6d 6f64 656c 2069 7320 4e6f 6e65 3a0a  _model is None:.
-0001bae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001baf0: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
-0001bb00: 2020 2020 2020 2020 2073 656c 662e 746d           self.tm
-0001bb10: 705f 6d6f 6465 6c20 3d20 636f 7079 2e64  p_model = copy.d
-0001bb20: 6565 7063 6f70 7928 6d6f 6465 6c29 0a20  eepcopy(model). 
-0001bb30: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0001bb40: 7863 6570 7420 4578 6365 7074 696f 6e20  xcept Exception 
-0001bb50: 6173 2065 3a20 2023 2070 7261 676d 613a  as e:  # pragma:
-0001bb60: 206e 6f20 636f 7665 720a 2020 2020 2020   no cover.      
-0001bb70: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-0001bb80: 6767 6572 2e77 6172 6e69 6e67 2822 4661  gger.warning("Fa
-0001bb90: 696c 2074 6f20 6465 6570 2063 6f70 7920  il to deep copy 
-0001bba0: 7468 6520 6d6f 6465 6c20 6475 6520 746f  the model due to
-0001bbb0: 207b 7d2c 2069 6e70 6c61 6365 2069 7320   {}, inplace is 
-0001bbc0: 7573 6564 206e 6f77 2e22 2e66 6f72 6d61  used now.".forma
-0001bbd0: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-0001bbe0: 2020 2020 2020 2020 2020 2072 6570 7228             repr(
-0001bbf0: 6529 2929 0a20 2020 2020 2020 2020 2020  e))).           
-0001bc00: 2020 2020 2020 2020 2073 656c 662e 746d           self.tm
-0001bc10: 705f 6d6f 6465 6c20 3d20 6d6f 6465 6c0a  p_model = model.
-0001bc20: 2020 2020 2020 2020 2020 2020 6966 2068              if h
-0001bc30: 6173 6174 7472 286d 6f64 656c 2e6d 6f64  asattr(model.mod
-0001bc40: 656c 2c20 2273 6176 655f 7163 6f6e 665f  el, "save_qconf_
-0001bc50: 7375 6d6d 6172 7922 293a 0a20 2020 2020  summary"):.     
-0001bc60: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-0001bc70: 6c66 2e74 6d70 5f6d 6f64 656c 2069 7320  lf.tmp_model is 
-0001bc80: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-0001bc90: 2020 2020 2020 2020 2020 7472 793a 0a20            try:. 
-0001bca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bcb0: 2020 2020 2020 2073 656c 662e 746d 705f         self.tmp_
-0001bcc0: 6d6f 6465 6c20 3d20 636f 7079 2e64 6565  model = copy.dee
-0001bcd0: 7063 6f70 7928 6d6f 6465 6c29 0a20 2020  pcopy(model).   
-0001bce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bcf0: 2065 7863 6570 7420 4578 6365 7074 696f   except Exceptio
-0001bd00: 6e20 6173 2065 3a20 2023 2070 7261 676d  n as e:  # pragm
-0001bd10: 613a 206e 6f20 636f 7665 720a 2020 2020  a: no cover.    
-0001bd20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bd30: 2020 2020 6c6f 6767 6572 2e77 6172 6e69      logger.warni
-0001bd40: 6e67 2822 4661 696c 2074 6f20 6465 6570  ng("Fail to deep
-0001bd50: 2063 6f70 7920 7468 6520 6d6f 6465 6c20   copy the model 
-0001bd60: 6475 6520 746f 207b 7d2c 2069 6e70 6c61  due to {}, inpla
-0001bd70: 6365 2069 7320 7573 6564 206e 6f77 2e22  ce is used now."
-0001bd80: 2e66 6f72 6d61 7428 0a20 2020 2020 2020  .format(.       
-0001bd90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bda0: 2020 2020 2072 6570 7228 6529 2929 0a20       repr(e))). 
-0001bdb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bdc0: 2020 2020 2020 2073 656c 662e 746d 705f         self.tmp_
-0001bdd0: 6d6f 6465 6c20 3d20 6d6f 6465 6c0a 2020  model = model.  
-0001bde0: 2020 2020 2020 2020 2020 2020 2020 715f                q_
-0001bdf0: 6d6f 6465 6c20 3d20 6d6f 6465 6c2e 6d6f  model = model.mo
-0001be00: 6465 6c0a 2020 2020 2020 2020 2020 2020  del.            
-0001be10: 2020 2020 715f 6d6f 6465 6c2e 6c6f 6164      q_model.load
-0001be20: 5f71 636f 6e66 5f73 756d 6d61 7279 2871  _qconf_summary(q
-0001be30: 636f 6e66 5f73 756d 6d61 7279 3d73 656c  conf_summary=sel
-0001be40: 662e 6970 6578 5f63 6f6e 6669 675f 7061  f.ipex_config_pa
-0001be50: 7468 290a 2020 2020 2020 2020 2020 2020  th).            
-0001be60: 2020 2020 6966 2071 5f66 756e 6320 6973      if q_func is
-0001be70: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
-0001be80: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-0001be90: 5f66 756e 6328 715f 6d6f 6465 6c29 0a20  _func(q_model). 
-0001bea0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0001beb0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0001bec0: 2020 2020 2020 2020 2073 656c 662e 6d6f           self.mo
-0001bed0: 6465 6c5f 6361 6c69 6272 6174 696f 6e28  del_calibration(
-0001bee0: 715f 6d6f 6465 6c2c 2064 6174 616c 6f61  q_model, dataloa
-0001bef0: 6465 722c 2069 7465 7261 7469 6f6e 732c  der, iterations,
-0001bf00: 204e 6f6e 652c 0a20 2020 2020 2020 2020   None,.         
-0001bf10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bf20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bf30: 2020 7475 6e65 5f63 6667 2e67 6574 2827    tune_cfg.get('
-0001bf40: 6361 6c69 625f 7361 6d70 6c69 6e67 5f73  calib_sampling_s
-0001bf50: 697a 6527 2c20 3129 290a 2020 2020 2020  ize', 1)).      
-0001bf60: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
-0001bf70: 6c2e 7361 7665 5f71 636f 6e66 5f73 756d  l.save_qconf_sum
-0001bf80: 6d61 7279 2871 636f 6e66 5f73 756d 6d61  mary(qconf_summa
-0001bf90: 7279 3d73 656c 662e 6970 6578 5f63 6f6e  ry=self.ipex_con
-0001bfa0: 6669 675f 7061 7468 290a 2020 2020 2020  fig_path).      
-0001bfb0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-0001bfc0: 662e 7573 655f 6266 3136 2061 6e64 2028  f.use_bf16 and (
-0001bfd0: 4370 7549 6e66 6f28 292e 6266 3136 206f  CpuInfo().bf16 o
-0001bfe0: 7220 6f73 2e67 6574 656e 7628 2746 4f52  r os.getenv('FOR
-0001bff0: 4345 5f42 4631 3627 2920 3d3d 2027 3127  CE_BF16') == '1'
-0001c000: 2920 616e 6420 5c0a 2020 2020 2020 2020  ) and \.        
-0001c010: 2020 2020 2020 2020 2020 2020 2873 656c              (sel
-0001c020: 662e 7665 7273 696f 6e2e 7265 6c65 6173  f.version.releas
-0001c030: 6520 3e3d 2056 6572 7369 6f6e 2822 312e  e >= Version("1.
-0001c040: 3131 2e30 2229 2e72 656c 6561 7365 293a  11.0").release):
-0001c050: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001c060: 2020 2020 2077 6974 6820 746f 7263 682e       with torch.
-0001c070: 6e6f 5f67 7261 6428 293a 0a20 2020 2020  no_grad():.     
-0001c080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c090: 2020 2077 6974 6820 746f 7263 682e 6370     with torch.cp
-0001c0a0: 752e 616d 702e 6175 746f 6361 7374 2829  u.amp.autocast()
-0001c0b0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001c0c0: 2020 2020 2020 2020 2020 2020 2020 715f                q_
-0001c0d0: 6d6f 6465 6c20 3d20 6970 6578 2e71 7561  model = ipex.qua
-0001c0e0: 6e74 697a 6174 696f 6e2e 636f 6e76 6572  ntization.conver
-0001c0f0: 7428 715f 6d6f 6465 6c2c 2069 6e70 6c61  t(q_model, inpla
-0001c100: 6365 3d46 616c 7365 290a 2020 2020 2020  ce=False).      
-0001c110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c120: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
-0001c130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c140: 2020 2020 2020 2020 2020 2071 5f6d 6f64             q_mod
-0001c150: 656c 203d 2074 6f72 6368 2e6a 6974 2e74  el = torch.jit.t
-0001c160: 7261 6365 2871 5f6d 6f64 656c 2c20 7365  race(q_model, se
-0001c170: 6c66 2e65 7861 6d70 6c65 5f69 6e70 7574  lf.example_input
-0001c180: 7329 0a20 2020 2020 2020 2020 2020 2020  s).             
-0001c190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c1a0: 2020 2071 5f6d 6f64 656c 203d 2074 6f72     q_model = tor
-0001c1b0: 6368 2e6a 6974 2e66 7265 657a 6528 715f  ch.jit.freeze(q_
-0001c1c0: 6d6f 6465 6c2e 6576 616c 2829 290a 2020  model.eval()).  
-0001c1d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c1e0: 2020 2020 2020 2020 2020 6578 6365 7074            except
-0001c1f0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001c200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c210: 2020 715f 6d6f 6465 6c20 3d20 746f 7263    q_model = torc
-0001c220: 682e 6a69 742e 7472 6163 6528 715f 6d6f  h.jit.trace(q_mo
-0001c230: 6465 6c2c 2073 656c 662e 6578 616d 706c  del, self.exampl
-0001c240: 655f 696e 7075 7473 2c20 7374 7269 6374  e_inputs, strict
-0001c250: 3d46 616c 7365 290a 2020 2020 2020 2020  =False).        
-0001c260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c270: 2020 2020 2020 2020 715f 6d6f 6465 6c20          q_model 
-0001c280: 3d20 746f 7263 682e 6a69 742e 6672 6565  = torch.jit.free
-0001c290: 7a65 2871 5f6d 6f64 656c 2e65 7661 6c28  ze(q_model.eval(
-0001c2a0: 2929 0a20 2020 2020 2020 2020 2020 2020  )).             
-0001c2b0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0001c2c0: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
-0001c2d0: 6f64 656c 203d 2069 7065 782e 7175 616e  odel = ipex.quan
-0001c2e0: 7469 7a61 7469 6f6e 2e63 6f6e 7665 7274  tization.convert
-0001c2f0: 2871 5f6d 6f64 656c 2c20 696e 706c 6163  (q_model, inplac
-0001c300: 653d 4661 6c73 6529 0a20 2020 2020 2020  e=False).       
-0001c310: 2020 2020 2020 2020 2020 2020 2077 6974               wit
-0001c320: 6820 746f 7263 682e 6e6f 5f67 7261 6428  h torch.no_grad(
-0001c330: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0001c340: 2020 2020 2020 2020 2020 2074 7279 3a0a             try:.
-0001c350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c360: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
-0001c370: 6465 6c20 3d20 746f 7263 682e 6a69 742e  del = torch.jit.
-0001c380: 7472 6163 6528 715f 6d6f 6465 6c2c 2073  trace(q_model, s
-0001c390: 656c 662e 6578 616d 706c 655f 696e 7075  elf.example_inpu
-0001c3a0: 7473 290a 2020 2020 2020 2020 2020 2020  ts).            
-0001c3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c3c0: 715f 6d6f 6465 6c20 3d20 746f 7263 682e  q_model = torch.
-0001c3d0: 6a69 742e 6672 6565 7a65 2871 5f6d 6f64  jit.freeze(q_mod
-0001c3e0: 656c 2e65 7661 6c28 2929 0a20 2020 2020  el.eval()).     
-0001c3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c400: 2020 2065 7863 6570 743a 0a20 2020 2020     except:.     
-0001c410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c420: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
-0001c430: 2074 6f72 6368 2e6a 6974 2e74 7261 6365   torch.jit.trace
-0001c440: 2871 5f6d 6f64 656c 2c20 7365 6c66 2e65  (q_model, self.e
-0001c450: 7861 6d70 6c65 5f69 6e70 7574 732c 2073  xample_inputs, s
-0001c460: 7472 6963 743d 4661 6c73 6529 0a20 2020  trict=False).   
-0001c470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c480: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
-0001c490: 203d 2074 6f72 6368 2e6a 6974 2e66 7265   = torch.jit.fre
-0001c4a0: 657a 6528 715f 6d6f 6465 6c2e 6576 616c  eze(q_model.eval
-0001c4b0: 2829 290a 2020 2020 2020 2020 2020 2020  ()).            
-0001c4c0: 2020 2020 2320 4166 7465 7220 6672 6565      # After free
-0001c4d0: 7a69 6e67 2c20 7275 6e20 3120 7469 6d65  zing, run 1 time
-0001c4e0: 2074 6f20 7761 726d 2075 7020 7468 6520   to warm up the 
-0001c4f0: 7072 6f66 696c 696e 6720 6772 6170 6820  profiling graph 
-0001c500: 6578 6563 7574 6f72 2074 6f20 696e 7365  executor to inse
-0001c510: 7274 2070 7269 6d3a 3a70 726f 6669 6c65  rt prim::profile
-0001c520: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001c530: 2023 2041 7420 7468 6520 326e 6420 7275   # At the 2nd ru
-0001c540: 6e2c 2074 6865 206c 6c67 6120 7061 7373  n, the llga pass
-0001c550: 2077 696c 6c20 6265 2074 7269 6767 6572   will be trigger
-0001c560: 6564 2061 6e64 2074 6865 206d 6f64 656c  ed and the model
-0001c570: 2069 7320 7475 726e 6564 2069 6e74 6f0a   is turned into.
-0001c580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c590: 2320 616e 2069 6e74 3820 6d6f 6465 6c3a  # an int8 model:
-0001c5a0: 2070 7269 6d3a 3a70 726f 6669 6c65 2077   prim::profile w
-0001c5b0: 696c 6c20 6265 2072 656d 6f76 6564 2061  ill be removed a
-0001c5c0: 6e64 2077 696c 6c20 6861 7665 204c 6c67  nd will have Llg
-0001c5d0: 6146 7573 696f 6e47 726f 7570 2069 6e20  aFusionGroup in 
-0001c5e0: 7468 6520 6772 6170 680a 2020 2020 2020  the graph.      
-0001c5f0: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
-0001c600: 616c 6962 5f66 756e 6328 715f 6d6f 6465  alib_func(q_mode
-0001c610: 6c2c 2064 6174 616c 6f61 6465 722c 2074  l, dataloader, t
-0001c620: 6d70 5f69 7465 7261 7469 6f6e 733d 3229  mp_iterations=2)
-0001c630: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
-0001c640: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-0001c650: 2020 2069 6620 7365 6c66 2e61 7070 726f     if self.appro
-0001c660: 6163 6820 696e 205b 2770 6f73 745f 7472  ach in ['post_tr
-0001c670: 6169 6e69 6e67 5f73 7461 7469 635f 7175  aining_static_qu
-0001c680: 616e 7427 2c20 2770 6f73 745f 7472 6169  ant', 'post_trai
-0001c690: 6e69 6e67 5f61 7574 6f5f 7175 616e 7427  ning_auto_quant'
-0001c6a0: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
-0001c6b0: 2020 2020 2020 2069 6620 7365 6c66 2e76         if self.v
-0001c6c0: 6572 7369 6f6e 2e72 656c 6561 7365 203c  ersion.release <
-0001c6d0: 2056 6572 7369 6f6e 2822 312e 3132 2e30   Version("1.12.0
-0001c6e0: 2229 2e72 656c 6561 7365 3a0a 2020 2020  ").release:.    
-0001c6f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c700: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0001c710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c720: 2020 2020 2073 656c 662e 746d 705f 6d6f       self.tmp_mo
-0001c730: 6465 6c20 3d20 636f 7079 2e64 6565 7063  del = copy.deepc
-0001c740: 6f70 7928 6d6f 6465 6c29 0a20 2020 2020  opy(model).     
-0001c750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c760: 2020 2065 7863 6570 7420 4578 6365 7074     except Except
-0001c770: 696f 6e20 6173 2065 3a20 2023 2070 7261  ion as e:  # pra
-0001c780: 676d 613a 206e 6f20 636f 7665 720a 2020  gma: no cover.  
-0001c790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c7a0: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
-0001c7b0: 2e77 6172 6e69 6e67 2822 4661 696c 2074  .warning("Fail t
-0001c7c0: 6f20 6465 6570 2063 6f70 7920 7468 6520  o deep copy the 
-0001c7d0: 6d6f 6465 6c20 6475 6520 746f 207b 7d2c  model due to {},
-0001c7e0: 2069 6e70 6c61 6365 2069 7320 7573 6564   inplace is used
-0001c7f0: 206e 6f77 2e22 2e66 6f72 6d61 7428 0a20   now.".format(. 
-0001c800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c810: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0001c820: 6570 7228 6529 2929 0a20 2020 2020 2020  epr(e))).       
-0001c830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c840: 2020 2020 2073 656c 662e 746d 705f 6d6f       self.tmp_mo
-0001c850: 6465 6c20 3d20 6d6f 6465 6c0a 2020 2020  del = model.    
-0001c860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c870: 2020 2020 6970 6578 5f63 6f6e 6620 3d20      ipex_conf = 
-0001c880: 6970 6578 2e71 7561 6e74 697a 6174 696f  ipex.quantizatio
-0001c890: 6e2e 5175 616e 7443 6f6e 6628 636f 6e66  n.QuantConf(conf
-0001c8a0: 6967 7572 655f 6669 6c65 3d73 656c 662e  igure_file=self.
-0001c8b0: 6970 6578 5f63 6f6e 6669 675f 7061 7468  ipex_config_path
-0001c8c0: 2c20 2023 2070 796c 696e 743a 2064 6973  ,  # pylint: dis
-0001c8d0: 6162 6c65 3d45 3131 3031 0a20 2020 2020  able=E1101.     
-0001c8e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c910: 2020 2020 2020 2020 2020 2071 7363 6865             qsche
-0001c920: 6d65 3d71 7363 6865 6d65 290a 2020 2020  me=qscheme).    
-0001c930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c940: 2020 2020 7365 6c66 2e6d 6f64 656c 5f63      self.model_c
-0001c950: 616c 6962 7261 7469 6f6e 2873 656c 662e  alibration(self.
-0001c960: 746d 705f 6d6f 6465 6c2e 6d6f 6465 6c2c  tmp_model.model,
-0001c970: 2064 6174 616c 6f61 6465 722c 2069 7465   dataloader, ite
-0001c980: 7261 7469 6f6e 732c 2069 7065 785f 636f  rations, ipex_co
-0001c990: 6e66 2c0a 2020 2020 2020 2020 2020 2020  nf,.            
-0001c9a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c9b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c9c0: 2020 2074 756e 655f 6366 672e 6765 7428     tune_cfg.get(
-0001c9d0: 2763 616c 6962 5f73 616d 706c 696e 675f  'calib_sampling_
-0001c9e0: 7369 7a65 272c 2031 2929 0a20 2020 2020  size', 1)).     
-0001c9f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ca00: 2020 2069 7065 785f 636f 6e66 2e73 6176     ipex_conf.sav
-0001ca10: 6528 7365 6c66 2e69 7065 785f 636f 6e66  e(self.ipex_conf
-0001ca20: 6967 5f70 6174 6829 0a20 2020 2020 2020  ig_path).       
-0001ca30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ca40: 2069 7065 785f 636f 6e66 203d 2069 7065   ipex_conf = ipe
-0001ca50: 782e 7175 616e 7469 7a61 7469 6f6e 2e51  x.quantization.Q
-0001ca60: 7561 6e74 436f 6e66 2873 656c 662e 6970  uantConf(self.ip
-0001ca70: 6578 5f63 6f6e 6669 675f 7061 7468 2920  ex_config_path) 
-0001ca80: 2020 2320 7079 6c69 6e74 3a20 6469 7361    # pylint: disa
-0001ca90: 626c 653d 4531 3130 310a 2020 2020 2020  ble=E1101.      
-0001caa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cab0: 2020 715f 6d6f 6465 6c20 3d20 6970 6578    q_model = ipex
-0001cac0: 2e71 7561 6e74 697a 6174 696f 6e2e 636f  .quantization.co
-0001cad0: 6e76 6572 7428 7365 6c66 2e74 6d70 5f6d  nvert(self.tmp_m
-0001cae0: 6f64 656c 2e6d 6f64 656c 2c0a 2020 2020  odel.model,.    
-0001caf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cb00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cb10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cb20: 2020 2020 2020 2020 6970 6578 5f63 6f6e          ipex_con
-0001cb30: 662c 0a20 2020 2020 2020 2020 2020 2020  f,.             
-0001cb40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cb50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cb60: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0001cb70: 656c 662e 6578 616d 706c 655f 696e 7075  elf.example_inpu
-0001cb80: 7473 2c0a 2020 2020 2020 2020 2020 2020  ts,.            
-0001cb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ad30: 2020 2073 6361 6c65 7320 3d20 7374 6174     scales = stat
+0001ad40: 655f 6469 6374 5b74 656e 736f 725f 6e61  e_dict[tensor_na
+0001ad50: 6d65 5d2e 715f 7363 616c 6528 290a 2020  me].q_scale().  
+0001ad60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ad70: 2020 7a65 726f 5f70 6f69 6e74 7320 3d20    zero_points = 
+0001ad80: 7374 6174 655f 6469 6374 5b74 656e 736f  state_dict[tenso
+0001ad90: 725f 6e61 6d65 5d2e 715f 7a65 726f 5f70  r_name].q_zero_p
+0001ada0: 6f69 6e74 2829 0a20 2020 2020 2020 2020  oint().         
+0001adb0: 2020 2020 2020 2020 2020 2073 7461 7465             state
+0001adc0: 5f64 6963 745b 7465 6e73 6f72 5f6e 616d  _dict[tensor_nam
+0001add0: 655d 203d 2074 6f72 6368 2e71 7561 6e74  e] = torch.quant
+0001ade0: 697a 655f 7065 725f 7465 6e73 6f72 280a  ize_per_tensor(.
+0001adf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ae00: 2020 2020 2020 2020 7465 6e73 6f72 2c20          tensor, 
+0001ae10: 7363 616c 6573 2c20 7a65 726f 5f70 6f69  scales, zero_poi
+0001ae20: 6e74 732c 2064 7479 7065 290a 2020 2020  nts, dtype).    
+0001ae30: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0001ae40: 2020 2020 2020 2020 2020 2020 2020 7374                st
+0001ae50: 6174 655f 6469 6374 5b74 656e 736f 725f  ate_dict[tensor_
+0001ae60: 6e61 6d65 5d20 3d20 7465 6e73 6f72 0a20  name] = tensor. 
+0001ae70: 2020 2020 2020 206d 6f64 656c 2e5f 6d6f         model._mo
+0001ae80: 6465 6c2e 6c6f 6164 5f73 7461 7465 5f64  del.load_state_d
+0001ae90: 6963 7428 7374 6174 655f 6469 6374 290a  ict(state_dict).
+0001aea0: 0a20 2020 2040 6475 6d70 5f65 6c61 7073  .    @dump_elaps
+0001aeb0: 6564 5f74 696d 6528 2250 6173 7320 7175  ed_time("Pass qu
+0001aec0: 6572 7920 6672 616d 6577 6f72 6b20 6361  ery framework ca
+0001aed0: 7061 6269 6c69 7479 2229 0a20 2020 2064  pability").    d
+0001aee0: 6566 2071 7565 7279 5f66 775f 6361 7061  ef query_fw_capa
+0001aef0: 6269 6c69 7479 2873 656c 662c 206d 6f64  bility(self, mod
+0001af00: 656c 293a 0a20 2020 2020 2020 2022 2222  el):.        """
+0001af10: 5468 6973 2069 7320 6120 6865 6c70 6572  This is a helper
+0001af20: 2066 756e 6374 696f 6e20 746f 2067 6574   function to get
+0001af30: 2061 6c6c 2071 7561 6e74 697a 6162 6c65   all quantizable
+0001af40: 206f 7073 2066 726f 6d20 6d6f 6465 6c2e   ops from model.
+0001af50: 0a0a 2020 2020 2020 2020 4172 6773 3a0a  ..        Args:.
+0001af60: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
+0001af70: 6c20 286f 626a 6563 7429 3a20 696e 7075  l (object): inpu
+0001af80: 7420 6d6f 6465 6c20 7768 6963 6820 6973  t model which is
+0001af90: 204e 6575 7261 6c20 436f 6d70 7265 7373   Neural Compress
+0001afa0: 6f72 206d 6f64 656c 0a0a 2020 2020 2020  or model..      
+0001afb0: 2020 5265 7475 726e 733a 0a20 2020 2020    Returns:.     
+0001afc0: 2020 2020 2020 2071 5f63 6170 6162 696c         q_capabil
+0001afd0: 6974 7920 2864 6963 7469 6f6e 6172 7929  ity (dictionary)
+0001afe0: 3a20 7475 6e69 6e67 2063 6170 6162 696c  : tuning capabil
+0001aff0: 6974 7920 666f 7220 6561 6368 206f 7020  ity for each op 
+0001b000: 6672 6f6d 206d 6f64 656c 2e0a 2020 2020  from model..    
+0001b010: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0001b020: 7365 6c66 2e70 7265 5f6f 7074 696d 697a  self.pre_optimiz
+0001b030: 6564 5f6d 6f64 656c 203d 206d 6f64 656c  ed_model = model
+0001b040: 0a20 2020 2020 2020 2073 656c 662e 6e6f  .        self.no
+0001b050: 6e5f 7175 616e 745f 6469 6374 203d 2073  n_quant_dict = s
+0001b060: 656c 662e 6765 745f 6e6f 6e5f 7175 616e  elf.get_non_quan
+0001b070: 745f 6d6f 6475 6c65 7328 6d6f 6465 6c2e  t_modules(model.
+0001b080: 6b77 6172 6773 290a 2020 2020 2020 2020  kwargs).        
+0001b090: 7265 7475 726e 2073 656c 662e 5f67 6574  return self._get
+0001b0a0: 5f71 7561 6e74 697a 6162 6c65 5f6f 7073  _quantizable_ops
+0001b0b0: 286d 6f64 656c 2e6d 6f64 656c 290a 0a20  (model.model).. 
+0001b0c0: 2020 2064 6566 2067 6574 5f6e 6f6e 5f71     def get_non_q
+0001b0d0: 7561 6e74 5f6d 6f64 756c 6573 2873 656c  uant_modules(sel
+0001b0e0: 662c 206d 6f64 656c 5f6b 7761 7267 7329  f, model_kwargs)
+0001b0f0: 3a0a 2020 2020 2020 2020 2222 2254 6869  :.        """Thi
+0001b100: 7320 6973 2061 2068 656c 7065 7220 6675  s is a helper fu
+0001b110: 6e63 7469 6f6e 2074 6f20 6765 7420 616c  nction to get al
+0001b120: 6c20 6e6f 6e5f 7175 616e 745f 6d6f 6475  l non_quant_modu
+0001b130: 6c65 7320 6672 6f6d 2063 7573 746f 6d65  les from custome
+0001b140: 7220 616e 6420 6465 6661 756c 742e 0a0a  r and default...
+0001b150: 2020 2020 2020 2020 4172 6773 3a0a 2020          Args:.  
+0001b160: 2020 2020 2020 2020 2020 6d6f 6465 6c5f            model_
+0001b170: 6b77 6172 6773 2028 6469 6374 696f 6e61  kwargs (dictiona
+0001b180: 7279 293a 206b 6579 776f 7264 2061 7267  ry): keyword arg
+0001b190: 7320 6672 6f6d 204e 6575 7261 6c20 436f  s from Neural Co
+0001b1a0: 6d70 7265 7373 6f72 206d 6f64 656c 0a0a  mpressor model..
+0001b1b0: 2020 2020 2020 2020 5265 7475 726e 733a          Returns:
+0001b1c0: 0a20 2020 2020 2020 2020 2020 2063 7573  .            cus
+0001b1d0: 746f 6d5f 6e6f 6e5f 7175 616e 745f 6469  tom_non_quant_di
+0001b1e0: 6374 2028 6469 6374 696f 6e61 7279 293a  ct (dictionary):
+0001b1f0: 206e 6f6e 5f71 7561 6e74 5f6d 6f64 756c   non_quant_modul
+0001b200: 6573 2066 6f72 206d 6f64 656c 2e0a 2020  es for model..  
+0001b210: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0001b220: 2020 6966 206d 6f64 656c 5f6b 7761 7267    if model_kwarg
+0001b230: 7320 6973 204e 6f6e 653a 0a20 2020 2020  s is None:.     
+0001b240: 2020 2020 2020 206d 6f64 656c 5f6b 7761         model_kwa
+0001b250: 7267 7320 3d20 7b7d 0a20 2020 2020 2020  rgs = {}.       
+0001b260: 2073 6b69 7070 6564 5f6d 6f64 756c 655f   skipped_module_
+0001b270: 6e61 6d65 7320 3d20 6d6f 6465 6c5f 6b77  names = model_kw
+0001b280: 6172 6773 2e67 6574 2822 6e6f 6e5f 7175  args.get("non_qu
+0001b290: 616e 745f 6d6f 6475 6c65 5f6e 616d 6522  ant_module_name"
+0001b2a0: 2c20 5b5d 290a 2020 2020 2020 2020 736b  , []).        sk
+0001b2b0: 6970 7065 645f 6d6f 6475 6c65 5f63 6c61  ipped_module_cla
+0001b2c0: 7373 6573 203d 206d 6f64 656c 5f6b 7761  sses = model_kwa
+0001b2d0: 7267 732e 6765 7428 226e 6f6e 5f71 7561  rgs.get("non_qua
+0001b2e0: 6e74 5f6d 6f64 756c 655f 636c 6173 7322  nt_module_class"
+0001b2f0: 2c20 5b5d 290a 2020 2020 2020 2020 6375  , []).        cu
+0001b300: 7374 6f6d 5f6e 6f6e 5f71 7561 6e74 5f64  stom_non_quant_d
+0001b310: 6963 7420 3d20 7b0a 2020 2020 2020 2020  ict = {.        
+0001b320: 2020 2020 2773 6b69 7070 6564 5f6d 6f64      'skipped_mod
+0001b330: 756c 655f 6e61 6d65 7327 3a20 736b 6970  ule_names': skip
+0001b340: 7065 645f 6d6f 6475 6c65 5f6e 616d 6573  ped_module_names
+0001b350: 2c0a 2020 2020 2020 2020 2020 2020 2773  ,.            's
+0001b360: 6b69 7070 6564 5f6d 6f64 756c 655f 636c  kipped_module_cl
+0001b370: 6173 7365 7327 3a20 736b 6970 7065 645f  asses': skipped_
+0001b380: 6d6f 6475 6c65 5f63 6c61 7373 6573 0a20  module_classes. 
+0001b390: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+0001b3a0: 2023 2049 676e 6f72 6520 4c61 7965 724e   # Ignore LayerN
+0001b3b0: 6f72 6d2c 2049 6e73 7461 6e63 654e 6f72  orm, InstanceNor
+0001b3c0: 6d33 6420 616e 6420 456d 6265 6464 696e  m3d and Embeddin
+0001b3d0: 6720 7175 616e 7469 7a61 626c 6520 6f70  g quantizable op
+0001b3e0: 732c 0a20 2020 2020 2020 2023 2064 7565  s,.        # due
+0001b3f0: 2074 6f20 6875 6765 2061 6363 7572 6163   to huge accurac
+0001b400: 7920 7265 6772 6573 7369 6f6e 2069 6e20  y regression in 
+0001b410: 5079 546f 7263 682e 0a20 2020 2020 2020  PyTorch..       
+0001b420: 2061 6464 6974 696f 6e61 6c5f 736b 6970   additional_skip
+0001b430: 7065 645f 6d6f 6475 6c65 5f63 6c61 7373  ped_module_class
+0001b440: 6573 203d 205b 274c 6179 6572 4e6f 726d  es = ['LayerNorm
+0001b450: 272c 2027 496e 7374 616e 6365 4e6f 726d  ', 'InstanceNorm
+0001b460: 3364 272c 2027 456d 6265 6464 696e 6727  3d', 'Embedding'
+0001b470: 2c20 2744 726f 706f 7574 275d 0a20 2020  , 'Dropout'].   
+0001b480: 2020 2020 2069 6620 7365 6c66 2e61 7070       if self.app
+0001b490: 726f 6163 6820 3d3d 2027 706f 7374 5f74  roach == 'post_t
+0001b4a0: 7261 696e 696e 675f 6479 6e61 6d69 635f  raining_dynamic_
+0001b4b0: 7175 616e 7427 3a0a 2020 2020 2020 2020  quant':.        
+0001b4c0: 2020 2020 6164 6469 7469 6f6e 616c 5f73      additional_s
+0001b4d0: 6b69 7070 6564 5f6d 6f64 756c 655f 636c  kipped_module_cl
+0001b4e0: 6173 7365 732e 7265 6d6f 7665 2827 456d  asses.remove('Em
+0001b4f0: 6265 6464 696e 6727 290a 2020 2020 2020  bedding').      
+0001b500: 2020 6375 7374 6f6d 5f6e 6f6e 5f71 7561    custom_non_qua
+0001b510: 6e74 5f64 6963 745b 2773 6b69 7070 6564  nt_dict['skipped
+0001b520: 5f6d 6f64 756c 655f 636c 6173 7365 7327  _module_classes'
+0001b530: 5d20 2b3d 2061 6464 6974 696f 6e61 6c5f  ] += additional_
+0001b540: 736b 6970 7065 645f 6d6f 6475 6c65 5f63  skipped_module_c
+0001b550: 6c61 7373 6573 0a20 2020 2020 2020 2072  lasses.        r
+0001b560: 6574 7572 6e20 6375 7374 6f6d 5f6e 6f6e  eturn custom_non
+0001b570: 5f71 7561 6e74 5f64 6963 740a 0a0a 756e  _quant_dict...un
+0001b580: 6966 795f 6f70 5f74 7970 655f 6d61 7070  ify_op_type_mapp
+0001b590: 696e 675f 6970 6578 203d 207b 0a20 2020  ing_ipex = {.   
+0001b5a0: 2022 436f 6e76 6f6c 7574 696f 6e5f 5265   "Convolution_Re
+0001b5b0: 6c75 223a 2022 636f 6e76 3264 222c 0a20  lu": "conv2d",. 
+0001b5c0: 2020 2022 436f 6e76 6f6c 7574 696f 6e5f     "Convolution_
+0001b5d0: 5375 6d5f 5265 6c75 223a 2022 636f 6e76  Sum_Relu": "conv
+0001b5e0: 3264 222c 0a20 2020 2022 436f 6e76 6f6c  2d",.    "Convol
+0001b5f0: 7574 696f 6e5f 4261 7463 684e 6f72 6d22  ution_BatchNorm"
+0001b600: 3a20 2263 6f6e 7632 6422 2c0a 2020 2020  : "conv2d",.    
+0001b610: 223c 636c 6173 7320 2774 6f72 6368 2e6e  "<class 'torch.n
+0001b620: 6e2e 6d6f 6475 6c65 732e 636f 6e76 2e43  n.modules.conv.C
+0001b630: 6f6e 7631 6427 3e22 3a20 2263 6f6e 7631  onv1d'>": "conv1
+0001b640: 6422 2c0a 2020 2020 223c 636c 6173 7320  d",.    "<class 
+0001b650: 2774 6f72 6368 2e6e 6e2e 6d6f 6475 6c65  'torch.nn.module
+0001b660: 732e 636f 6e76 2e43 6f6e 7632 6427 3e22  s.conv.Conv2d'>"
+0001b670: 3a20 2263 6f6e 7632 6422 2c0a 2020 2020  : "conv2d",.    
+0001b680: 223c 636c 6173 7320 2774 6f72 6368 2e6e  "<class 'torch.n
+0001b690: 6e2e 6d6f 6475 6c65 732e 636f 6e76 2e43  n.modules.conv.C
+0001b6a0: 6f6e 7633 6427 3e22 3a20 2263 6f6e 7633  onv3d'>": "conv3
+0001b6b0: 6422 2c0a 2020 2020 223c 636c 6173 7320  d",.    "<class 
+0001b6c0: 2774 6f72 6368 2e6e 6e2e 6d6f 6475 6c65  'torch.nn.module
+0001b6d0: 732e 6163 7469 7661 7469 6f6e 2e52 654c  s.activation.ReL
+0001b6e0: 5527 3e22 3a20 2272 656c 7522 2c0a 2020  U'>": "relu",.  
+0001b6f0: 2020 223c 6d65 7468 6f64 2027 6164 6427    "<method 'add'
+0001b700: 206f 6620 2774 6f72 6368 2e5f 432e 5f54   of 'torch._C._T
+0001b710: 656e 736f 7242 6173 6527 206f 626a 6563  ensorBase' objec
+0001b720: 7473 3e22 3a20 2261 6464 222c 0a20 2020  ts>": "add",.   
+0001b730: 2022 3c63 6c61 7373 2027 746f 7263 682e   "<class 'torch.
+0001b740: 6e6e 2e6d 6f64 756c 6573 2e70 6f6f 6c69  nn.modules.pooli
+0001b750: 6e67 2e41 6461 7074 6976 6541 7667 506f  ng.AdaptiveAvgPo
+0001b760: 6f6c 3264 273e 223a 2022 6164 6170 7469  ol2d'>": "adapti
+0001b770: 7665 6176 6770 6f6f 6c32 6422 2c0a 2020  veavgpool2d",.  
+0001b780: 2020 224c 696e 6561 725f 5265 6c75 223a    "Linear_Relu":
+0001b790: 2022 6c69 6e65 6172 222c 0a20 2020 2022   "linear",.    "
+0001b7a0: 3c63 6c61 7373 2027 746f 7263 682e 6e6e  <class 'torch.nn
+0001b7b0: 2e6d 6f64 756c 6573 2e6c 696e 6561 722e  .modules.linear.
+0001b7c0: 4c69 6e65 6172 273e 223a 2022 6c69 6e65  Linear'>": "line
+0001b7d0: 6172 222c 0a20 2020 2022 3c63 6c61 7373  ar",.    "<class
+0001b7e0: 2027 746f 7263 682e 6e6e 2e6d 6f64 756c   'torch.nn.modul
+0001b7f0: 6573 2e70 6f6f 6c69 6e67 2e4d 6178 506f  es.pooling.MaxPo
+0001b800: 6f6c 3264 273e 223a 2022 6d61 7870 6f6f  ol2d'>": "maxpoo
+0001b810: 6c32 6422 0a7d 0a0a 0a40 6164 6170 746f  l2d".}...@adapto
+0001b820: 725f 7265 6769 7374 7279 0a63 6c61 7373  r_registry.class
+0001b830: 2050 7954 6f72 6368 5f49 5045 5841 6461   PyTorch_IPEXAda
+0001b840: 7074 6f72 2854 656d 706c 6174 6541 6461  ptor(TemplateAda
+0001b850: 7074 6f72 293a 2020 2320 7072 6167 6d61  ptor):  # pragma
+0001b860: 3a20 6e6f 2063 6f76 6572 0a20 2020 2022  : no cover.    "
+0001b870: 2222 4164 6170 746f 7220 6f66 2050 7954  ""Adaptor of PyT
+0001b880: 6f72 6368 2066 7261 6d65 776f 726b 2077  orch framework w
+0001b890: 6974 6820 496e 7465 6c20 5079 546f 7263  ith Intel PyTorc
+0001b8a0: 6820 4578 7465 6e73 696f 6e2c 0a20 2020  h Extension,.   
+0001b8b0: 2020 2020 616c 6c20 5079 546f 7263 6820      all PyTorch 
+0001b8c0: 4950 4558 2041 5049 2069 7320 696e 2074  IPEX API is in t
+0001b8d0: 6869 7320 636c 6173 732e 0a0a 2020 2020  his class...    
+0001b8e0: 4172 6773 3a0a 2020 2020 2020 2020 6672  Args:.        fr
+0001b8f0: 616d 6577 6f72 6b5f 7370 6563 6966 6963  amework_specific
+0001b900: 5f69 6e66 6f20 2864 6963 7429 3a20 6469  _info (dict): di
+0001b910: 6374 696f 6e61 7279 206f 6620 7475 6e69  ctionary of tuni
+0001b920: 6e67 2063 6f6e 6669 6775 7265 2066 726f  ng configure fro
+0001b930: 6d20 7961 6d6c 2066 696c 652e 0a20 2020  m yaml file..   
+0001b940: 2022 2222 0a20 2020 2064 6566 205f 5f69   """.    def __i
+0001b950: 6e69 745f 5f28 7365 6c66 2c20 6672 616d  nit__(self, fram
+0001b960: 6577 6f72 6b5f 7370 6563 6966 6963 5f69  ework_specific_i
+0001b970: 6e66 6f29 3a0a 2020 2020 2020 2020 7375  nfo):.        su
+0001b980: 7065 7228 5079 546f 7263 685f 4950 4558  per(PyTorch_IPEX
+0001b990: 4164 6170 746f 722c 2073 656c 6629 2e5f  Adaptor, self)._
+0001b9a0: 5f69 6e69 745f 5f28 6672 616d 6577 6f72  _init__(framewor
+0001b9b0: 6b5f 7370 6563 6966 6963 5f69 6e66 6f29  k_specific_info)
+0001b9c0: 0a20 2020 2020 2020 2073 656c 662e 7665  .        self.ve
+0001b9d0: 7273 696f 6e20 3d20 6765 745f 746f 7263  rsion = get_torc
+0001b9e0: 685f 7665 7273 696f 6e28 290a 2020 2020  h_version().    
+0001b9f0: 2020 2020 7175 6572 795f 636f 6e66 6967      query_config
+0001ba00: 5f66 696c 6520 3d20 2270 7974 6f72 6368  _file = "pytorch
+0001ba10: 5f69 7065 782e 7961 6d6c 220a 2020 2020  _ipex.yaml".    
+0001ba20: 2020 2020 7365 6c66 2e71 7565 7279 5f68      self.query_h
+0001ba30: 616e 646c 6572 203d 2050 7954 6f72 6368  andler = PyTorch
+0001ba40: 5175 6572 7928 0a20 2020 2020 2020 2020  Query(.         
+0001ba50: 2020 206c 6f63 616c 5f63 6f6e 6669 675f     local_config_
+0001ba60: 6669 6c65 3d6f 732e 7061 7468 2e6a 6f69  file=os.path.joi
+0001ba70: 6e28 6f73 2e70 6174 682e 6469 726e 616d  n(os.path.dirnam
+0001ba80: 6528 5f5f 6669 6c65 5f5f 292c 2071 7565  e(__file__), que
+0001ba90: 7279 5f63 6f6e 6669 675f 6669 6c65 2929  ry_config_file))
+0001baa0: 0a20 2020 2020 2020 2073 656c 662e 6366  .        self.cf
+0001bab0: 6773 203d 204e 6f6e 650a 2020 2020 2020  gs = None.      
+0001bac0: 2020 7365 6c66 2e66 7573 655f 6f70 7320    self.fuse_ops 
+0001bad0: 3d20 4e6f 6e65 0a20 2020 2020 2020 2073  = None.        s
+0001bae0: 656c 662e 6f70 5f69 6e66 6f73 5f66 726f  elf.op_infos_fro
+0001baf0: 6d5f 6366 6773 203d 204e 6f6e 650a 2020  m_cfgs = None.  
+0001bb00: 2020 2020 2020 7365 6c66 2e6f 7574 7075        self.outpu
+0001bb10: 745f 7465 6e73 6f72 5f69 645f 6f70 5f6e  t_tensor_id_op_n
+0001bb20: 616d 6520 3d20 4e6f 6e65 0a20 2020 2020  ame = None.     
+0001bb30: 2020 2073 656c 662e 6970 6578 5f63 6f6e     self.ipex_con
+0001bb40: 6669 675f 7061 7468 203d 205c 0a20 2020  fig_path = \.   
+0001bb50: 2020 2020 2020 2020 206f 732e 7061 7468           os.path
+0001bb60: 2e6a 6f69 6e28 7365 6c66 2e77 6f72 6b73  .join(self.works
+0001bb70: 7061 6365 5f70 6174 682c 2027 6970 6578  pace_path, 'ipex
+0001bb80: 5f63 6f6e 6669 675f 746d 702e 6a73 6f6e  _config_tmp.json
+0001bb90: 2729 0a0a 2020 2020 2020 2020 7472 793a  ')..        try:
+0001bba0: 0a20 2020 2020 2020 2020 2020 206f 732e  .            os.
+0001bbb0: 7265 6d6f 7665 2873 656c 662e 6970 6578  remove(self.ipex
+0001bbc0: 5f63 6f6e 6669 675f 7061 7468 290a 2020  _config_path).  
+0001bbd0: 2020 2020 2020 6578 6365 7074 3a0a 2020        except:.  
+0001bbe0: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
+0001bbf0: 2e77 6172 6e69 6e67 2827 4661 696c 2074  .warning('Fail t
+0001bc00: 6f20 7265 6d6f 7665 207b 7d2e 272e 666f  o remove {}.'.fo
+0001bc10: 726d 6174 2873 656c 662e 6970 6578 5f63  rmat(self.ipex_c
+0001bc20: 6f6e 6669 675f 7061 7468 2929 0a20 2020  onfig_path)).   
+0001bc30: 2020 2020 2073 656c 662e 6465 7669 6365       self.device
+0001bc40: 203d 2027 6970 6578 270a 2020 2020 2020   = 'ipex'.      
+0001bc50: 2020 7365 6c66 2e74 6d70 5f6d 6f64 656c    self.tmp_model
+0001bc60: 203d 204e 6f6e 650a 0a20 2020 2040 6475   = None..    @du
+0001bc70: 6d70 5f65 6c61 7073 6564 5f74 696d 6528  mp_elapsed_time(
+0001bc80: 2250 6173 7320 7175 616e 7469 7a65 206d  "Pass quantize m
+0001bc90: 6f64 656c 2229 0a20 2020 2064 6566 2071  odel").    def q
+0001bca0: 7561 6e74 697a 6528 7365 6c66 2c20 7475  uantize(self, tu
+0001bcb0: 6e65 5f63 6667 2c20 6d6f 6465 6c2c 2064  ne_cfg, model, d
+0001bcc0: 6174 616c 6f61 6465 722c 2071 5f66 756e  ataloader, q_fun
+0001bcd0: 633d 4e6f 6e65 293a 0a20 2020 2020 2020  c=None):.       
+0001bce0: 2022 2222 4578 6563 7574 6520 7468 6520   """Execute the 
+0001bcf0: 7175 616e 7469 7a65 2070 726f 6365 7373  quantize process
+0001bd00: 206f 6e20 7468 6520 7370 6563 6966 6965   on the specifie
+0001bd10: 6420 6d6f 6465 6c2e 0a0a 2020 2020 2020  d model...      
+0001bd20: 2020 4172 6773 3a0a 2020 2020 2020 2020    Args:.        
+0001bd30: 2020 2020 7475 6e65 5f63 6667 2028 6469      tune_cfg (di
+0001bd40: 6374 293a 2071 7561 6e74 697a 6174 696f  ct): quantizatio
+0001bd50: 6e20 636f 6e66 6967 2e0a 2020 2020 2020  n config..      
+0001bd60: 2020 2020 2020 6d6f 6465 6c20 286f 626a        model (obj
+0001bd70: 6563 7429 3a20 6d6f 6465 6c20 6e65 6564  ect): model need
+0001bd80: 2074 6f20 646f 2071 7561 6e74 697a 6174   to do quantizat
+0001bd90: 696f 6e2c 2069 7420 6973 204e 6575 7261  ion, it is Neura
+0001bda0: 6c20 436f 6d70 7265 7373 6f72 206d 6f64  l Compressor mod
+0001bdb0: 656c 2e0a 2020 2020 2020 2020 2020 2020  el..            
+0001bdc0: 6461 7461 6c6f 6164 6572 2028 6f62 6a65  dataloader (obje
+0001bdd0: 6374 293a 2063 616c 6962 7261 7469 6f6e  ct): calibration
+0001bde0: 2064 6174 6173 6574 2e0a 2020 2020 2020   dataset..      
+0001bdf0: 2020 2020 2020 715f 6675 6e63 2028 6f62        q_func (ob
+0001be00: 6a65 7874 2c20 6f70 7469 6f6e 616c 293a  jext, optional):
+0001be10: 2074 7261 696e 696e 6720 6675 6e63 7469   training functi
+0001be20: 6f6e 2066 6f72 2071 7561 6e74 697a 6174  on for quantizat
+0001be30: 696f 6e20 6177 6172 6520 7472 6169 6e69  ion aware traini
+0001be40: 6e67 206d 6f64 652e 0a0a 2020 2020 2020  ng mode...      
+0001be50: 2020 5265 7475 726e 733a 0a20 2020 2020    Returns:.     
+0001be60: 2020 2020 2020 2028 6469 6374 293a 2071         (dict): q
+0001be70: 7561 6e74 697a 6564 206d 6f64 656c 0a20  uantized model. 
+0001be80: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
+0001be90: 2020 2020 2320 466f 7220 736d 6f6f 7468      # For smooth
+0001bea0: 7175 616e 7420 6f70 7469 6d69 7a65 6420  quant optimized 
+0001beb0: 6d6f 6465 6c0a 2020 2020 2020 2020 7265  model.        re
+0001bec0: 6369 7065 5f63 6667 7320 3d20 7475 6e65  cipe_cfgs = tune
+0001bed0: 5f63 6667 2e67 6574 2827 7265 6369 7065  _cfg.get('recipe
+0001bee0: 5f63 6667 7327 2c20 4e6f 6e65 290a 2020  _cfgs', None).  
+0001bef0: 2020 2020 2020 6966 2072 6563 6970 655f        if recipe_
+0001bf00: 6366 6773 2061 6e64 2072 6563 6970 655f  cfgs and recipe_
+0001bf10: 6366 6773 2e67 6574 2827 736d 6f6f 7468  cfgs.get('smooth
+0001bf20: 5f71 7561 6e74 272c 2046 616c 7365 2920  _quant', False) 
+0001bf30: 5c0a 2020 2020 2020 2020 2020 616e 6420  \.          and 
+0001bf40: 7365 6c66 2e76 6572 7369 6f6e 2e72 656c  self.version.rel
+0001bf50: 6561 7365 203e 3d20 5665 7273 696f 6e28  ease >= Version(
+0001bf60: 2232 2e31 2229 2e72 656c 6561 7365 205c  "2.1").release \
+0001bf70: 0a20 2020 2020 2020 2020 2061 6e64 2073  .          and s
+0001bf80: 656c 662e 6170 7072 6f61 6368 2021 3d20  elf.approach != 
+0001bf90: 2770 6f73 745f 7472 6169 6e69 6e67 5f64  'post_training_d
+0001bfa0: 796e 616d 6963 5f71 7561 6e74 273a 0a20  ynamic_quant':. 
+0001bfb0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0001bfc0: 6e20 7365 6c66 2e71 6471 5f71 7561 6e74  n self.qdq_quant
+0001bfd0: 697a 6528 6d6f 6465 6c2c 2074 756e 655f  ize(model, tune_
+0001bfe0: 6366 672c 2064 6174 616c 6f61 6465 7229  cfg, dataloader)
+0001bff0: 0a0a 2020 2020 2020 2020 6173 7365 7274  ..        assert
+0001c000: 2073 656c 662e 6170 7072 6f61 6368 2021   self.approach !
+0001c010: 3d20 2771 7561 6e74 5f61 7761 7265 5f74  = 'quant_aware_t
+0001c020: 7261 696e 696e 6727 2c20 5c0a 2020 2020  raining', \.    
+0001c030: 2020 2020 2020 2020 2249 6e74 656c 2050          "Intel P
+0001c040: 7954 6f72 6368 2045 7874 656e 7369 6f6e  yTorch Extension
+0001c050: 2064 6964 6e27 7420 7375 7070 6f72 7420   didn't support 
+0001c060: 7175 616e 7469 7a61 7469 6f6e 2061 7761  quantization awa
+0001c070: 7265 2074 7261 696e 696e 6720 6d6f 6465  re training mode
+0001c080: 220a 2020 2020 2020 2020 6173 7365 7274  ".        assert
+0001c090: 206e 6f74 2073 656c 662e 7665 7273 696f   not self.versio
+0001c0a0: 6e2e 7265 6c65 6173 6520 3c20 5665 7273  n.release < Vers
+0001c0b0: 696f 6e28 2231 2e31 302e 3022 292e 7265  ion("1.10.0").re
+0001c0c0: 6c65 6173 652c 205c 0a20 2020 2020 2020  lease, \.       
+0001c0d0: 2020 2020 2020 2020 2022 494e 4320 7375           "INC su
+0001c0e0: 7070 6f72 7420 4950 4558 2076 6572 7369  pport IPEX versi
+0001c0f0: 6f6e 203e 3d20 312e 3130 2e30 220a 0a20  on >= 1.10.0".. 
+0001c100: 2020 2020 2020 2071 7363 6865 6d65 203d         qscheme =
+0001c110: 2073 656c 662e 5f63 6667 5f74 6f5f 7163   self._cfg_to_qc
+0001c120: 6f6e 6669 6728 7475 6e65 5f63 6667 290a  onfig(tune_cfg).
+0001c130: 2020 2020 2020 2020 6974 6572 6174 696f          iteratio
+0001c140: 6e73 203d 2074 756e 655f 6366 672e 6765  ns = tune_cfg.ge
+0001c150: 7428 2763 616c 6962 5f69 7465 7261 7469  t('calib_iterati
+0001c160: 6f6e 272c 2031 290a 2020 2020 2020 2020  on', 1).        
+0001c170: 6d6f 6465 6c2e 6d6f 6465 6c2e 6576 616c  model.model.eval
+0001c180: 2829 0a0a 2020 2020 2020 2020 6966 2073  ()..        if s
+0001c190: 656c 662e 7065 7266 6f72 6d61 6e63 655f  elf.performance_
+0001c1a0: 6f6e 6c79 3a0a 2020 2020 2020 2020 2020  only:.          
+0001c1b0: 2020 6966 2068 6173 6174 7472 286d 6f64    if hasattr(mod
+0001c1c0: 656c 2e6d 6f64 656c 2c20 2273 6176 655f  el.model, "save_
+0001c1d0: 7163 6f6e 665f 7375 6d6d 6172 7922 293a  qconf_summary"):
+0001c1e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c1f0: 2071 5f6d 6f64 656c 203d 206d 6f64 656c   q_model = model
+0001c200: 2e6d 6f64 656c 0a20 2020 2020 2020 2020  .model.         
+0001c210: 2020 2020 2020 2071 5f6d 6f64 656c 2e6c         q_model.l
+0001c220: 6f61 645f 7163 6f6e 665f 7375 6d6d 6172  oad_qconf_summar
+0001c230: 7928 7163 6f6e 665f 7375 6d6d 6172 793d  y(qconf_summary=
+0001c240: 7365 6c66 2e69 7065 785f 636f 6e66 6967  self.ipex_config
+0001c250: 5f70 6174 6829 0a20 2020 2020 2020 2020  _path).         
+0001c260: 2020 2020 2020 2069 6620 715f 6675 6e63         if q_func
+0001c270: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+0001c280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c290: 2020 715f 6675 6e63 2871 5f6d 6f64 656c    q_func(q_model
+0001c2a0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0001c2b0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0001c2c0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0001c2d0: 2e6d 6f64 656c 5f63 616c 6962 7261 7469  .model_calibrati
+0001c2e0: 6f6e 2871 5f6d 6f64 656c 2c20 6461 7461  on(q_model, data
+0001c2f0: 6c6f 6164 6572 2c20 6974 6572 6174 696f  loader, iteratio
+0001c300: 6e73 2c20 4e6f 6e65 2c0a 2020 2020 2020  ns, None,.      
+0001c310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c330: 2020 2020 2074 756e 655f 6366 672e 6765       tune_cfg.ge
+0001c340: 7428 2763 616c 6962 5f73 616d 706c 696e  t('calib_samplin
+0001c350: 675f 7369 7a65 272c 2031 2929 0a20 2020  g_size', 1)).   
+0001c360: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+0001c370: 6f64 656c 2e73 6176 655f 7163 6f6e 665f  odel.save_qconf_
+0001c380: 7375 6d6d 6172 7928 7163 6f6e 665f 7375  summary(qconf_su
+0001c390: 6d6d 6172 793d 7365 6c66 2e69 7065 785f  mmary=self.ipex_
+0001c3a0: 636f 6e66 6967 5f70 6174 6829 0a20 2020  config_path).   
+0001c3b0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0001c3c0: 7365 6c66 2e75 7365 5f62 6631 3620 616e  self.use_bf16 an
+0001c3d0: 6420 2843 7075 496e 666f 2829 2e62 6631  d (CpuInfo().bf1
+0001c3e0: 3620 6f72 206f 732e 6765 7465 6e76 2827  6 or os.getenv('
+0001c3f0: 464f 5243 455f 4246 3136 2729 203d 3d20  FORCE_BF16') == 
+0001c400: 2731 2729 2061 6e64 205c 0a20 2020 2020  '1') and \.     
+0001c410: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+0001c420: 7365 6c66 2e76 6572 7369 6f6e 2e72 656c  self.version.rel
+0001c430: 6561 7365 203e 3d20 5665 7273 696f 6e28  ease >= Version(
+0001c440: 2231 2e31 312e 3022 292e 7265 6c65 6173  "1.11.0").releas
+0001c450: 6529 3a0a 2020 2020 2020 2020 2020 2020  e):.            
+0001c460: 2020 2020 2020 2020 7769 7468 2074 6f72          with tor
+0001c470: 6368 2e6e 6f5f 6772 6164 2829 3a0a 2020  ch.no_grad():.  
+0001c480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c490: 2020 2020 2020 7769 7468 2074 6f72 6368        with torch
+0001c4a0: 2e63 7075 2e61 6d70 2e61 7574 6f63 6173  .cpu.amp.autocas
+0001c4b0: 7428 293a 0a20 2020 2020 2020 2020 2020  t():.           
+0001c4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c4d0: 2071 5f6d 6f64 656c 203d 2069 7065 782e   q_model = ipex.
+0001c4e0: 7175 616e 7469 7a61 7469 6f6e 2e63 6f6e  quantization.con
+0001c4f0: 7665 7274 2871 5f6d 6f64 656c 2c20 696e  vert(q_model, in
+0001c500: 706c 6163 653d 5472 7565 290a 2020 2020  place=True).    
+0001c510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c520: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+0001c530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c540: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+0001c550: 6f64 656c 203d 2074 6f72 6368 2e6a 6974  odel = torch.jit
+0001c560: 2e74 7261 6365 2871 5f6d 6f64 656c 2c20  .trace(q_model, 
+0001c570: 7365 6c66 2e65 7861 6d70 6c65 5f69 6e70  self.example_inp
+0001c580: 7574 7329 0a20 2020 2020 2020 2020 2020  uts).           
+0001c590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c5a0: 2020 2020 2071 5f6d 6f64 656c 203d 2074       q_model = t
+0001c5b0: 6f72 6368 2e6a 6974 2e66 7265 657a 6528  orch.jit.freeze(
+0001c5c0: 715f 6d6f 6465 6c2e 6576 616c 2829 290a  q_model.eval()).
+0001c5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c5e0: 2020 2020 2020 2020 2020 2020 6578 6365              exce
+0001c5f0: 7074 3a0a 2020 2020 2020 2020 2020 2020  pt:.            
+0001c600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c610: 2020 2020 715f 6d6f 6465 6c20 3d20 746f      q_model = to
+0001c620: 7263 682e 6a69 742e 7472 6163 6528 715f  rch.jit.trace(q_
+0001c630: 6d6f 6465 6c2c 2073 656c 662e 6578 616d  model, self.exam
+0001c640: 706c 655f 696e 7075 7473 2c20 7374 7269  ple_inputs, stri
+0001c650: 6374 3d46 616c 7365 290a 2020 2020 2020  ct=False).      
+0001c660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c670: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
+0001c680: 6c20 3d20 746f 7263 682e 6a69 742e 6672  l = torch.jit.fr
+0001c690: 6565 7a65 2871 5f6d 6f64 656c 2e65 7661  eeze(q_model.eva
+0001c6a0: 6c28 2929 0a20 2020 2020 2020 2020 2020  l()).           
+0001c6b0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0001c6c0: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+0001c6d0: 5f6d 6f64 656c 203d 2069 7065 782e 7175  _model = ipex.qu
+0001c6e0: 616e 7469 7a61 7469 6f6e 2e63 6f6e 7665  antization.conve
+0001c6f0: 7274 2871 5f6d 6f64 656c 2c20 696e 706c  rt(q_model, inpl
+0001c700: 6163 653d 5472 7565 290a 2020 2020 2020  ace=True).      
+0001c710: 2020 2020 2020 2020 2020 2020 2020 7769                wi
+0001c720: 7468 2074 6f72 6368 2e6e 6f5f 6772 6164  th torch.no_grad
+0001c730: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+0001c740: 2020 2020 2020 2020 2020 2020 7472 793a              try:
+0001c750: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c760: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+0001c770: 6f64 656c 203d 2074 6f72 6368 2e6a 6974  odel = torch.jit
+0001c780: 2e74 7261 6365 2871 5f6d 6f64 656c 2c20  .trace(q_model, 
+0001c790: 7365 6c66 2e65 7861 6d70 6c65 5f69 6e70  self.example_inp
+0001c7a0: 7574 7329 0a20 2020 2020 2020 2020 2020  uts).           
+0001c7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c7c0: 2071 5f6d 6f64 656c 203d 2074 6f72 6368   q_model = torch
+0001c7d0: 2e6a 6974 2e66 7265 657a 6528 715f 6d6f  .jit.freeze(q_mo
+0001c7e0: 6465 6c2e 6576 616c 2829 290a 2020 2020  del.eval()).    
+0001c7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c800: 2020 2020 6578 6365 7074 3a0a 2020 2020      except:.    
+0001c810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c820: 2020 2020 2020 2020 715f 6d6f 6465 6c20          q_model 
+0001c830: 3d20 746f 7263 682e 6a69 742e 7472 6163  = torch.jit.trac
+0001c840: 6528 715f 6d6f 6465 6c2c 2073 656c 662e  e(q_model, self.
+0001c850: 6578 616d 706c 655f 696e 7075 7473 2c20  example_inputs, 
+0001c860: 7374 7269 6374 3d46 616c 7365 290a 2020  strict=False).  
+0001c870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c880: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
+0001c890: 6c20 3d20 746f 7263 682e 6a69 742e 6672  l = torch.jit.fr
+0001c8a0: 6565 7a65 2871 5f6d 6f64 656c 2e65 7661  eeze(q_model.eva
+0001c8b0: 6c28 2929 0a20 2020 2020 2020 2020 2020  l()).           
+0001c8c0: 2020 2020 2023 2041 6674 6572 2066 7265       # After fre
+0001c8d0: 657a 696e 672c 2072 756e 2031 2074 696d  ezing, run 1 tim
+0001c8e0: 6520 746f 2077 6172 6d20 7570 2074 6865  e to warm up the
+0001c8f0: 2070 726f 6669 6c69 6e67 2067 7261 7068   profiling graph
+0001c900: 2065 7865 6375 746f 7220 746f 2069 6e73   executor to ins
+0001c910: 6572 7420 7072 696d 3a3a 7072 6f66 696c  ert prim::profil
+0001c920: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+0001c930: 2020 2320 4174 2074 6865 2032 6e64 2072    # At the 2nd r
+0001c940: 756e 2c20 7468 6520 6c6c 6761 2070 6173  un, the llga pas
+0001c950: 7320 7769 6c6c 2062 6520 7472 6967 6765  s will be trigge
+0001c960: 7265 6420 616e 6420 7468 6520 6d6f 6465  red and the mode
+0001c970: 6c20 6973 2074 7572 6e65 6420 696e 746f  l is turned into
+0001c980: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c990: 2023 2061 6e20 696e 7438 206d 6f64 656c   # an int8 model
+0001c9a0: 3a20 7072 696d 3a3a 7072 6f66 696c 6520  : prim::profile 
+0001c9b0: 7769 6c6c 2062 6520 7265 6d6f 7665 6420  will be removed 
+0001c9c0: 616e 6420 7769 6c6c 2068 6176 6520 4c6c  and will have Ll
+0001c9d0: 6761 4675 7369 6f6e 4772 6f75 7020 696e  gaFusionGroup in
+0001c9e0: 2074 6865 2067 7261 7068 0a20 2020 2020   the graph.     
+0001c9f0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0001ca00: 6361 6c69 625f 6675 6e63 2871 5f6d 6f64  calib_func(q_mod
+0001ca10: 656c 2c20 6461 7461 6c6f 6164 6572 2c20  el, dataloader, 
+0001ca20: 746d 705f 6974 6572 6174 696f 6e73 3d32  tmp_iterations=2
+0001ca30: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
+0001ca40: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+0001ca50: 2020 2020 6173 7365 7274 206e 6f74 2073      assert not s
+0001ca60: 656c 662e 7665 7273 696f 6e2e 7265 6c65  elf.version.rele
+0001ca70: 6173 6520 3c20 5665 7273 696f 6e28 2231  ase < Version("1
+0001ca80: 2e31 302e 3022 292e 7265 6c65 6173 652c  .10.0").release,
+0001ca90: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0001caa0: 2020 2020 2020 2022 494e 4320 7375 7070         "INC supp
+0001cab0: 6f72 7420 4950 4558 2076 6572 7369 6f6e  ort IPEX version
+0001cac0: 203e 3d20 312e 3130 2e30 220a 2020 2020   >= 1.10.0".    
+0001cad0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+0001cae0: 656c 662e 6170 7072 6f61 6368 2069 6e20  elf.approach in 
+0001caf0: 5b27 706f 7374 5f74 7261 696e 696e 675f  ['post_training_
+0001cb00: 7374 6174 6963 5f71 7561 6e74 272c 2027  static_quant', '
+0001cb10: 706f 7374 5f74 7261 696e 696e 675f 6175  post_training_au
+0001cb20: 746f 5f71 7561 6e74 275d 3a0a 2020 2020  to_quant']:.    
+0001cb30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cb40: 715f 6d6f 6465 6c20 3d20 6d6f 6465 6c2e  q_model = model.
+0001cb50: 6d6f 6465 6c0a 2020 2020 2020 2020 2020  model.          
+0001cb60: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+0001cb70: 662e 7665 7273 696f 6e2e 7265 6c65 6173  f.version.releas
+0001cb80: 6520 3c20 5665 7273 696f 6e28 2231 2e31  e < Version("1.1
+0001cb90: 322e 3022 292e 7265 6c65 6173 653a 0a20  2.0").release:. 
 0001cba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cbc0: 696e 706c 6163 653d 5472 7565 2920 2023  inplace=True)  #
-0001cbd0: 2070 796c 696e 743a 2064 6973 6162 6c65   pylint: disable
-0001cbe0: 3d45 3131 3231 0a20 2020 2020 2020 2020  =E1121.         
-0001cbf0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0001cc00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001cc10: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-0001cc20: 2e74 6d70 5f6d 6f64 656c 2069 7320 4e6f  .tmp_model is No
-0001cc30: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+0001cbb0: 2020 2020 2020 2069 7065 785f 636f 6e66         ipex_conf
+0001cbc0: 203d 2069 7065 782e 7175 616e 7469 7a61   = ipex.quantiza
+0001cbd0: 7469 6f6e 2e51 7561 6e74 436f 6e66 2863  tion.QuantConf(c
+0001cbe0: 6f6e 6669 6775 7265 5f66 696c 653d 7365  onfigure_file=se
+0001cbf0: 6c66 2e69 7065 785f 636f 6e66 6967 5f70  lf.ipex_config_p
+0001cc00: 6174 682c 2020 2320 7079 6c69 6e74 3a20  ath,  # pylint: 
+0001cc10: 6469 7361 626c 653d 4531 3130 310a 2020  disable=E1101.  
+0001cc20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc30: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0001cc40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cc50: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
-0001cc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cc70: 2020 2020 2073 656c 662e 746d 705f 6d6f       self.tmp_mo
-0001cc80: 6465 6c20 3d20 636f 7079 2e64 6565 7063  del = copy.deepc
-0001cc90: 6f70 7928 6d6f 6465 6c29 0a20 2020 2020  opy(model).     
-0001cca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ccb0: 2020 2020 2020 2065 7863 6570 7420 4578         except Ex
-0001ccc0: 6365 7074 696f 6e20 6173 2065 3a20 2023  ception as e:  #
-0001ccd0: 2070 7261 676d 613a 206e 6f20 636f 7665   pragma: no cove
-0001cce0: 720a 2020 2020 2020 2020 2020 2020 2020  r.              
-0001ccf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cd00: 2020 6c6f 6767 6572 2e77 6172 6e69 6e67    logger.warning
-0001cd10: 2822 4661 696c 2074 6f20 6465 6570 2063  ("Fail to deep c
-0001cd20: 6f70 7920 7468 6520 6d6f 6465 6c20 6475  opy the model du
-0001cd30: 6520 746f 207b 7d2c 2069 6e70 6c61 6365  e to {}, inplace
-0001cd40: 2069 7320 7573 6564 206e 6f77 2e22 2e66   is used now.".f
-0001cd50: 6f72 6d61 7428 0a20 2020 2020 2020 2020  ormat(.         
+0001cc50: 2020 2020 2020 2020 2020 2020 2020 7173                qs
+0001cc60: 6368 656d 653d 7173 6368 656d 6529 0a20  cheme=qscheme). 
+0001cc70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc80: 2020 2020 2020 2073 656c 662e 6d6f 6465         self.mode
+0001cc90: 6c5f 6361 6c69 6272 6174 696f 6e28 715f  l_calibration(q_
+0001cca0: 6d6f 6465 6c2c 2064 6174 616c 6f61 6465  model, dataloade
+0001ccb0: 722c 2069 7465 7261 7469 6f6e 732c 2069  r, iterations, i
+0001ccc0: 7065 785f 636f 6e66 2c0a 2020 2020 2020  pex_conf,.      
+0001ccd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ccf0: 2020 2020 2020 2020 2074 756e 655f 6366           tune_cf
+0001cd00: 672e 6765 7428 2763 616c 6962 5f73 616d  g.get('calib_sam
+0001cd10: 706c 696e 675f 7369 7a65 272c 2031 2929  pling_size', 1))
+0001cd20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001cd30: 2020 2020 2020 2020 2069 7065 785f 636f           ipex_co
+0001cd40: 6e66 2e73 6176 6528 7365 6c66 2e69 7065  nf.save(self.ipe
+0001cd50: 785f 636f 6e66 6967 5f70 6174 6829 0a20  x_config_path). 
 0001cd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cd70: 2020 2020 2020 2020 2020 2072 6570 7228             repr(
-0001cd80: 6529 2929 0a20 2020 2020 2020 2020 2020  e))).           
-0001cd90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cda0: 2020 2020 2073 656c 662e 746d 705f 6d6f       self.tmp_mo
-0001cdb0: 6465 6c20 3d20 6d6f 6465 6c0a 2020 2020  del = model.    
-0001cdc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cdd0: 2020 2020 6672 6f6d 2074 6f72 6368 2e61      from torch.a
-0001cde0: 6f2e 7175 616e 7469 7a61 7469 6f6e 2069  o.quantization i
-0001cdf0: 6d70 6f72 7420 4d69 6e4d 6178 4f62 7365  mport MinMaxObse
-0001ce00: 7276 6572 2c20 5065 7243 6861 6e6e 656c  rver, PerChannel
-0001ce10: 4d69 6e4d 6178 4f62 7365 7276 6572 2c20  MinMaxObserver, 
-0001ce20: 5143 6f6e 6669 670a 2020 2020 2020 2020  QConfig.        
+0001cd70: 2020 2020 2020 2069 7065 785f 636f 6e66         ipex_conf
+0001cd80: 203d 2069 7065 782e 7175 616e 7469 7a61   = ipex.quantiza
+0001cd90: 7469 6f6e 2e51 7561 6e74 436f 6e66 2873  tion.QuantConf(s
+0001cda0: 656c 662e 6970 6578 5f63 6f6e 6669 675f  elf.ipex_config_
+0001cdb0: 7061 7468 2920 2020 2320 7079 6c69 6e74  path)   # pylint
+0001cdc0: 3a20 6469 7361 626c 653d 4531 3130 310a  : disable=E1101.
+0001cdd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cde0: 2020 2020 2020 2020 715f 6d6f 6465 6c20          q_model 
+0001cdf0: 3d20 6970 6578 2e71 7561 6e74 697a 6174  = ipex.quantizat
+0001ce00: 696f 6e2e 636f 6e76 6572 7428 715f 6d6f  ion.convert(q_mo
+0001ce10: 6465 6c2c 0a20 2020 2020 2020 2020 2020  del,.           
+0001ce20: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0001ce30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ce40: 7374 6174 6963 5f71 636f 6e66 6967 203d  static_qconfig =
-0001ce50: 2051 436f 6e66 6967 2861 6374 6976 6174   QConfig(activat
-0001ce60: 696f 6e3d 4d69 6e4d 6178 4f62 7365 7276  ion=MinMaxObserv
-0001ce70: 6572 2e77 6974 685f 6172 6773 280a 2020  er.with_args(.  
+0001ce40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ce50: 2069 7065 785f 636f 6e66 2c0a 2020 2020   ipex_conf,.    
+0001ce60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ce70: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0001ce80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ce90: 2020 2020 2020 2020 2020 7173 6368 656d            qschem
-0001cea0: 653d 746f 7263 682e 7065 725f 7465 6e73  e=torch.per_tens
-0001ceb0: 6f72 5f61 6666 696e 652c 2064 7479 7065  or_affine, dtype
-0001cec0: 3d74 6f72 6368 2e71 7569 6e74 3829 2c0a  =torch.quint8),.
+0001ce90: 2020 2020 2020 2020 7365 6c66 2e65 7861          self.exa
+0001cea0: 6d70 6c65 5f69 6e70 7574 732c 0a20 2020  mple_inputs,.   
+0001ceb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0001ced0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cee0: 2020 2020 2020 2020 2020 2020 7765 6967              weig
-0001cef0: 6874 3d50 6572 4368 616e 6e65 6c4d 696e  ht=PerChannelMin
-0001cf00: 4d61 784f 6273 6572 7665 722e 7769 7468  MaxObserver.with
-0001cf10: 5f61 7267 7328 6474 7970 653d 746f 7263  _args(dtype=torc
-0001cf20: 682e 7169 6e74 382c 205c 0a20 2020 2020  h.qint8, \.     
+0001cee0: 2020 2020 2020 2020 2069 6e70 6c61 6365           inplace
+0001cef0: 3d54 7275 6529 2020 2320 7079 6c69 6e74  =True)  # pylint
+0001cf00: 3a20 6469 7361 626c 653d 4531 3132 310a  : disable=E1121.
+0001cf10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cf20: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
 0001cf30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cf40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cf50: 2020 2071 7363 6865 6d65 3d74 6f72 6368     qscheme=torch
-0001cf60: 2e70 6572 5f63 6861 6e6e 656c 5f73 796d  .per_channel_sym
-0001cf70: 6d65 7472 6963 2929 0a0a 2020 2020 2020  metric))..      
-0001cf80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cf90: 2020 715f 6d6f 6465 6c20 3d20 6970 6578    q_model = ipex
-0001cfa0: 2e71 7561 6e74 697a 6174 696f 6e2e 7072  .quantization.pr
-0001cfb0: 6570 6172 6528 6d6f 6465 6c2e 5f6d 6f64  epare(model._mod
-0001cfc0: 656c 2c20 7374 6174 6963 5f71 636f 6e66  el, static_qconf
-0001cfd0: 6967 2c20 5c0a 2020 2020 2020 2020 2020  ig, \.          
-0001cfe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cf40: 2020 6672 6f6d 2074 6f72 6368 2e61 6f2e    from torch.ao.
+0001cf50: 7175 616e 7469 7a61 7469 6f6e 2069 6d70  quantization imp
+0001cf60: 6f72 7420 4d69 6e4d 6178 4f62 7365 7276  ort MinMaxObserv
+0001cf70: 6572 2c20 5065 7243 6861 6e6e 656c 4d69  er, PerChannelMi
+0001cf80: 6e4d 6178 4f62 7365 7276 6572 2c20 5143  nMaxObserver, QC
+0001cf90: 6f6e 6669 670a 2020 2020 2020 2020 2020  onfig.          
+0001cfa0: 2020 2020 2020 2020 2020 2020 2020 7374                st
+0001cfb0: 6174 6963 5f71 636f 6e66 6967 203d 2051  atic_qconfig = Q
+0001cfc0: 436f 6e66 6967 2861 6374 6976 6174 696f  Config(activatio
+0001cfd0: 6e3d 4d69 6e4d 6178 4f62 7365 7276 6572  n=MinMaxObserver
+0001cfe0: 2e77 6974 685f 6172 6773 280a 2020 2020  .with_args(.    
 0001cff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d000: 2020 2020 2020 6578 616d 706c 655f 696e        example_in
-0001d010: 7075 7473 3d73 656c 662e 6578 616d 706c  puts=self.exampl
-0001d020: 655f 696e 7075 7473 2c20 696e 706c 6163  e_inputs, inplac
-0001d030: 653d 4661 6c73 6529 0a20 2020 2020 2020  e=False).       
+0001d000: 2020 2020 2020 2020 7173 6368 656d 653d          qscheme=
+0001d010: 746f 7263 682e 7065 725f 7465 6e73 6f72  torch.per_tensor
+0001d020: 5f61 6666 696e 652c 2064 7479 7065 3d74  _affine, dtype=t
+0001d030: 6f72 6368 2e71 7569 6e74 3829 2c0a 2020  orch.quint8),.  
 0001d040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d050: 2071 5f6d 6f64 656c 2e6c 6f61 645f 7163   q_model.load_qc
-0001d060: 6f6e 665f 7375 6d6d 6172 7928 7163 6f6e  onf_summary(qcon
-0001d070: 665f 7375 6d6d 6172 793d 7365 6c66 2e69  f_summary=self.i
-0001d080: 7065 785f 636f 6e66 6967 5f70 6174 6829  pex_config_path)
-0001d090: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001d0a0: 2020 2020 2020 2020 2069 6620 715f 6675           if q_fu
-0001d0b0: 6e63 2069 7320 6e6f 7420 4e6f 6e65 3a0a  nc is not None:.
-0001d0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d0d0: 2020 2020 2020 2020 2020 2020 715f 6675              q_fu
-0001d0e0: 6e63 2871 5f6d 6f64 656c 290a 2020 2020  nc(q_model).    
+0001d050: 2020 2020 2020 2020 2020 7765 6967 6874            weight
+0001d060: 3d50 6572 4368 616e 6e65 6c4d 696e 4d61  =PerChannelMinMa
+0001d070: 784f 6273 6572 7665 722e 7769 7468 5f61  xObserver.with_a
+0001d080: 7267 7328 6474 7970 653d 746f 7263 682e  rgs(dtype=torch.
+0001d090: 7169 6e74 382c 205c 0a20 2020 2020 2020  qint8, \.       
+0001d0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d0c0: 2071 7363 6865 6d65 3d74 6f72 6368 2e70   qscheme=torch.p
+0001d0d0: 6572 5f63 6861 6e6e 656c 5f73 796d 6d65  er_channel_symme
+0001d0e0: 7472 6963 2929 0a0a 2020 2020 2020 2020  tric))..        
 0001d0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d100: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0001d110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d120: 2020 2020 2020 7365 6c66 2e6d 6f64 656c        self.model
-0001d130: 5f63 616c 6962 7261 7469 6f6e 2871 5f6d  _calibration(q_m
-0001d140: 6f64 656c 2c20 6461 7461 6c6f 6164 6572  odel, dataloader
-0001d150: 2c20 6974 6572 6174 696f 6e73 2c20 4e6f  , iterations, No
-0001d160: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
-0001d170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d190: 2020 2020 2020 2074 756e 655f 6366 672e         tune_cfg.
-0001d1a0: 6765 7428 2763 616c 6962 5f73 616d 706c  get('calib_sampl
-0001d1b0: 696e 675f 7369 7a65 272c 2031 2929 0a20  ing_size', 1)). 
-0001d1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d1d0: 2020 2020 2020 2071 5f6d 6f64 656c 2e73         q_model.s
-0001d1e0: 6176 655f 7163 6f6e 665f 7375 6d6d 6172  ave_qconf_summar
-0001d1f0: 7928 7163 6f6e 665f 7375 6d6d 6172 793d  y(qconf_summary=
-0001d200: 7365 6c66 2e69 7065 785f 636f 6e66 6967  self.ipex_config
-0001d210: 5f70 6174 6829 0a20 2020 2020 2020 2020  _path).         
-0001d220: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0001d230: 6620 7365 6c66 2e75 7365 5f62 6631 3620  f self.use_bf16 
-0001d240: 616e 6420 2843 7075 496e 666f 2829 2e62  and (CpuInfo().b
-0001d250: 6631 3620 6f72 206f 732e 6765 7465 6e76  f16 or os.getenv
-0001d260: 2827 464f 5243 455f 4246 3136 2729 203d  ('FORCE_BF16') =
-0001d270: 3d20 2731 2729 2061 6e64 205c 0a20 2020  = '1') and \.   
+0001d100: 715f 6d6f 6465 6c20 3d20 6970 6578 2e71  q_model = ipex.q
+0001d110: 7561 6e74 697a 6174 696f 6e2e 7072 6570  uantization.prep
+0001d120: 6172 6528 6d6f 6465 6c2e 5f6d 6f64 656c  are(model._model
+0001d130: 2c20 7374 6174 6963 5f71 636f 6e66 6967  , static_qconfig
+0001d140: 2c20 5c0a 2020 2020 2020 2020 2020 2020  , \.            
+0001d150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d170: 2020 2020 6578 616d 706c 655f 696e 7075      example_inpu
+0001d180: 7473 3d73 656c 662e 6578 616d 706c 655f  ts=self.example_
+0001d190: 696e 7075 7473 2c20 696e 706c 6163 653d  inputs, inplace=
+0001d1a0: 5472 7565 290a 2020 2020 2020 2020 2020  True).          
+0001d1b0: 2020 2020 2020 2020 2020 2020 2020 715f                q_
+0001d1c0: 6d6f 6465 6c2e 6c6f 6164 5f71 636f 6e66  model.load_qconf
+0001d1d0: 5f73 756d 6d61 7279 2871 636f 6e66 5f73  _summary(qconf_s
+0001d1e0: 756d 6d61 7279 3d73 656c 662e 6970 6578  ummary=self.ipex
+0001d1f0: 5f63 6f6e 6669 675f 7061 7468 290a 2020  _config_path).  
+0001d200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d210: 2020 2020 2020 6966 2071 5f66 756e 6320        if q_func 
+0001d220: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+0001d230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d240: 2020 2020 2020 2020 2071 5f66 756e 6328           q_func(
+0001d250: 715f 6d6f 6465 6c29 0a20 2020 2020 2020  q_model).       
+0001d260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d270: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
 0001d280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d290: 2020 2020 2020 2020 2028 7365 6c66 2e76           (self.v
-0001d2a0: 6572 7369 6f6e 2e72 656c 6561 7365 203e  ersion.release >
-0001d2b0: 3d20 5665 7273 696f 6e28 2231 2e31 312e  = Version("1.11.
-0001d2c0: 3022 292e 7265 6c65 6173 6529 3a0a 2020  0").release):.  
-0001d2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d2e0: 2020 2020 2020 2020 2020 7769 7468 2074            with t
-0001d2f0: 6f72 6368 2e6e 6f5f 6772 6164 2829 3a0a  orch.no_grad():.
-0001d300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d320: 7769 7468 2074 6f72 6368 2e63 7075 2e61  with torch.cpu.a
-0001d330: 6d70 2e61 7574 6f63 6173 7428 293a 0a20  mp.autocast():. 
-0001d340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d360: 2020 2071 5f6d 6f64 656c 203d 2069 7065     q_model = ipe
-0001d370: 782e 7175 616e 7469 7a61 7469 6f6e 2e63  x.quantization.c
-0001d380: 6f6e 7665 7274 2871 5f6d 6f64 656c 2c20  onvert(q_model, 
-0001d390: 696e 706c 6163 653d 5472 7565 290a 2020  inplace=True).  
-0001d3a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d3c0: 2020 7472 793a 0a20 2020 2020 2020 2020    try:.         
-0001d3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d3e0: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-0001d3f0: 5f6d 6f64 656c 203d 2074 6f72 6368 2e6a  _model = torch.j
-0001d400: 6974 2e74 7261 6365 2871 5f6d 6f64 656c  it.trace(q_model
-0001d410: 2c20 7365 6c66 2e65 7861 6d70 6c65 5f69  , self.example_i
-0001d420: 6e70 7574 7329 0a20 2020 2020 2020 2020  nputs).         
-0001d430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d440: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-0001d450: 5f6d 6f64 656c 203d 2074 6f72 6368 2e6a  _model = torch.j
-0001d460: 6974 2e66 7265 657a 6528 715f 6d6f 6465  it.freeze(q_mode
-0001d470: 6c2e 6576 616c 2829 290a 2020 2020 2020  l.eval()).      
-0001d480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d490: 2020 2020 2020 2020 2020 2020 2020 6578                ex
-0001d4a0: 6365 7074 3a0a 2020 2020 2020 2020 2020  cept:.          
+0001d290: 2020 2073 656c 662e 6d6f 6465 6c5f 6361     self.model_ca
+0001d2a0: 6c69 6272 6174 696f 6e28 715f 6d6f 6465  libration(q_mode
+0001d2b0: 6c2c 2064 6174 616c 6f61 6465 722c 2069  l, dataloader, i
+0001d2c0: 7465 7261 7469 6f6e 732c 204e 6f6e 652c  terations, None,
+0001d2d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001d2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d300: 2020 2020 7475 6e65 5f63 6667 2e67 6574      tune_cfg.get
+0001d310: 2827 6361 6c69 625f 7361 6d70 6c69 6e67  ('calib_sampling
+0001d320: 5f73 697a 6527 2c20 3129 290a 2020 2020  _size', 1)).    
+0001d330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d340: 2020 2020 715f 6d6f 6465 6c2e 7361 7665      q_model.save
+0001d350: 5f71 636f 6e66 5f73 756d 6d61 7279 2871  _qconf_summary(q
+0001d360: 636f 6e66 5f73 756d 6d61 7279 3d73 656c  conf_summary=sel
+0001d370: 662e 6970 6578 5f63 6f6e 6669 675f 7061  f.ipex_config_pa
+0001d380: 7468 290a 2020 2020 2020 2020 2020 2020  th).            
+0001d390: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+0001d3a0: 656c 662e 7573 655f 6266 3136 2061 6e64  elf.use_bf16 and
+0001d3b0: 2028 4370 7549 6e66 6f28 292e 6266 3136   (CpuInfo().bf16
+0001d3c0: 206f 7220 6f73 2e67 6574 656e 7628 2746   or os.getenv('F
+0001d3d0: 4f52 4345 5f42 4631 3627 2920 3d3d 2027  ORCE_BF16') == '
+0001d3e0: 3127 2920 616e 6420 5c0a 2020 2020 2020  1') and \.      
+0001d3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d400: 2020 2020 2020 2873 656c 662e 7665 7273        (self.vers
+0001d410: 696f 6e2e 7265 6c65 6173 6520 3e3d 2056  ion.release >= V
+0001d420: 6572 7369 6f6e 2822 312e 3131 2e30 2229  ersion("1.11.0")
+0001d430: 2e72 656c 6561 7365 293a 0a20 2020 2020  .release):.     
+0001d440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d450: 2020 2020 2020 2077 6974 6820 746f 7263         with torc
+0001d460: 682e 6e6f 5f67 7261 6428 293a 0a20 2020  h.no_grad():.   
+0001d470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d480: 2020 2020 2020 2020 2020 2020 2077 6974               wit
+0001d490: 6820 746f 7263 682e 6370 752e 616d 702e  h torch.cpu.amp.
+0001d4a0: 6175 746f 6361 7374 2829 3a0a 2020 2020  autocast():.    
 0001d4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d4c0: 2020 2020 2020 2020 2020 2020 2020 715f                q_
-0001d4d0: 6d6f 6465 6c20 3d20 746f 7263 682e 6a69  model = torch.ji
-0001d4e0: 742e 7472 6163 6528 715f 6d6f 6465 6c2c  t.trace(q_model,
-0001d4f0: 2073 656c 662e 6578 616d 706c 655f 696e   self.example_in
-0001d500: 7075 7473 2c20 7374 7269 6374 3d46 616c  puts, strict=Fal
-0001d510: 7365 290a 2020 2020 2020 2020 2020 2020  se).            
-0001d520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d530: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
-0001d540: 6465 6c20 3d20 746f 7263 682e 6a69 742e  del = torch.jit.
-0001d550: 6672 6565 7a65 2871 5f6d 6f64 656c 2e65  freeze(q_model.e
-0001d560: 7661 6c28 2929 0a20 2020 2020 2020 2020  val()).         
-0001d570: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0001d580: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0001d590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d5a0: 2071 5f6d 6f64 656c 203d 2069 7065 782e   q_model = ipex.
-0001d5b0: 7175 616e 7469 7a61 7469 6f6e 2e63 6f6e  quantization.con
-0001d5c0: 7665 7274 2871 5f6d 6f64 656c 2c20 696e  vert(q_model, in
-0001d5d0: 706c 6163 653d 5472 7565 290a 2020 2020  place=True).    
-0001d5e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d5f0: 2020 2020 2020 2020 7769 7468 2074 6f72          with tor
-0001d600: 6368 2e6e 6f5f 6772 6164 2829 3a0a 2020  ch.no_grad():.  
-0001d610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d620: 2020 2020 2020 2020 2020 2020 2020 7472                tr
-0001d630: 793a 0a20 2020 2020 2020 2020 2020 2020  y:.             
-0001d640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d650: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
-0001d660: 2074 6f72 6368 2e6a 6974 2e74 7261 6365   torch.jit.trace
-0001d670: 2871 5f6d 6f64 656c 2c20 7365 6c66 2e65  (q_model, self.e
-0001d680: 7861 6d70 6c65 5f69 6e70 7574 7329 0a20  xample_inputs). 
+0001d4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d4d0: 715f 6d6f 6465 6c20 3d20 6970 6578 2e71  q_model = ipex.q
+0001d4e0: 7561 6e74 697a 6174 696f 6e2e 636f 6e76  uantization.conv
+0001d4f0: 6572 7428 715f 6d6f 6465 6c2c 2069 6e70  ert(q_model, inp
+0001d500: 6c61 6365 3d54 7275 6529 0a20 2020 2020  lace=True).     
+0001d510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d520: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+0001d530: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
+0001d540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d550: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
+0001d560: 6465 6c20 3d20 746f 7263 682e 6a69 742e  del = torch.jit.
+0001d570: 7472 6163 6528 715f 6d6f 6465 6c2c 2073  trace(q_model, s
+0001d580: 656c 662e 6578 616d 706c 655f 696e 7075  elf.example_inpu
+0001d590: 7473 290a 2020 2020 2020 2020 2020 2020  ts).            
+0001d5a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d5b0: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
+0001d5c0: 6465 6c20 3d20 746f 7263 682e 6a69 742e  del = torch.jit.
+0001d5d0: 6672 6565 7a65 2871 5f6d 6f64 656c 2e65  freeze(q_model.e
+0001d5e0: 7661 6c28 2929 0a20 2020 2020 2020 2020  val()).         
+0001d5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d600: 2020 2020 2020 2020 2020 2065 7863 6570             excep
+0001d610: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+0001d620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d630: 2020 2020 2020 2020 2020 2071 5f6d 6f64             q_mod
+0001d640: 656c 203d 2074 6f72 6368 2e6a 6974 2e74  el = torch.jit.t
+0001d650: 7261 6365 2871 5f6d 6f64 656c 2c20 7365  race(q_model, se
+0001d660: 6c66 2e65 7861 6d70 6c65 5f69 6e70 7574  lf.example_input
+0001d670: 732c 2073 7472 6963 743d 4661 6c73 6529  s, strict=False)
+0001d680: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 0001d690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d6b0: 2020 2071 5f6d 6f64 656c 203d 2074 6f72     q_model = tor
-0001d6c0: 6368 2e6a 6974 2e66 7265 657a 6528 715f  ch.jit.freeze(q_
-0001d6d0: 6d6f 6465 6c2e 6576 616c 2829 290a 2020  model.eval()).  
-0001d6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d6f0: 2020 2020 2020 2020 2020 2020 2020 6578                ex
-0001d700: 6365 7074 3a0a 2020 2020 2020 2020 2020  cept:.          
-0001d710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d720: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
-0001d730: 6c20 3d20 746f 7263 682e 6a69 742e 7472  l = torch.jit.tr
-0001d740: 6163 6528 715f 6d6f 6465 6c2c 2073 656c  ace(q_model, sel
-0001d750: 662e 6578 616d 706c 655f 696e 7075 7473  f.example_inputs
-0001d760: 2c20 7374 7269 6374 3d46 616c 7365 290a  , strict=False).
-0001d770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d6a0: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
+0001d6b0: 203d 2074 6f72 6368 2e6a 6974 2e66 7265   = torch.jit.fre
+0001d6c0: 657a 6528 715f 6d6f 6465 6c2e 6576 616c  eze(q_model.eval
+0001d6d0: 2829 290a 2020 2020 2020 2020 2020 2020  ()).            
+0001d6e0: 2020 2020 2020 2020 2020 2020 656c 7365              else
+0001d6f0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0001d700: 2020 2020 2020 2020 2020 2020 2020 715f                q_
+0001d710: 6d6f 6465 6c20 3d20 6970 6578 2e71 7561  model = ipex.qua
+0001d720: 6e74 697a 6174 696f 6e2e 636f 6e76 6572  ntization.conver
+0001d730: 7428 715f 6d6f 6465 6c2c 2069 6e70 6c61  t(q_model, inpla
+0001d740: 6365 3d54 7275 6529 0a20 2020 2020 2020  ce=True).       
+0001d750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d760: 2020 2020 2077 6974 6820 746f 7263 682e       with torch.
+0001d770: 6e6f 5f67 7261 6428 293a 0a20 2020 2020  no_grad():.     
 0001d780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d790: 2020 2020 715f 6d6f 6465 6c20 3d20 746f      q_model = to
-0001d7a0: 7263 682e 6a69 742e 6672 6565 7a65 2871  rch.jit.freeze(q
-0001d7b0: 5f6d 6f64 656c 2e65 7661 6c28 2929 0a20  _model.eval()). 
-0001d7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d7d0: 2020 2020 2020 2023 2041 6674 6572 2066         # After f
-0001d7e0: 7265 657a 696e 672c 2072 756e 2031 2074  reezing, run 1 t
-0001d7f0: 696d 6520 746f 2077 6172 6d20 7570 2074  ime to warm up t
-0001d800: 6865 2070 726f 6669 6c69 6e67 2067 7261  he profiling gra
-0001d810: 7068 2065 7865 6375 746f 7220 746f 2069  ph executor to i
-0001d820: 6e73 6572 7420 7072 696d 3a3a 7072 6f66  nsert prim::prof
-0001d830: 696c 650a 2020 2020 2020 2020 2020 2020  ile.            
-0001d840: 2020 2020 2020 2020 2020 2020 2320 4174              # At
-0001d850: 2074 6865 2032 6e64 2072 756e 2c20 7468   the 2nd run, th
-0001d860: 6520 6c6c 6761 2070 6173 7320 7769 6c6c  e llga pass will
-0001d870: 2062 6520 7472 6967 6765 7265 6420 616e   be triggered an
-0001d880: 6420 7468 6520 6d6f 6465 6c20 6973 2074  d the model is t
-0001d890: 7572 6e65 6420 696e 746f 0a20 2020 2020  urned into.     
-0001d8a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d8b0: 2020 2023 2061 6e20 696e 7438 206d 6f64     # an int8 mod
-0001d8c0: 656c 3a20 7072 696d 3a3a 7072 6f66 696c  el: prim::profil
-0001d8d0: 6520 7769 6c6c 2062 6520 7265 6d6f 7665  e will be remove
-0001d8e0: 6420 616e 6420 7769 6c6c 2068 6176 6520  d and will have 
-0001d8f0: 4c6c 6761 4675 7369 6f6e 4772 6f75 7020  LlgaFusionGroup 
-0001d900: 696e 2074 6865 2067 7261 7068 0a20 2020  in the graph.   
-0001d910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d920: 2020 2020 2073 656c 662e 6361 6c69 625f       self.calib_
-0001d930: 6675 6e63 2871 5f6d 6f64 656c 2c20 6461  func(q_model, da
-0001d940: 7461 6c6f 6164 6572 2c20 746d 705f 6974  taloader, tmp_it
-0001d950: 6572 6174 696f 6e73 3d32 290a 0a20 2020  erations=2)..   
-0001d960: 2020 2020 2020 2020 2073 656c 662e 746d           self.tm
-0001d970: 705f 6d6f 6465 6c2e 5f6d 6f64 656c 203d  p_model._model =
-0001d980: 2071 5f6d 6f64 656c 0a20 2020 2020 2020   q_model.       
-0001d990: 2020 2020 2077 6974 6820 6f70 656e 2873       with open(s
-0001d9a0: 656c 662e 6970 6578 5f63 6f6e 6669 675f  elf.ipex_config_
-0001d9b0: 7061 7468 2c20 2772 2729 2061 7320 663a  path, 'r') as f:
-0001d9c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001d9d0: 2073 656c 662e 746d 705f 6d6f 6465 6c2e   self.tmp_model.
-0001d9e0: 7475 6e65 5f63 6667 203d 206a 736f 6e2e  tune_cfg = json.
-0001d9f0: 6c6f 6164 2866 290a 2020 2020 2020 2020  load(f).        
-0001da00: 2020 2020 7365 6c66 2e74 6d70 5f6d 6f64      self.tmp_mod
-0001da10: 656c 2e69 7065 785f 636f 6e66 6967 5f70  el.ipex_config_p
-0001da20: 6174 6820 3d20 7365 6c66 2e69 7065 785f  ath = self.ipex_
-0001da30: 636f 6e66 6967 5f70 6174 680a 2020 2020  config_path.    
-0001da40: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-0001da50: 656c 662e 746d 705f 6d6f 6465 6c0a 0a20  elf.tmp_model.. 
-0001da60: 2020 2064 6566 205f 6366 675f 746f 5f71     def _cfg_to_q
-0001da70: 636f 6e66 6967 2873 656c 662c 2074 756e  config(self, tun
-0001da80: 655f 6366 6729 3a0a 2020 2020 2020 2020  e_cfg):.        
-0001da90: 2222 2243 6f6e 7665 7274 2074 756e 6520  """Convert tune 
-0001daa0: 636f 6e66 6967 7572 6520 746f 2071 7561  configure to qua
-0001dab0: 6e74 697a 6174 696f 6e20 636f 6e66 6967  ntization config
-0001dac0: 2066 6f72 2065 6163 6820 6f70 2e0a 0a20   for each op... 
-0001dad0: 2020 2020 2020 2020 2020 2041 7267 733a             Args:
-0001dae0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001daf0: 2074 756e 655f 6366 6720 2864 6963 7429   tune_cfg (dict)
-0001db00: 3a20 6469 6374 696f 6e61 7279 206f 6620  : dictionary of 
-0001db10: 7475 6e65 2063 6f6e 6669 6775 7265 2066  tune configure f
-0001db20: 6f72 2065 6163 6820 6f70 0a20 2020 2020  or each op.     
-0001db30: 2020 2020 2020 2020 2020 2069 7065 785f             ipex_
-0001db40: 636f 6e66 6967 5f70 6174 683a 2063 6f6e  config_path: con
-0001db50: 6669 6775 7265 2066 696c 6520 6f66 2049  figure file of I
-0001db60: 6e74 656c 2050 7954 6f72 6368 2045 7874  ntel PyTorch Ext
-0001db70: 656e 7369 6f6e 0a0a 2020 2020 2020 2020  ension..        
-0001db80: 2020 2020 7475 6e65 5f63 6667 2073 686f      tune_cfg sho
-0001db90: 756c 6420 6265 2061 2066 6f72 6d61 7420  uld be a format 
-0001dba0: 6c69 6b65 2062 656c 6f77 3a0a 2020 2020  like below:.    
-0001dbb0: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
-0001dbc0: 2020 2020 2020 2020 2763 616c 6962 5f69          'calib_i
-0001dbd0: 7465 7261 7469 6f6e 273a 2031 302c 0a20  teration': 10,. 
-0001dbe0: 2020 2020 2020 2020 2020 2020 2027 6f70               'op
-0001dbf0: 273a 207b 0a20 2020 2020 2020 2020 2020  ': {.           
-0001dc00: 2020 2020 2020 2827 6f70 3127 2c20 2743        ('op1', 'C
-0001dc10: 4f4e 5632 4427 293a 207b 0a20 2020 2020  ONV2D'): {.     
-0001dc20: 2020 2020 2020 2020 2020 2020 2020 2761                'a
-0001dc30: 6374 6976 6174 696f 6e27 3a20 207b 2764  ctivation':  {'d
-0001dc40: 7479 7065 273a 2027 7569 6e74 3827 2c0a  type': 'uint8',.
-0001dc50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dc70: 2020 2027 616c 676f 7269 7468 6d27 3a20     'algorithm': 
-0001dc80: 276d 696e 6d61 7827 2c0a 2020 2020 2020  'minmax',.      
-0001dc90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dca0: 2020 2020 2020 2020 2020 2020 2027 7363               'sc
-0001dcb0: 6865 6d65 273a 2773 796d 272c 0a20 2020  heme':'sym',.   
-0001dcc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d790: 2020 2020 2020 2020 2020 2074 7279 3a0a             try:.
+0001d7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d7c0: 2020 2020 715f 6d6f 6465 6c20 3d20 746f      q_model = to
+0001d7d0: 7263 682e 6a69 742e 7472 6163 6528 715f  rch.jit.trace(q_
+0001d7e0: 6d6f 6465 6c2c 2073 656c 662e 6578 616d  model, self.exam
+0001d7f0: 706c 655f 696e 7075 7473 290a 2020 2020  ple_inputs).    
+0001d800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d820: 715f 6d6f 6465 6c20 3d20 746f 7263 682e  q_model = torch.
+0001d830: 6a69 742e 6672 6565 7a65 2871 5f6d 6f64  jit.freeze(q_mod
+0001d840: 656c 2e65 7661 6c28 2929 0a20 2020 2020  el.eval()).     
+0001d850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d860: 2020 2020 2020 2020 2020 2065 7863 6570             excep
+0001d870: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+0001d880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d890: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
+0001d8a0: 2074 6f72 6368 2e6a 6974 2e74 7261 6365   torch.jit.trace
+0001d8b0: 2871 5f6d 6f64 656c 2c20 7365 6c66 2e65  (q_model, self.e
+0001d8c0: 7861 6d70 6c65 5f69 6e70 7574 732c 2073  xample_inputs, s
+0001d8d0: 7472 6963 743d 4661 6c73 6529 0a20 2020  trict=False).   
+0001d8e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d900: 2071 5f6d 6f64 656c 203d 2074 6f72 6368   q_model = torch
+0001d910: 2e6a 6974 2e66 7265 657a 6528 715f 6d6f  .jit.freeze(q_mo
+0001d920: 6465 6c2e 6576 616c 2829 290a 2020 2020  del.eval()).    
+0001d930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d940: 2020 2020 2320 4166 7465 7220 6672 6565      # After free
+0001d950: 7a69 6e67 2c20 7275 6e20 3120 7469 6d65  zing, run 1 time
+0001d960: 2074 6f20 7761 726d 2075 7020 7468 6520   to warm up the 
+0001d970: 7072 6f66 696c 696e 6720 6772 6170 6820  profiling graph 
+0001d980: 6578 6563 7574 6f72 2074 6f20 696e 7365  executor to inse
+0001d990: 7274 2070 7269 6d3a 3a70 726f 6669 6c65  rt prim::profile
+0001d9a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001d9b0: 2020 2020 2020 2020 2023 2041 7420 7468           # At th
+0001d9c0: 6520 326e 6420 7275 6e2c 2074 6865 206c  e 2nd run, the l
+0001d9d0: 6c67 6120 7061 7373 2077 696c 6c20 6265  lga pass will be
+0001d9e0: 2074 7269 6767 6572 6564 2061 6e64 2074   triggered and t
+0001d9f0: 6865 206d 6f64 656c 2069 7320 7475 726e  he model is turn
+0001da00: 6564 2069 6e74 6f0a 2020 2020 2020 2020  ed into.        
+0001da10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001da20: 2320 616e 2069 6e74 3820 6d6f 6465 6c3a  # an int8 model:
+0001da30: 2070 7269 6d3a 3a70 726f 6669 6c65 2077   prim::profile w
+0001da40: 696c 6c20 6265 2072 656d 6f76 6564 2061  ill be removed a
+0001da50: 6e64 2077 696c 6c20 6861 7665 204c 6c67  nd will have Llg
+0001da60: 6146 7573 696f 6e47 726f 7570 2069 6e20  aFusionGroup in 
+0001da70: 7468 6520 6772 6170 680a 2020 2020 2020  the graph.      
+0001da80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001da90: 2020 7365 6c66 2e63 616c 6962 5f66 756e    self.calib_fun
+0001daa0: 6328 715f 6d6f 6465 6c2c 2064 6174 616c  c(q_model, datal
+0001dab0: 6f61 6465 722c 2074 6d70 5f69 7465 7261  oader, tmp_itera
+0001dac0: 7469 6f6e 733d 3229 0a20 2020 2020 2020  tions=2).       
+0001dad0: 2020 2020 206d 6f64 656c 2e5f 6d6f 6465       model._mode
+0001dae0: 6c20 3d20 715f 6d6f 6465 6c0a 2020 2020  l = q_model.    
+0001daf0: 2020 2020 2020 2020 7769 7468 206f 7065          with ope
+0001db00: 6e28 7365 6c66 2e69 7065 785f 636f 6e66  n(self.ipex_conf
+0001db10: 6967 5f70 6174 682c 2027 7227 2920 6173  ig_path, 'r') as
+0001db20: 2066 3a0a 2020 2020 2020 2020 2020 2020   f:.            
+0001db30: 2020 2020 6d6f 6465 6c2e 7475 6e65 5f63      model.tune_c
+0001db40: 6667 203d 206a 736f 6e2e 6c6f 6164 2866  fg = json.load(f
+0001db50: 290a 2020 2020 2020 2020 2020 2020 6d6f  ).            mo
+0001db60: 6465 6c2e 6970 6578 5f63 6f6e 6669 675f  del.ipex_config_
+0001db70: 7061 7468 203d 2073 656c 662e 6970 6578  path = self.ipex
+0001db80: 5f63 6f6e 6669 675f 7061 7468 0a20 2020  _config_path.   
+0001db90: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0001dba0: 6d6f 6465 6c0a 2020 2020 2020 2020 656c  model.        el
+0001dbb0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+0001dbc0: 6966 2073 656c 662e 746d 705f 6d6f 6465  if self.tmp_mode
+0001dbd0: 6c20 6973 204e 6f6e 653a 0a20 2020 2020  l is None:.     
+0001dbe0: 2020 2020 2020 2020 2020 2074 7279 3a0a             try:.
+0001dbf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001dc00: 2020 2020 7365 6c66 2e74 6d70 5f6d 6f64      self.tmp_mod
+0001dc10: 656c 203d 2063 6f70 792e 6465 6570 636f  el = copy.deepco
+0001dc20: 7079 286d 6f64 656c 290a 2020 2020 2020  py(model).      
+0001dc30: 2020 2020 2020 2020 2020 6578 6365 7074            except
+0001dc40: 2045 7863 6570 7469 6f6e 2061 7320 653a   Exception as e:
+0001dc50: 2020 2320 7072 6167 6d61 3a20 6e6f 2063    # pragma: no c
+0001dc60: 6f76 6572 0a20 2020 2020 2020 2020 2020  over.           
+0001dc70: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+0001dc80: 7761 726e 696e 6728 2246 6169 6c20 746f  warning("Fail to
+0001dc90: 2064 6565 7020 636f 7079 2074 6865 206d   deep copy the m
+0001dca0: 6f64 656c 2064 7565 2074 6f20 7b7d 2c20  odel due to {}, 
+0001dcb0: 696e 706c 6163 6520 6973 2075 7365 6420  inplace is used 
+0001dcc0: 6e6f 772e 222e 666f 726d 6174 280a 2020  now.".format(.  
 0001dcd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dce0: 2767 7261 6e75 6c61 7269 7479 273a 2027  'granularity': '
-0001dcf0: 7065 725f 7465 6e73 6f72 277d 2c0a 2020  per_tensor'},.  
-0001dd00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dd10: 2027 7765 6967 6874 273a 207b 2764 7479   'weight': {'dty
-0001dd20: 7065 273a 2027 696e 7438 272c 0a20 2020  pe': 'int8',.   
-0001dd30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dd40: 2020 2020 2020 2020 2020 2027 616c 676f             'algo
-0001dd50: 7269 7468 6d27 3a20 276b 6c27 2c0a 2020  rithm': 'kl',.  
-0001dd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dd70: 2020 2020 2020 2020 2020 2020 2773 6368              'sch
-0001dd80: 656d 6527 3a27 6173 796d 272c 0a20 2020  eme':'asym',.   
-0001dd90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dda0: 2020 2020 2020 2020 2020 2027 6772 616e             'gran
-0001ddb0: 756c 6172 6974 7927 3a20 2770 6572 5f63  ularity': 'per_c
-0001ddc0: 6861 6e6e 656c 277d 0a20 2020 2020 2020  hannel'}.       
-0001ddd0: 2020 2020 2020 2020 2020 7d2c 0a20 2020            },.   
-0001dde0: 2020 2020 2020 2020 2020 2020 2020 2827                ('
-0001ddf0: 6f70 3227 2c20 2752 454c 5529 3a20 7b0a  op2', 'RELU): {.
-0001de00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001de10: 2020 2027 6163 7469 7661 7469 6f6e 273a     'activation':
-0001de20: 207b 2764 7479 7065 273a 2027 696e 7438   {'dtype': 'int8
-0001de30: 272c 0a20 2020 2020 2020 2020 2020 2020  ',.             
-0001de40: 2020 2020 2020 2773 6368 656d 6527 3a20        'scheme': 
-0001de50: 2761 7379 6d27 2c0a 2020 2020 2020 2020  'asym',.        
-0001de60: 2020 2020 2020 2020 2020 2027 6772 616e             'gran
-0001de70: 756c 6172 6974 7927 3a20 2770 6572 5f74  ularity': 'per_t
-0001de80: 656e 736f 7227 2c0a 2020 2020 2020 2020  ensor',.        
-0001de90: 2020 2020 2020 2020 2020 2027 616c 676f             'algo
-0001dea0: 7269 7468 6d27 3a20 276d 696e 6d61 7827  rithm': 'minmax'
-0001deb0: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
-0001dec0: 2020 207d 2c0a 2020 2020 2020 2020 2020     },.          
-0001ded0: 2020 2020 2020 2028 276f 7033 272c 2027         ('op3', '
-0001dee0: 434f 4e56 3244 2729 3a20 7b0a 2020 2020  CONV2D'): {.    
-0001def0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-0001df00: 6163 7469 7661 7469 6f6e 273a 2020 7b27  activation':  {'
-0001df10: 6474 7970 6527 3a20 2766 7033 3227 7d2c  dtype': 'fp32'},
-0001df20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001df30: 2020 2020 2777 6569 6768 7427 3a20 7b27      'weight': {'
-0001df40: 6474 7970 6527 3a20 2766 7033 3227 7d0a  dtype': 'fp32'}.
-0001df50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001df60: 207d 2c0a 2020 2020 2020 2020 2020 2020   },.            
-0001df70: 2020 2020 202e 2e2e 0a20 2020 2020 2020       ....       
-0001df80: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
-0001df90: 2020 2020 207d 0a20 2020 2020 2020 2022       }.        "
-0001dfa0: 2222 0a20 2020 2020 2020 2061 7373 6572  "".        asser
-0001dfb0: 7420 7365 6c66 2e63 6667 7320 6973 206e  t self.cfgs is n
-0001dfc0: 6f74 204e 6f6e 652c 2022 4e6f 2063 6f6e  ot None, "No con
-0001dfd0: 6669 6775 7265 2066 6f72 2049 5045 5820  figure for IPEX 
-0001dfe0: 696e 7438 206d 6f64 656c 2e2e 2e22 0a20  int8 model...". 
-0001dff0: 2020 2020 2020 2069 6620 7365 6c66 2e76         if self.v
-0001e000: 6572 7369 6f6e 2e72 656c 6561 7365 203c  ersion.release <
-0001e010: 2056 6572 7369 6f6e 2822 312e 3132 2e30   Version("1.12.0
-0001e020: 2229 2e72 656c 6561 7365 3a0a 2020 2020  ").release:.    
-0001e030: 2020 2020 2020 2020 666f 7220 6b65 7920          for key 
-0001e040: 696e 2074 756e 655f 6366 675b 276f 7027  in tune_cfg['op'
-0001e050: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
-0001e060: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
-0001e070: 2020 2020 2020 2020 2020 2020 7363 6865              sche
-0001e080: 6d65 203d 2074 756e 655f 6366 675b 276f  me = tune_cfg['o
-0001e090: 7027 5d5b 6b65 795d 5b27 6163 7469 7661  p'][key]['activa
-0001e0a0: 7469 6f6e 275d 5b27 7363 6865 6d65 275d  tion']['scheme']
-0001e0b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001e0c0: 2065 7863 6570 743a 0a20 2020 2020 2020   except:.       
-0001e0d0: 2020 2020 2020 2020 2020 2020 2073 6368               sch
-0001e0e0: 656d 6520 3d20 2761 7379 6d27 0a20 2020  eme = 'asym'.   
-0001e0f0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-0001e100: 7363 6865 6d65 206e 6f74 2069 6e20 5b27  scheme not in ['
-0001e110: 6173 796d 272c 2027 7379 6d27 5d3a 0a20  asym', 'sym']:. 
-0001e120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e130: 2020 2073 6368 656d 6520 3d20 2761 7379     scheme = 'asy
-0001e140: 6d27 0a20 2020 2020 2020 2020 2020 2020  m'.             
-0001e150: 2020 2062 7265 616b 0a20 2020 2020 2020     break.       
-0001e160: 2020 2020 2066 6f72 206b 6579 2069 6e20       for key in 
-0001e170: 7475 6e65 5f63 6667 5b27 6f70 275d 3a0a  tune_cfg['op']:.
-0001e180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e190: 7661 6c75 6520 3d20 7475 6e65 5f63 6667  value = tune_cfg
-0001e1a0: 5b27 6f70 275d 5b6b 6579 5d0a 2020 2020  ['op'][key].    
-0001e1b0: 2020 2020 2020 2020 2020 2020 7061 7474              patt
-0001e1c0: 6572 6e20 3d20 7365 6c66 2e67 6574 5f70  ern = self.get_p
-0001e1d0: 6174 7465 726e 286b 6579 2c20 7365 6c66  attern(key, self
-0001e1e0: 2e66 7573 655f 6f70 7329 0a20 2020 2020  .fuse_ops).     
-0001e1f0: 2020 2020 2020 2020 2020 2061 7373 6572             asser
-0001e200: 7420 6973 696e 7374 616e 6365 2876 616c  t isinstance(val
-0001e210: 7565 2c20 6469 6374 290a 2020 2020 2020  ue, dict).      
-0001e220: 2020 2020 2020 2020 2020 6173 7365 7274            assert
-0001e230: 2027 6163 7469 7661 7469 6f6e 2720 696e   'activation' in
-0001e240: 2076 616c 7565 0a20 2020 2020 2020 2020   value.         
-0001e250: 2020 2020 2020 2069 6620 7661 6c75 655b         if value[
-0001e260: 2761 6374 6976 6174 696f 6e27 5d5b 2764  'activation']['d
-0001e270: 7479 7065 275d 203d 3d20 2766 7033 3227  type'] == 'fp32'
-0001e280: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001e290: 2020 2020 2020 6966 2027 7765 6967 6874        if 'weight
-0001e2a0: 2720 696e 2076 616c 7565 3a0a 2020 2020  ' in value:.    
-0001e2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e2c0: 2020 2020 6173 7365 7274 2076 616c 7565      assert value
-0001e2d0: 5b27 7765 6967 6874 275d 5b27 6474 7970  ['weight']['dtyp
-0001e2e0: 6527 5d20 3d3d 2027 6670 3332 270a 2020  e'] == 'fp32'.  
+0001dce0: 2020 2020 2020 7265 7072 2865 2929 290a        repr(e))).
+0001dcf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001dd00: 2020 2020 7365 6c66 2e74 6d70 5f6d 6f64      self.tmp_mod
+0001dd10: 656c 203d 206d 6f64 656c 0a20 2020 2020  el = model.     
+0001dd20: 2020 2020 2020 2069 6620 6861 7361 7474         if hasatt
+0001dd30: 7228 6d6f 6465 6c2e 6d6f 6465 6c2c 2022  r(model.model, "
+0001dd40: 7361 7665 5f71 636f 6e66 5f73 756d 6d61  save_qconf_summa
+0001dd50: 7279 2229 3a0a 2020 2020 2020 2020 2020  ry"):.          
+0001dd60: 2020 2020 2020 6966 2073 656c 662e 746d        if self.tm
+0001dd70: 705f 6d6f 6465 6c20 6973 204e 6f6e 653a  p_model is None:
+0001dd80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001dd90: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
+0001dda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ddb0: 2020 7365 6c66 2e74 6d70 5f6d 6f64 656c    self.tmp_model
+0001ddc0: 203d 2063 6f70 792e 6465 6570 636f 7079   = copy.deepcopy
+0001ddd0: 286d 6f64 656c 290a 2020 2020 2020 2020  (model).        
+0001dde0: 2020 2020 2020 2020 2020 2020 6578 6365              exce
+0001ddf0: 7074 2045 7863 6570 7469 6f6e 2061 7320  pt Exception as 
+0001de00: 653a 2020 2320 7072 6167 6d61 3a20 6e6f  e:  # pragma: no
+0001de10: 2063 6f76 6572 0a20 2020 2020 2020 2020   cover.         
+0001de20: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+0001de30: 6f67 6765 722e 7761 726e 696e 6728 2246  ogger.warning("F
+0001de40: 6169 6c20 746f 2064 6565 7020 636f 7079  ail to deep copy
+0001de50: 2074 6865 206d 6f64 656c 2064 7565 2074   the model due t
+0001de60: 6f20 7b7d 2c20 696e 706c 6163 6520 6973  o {}, inplace is
+0001de70: 2075 7365 6420 6e6f 772e 222e 666f 726d   used now.".form
+0001de80: 6174 280a 2020 2020 2020 2020 2020 2020  at(.            
+0001de90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001dea0: 7265 7072 2865 2929 290a 2020 2020 2020  repr(e))).      
+0001deb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001dec0: 2020 7365 6c66 2e74 6d70 5f6d 6f64 656c    self.tmp_model
+0001ded0: 203d 206d 6f64 656c 0a20 2020 2020 2020   = model.       
+0001dee0: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
+0001def0: 203d 206d 6f64 656c 2e6d 6f64 656c 0a20   = model.model. 
+0001df00: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+0001df10: 5f6d 6f64 656c 2e6c 6f61 645f 7163 6f6e  _model.load_qcon
+0001df20: 665f 7375 6d6d 6172 7928 7163 6f6e 665f  f_summary(qconf_
+0001df30: 7375 6d6d 6172 793d 7365 6c66 2e69 7065  summary=self.ipe
+0001df40: 785f 636f 6e66 6967 5f70 6174 6829 0a20  x_config_path). 
+0001df50: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0001df60: 6620 715f 6675 6e63 2069 7320 6e6f 7420  f q_func is not 
+0001df70: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+0001df80: 2020 2020 2020 2020 2020 715f 6675 6e63            q_func
+0001df90: 2871 5f6d 6f64 656c 290a 2020 2020 2020  (q_model).      
+0001dfa0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+0001dfb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001dfc0: 2020 2020 7365 6c66 2e6d 6f64 656c 5f63      self.model_c
+0001dfd0: 616c 6962 7261 7469 6f6e 2871 5f6d 6f64  alibration(q_mod
+0001dfe0: 656c 2c20 6461 7461 6c6f 6164 6572 2c20  el, dataloader, 
+0001dff0: 6974 6572 6174 696f 6e73 2c20 4e6f 6e65  iterations, None
+0001e000: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0001e010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e020: 2020 2020 2020 2020 2020 2020 2074 756e               tun
+0001e030: 655f 6366 672e 6765 7428 2763 616c 6962  e_cfg.get('calib
+0001e040: 5f73 616d 706c 696e 675f 7369 7a65 272c  _sampling_size',
+0001e050: 2031 2929 0a20 2020 2020 2020 2020 2020   1)).           
+0001e060: 2020 2020 2071 5f6d 6f64 656c 2e73 6176       q_model.sav
+0001e070: 655f 7163 6f6e 665f 7375 6d6d 6172 7928  e_qconf_summary(
+0001e080: 7163 6f6e 665f 7375 6d6d 6172 793d 7365  qconf_summary=se
+0001e090: 6c66 2e69 7065 785f 636f 6e66 6967 5f70  lf.ipex_config_p
+0001e0a0: 6174 6829 0a20 2020 2020 2020 2020 2020  ath).           
+0001e0b0: 2020 2020 2069 6620 7365 6c66 2e75 7365       if self.use
+0001e0c0: 5f62 6631 3620 616e 6420 2843 7075 496e  _bf16 and (CpuIn
+0001e0d0: 666f 2829 2e62 6631 3620 6f72 206f 732e  fo().bf16 or os.
+0001e0e0: 6765 7465 6e76 2827 464f 5243 455f 4246  getenv('FORCE_BF
+0001e0f0: 3136 2729 203d 3d20 2731 2729 2061 6e64  16') == '1') and
+0001e100: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0001e110: 2020 2020 2020 2028 7365 6c66 2e76 6572         (self.ver
+0001e120: 7369 6f6e 2e72 656c 6561 7365 203e 3d20  sion.release >= 
+0001e130: 5665 7273 696f 6e28 2231 2e31 312e 3022  Version("1.11.0"
+0001e140: 292e 7265 6c65 6173 6529 3a0a 2020 2020  ).release):.    
+0001e150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e160: 7769 7468 2074 6f72 6368 2e6e 6f5f 6772  with torch.no_gr
+0001e170: 6164 2829 3a0a 2020 2020 2020 2020 2020  ad():.          
+0001e180: 2020 2020 2020 2020 2020 2020 2020 7769                wi
+0001e190: 7468 2074 6f72 6368 2e63 7075 2e61 6d70  th torch.cpu.amp
+0001e1a0: 2e61 7574 6f63 6173 7428 293a 0a20 2020  .autocast():.   
+0001e1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e1c0: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
+0001e1d0: 203d 2069 7065 782e 7175 616e 7469 7a61   = ipex.quantiza
+0001e1e0: 7469 6f6e 2e63 6f6e 7665 7274 2871 5f6d  tion.convert(q_m
+0001e1f0: 6f64 656c 2c20 696e 706c 6163 653d 4661  odel, inplace=Fa
+0001e200: 6c73 6529 0a20 2020 2020 2020 2020 2020  lse).           
+0001e210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e220: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
+0001e230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e240: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
+0001e250: 746f 7263 682e 6a69 742e 7472 6163 6528  torch.jit.trace(
+0001e260: 715f 6d6f 6465 6c2c 2073 656c 662e 6578  q_model, self.ex
+0001e270: 616d 706c 655f 696e 7075 7473 290a 2020  ample_inputs).  
+0001e280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e290: 2020 2020 2020 2020 2020 2020 2020 715f                q_
+0001e2a0: 6d6f 6465 6c20 3d20 746f 7263 682e 6a69  model = torch.ji
+0001e2b0: 742e 6672 6565 7a65 2871 5f6d 6f64 656c  t.freeze(q_model
+0001e2c0: 2e65 7661 6c28 2929 0a20 2020 2020 2020  .eval()).       
+0001e2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e2e0: 2020 2020 2065 7863 6570 743a 0a20 2020       except:.   
 0001e2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e300: 2020 666f 7220 6f70 5f63 6667 2069 6e20    for op_cfg in 
-0001e310: 7365 6c66 2e63 6667 733a 0a20 2020 2020  self.cfgs:.     
-0001e320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e330: 2020 2069 6620 6f70 5f63 6667 5b22 6964     if op_cfg["id
-0001e340: 225d 203d 3d20 6b65 795b 305d 3a0a 2020  "] == key[0]:.  
-0001e350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e360: 2020 2020 2020 2020 2020 6966 206b 6579            if key
-0001e370: 5b31 5d20 696e 205b 2772 656c 755f 272c  [1] in ['relu_',
-0001e380: 2027 6164 645f 275d 3a0a 2020 2020 2020   'add_']:.      
-0001e390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e3a0: 2020 2020 2020 2020 2020 636f 6e74 696e            contin
-0001e3b0: 7565 0a20 2020 2020 2020 2020 2020 2020  ue.             
-0001e3c0: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-0001e3d0: 756d 5f69 6e70 7574 7320 3d20 6c65 6e28  um_inputs = len(
-0001e3e0: 6f70 5f63 6667 5b22 696e 7075 7473 5f71  op_cfg["inputs_q
-0001e3f0: 7561 6e74 697a 6564 225d 290a 2020 2020  uantized"]).    
-0001e400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e410: 2020 2020 2020 2020 6e75 6d5f 6f75 7470          num_outp
-0001e420: 7574 7320 3d20 6c65 6e28 6f70 5f63 6667  uts = len(op_cfg
-0001e430: 5b22 6f75 7470 7574 735f 7175 616e 7469  ["outputs_quanti
-0001e440: 7a65 6422 5d29 0a20 2020 2020 2020 2020  zed"]).         
+0001e300: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+0001e310: 6f64 656c 203d 2074 6f72 6368 2e6a 6974  odel = torch.jit
+0001e320: 2e74 7261 6365 2871 5f6d 6f64 656c 2c20  .trace(q_model, 
+0001e330: 7365 6c66 2e65 7861 6d70 6c65 5f69 6e70  self.example_inp
+0001e340: 7574 732c 2073 7472 6963 743d 4661 6c73  uts, strict=Fals
+0001e350: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+0001e360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e370: 2020 2071 5f6d 6f64 656c 203d 2074 6f72     q_model = tor
+0001e380: 6368 2e6a 6974 2e66 7265 657a 6528 715f  ch.jit.freeze(q_
+0001e390: 6d6f 6465 6c2e 6576 616c 2829 290a 2020  model.eval()).  
+0001e3a0: 2020 2020 2020 2020 2020 2020 2020 656c                el
+0001e3b0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+0001e3c0: 2020 2020 2020 2020 715f 6d6f 6465 6c20          q_model 
+0001e3d0: 3d20 6970 6578 2e71 7561 6e74 697a 6174  = ipex.quantizat
+0001e3e0: 696f 6e2e 636f 6e76 6572 7428 715f 6d6f  ion.convert(q_mo
+0001e3f0: 6465 6c2c 2069 6e70 6c61 6365 3d46 616c  del, inplace=Fal
+0001e400: 7365 290a 2020 2020 2020 2020 2020 2020  se).            
+0001e410: 2020 2020 2020 2020 7769 7468 2074 6f72          with tor
+0001e420: 6368 2e6e 6f5f 6772 6164 2829 3a0a 2020  ch.no_grad():.  
+0001e430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e440: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
 0001e450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e460: 2020 2066 6f72 2069 5f6e 756d 2069 6e20     for i_num in 
-0001e470: 7261 6e67 6528 6e75 6d5f 696e 7075 7473  range(num_inputs
-0001e480: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0001e490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e4a0: 2020 206f 705f 6366 675b 2269 6e70 7574     op_cfg["input
-0001e4b0: 735f 7175 616e 7469 7a65 6422 5d5b 695f  s_quantized"][i_
-0001e4c0: 6e75 6d5d 203d 2046 616c 7365 0a20 2020  num] = False.   
-0001e4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e4e0: 2020 2020 2020 2020 2066 6f72 206f 5f6e           for o_n
-0001e4f0: 756d 2069 6e20 7261 6e67 6528 6e75 6d5f  um in range(num_
-0001e500: 6f75 7470 7574 7329 3a0a 2020 2020 2020  outputs):.      
+0001e460: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
+0001e470: 2074 6f72 6368 2e6a 6974 2e74 7261 6365   torch.jit.trace
+0001e480: 2871 5f6d 6f64 656c 2c20 7365 6c66 2e65  (q_model, self.e
+0001e490: 7861 6d70 6c65 5f69 6e70 7574 7329 0a20  xample_inputs). 
+0001e4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e4b0: 2020 2020 2020 2020 2020 2071 5f6d 6f64             q_mod
+0001e4c0: 656c 203d 2074 6f72 6368 2e6a 6974 2e66  el = torch.jit.f
+0001e4d0: 7265 657a 6528 715f 6d6f 6465 6c2e 6576  reeze(q_model.ev
+0001e4e0: 616c 2829 290a 2020 2020 2020 2020 2020  al()).          
+0001e4f0: 2020 2020 2020 2020 2020 2020 2020 6578                ex
+0001e500: 6365 7074 3a0a 2020 2020 2020 2020 2020  cept:.          
 0001e510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e520: 2020 2020 2020 2020 2020 6f70 5f63 6667            op_cfg
-0001e530: 5b22 6f75 7470 7574 735f 7175 616e 7469  ["outputs_quanti
-0001e540: 7a65 6422 5d5b 6f5f 6e75 6d5d 203d 2046  zed"][o_num] = F
-0001e550: 616c 7365 0a20 2020 2020 2020 2020 2020  alse.           
-0001e560: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e570: 2069 6620 7061 7474 6572 6e3a 0a20 2020   if pattern:.   
-0001e580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e590: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-0001e5a0: 7061 7474 6572 6e5b 315d 2069 6e20 5b27  pattern[1] in ['
-0001e5b0: 7265 6c75 5f27 2c20 2761 6464 5f27 5d3a  relu_', 'add_']:
-0001e5c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001e5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e5e0: 2020 2020 2063 6f6e 7469 6e75 650a 2020       continue.  
-0001e5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e600: 2020 2020 2020 2020 2020 2020 2020 7475                tu
-0001e610: 6e65 5f63 6667 5b27 6f70 275d 5b70 6174  ne_cfg['op'][pat
-0001e620: 7465 726e 5d5b 2761 6374 6976 6174 696f  tern]['activatio
-0001e630: 6e27 5d5b 2764 7479 7065 275d 203d 2027  n']['dtype'] = '
-0001e640: 6670 3332 270a 2020 2020 2020 2020 2020  fp32'.          
-0001e650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e660: 2020 2020 2020 6966 2027 7765 6967 6874        if 'weight
-0001e670: 2720 696e 2074 756e 655f 6366 675b 276f  ' in tune_cfg['o
-0001e680: 7027 5d5b 7061 7474 6572 6e5d 3a0a 2020  p'][pattern]:.  
-0001e690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e6b0: 2020 7475 6e65 5f63 6667 5b27 6f70 275d    tune_cfg['op']
-0001e6c0: 5b70 6174 7465 726e 5d5b 2777 6569 6768  [pattern]['weigh
-0001e6d0: 7427 5d5b 2764 7479 7065 275d 203d 2027  t']['dtype'] = '
-0001e6e0: 6670 3332 270a 2020 2020 2020 2020 2020  fp32'.          
-0001e6f0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-0001e700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e710: 666f 7220 6f70 5f63 6667 2069 6e20 7365  for op_cfg in se
-0001e720: 6c66 2e63 6667 733a 0a20 2020 2020 2020  lf.cfgs:.       
-0001e730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e740: 2069 6620 6f70 5f63 6667 5b22 6964 225d   if op_cfg["id"]
-0001e750: 203d 3d20 6b65 795b 305d 3a0a 2020 2020   == key[0]:.    
-0001e760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e770: 2020 2020 2020 2020 6966 206b 6579 5b31          if key[1
-0001e780: 5d20 696e 205b 2772 656c 755f 272c 2027  ] in ['relu_', '
-0001e790: 6164 645f 275d 3a0a 2020 2020 2020 2020  add_']:.        
+0001e520: 2020 715f 6d6f 6465 6c20 3d20 746f 7263    q_model = torc
+0001e530: 682e 6a69 742e 7472 6163 6528 715f 6d6f  h.jit.trace(q_mo
+0001e540: 6465 6c2c 2073 656c 662e 6578 616d 706c  del, self.exampl
+0001e550: 655f 696e 7075 7473 2c20 7374 7269 6374  e_inputs, strict
+0001e560: 3d46 616c 7365 290a 2020 2020 2020 2020  =False).        
+0001e570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e580: 2020 2020 715f 6d6f 6465 6c20 3d20 746f      q_model = to
+0001e590: 7263 682e 6a69 742e 6672 6565 7a65 2871  rch.jit.freeze(q
+0001e5a0: 5f6d 6f64 656c 2e65 7661 6c28 2929 0a20  _model.eval()). 
+0001e5b0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0001e5c0: 2041 6674 6572 2066 7265 657a 696e 672c   After freezing,
+0001e5d0: 2072 756e 2031 2074 696d 6520 746f 2077   run 1 time to w
+0001e5e0: 6172 6d20 7570 2074 6865 2070 726f 6669  arm up the profi
+0001e5f0: 6c69 6e67 2067 7261 7068 2065 7865 6375  ling graph execu
+0001e600: 746f 7220 746f 2069 6e73 6572 7420 7072  tor to insert pr
+0001e610: 696d 3a3a 7072 6f66 696c 650a 2020 2020  im::profile.    
+0001e620: 2020 2020 2020 2020 2020 2020 2320 4174              # At
+0001e630: 2074 6865 2032 6e64 2072 756e 2c20 7468   the 2nd run, th
+0001e640: 6520 6c6c 6761 2070 6173 7320 7769 6c6c  e llga pass will
+0001e650: 2062 6520 7472 6967 6765 7265 6420 616e   be triggered an
+0001e660: 6420 7468 6520 6d6f 6465 6c20 6973 2074  d the model is t
+0001e670: 7572 6e65 6420 696e 746f 0a20 2020 2020  urned into.     
+0001e680: 2020 2020 2020 2020 2020 2023 2061 6e20             # an 
+0001e690: 696e 7438 206d 6f64 656c 3a20 7072 696d  int8 model: prim
+0001e6a0: 3a3a 7072 6f66 696c 6520 7769 6c6c 2062  ::profile will b
+0001e6b0: 6520 7265 6d6f 7665 6420 616e 6420 7769  e removed and wi
+0001e6c0: 6c6c 2068 6176 6520 4c6c 6761 4675 7369  ll have LlgaFusi
+0001e6d0: 6f6e 4772 6f75 7020 696e 2074 6865 2067  onGroup in the g
+0001e6e0: 7261 7068 0a20 2020 2020 2020 2020 2020  raph.           
+0001e6f0: 2020 2020 2073 656c 662e 6361 6c69 625f       self.calib_
+0001e700: 6675 6e63 2871 5f6d 6f64 656c 2c20 6461  func(q_model, da
+0001e710: 7461 6c6f 6164 6572 2c20 746d 705f 6974  taloader, tmp_it
+0001e720: 6572 6174 696f 6e73 3d32 290a 2020 2020  erations=2).    
+0001e730: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0001e740: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0001e750: 2073 656c 662e 6170 7072 6f61 6368 2069   self.approach i
+0001e760: 6e20 5b27 706f 7374 5f74 7261 696e 696e  n ['post_trainin
+0001e770: 675f 7374 6174 6963 5f71 7561 6e74 272c  g_static_quant',
+0001e780: 2027 706f 7374 5f74 7261 696e 696e 675f   'post_training_
+0001e790: 6175 746f 5f71 7561 6e74 275d 3a0a 2020  auto_quant']:.  
 0001e7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e7b0: 2020 2020 2020 2020 636f 6e74 696e 7565          continue
-0001e7c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001e7d0: 2020 2020 2020 2020 2020 2020 206e 756d               num
-0001e7e0: 5f69 6e70 7574 7320 3d20 6c65 6e28 6f70  _inputs = len(op
-0001e7f0: 5f63 6667 5b22 696e 7075 7473 5f71 7561  _cfg["inputs_qua
-0001e800: 6e74 697a 6564 225d 290a 2020 2020 2020  ntized"]).      
+0001e7b0: 2020 6966 2073 656c 662e 7665 7273 696f    if self.versio
+0001e7c0: 6e2e 7265 6c65 6173 6520 3c20 5665 7273  n.release < Vers
+0001e7d0: 696f 6e28 2231 2e31 322e 3022 292e 7265  ion("1.12.0").re
+0001e7e0: 6c65 6173 653a 0a20 2020 2020 2020 2020  lease:.         
+0001e7f0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+0001e800: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
 0001e810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e820: 2020 2020 2020 6e75 6d5f 6f75 7470 7574        num_output
-0001e830: 7320 3d20 6c65 6e28 6f70 5f63 6667 5b22  s = len(op_cfg["
-0001e840: 6f75 7470 7574 735f 7175 616e 7469 7a65  outputs_quantize
-0001e850: 6422 5d29 0a20 2020 2020 2020 2020 2020  d"]).           
-0001e860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e870: 2066 6f72 2069 5f6e 756d 2069 6e20 7261   for i_num in ra
-0001e880: 6e67 6528 6e75 6d5f 696e 7075 7473 293a  nge(num_inputs):
-0001e890: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001e8a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e8b0: 206f 705f 6366 675b 2269 6e70 7574 735f   op_cfg["inputs_
-0001e8c0: 7175 616e 7469 7a65 6422 5d5b 695f 6e75  quantized"][i_nu
-0001e8d0: 6d5d 203d 205c 0a20 2020 2020 2020 2020  m] = \.         
-0001e8e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e900: 2020 2020 2073 656c 662e 6465 6661 756c       self.defaul
-0001e910: 745f 6366 6773 5b6b 6579 5b30 5d5d 5b22  t_cfgs[key[0]]["
-0001e920: 696e 7075 7473 5f71 7561 6e74 697a 6564  inputs_quantized
-0001e930: 225d 5b69 5f6e 756d 5d0a 2020 2020 2020  "][i_num].      
-0001e940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e950: 2020 2020 2020 666f 7220 6f5f 6e75 6d20        for o_num 
-0001e960: 696e 2072 616e 6765 286e 756d 5f6f 7574  in range(num_out
-0001e970: 7075 7473 293a 0a20 2020 2020 2020 2020  puts):.         
-0001e980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e990: 2020 2020 2020 206f 705f 6366 675b 226f         op_cfg["o
-0001e9a0: 7574 7075 7473 5f71 7561 6e74 697a 6564  utputs_quantized
-0001e9b0: 225d 5b6f 5f6e 756d 5d20 3d20 5c0a 2020  "][o_num] = \.  
-0001e9c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e9d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e9e0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0001e9f0: 6465 6661 756c 745f 6366 6773 5b6b 6579  default_cfgs[key
-0001ea00: 5b30 5d5d 5b22 6f75 7470 7574 735f 7175  [0]]["outputs_qu
-0001ea10: 616e 7469 7a65 6422 5d5b 6f5f 6e75 6d5d  antized"][o_num]
-0001ea20: 0a20 2020 2020 2020 2020 2020 2077 6974  .            wit
-0001ea30: 6820 6f70 656e 2873 656c 662e 6970 6578  h open(self.ipex
-0001ea40: 5f63 6f6e 6669 675f 7061 7468 2c20 2277  _config_path, "w
-0001ea50: 2229 2061 7320 7772 6974 655f 663a 0a20  ") as write_f:. 
-0001ea60: 2020 2020 2020 2020 2020 2020 2020 206a                 j
-0001ea70: 736f 6e2e 6475 6d70 2873 656c 662e 6366  son.dump(self.cf
-0001ea80: 6773 2c20 7772 6974 655f 6629 0a20 2020  gs, write_f).   
-0001ea90: 2020 2020 2020 2020 2069 6620 7363 6865           if sche
-0001eaa0: 6d65 203d 3d20 2261 7379 6d22 3a0a 2020  me == "asym":.  
-0001eab0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-0001eac0: 7475 726e 2074 6f72 6368 2e70 6572 5f74  turn torch.per_t
-0001ead0: 656e 736f 725f 6166 6669 6e65 0a20 2020  ensor_affine.   
-0001eae0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-0001eaf0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0001eb00: 6574 7572 6e20 746f 7263 682e 7065 725f  eturn torch.per_
-0001eb10: 7465 6e73 6f72 5f73 796d 6d65 7472 6963  tensor_symmetric
-0001eb20: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-0001eb30: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0001eb40: 6366 6773 203d 2074 6f72 6368 5f75 7469  cfgs = torch_uti
-0001eb50: 6c73 2e75 7469 6c2e 6368 6563 6b5f 6366  ls.util.check_cf
-0001eb60: 675f 616e 645f 7163 6f6e 6669 6728 7475  g_and_qconfig(tu
-0001eb70: 6e65 5f63 6667 5b27 6f70 275d 2c0a 2020  ne_cfg['op'],.  
-0001eb80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001eb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001eba0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0001ebb0: 2e63 6667 732c 0a20 2020 2020 2020 2020  .cfgs,.         
-0001ebc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ebd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ebe0: 2020 2020 2073 656c 662e 6f70 5f69 6e66       self.op_inf
-0001ebf0: 6f73 5f66 726f 6d5f 6366 6773 2c0a 2020  os_from_cfgs,.  
+0001e820: 7365 6c66 2e74 6d70 5f6d 6f64 656c 203d  self.tmp_model =
+0001e830: 2063 6f70 792e 6465 6570 636f 7079 286d   copy.deepcopy(m
+0001e840: 6f64 656c 290a 2020 2020 2020 2020 2020  odel).          
+0001e850: 2020 2020 2020 2020 2020 2020 2020 6578                ex
+0001e860: 6365 7074 2045 7863 6570 7469 6f6e 2061  cept Exception a
+0001e870: 7320 653a 2020 2320 7072 6167 6d61 3a20  s e:  # pragma: 
+0001e880: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
+0001e890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e8a0: 2020 2020 206c 6f67 6765 722e 7761 726e       logger.warn
+0001e8b0: 696e 6728 2246 6169 6c20 746f 2064 6565  ing("Fail to dee
+0001e8c0: 7020 636f 7079 2074 6865 206d 6f64 656c  p copy the model
+0001e8d0: 2064 7565 2074 6f20 7b7d 2c20 696e 706c   due to {}, inpl
+0001e8e0: 6163 6520 6973 2075 7365 6420 6e6f 772e  ace is used now.
+0001e8f0: 222e 666f 726d 6174 280a 2020 2020 2020  ".format(.      
+0001e900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e910: 2020 2020 2020 2020 2020 7265 7072 2865            repr(e
+0001e920: 2929 290a 2020 2020 2020 2020 2020 2020  ))).            
+0001e930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e940: 7365 6c66 2e74 6d70 5f6d 6f64 656c 203d  self.tmp_model =
+0001e950: 206d 6f64 656c 0a20 2020 2020 2020 2020   model.         
+0001e960: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0001e970: 7065 785f 636f 6e66 203d 2069 7065 782e  pex_conf = ipex.
+0001e980: 7175 616e 7469 7a61 7469 6f6e 2e51 7561  quantization.Qua
+0001e990: 6e74 436f 6e66 2863 6f6e 6669 6775 7265  ntConf(configure
+0001e9a0: 5f66 696c 653d 7365 6c66 2e69 7065 785f  _file=self.ipex_
+0001e9b0: 636f 6e66 6967 5f70 6174 682c 2020 2320  config_path,  # 
+0001e9c0: 7079 6c69 6e74 3a20 6469 7361 626c 653d  pylint: disable=
+0001e9d0: 4531 3130 310a 2020 2020 2020 2020 2020  E1101.          
+0001e9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e9f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ea00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ea10: 2020 2020 2020 7173 6368 656d 653d 7173        qscheme=qs
+0001ea20: 6368 656d 6529 0a20 2020 2020 2020 2020  cheme).         
+0001ea30: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0001ea40: 656c 662e 6d6f 6465 6c5f 6361 6c69 6272  elf.model_calibr
+0001ea50: 6174 696f 6e28 7365 6c66 2e74 6d70 5f6d  ation(self.tmp_m
+0001ea60: 6f64 656c 2e6d 6f64 656c 2c20 6461 7461  odel.model, data
+0001ea70: 6c6f 6164 6572 2c20 6974 6572 6174 696f  loader, iteratio
+0001ea80: 6e73 2c20 6970 6578 5f63 6f6e 662c 0a20  ns, ipex_conf,. 
+0001ea90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eaa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eab0: 2020 2020 2020 2020 2020 2020 2020 7475                tu
+0001eac0: 6e65 5f63 6667 2e67 6574 2827 6361 6c69  ne_cfg.get('cali
+0001ead0: 625f 7361 6d70 6c69 6e67 5f73 697a 6527  b_sampling_size'
+0001eae0: 2c20 3129 290a 2020 2020 2020 2020 2020  , 1)).          
+0001eaf0: 2020 2020 2020 2020 2020 2020 2020 6970                ip
+0001eb00: 6578 5f63 6f6e 662e 7361 7665 2873 656c  ex_conf.save(sel
+0001eb10: 662e 6970 6578 5f63 6f6e 6669 675f 7061  f.ipex_config_pa
+0001eb20: 7468 290a 2020 2020 2020 2020 2020 2020  th).            
+0001eb30: 2020 2020 2020 2020 2020 2020 6970 6578              ipex
+0001eb40: 5f63 6f6e 6620 3d20 6970 6578 2e71 7561  _conf = ipex.qua
+0001eb50: 6e74 697a 6174 696f 6e2e 5175 616e 7443  ntization.QuantC
+0001eb60: 6f6e 6628 7365 6c66 2e69 7065 785f 636f  onf(self.ipex_co
+0001eb70: 6e66 6967 5f70 6174 6829 2020 2023 2070  nfig_path)   # p
+0001eb80: 796c 696e 743a 2064 6973 6162 6c65 3d45  ylint: disable=E
+0001eb90: 3131 3031 0a20 2020 2020 2020 2020 2020  1101.           
+0001eba0: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+0001ebb0: 6f64 656c 203d 2069 7065 782e 7175 616e  odel = ipex.quan
+0001ebc0: 7469 7a61 7469 6f6e 2e63 6f6e 7665 7274  tization.convert
+0001ebd0: 2873 656c 662e 746d 705f 6d6f 6465 6c2e  (self.tmp_model.
+0001ebe0: 6d6f 6465 6c2c 0a20 2020 2020 2020 2020  model,.         
+0001ebf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0001ec00: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0001ec10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ec20: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0001ec30: 2e6f 7574 7075 745f 7465 6e73 6f72 5f69  .output_tensor_i
-0001ec40: 645f 6f70 5f6e 616d 6529 0a0a 2020 2020  d_op_name)..    
-0001ec50: 2020 2020 2020 2020 7769 7468 206f 7065          with ope
-0001ec60: 6e28 7365 6c66 2e69 7065 785f 636f 6e66  n(self.ipex_conf
-0001ec70: 6967 5f70 6174 682c 2022 7722 2920 6173  ig_path, "w") as
-0001ec80: 2077 7269 7465 5f66 3a0a 2020 2020 2020   write_f:.      
-0001ec90: 2020 2020 2020 2020 2020 6a73 6f6e 2e64            json.d
-0001eca0: 756d 7028 7365 6c66 2e63 6667 732c 2077  ump(self.cfgs, w
-0001ecb0: 7269 7465 5f66 2c20 696e 6465 6e74 3d34  rite_f, indent=4
-0001ecc0: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
-0001ecd0: 7475 726e 204e 6f6e 650a 0a20 2020 2064  turn None..    d
-0001ece0: 6566 2067 6574 5f70 6174 7465 726e 2873  ef get_pattern(s
-0001ecf0: 656c 662c 2066 616c 6c62 6163 6b5f 6f70  elf, fallback_op
-0001ed00: 2c20 6675 7365 5f6f 7073 293a 0a20 2020  , fuse_ops):.   
-0001ed10: 2020 2020 2066 6f72 2066 7573 655f 7061       for fuse_pa
-0001ed20: 7474 6572 6e20 696e 2066 7573 655f 6f70  ttern in fuse_op
-0001ed30: 733a 0a20 2020 2020 2020 2020 2020 2069  s:.            i
-0001ed40: 6620 6675 7365 5f70 6174 7465 726e 5b30  f fuse_pattern[0
-0001ed50: 5d20 3d3d 2066 616c 6c62 6163 6b5f 6f70  ] == fallback_op
-0001ed60: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001ed70: 2020 6966 2066 7573 655f 7061 7474 6572    if fuse_patter
-0001ed80: 6e5b 315d 2069 6e20 5b27 7265 6c75 5f27  n[1] in ['relu_'
-0001ed90: 2c20 2761 6464 5f27 5d3a 0a20 2020 2020  , 'add_']:.     
-0001eda0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0001edb0: 6574 7572 6e20 4e6f 6e65 0a20 2020 2020  eturn None.     
-0001edc0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0001edd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001ede0: 2020 2020 2072 6574 7572 6e20 6675 7365       return fuse
-0001edf0: 5f70 6174 7465 726e 5b31 5d0a 2020 2020  _pattern[1].    
-0001ee00: 2020 2020 7265 7475 726e 204e 6f6e 650a      return None.
-0001ee10: 0a20 2020 2064 6566 2065 7661 6c75 6174  .    def evaluat
-0001ee20: 6528 7365 6c66 2c0a 2020 2020 2020 2020  e(self,.        
-0001ee30: 2020 2020 2020 2020 206d 6f64 656c 2c0a           model,.
-0001ee40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ee50: 2064 6174 616c 6f61 6465 722c 0a20 2020   dataloader,.   
-0001ee60: 2020 2020 2020 2020 2020 2020 2020 706f                po
-0001ee70: 7374 7072 6f63 6573 733d 4e6f 6e65 2c0a  stprocess=None,.
+0001ec20: 2020 2069 7065 785f 636f 6e66 2c0a 2020     ipex_conf,.  
+0001ec30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ec40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ec50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ec60: 2020 2020 2020 2020 2020 7365 6c66 2e65            self.e
+0001ec70: 7861 6d70 6c65 5f69 6e70 7574 732c 0a20  xample_inputs,. 
+0001ec80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ec90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ecb0: 2020 2020 2020 2020 2020 2069 6e70 6c61             inpla
+0001ecc0: 6365 3d54 7275 6529 2020 2320 7079 6c69  ce=True)  # pyli
+0001ecd0: 6e74 3a20 6469 7361 626c 653d 4531 3132  nt: disable=E112
+0001ece0: 310a 2020 2020 2020 2020 2020 2020 2020  1.              
+0001ecf0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+0001ed00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed10: 2020 2020 6966 2073 656c 662e 746d 705f      if self.tmp_
+0001ed20: 6d6f 6465 6c20 6973 204e 6f6e 653a 0a20  model is None:. 
+0001ed30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed40: 2020 2020 2020 2020 2020 2074 7279 3a0a             try:.
+0001ed50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed70: 7365 6c66 2e74 6d70 5f6d 6f64 656c 203d  self.tmp_model =
+0001ed80: 2063 6f70 792e 6465 6570 636f 7079 286d   copy.deepcopy(m
+0001ed90: 6f64 656c 290a 2020 2020 2020 2020 2020  odel).          
+0001eda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001edb0: 2020 6578 6365 7074 2045 7863 6570 7469    except Excepti
+0001edc0: 6f6e 2061 7320 653a 2020 2320 7072 6167  on as e:  # prag
+0001edd0: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
+0001ede0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001edf0: 2020 2020 2020 2020 2020 2020 206c 6f67               log
+0001ee00: 6765 722e 7761 726e 696e 6728 2246 6169  ger.warning("Fai
+0001ee10: 6c20 746f 2064 6565 7020 636f 7079 2074  l to deep copy t
+0001ee20: 6865 206d 6f64 656c 2064 7565 2074 6f20  he model due to 
+0001ee30: 7b7d 2c20 696e 706c 6163 6520 6973 2075  {}, inplace is u
+0001ee40: 7365 6420 6e6f 772e 222e 666f 726d 6174  sed now.".format
+0001ee50: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0001ee60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ee70: 2020 2020 2020 7265 7072 2865 2929 290a        repr(e))).
 0001ee80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ee90: 206d 6574 7269 6373 3d4e 6f6e 652c 0a20   metrics=None,. 
-0001eea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001eeb0: 6d65 6173 7572 6572 3d4e 6f6e 652c 0a20  measurer=None,. 
-0001eec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001eed0: 6974 6572 6174 696f 6e3d 2d31 2c0a 2020  iteration=-1,.  
-0001eee0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-0001eef0: 656e 736f 7262 6f61 7264 3d46 616c 7365  ensorboard=False
-0001ef00: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0001ef10: 2020 2066 7033 325f 6261 7365 6c69 6e65     fp32_baseline
-0001ef20: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
-0001ef30: 2022 2222 4578 6563 7574 6520 7468 6520   """Execute the 
-0001ef40: 6576 616c 7561 7465 2070 726f 6365 7373  evaluate process
-0001ef50: 206f 6e20 7468 6520 7370 6563 6966 6965   on the specifie
-0001ef60: 6420 6d6f 6465 6c2e 0a0a 2020 2020 2020  d model...      
-0001ef70: 2020 4172 6773 3a0a 2020 2020 2020 2020    Args:.        
-0001ef80: 2020 2020 6d6f 6465 6c20 286f 626a 6563      model (objec
-0001ef90: 7429 3a20 4e65 7572 616c 2043 6f6d 7072  t): Neural Compr
-0001efa0: 6573 736f 7220 6d6f 6465 6c20 746f 2072  essor model to r
-0001efb0: 756e 2065 7661 6c75 6174 696f 6e2e 0a20  un evaluation.. 
-0001efc0: 2020 2020 2020 2020 2020 2064 6174 616c             datal
-0001efd0: 6f61 6465 7220 286f 626a 6563 7429 3a20  oader (object): 
-0001efe0: 6576 616c 7561 7469 6f6e 2064 6174 6173  evaluation datas
-0001eff0: 6574 2e0a 2020 2020 2020 2020 2020 2020  et..            
-0001f000: 706f 7374 7072 6f63 6573 7320 286f 626a  postprocess (obj
-0001f010: 6563 742c 206f 7074 696f 6e61 6c29 3a20  ect, optional): 
-0001f020: 7072 6f63 6573 7320 6675 6e63 7469 6f6e  process function
-0001f030: 2061 6674 6572 2065 7661 6c75 6174 696f   after evaluatio
-0001f040: 6e2e 0a20 2020 2020 2020 2020 2020 206d  n..            m
-0001f050: 6574 7269 6373 2028 6c69 7374 2c20 6f70  etrics (list, op
-0001f060: 7469 6f6e 616c 293a 206c 6973 7420 6f66  tional): list of
-0001f070: 206d 6574 7269 6320 6675 6e63 7469 6f6e   metric function
-0001f080: 2e0a 2020 2020 2020 2020 2020 2020 6d65  ..            me
-0001f090: 6173 7572 6572 2028 6f62 6a65 6374 2c20  asurer (object, 
-0001f0a0: 6f70 7469 6f6e 616c 293a 206d 6561 7375  optional): measu
-0001f0b0: 7265 7220 6675 6e63 7469 6f6e 2e0a 2020  rer function..  
-0001f0c0: 2020 2020 2020 2020 2020 6974 6572 6174            iterat
-0001f0d0: 696f 6e20 2869 6e74 2c20 6f70 7469 6f6e  ion (int, option
-0001f0e0: 616c 293a 206e 756d 6265 7220 6f66 2069  al): number of i
-0001f0f0: 7465 7261 7469 6f6e 7320 746f 2065 7661  terations to eva
-0001f100: 6c75 6174 652e 0a20 2020 2020 2020 2020  luate..         
-0001f110: 2020 2074 656e 736f 7262 6f61 7264 2028     tensorboard (
-0001f120: 626f 6f6c 2c20 6f70 7469 6f6e 616c 293a  bool, optional):
-0001f130: 2064 756d 7020 6f75 7470 7574 2074 656e   dump output ten
-0001f140: 736f 7220 746f 2074 656e 736f 7262 6f61  sor to tensorboa
-0001f150: 7264 2073 756d 6d61 7279 0a20 2020 2020  rd summary.     
-0001f160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001f170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001f180: 2020 2020 2066 696c 6573 2849 5045 5820       files(IPEX 
-0001f190: 756e 7370 706f 7274 292e 0a20 2020 2020  unspport)..     
-0001f1a0: 2020 2020 2020 2066 7033 325f 6261 7365         fp32_base
-0001f1b0: 6c69 6e65 2028 626f 6f6c 656e 2c20 6f70  line (boolen, op
-0001f1c0: 7469 6f6e 616c 293a 206f 6e6c 7920 666f  tional): only fo
-0001f1d0: 7220 636f 6d70 6172 655f 6c61 6265 6c3d  r compare_label=
-0001f1e0: 4661 6c73 6520 7069 7065 6c69 6e65 0a0a  False pipeline..
-0001f1f0: 2020 2020 2020 2020 5265 7475 726e 733a          Returns:
-0001f200: 0a20 2020 2020 2020 2020 2020 2028 6469  .            (di
-0001f210: 6374 293a 2071 7561 6e74 697a 6564 206d  ct): quantized m
-0001f220: 6f64 656c 0a20 2020 2020 2020 2022 2222  odel.        """
-0001f230: 0a0a 2020 2020 2020 2020 6173 7365 7274  ..        assert
-0001f240: 206e 6f74 2074 656e 736f 7262 6f61 7264   not tensorboard
-0001f250: 2c20 2249 6e74 656c 2050 7954 6f72 6368  , "Intel PyTorch
-0001f260: 2045 7874 656e 7369 6f6e 2064 6964 6e27   Extension didn'
-0001f270: 7420 7465 6e73 6f72 2064 756d 7022 0a20  t tensor dump". 
-0001f280: 2020 2020 2020 2073 656c 662e 6973 5f62         self.is_b
-0001f290: 6173 656c 696e 6520 3d20 6670 3332 5f62  aseline = fp32_b
-0001f2a0: 6173 656c 696e 650a 0a20 2020 2020 2020  aseline..       
-0001f2b0: 206d 6f64 656c 5f20 3d20 6d6f 6465 6c2e   model_ = model.
-0001f2c0: 5f6d 6f64 656c 0a20 2020 2020 2020 206d  _model.        m
-0001f2d0: 6f64 656c 5f2e 6576 616c 2829 0a0a 2020  odel_.eval()..  
-0001f2e0: 2020 2020 2020 6966 206d 6574 7269 6373        if metrics
-0001f2f0: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
-0001f300: 6c66 2e66 7033 325f 7072 6564 735f 6173  lf.fp32_preds_as
-0001f310: 5f6c 6162 656c 203d 2061 6e79 285b 6861  _label = any([ha
-0001f320: 7361 7474 7228 6d65 7472 6963 2c20 2263  sattr(metric, "c
-0001f330: 6f6d 7061 7265 5f6c 6162 656c 2229 2061  ompare_label") a
-0001f340: 6e64 205c 0a20 2020 2020 2020 2020 2020  nd \.           
-0001f350: 2020 2020 206e 6f74 206d 6574 7269 632e       not metric.
-0001f360: 636f 6d70 6172 655f 6c61 6265 6c20 666f  compare_label fo
-0001f370: 7220 6d65 7472 6963 2069 6e20 6d65 7472  r metric in metr
-0001f380: 6963 735d 290a 0a20 2020 2020 2020 2069  ics])..        i
-0001f390: 7065 785f 636f 6e66 6967 203d 2028 7365  pex_config = (se
-0001f3a0: 6c66 2e69 7065 785f 636f 6e66 6967 5f70  lf.ipex_config_p
-0001f3b0: 6174 6820 6966 206e 6f74 2073 656c 662e  ath if not self.
-0001f3c0: 6265 6e63 686d 6172 6b20 656c 7365 204e  benchmark else N
-0001f3d0: 6f6e 6529 0a20 2020 2020 2020 2069 6620  one).        if 
-0001f3e0: 7365 6c66 2e76 6572 7369 6f6e 2e72 656c  self.version.rel
-0001f3f0: 6561 7365 203c 2056 6572 7369 6f6e 2822  ease < Version("
-0001f400: 312e 3132 2e30 2229 2e72 656c 6561 7365  1.12.0").release
-0001f410: 3a0a 2020 2020 2020 2020 2020 2020 636f  :.            co
-0001f420: 6e66 203d 2028 6970 6578 2e71 7561 6e74  nf = (ipex.quant
-0001f430: 697a 6174 696f 6e2e 5175 616e 7443 6f6e  ization.QuantCon
-0001f440: 6628 636f 6e66 6967 7572 655f 6669 6c65  f(configure_file
-0001f450: 3d69 7065 785f 636f 6e66 6967 2920 2020  =ipex_config)   
-0001f460: 2320 7079 6c69 6e74 3a20 6469 7361 626c  # pylint: disabl
-0001f470: 653d 4531 3130 310a 2020 2020 2020 2020  e=E1101.        
-0001f480: 2020 2020 2020 2020 2020 2020 6966 206e              if n
-0001f490: 6f74 2073 656c 662e 6973 5f62 6173 656c  ot self.is_basel
-0001f4a0: 696e 6520 656c 7365 204e 6f6e 6529 0a20  ine else None). 
-0001f4b0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0001f4c0: 2020 2020 2020 2020 2063 6f6e 6620 3d20           conf = 
-0001f4d0: 4e6f 6e65 0a0a 2020 2020 2020 2020 7265  None..        re
-0001f4e0: 7475 726e 2073 656c 662e 6d6f 6465 6c5f  turn self.model_
-0001f4f0: 6576 616c 286d 6f64 656c 5f2c 2064 6174  eval(model_, dat
-0001f500: 616c 6f61 6465 722c 2070 6f73 7470 726f  aloader, postpro
-0001f510: 6365 7373 2c20 6d65 7472 6963 732c 206d  cess, metrics, m
-0001f520: 6561 7375 7265 722c 2069 7465 7261 7469  easurer, iterati
-0001f530: 6f6e 2c20 636f 6e66 290a 0a20 2020 2040  on, conf)..    @
-0001f540: 6475 6d70 5f65 6c61 7073 6564 5f74 696d  dump_elapsed_tim
-0001f550: 6528 2250 6173 7320 7175 6572 7920 6672  e("Pass query fr
-0001f560: 616d 6577 6f72 6b20 6361 7061 6269 6c69  amework capabili
-0001f570: 7479 2229 0a20 2020 2064 6566 2071 7565  ty").    def que
-0001f580: 7279 5f66 775f 6361 7061 6269 6c69 7479  ry_fw_capability
-0001f590: 2873 656c 662c 206d 6f64 656c 293a 0a20  (self, model):. 
-0001f5a0: 2020 2020 2020 2022 2222 5468 6973 2069         """This i
-0001f5b0: 7320 6120 6865 6c70 6572 2066 756e 6374  s a helper funct
-0001f5c0: 696f 6e20 746f 2067 6574 2061 6c6c 2071  ion to get all q
-0001f5d0: 7561 6e74 697a 6162 6c65 206f 7073 2066  uantizable ops f
-0001f5e0: 726f 6d20 6d6f 6465 6c2e 0a0a 2020 2020  rom model...    
-0001f5f0: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
-0001f600: 2020 2020 2020 6d6f 6465 6c20 286f 626a        model (obj
-0001f610: 6563 7429 3a20 696e 7075 7420 6d6f 6465  ect): input mode
-0001f620: 6c20 7768 6963 6820 6973 204e 6575 7261  l which is Neura
-0001f630: 6c20 436f 6d70 7265 7373 6f72 206d 6f64  l Compressor mod
-0001f640: 656c 0a0a 2020 2020 2020 2020 5265 7475  el..        Retu
-0001f650: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
-0001f660: 2071 5f63 6170 6162 696c 6974 7920 2864   q_capability (d
-0001f670: 6963 7469 6f6e 6172 7929 3a20 7475 6e69  ictionary): tuni
-0001f680: 6e67 2063 6170 6162 696c 6974 7920 666f  ng capability fo
-0001f690: 7220 6561 6368 206f 7020 6672 6f6d 206d  r each op from m
-0001f6a0: 6f64 656c 2e0a 2020 2020 2020 2020 2222  odel..        ""
-0001f6b0: 220a 2020 2020 2020 2020 7365 6c66 2e70  ".        self.p
-0001f6c0: 7265 5f6f 7074 696d 697a 6564 5f6d 6f64  re_optimized_mod
-0001f6d0: 656c 203d 206d 6f64 656c 0a20 2020 2020  el = model.     
-0001f6e0: 2020 2072 6574 7572 6e20 7365 6c66 2e5f     return self._
-0001f6f0: 6765 745f 7175 616e 7469 7a61 626c 655f  get_quantizable_
-0001f700: 6f70 7328 6d6f 6465 6c2e 6d6f 6465 6c29  ops(model.model)
-0001f710: 0a0a 2020 2020 6465 6620 5f67 6574 5f71  ..    def _get_q
-0001f720: 7561 6e74 697a 6162 6c65 5f6f 7073 5f72  uantizable_ops_r
-0001f730: 6563 7572 7369 7665 6c79 2873 656c 662c  ecursively(self,
-0001f740: 206d 6f64 656c 2c20 7072 6566 6978 2c20   model, prefix, 
-0001f750: 7175 616e 7469 7a61 626c 655f 6f70 7329  quantizable_ops)
-0001f760: 3a0a 2020 2020 2020 2020 2222 2254 6869  :.        """Thi
-0001f770: 7320 6973 2061 2068 656c 7065 7220 6675  s is a helper fu
-0001f780: 6e63 7469 6f6e 2066 6f72 2060 7175 6572  nction for `quer
-0001f790: 795f 6677 5f63 6170 6162 696c 6974 7960  y_fw_capability`
-0001f7a0: 2c0a 2020 2020 2020 2020 2020 2061 6e64  ,.           and
-0001f7b0: 2069 7420 7769 6c6c 2067 6574 2061 6c6c   it will get all
-0001f7c0: 2071 7561 6e74 697a 6162 6c65 206f 7073   quantizable ops
-0001f7d0: 2066 726f 6d20 6d6f 6465 6c2e 0a20 2020   from model..   
-0001f7e0: 2020 2020 2041 7267 733a 0a20 2020 2020       Args:.     
-0001f7f0: 2020 2020 2020 206d 6f64 656c 2028 6f62         model (ob
-0001f800: 6a65 6374 293a 2069 6e70 7574 206d 6f64  ject): input mod
-0001f810: 656c 0a20 2020 2020 2020 2020 2020 2070  el.            p
-0001f820: 7265 6669 7820 2873 7472 696e 6729 3a20  refix (string): 
-0001f830: 7072 6566 6978 206f 6620 6f70 206e 616d  prefix of op nam
-0001f840: 650a 2020 2020 2020 2020 2020 2020 7175  e.            qu
-0001f850: 616e 7469 7a61 626c 655f 6f70 7320 286c  antizable_ops (l
-0001f860: 6973 7429 3a20 6c69 7374 206f 6620 7175  ist): list of qu
-0001f870: 616e 7469 7a61 626c 6520 6f70 7320 6672  antizable ops fr
-0001f880: 6f6d 206d 6f64 656c 2069 6e63 6c75 6465  om model include
-0001f890: 206f 7020 6e61 6d65 2061 6e64 2074 7970   op name and typ
-0001f8a0: 652e 0a20 2020 2020 2020 2052 6574 7572  e..        Retur
-0001f8b0: 6e73 3a0a 2020 2020 2020 2020 2020 2020  ns:.            
-0001f8c0: 4e6f 6e65 0a20 2020 2020 2020 2022 2222  None.        """
-0001f8d0: 0a0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
-0001f8e0: 206f 732e 7061 7468 2e65 7869 7374 7328   os.path.exists(
-0001f8f0: 7365 6c66 2e69 7065 785f 636f 6e66 6967  self.ipex_config
-0001f900: 5f70 6174 6829 3a0a 2020 2020 2020 2020  _path):.        
-0001f910: 2020 2020 6173 7365 7274 2069 7369 6e73      assert isins
-0001f920: 7461 6e63 6528 6d6f 6465 6c2c 2074 6f72  tance(model, tor
-0001f930: 6368 2e6e 6e2e 4d6f 6475 6c65 292c 205c  ch.nn.Module), \
-0001f940: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001f950: 2020 2020 2022 5468 6520 6d6f 6465 6c20       "The model 
-0001f960: 7061 7373 6564 2069 6e20 6973 206e 6f74  passed in is not
-0001f970: 2074 6865 2069 6e73 7461 6e63 6520 6f66   the instance of
-0001f980: 2074 6f72 6368 2e6e 6e2e 4d6f 6475 6c65   torch.nn.Module
-0001f990: 220a 0a20 2020 2020 2020 2069 6620 6861  "..        if ha
-0001f9a0: 7361 7474 7228 6d6f 6465 6c2c 2022 7361  sattr(model, "sa
-0001f9b0: 7665 5f71 636f 6e66 5f73 756d 6d61 7279  ve_qconf_summary
-0001f9c0: 2229 3a0a 2020 2020 2020 2020 2020 2020  "):.            
-0001f9d0: 6f73 2e6d 616b 6564 6972 7328 6f73 2e70  os.makedirs(os.p
-0001f9e0: 6174 682e 6469 726e 616d 6528 7365 6c66  ath.dirname(self
-0001f9f0: 2e69 7065 785f 636f 6e66 6967 5f70 6174  .ipex_config_pat
-0001fa00: 6829 2c20 6578 6973 745f 6f6b 3d54 7275  h), exist_ok=Tru
-0001fa10: 6529 0a20 2020 2020 2020 2020 2020 206d  e).            m
-0001fa20: 6f64 656c 2e73 6176 655f 7163 6f6e 665f  odel.save_qconf_
-0001fa30: 7375 6d6d 6172 7928 7163 6f6e 665f 7375  summary(qconf_su
-0001fa40: 6d6d 6172 793d 7365 6c66 2e69 7065 785f  mmary=self.ipex_
-0001fa50: 636f 6e66 6967 5f70 6174 6829 0a20 2020  config_path).   
-0001fa60: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-0001fa70: 2e65 7861 6d70 6c65 5f69 6e70 7574 7320  .example_inputs 
-0001fa80: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
-0001fa90: 2020 2020 2020 2020 2073 656c 662e 6578           self.ex
-0001faa0: 616d 706c 655f 696e 7075 7473 203d 2067  ample_inputs = g
-0001fab0: 6574 5f65 7861 6d70 6c65 5f69 6e70 7574  et_example_input
-0001fac0: 7328 6d6f 6465 6c2c 2073 656c 662e 715f  s(model, self.q_
-0001fad0: 6461 7461 6c6f 6164 6572 290a 2020 2020  dataloader).    
-0001fae0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0001faf0: 2020 2020 2020 6966 2073 656c 662e 7065        if self.pe
-0001fb00: 7266 6f72 6d61 6e63 655f 6f6e 6c79 3a0a  rformance_only:.
-0001fb10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001fb20: 746d 705f 6d6f 6465 6c20 3d20 6d6f 6465  tmp_model = mode
-0001fb30: 6c0a 2020 2020 2020 2020 2020 2020 656c  l.            el
-0001fb40: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0001fb50: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0001fb60: 2020 2020 2020 2020 2020 2020 2074 6d70               tmp
-0001fb70: 5f6d 6f64 656c 203d 2063 6f70 792e 6465  _model = copy.de
-0001fb80: 6570 636f 7079 286d 6f64 656c 290a 2020  epcopy(model).  
-0001fb90: 2020 2020 2020 2020 2020 2020 2020 6578                ex
-0001fba0: 6365 7074 2045 7863 6570 7469 6f6e 2061  cept Exception a
-0001fbb0: 7320 653a 2020 2320 7072 6167 6d61 3a20  s e:  # pragma: 
-0001fbc0: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
-0001fbd0: 2020 2020 2020 2020 2020 2020 206c 6f67               log
-0001fbe0: 6765 722e 7761 726e 696e 6728 2246 6169  ger.warning("Fai
-0001fbf0: 6c20 746f 2064 6565 7020 636f 7079 2074  l to deep copy t
-0001fc00: 6865 206d 6f64 656c 2064 7565 2074 6f20  he model due to 
-0001fc10: 7b7d 2c20 696e 706c 6163 6520 6973 2075  {}, inplace is u
-0001fc20: 7365 6420 6e6f 772e 222e 666f 726d 6174  sed now.".format
-0001fc30: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0001fc40: 2020 2020 2020 2020 2020 7265 7072 2865            repr(e
-0001fc50: 2929 290a 2020 2020 2020 2020 2020 2020  ))).            
-0001fc60: 2020 2020 2020 2020 7261 6973 650a 2020          raise.  
-0001fc70: 2020 2020 2020 2020 2020 746d 705f 6d6f            tmp_mo
-0001fc80: 6465 6c2e 6576 616c 2829 0a20 2020 2020  del.eval().     
-0001fc90: 2020 2020 2020 2023 2074 6f20 7265 636f         # to reco
-0001fca0: 7264 2074 6865 206f 7269 6769 6e20 6261  rd the origin ba
-0001fcb0: 7463 685f 7369 7a65 0a20 2020 2020 2020  tch_size.       
-0001fcc0: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
-0001fcd0: 6365 2873 656c 662e 715f 6461 7461 6c6f  ce(self.q_datalo
-0001fce0: 6164 6572 2c20 4261 7365 4461 7461 4c6f  ader, BaseDataLo
-0001fcf0: 6164 6572 293a 0a20 2020 2020 2020 2020  ader):.         
-0001fd00: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
-0001fd10: 6520 3d20 7365 6c66 2e71 5f64 6174 616c  e = self.q_datal
-0001fd20: 6f61 6465 722e 6261 7463 685f 7369 7a65  oader.batch_size
-0001fd30: 0a0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-0001fd40: 6372 6561 7465 2061 2071 7561 6e74 697a  create a quantiz
-0001fd50: 6174 696f 6e20 636f 6e66 6967 2066 696c  ation config fil
-0001fd60: 6520 666f 7220 696e 7465 6c20 7079 746f  e for intel pyto
-0001fd70: 7263 6820 6578 7465 6e73 696f 6e20 6d6f  rch extension mo
-0001fd80: 6465 6c0a 2020 2020 2020 2020 2020 2020  del.            
-0001fd90: 6f73 2e6d 616b 6564 6972 7328 6f73 2e70  os.makedirs(os.p
-0001fda0: 6174 682e 6469 726e 616d 6528 7365 6c66  ath.dirname(self
-0001fdb0: 2e69 7065 785f 636f 6e66 6967 5f70 6174  .ipex_config_pat
-0001fdc0: 6829 2c20 6578 6973 745f 6f6b 3d54 7275  h), exist_ok=Tru
-0001fdd0: 6529 0a20 2020 2020 2020 2020 2020 2069  e).            i
-0001fde0: 6620 7365 6c66 2e76 6572 7369 6f6e 2e72  f self.version.r
-0001fdf0: 656c 6561 7365 203c 2056 6572 7369 6f6e  elease < Version
-0001fe00: 2822 312e 3132 2e30 2229 2e72 656c 6561  ("1.12.0").relea
-0001fe10: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0001fe20: 2020 2020 6173 7365 7274 2073 656c 662e      assert self.
-0001fe30: 715f 6675 6e63 2069 7320 4e6f 6e65 2c20  q_func is None, 
-0001fe40: 2822 4950 4558 203c 2031 2e31 322e 3020  ("IPEX < 1.12.0 
-0001fe50: 6469 646e 2774 2073 7570 706f 7274 2063  didn't support c
-0001fe60: 616c 6962 7261 7469 6f6e 2066 756e 6374  alibration funct
-0001fe70: 696f 6e2c 2022 0a20 2020 2020 2020 2020  ion, ".         
-0001fe80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ee90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eea0: 7365 6c66 2e74 6d70 5f6d 6f64 656c 203d  self.tmp_model =
+0001eeb0: 206d 6f64 656c 0a20 2020 2020 2020 2020   model.         
+0001eec0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0001eed0: 726f 6d20 746f 7263 682e 616f 2e71 7561  rom torch.ao.qua
+0001eee0: 6e74 697a 6174 696f 6e20 696d 706f 7274  ntization import
+0001eef0: 204d 696e 4d61 784f 6273 6572 7665 722c   MinMaxObserver,
+0001ef00: 2050 6572 4368 616e 6e65 6c4d 696e 4d61   PerChannelMinMa
+0001ef10: 784f 6273 6572 7665 722c 2051 436f 6e66  xObserver, QConf
+0001ef20: 6967 0a20 2020 2020 2020 2020 2020 2020  ig.             
+0001ef30: 2020 2020 2020 2020 2020 2073 7461 7469             stati
+0001ef40: 635f 7163 6f6e 6669 6720 3d20 5143 6f6e  c_qconfig = QCon
+0001ef50: 6669 6728 6163 7469 7661 7469 6f6e 3d4d  fig(activation=M
+0001ef60: 696e 4d61 784f 6273 6572 7665 722e 7769  inMaxObserver.wi
+0001ef70: 7468 5f61 7267 7328 0a20 2020 2020 2020  th_args(.       
+0001ef80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ef90: 2020 2020 2071 7363 6865 6d65 3d74 6f72       qscheme=tor
+0001efa0: 6368 2e70 6572 5f74 656e 736f 725f 6166  ch.per_tensor_af
+0001efb0: 6669 6e65 2c20 6474 7970 653d 746f 7263  fine, dtype=torc
+0001efc0: 682e 7175 696e 7438 292c 0a20 2020 2020  h.quint8),.     
+0001efd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001efe0: 2020 2020 2020 2077 6569 6768 743d 5065         weight=Pe
+0001eff0: 7243 6861 6e6e 656c 4d69 6e4d 6178 4f62  rChannelMinMaxOb
+0001f000: 7365 7276 6572 2e77 6974 685f 6172 6773  server.with_args
+0001f010: 2864 7479 7065 3d74 6f72 6368 2e71 696e  (dtype=torch.qin
+0001f020: 7438 2c20 5c0a 2020 2020 2020 2020 2020  t8, \.          
+0001f030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f040: 2020 2020 2020 2020 2020 2020 2020 7173                qs
+0001f050: 6368 656d 653d 746f 7263 682e 7065 725f  cheme=torch.per_
+0001f060: 6368 616e 6e65 6c5f 7379 6d6d 6574 7269  channel_symmetri
+0001f070: 6329 290a 0a20 2020 2020 2020 2020 2020  c))..           
+0001f080: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+0001f090: 6f64 656c 203d 2069 7065 782e 7175 616e  odel = ipex.quan
+0001f0a0: 7469 7a61 7469 6f6e 2e70 7265 7061 7265  tization.prepare
+0001f0b0: 286d 6f64 656c 2e5f 6d6f 6465 6c2c 2073  (model._model, s
+0001f0c0: 7461 7469 635f 7163 6f6e 6669 672c 205c  tatic_qconfig, \
+0001f0d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001f0e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f100: 2065 7861 6d70 6c65 5f69 6e70 7574 733d   example_inputs=
+0001f110: 7365 6c66 2e65 7861 6d70 6c65 5f69 6e70  self.example_inp
+0001f120: 7574 732c 2069 6e70 6c61 6365 3d46 616c  uts, inplace=Fal
+0001f130: 7365 290a 2020 2020 2020 2020 2020 2020  se).            
+0001f140: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
+0001f150: 6465 6c2e 6c6f 6164 5f71 636f 6e66 5f73  del.load_qconf_s
+0001f160: 756d 6d61 7279 2871 636f 6e66 5f73 756d  ummary(qconf_sum
+0001f170: 6d61 7279 3d73 656c 662e 6970 6578 5f63  mary=self.ipex_c
+0001f180: 6f6e 6669 675f 7061 7468 290a 2020 2020  onfig_path).    
+0001f190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f1a0: 2020 2020 6966 2071 5f66 756e 6320 6973      if q_func is
+0001f1b0: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+0001f1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f1d0: 2020 2020 2020 2071 5f66 756e 6328 715f         q_func(q_
+0001f1e0: 6d6f 6465 6c29 0a20 2020 2020 2020 2020  model).         
+0001f1f0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0001f200: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0001f210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f220: 2073 656c 662e 6d6f 6465 6c5f 6361 6c69   self.model_cali
+0001f230: 6272 6174 696f 6e28 715f 6d6f 6465 6c2c  bration(q_model,
+0001f240: 2064 6174 616c 6f61 6465 722c 2069 7465   dataloader, ite
+0001f250: 7261 7469 6f6e 732c 204e 6f6e 652c 0a20  rations, None,. 
+0001f260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f290: 2020 7475 6e65 5f63 6667 2e67 6574 2827    tune_cfg.get('
+0001f2a0: 6361 6c69 625f 7361 6d70 6c69 6e67 5f73  calib_sampling_s
+0001f2b0: 697a 6527 2c20 3129 290a 2020 2020 2020  ize', 1)).      
+0001f2c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f2d0: 2020 715f 6d6f 6465 6c2e 7361 7665 5f71    q_model.save_q
+0001f2e0: 636f 6e66 5f73 756d 6d61 7279 2871 636f  conf_summary(qco
+0001f2f0: 6e66 5f73 756d 6d61 7279 3d73 656c 662e  nf_summary=self.
+0001f300: 6970 6578 5f63 6f6e 6669 675f 7061 7468  ipex_config_path
+0001f310: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0001f320: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+0001f330: 662e 7573 655f 6266 3136 2061 6e64 2028  f.use_bf16 and (
+0001f340: 4370 7549 6e66 6f28 292e 6266 3136 206f  CpuInfo().bf16 o
+0001f350: 7220 6f73 2e67 6574 656e 7628 2746 4f52  r os.getenv('FOR
+0001f360: 4345 5f42 4631 3627 2920 3d3d 2027 3127  CE_BF16') == '1'
+0001f370: 2920 616e 6420 5c0a 2020 2020 2020 2020  ) and \.        
+0001f380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f390: 2020 2020 2873 656c 662e 7665 7273 696f      (self.versio
+0001f3a0: 6e2e 7265 6c65 6173 6520 3e3d 2056 6572  n.release >= Ver
+0001f3b0: 7369 6f6e 2822 312e 3131 2e30 2229 2e72  sion("1.11.0").r
+0001f3c0: 656c 6561 7365 293a 0a20 2020 2020 2020  elease):.       
+0001f3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f3e0: 2020 2020 2077 6974 6820 746f 7263 682e       with torch.
+0001f3f0: 6e6f 5f67 7261 6428 293a 0a20 2020 2020  no_grad():.     
+0001f400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f410: 2020 2020 2020 2020 2020 2077 6974 6820             with 
+0001f420: 746f 7263 682e 6370 752e 616d 702e 6175  torch.cpu.amp.au
+0001f430: 746f 6361 7374 2829 3a0a 2020 2020 2020  tocast():.      
+0001f440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f450: 2020 2020 2020 2020 2020 2020 2020 715f                q_
+0001f460: 6d6f 6465 6c20 3d20 6970 6578 2e71 7561  model = ipex.qua
+0001f470: 6e74 697a 6174 696f 6e2e 636f 6e76 6572  ntization.conver
+0001f480: 7428 715f 6d6f 6465 6c2c 2069 6e70 6c61  t(q_model, inpla
+0001f490: 6365 3d54 7275 6529 0a20 2020 2020 2020  ce=True).       
+0001f4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f4b0: 2020 2020 2020 2020 2020 2020 2074 7279               try
+0001f4c0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0001f4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f4e0: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
+0001f4f0: 6c20 3d20 746f 7263 682e 6a69 742e 7472  l = torch.jit.tr
+0001f500: 6163 6528 715f 6d6f 6465 6c2c 2073 656c  ace(q_model, sel
+0001f510: 662e 6578 616d 706c 655f 696e 7075 7473  f.example_inputs
+0001f520: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0001f530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f540: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
+0001f550: 6c20 3d20 746f 7263 682e 6a69 742e 6672  l = torch.jit.fr
+0001f560: 6565 7a65 2871 5f6d 6f64 656c 2e65 7661  eeze(q_model.eva
+0001f570: 6c28 2929 0a20 2020 2020 2020 2020 2020  l()).           
+0001f580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f590: 2020 2020 2020 2020 2065 7863 6570 743a           except:
+0001f5a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001f5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f5c0: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
+0001f5d0: 203d 2074 6f72 6368 2e6a 6974 2e74 7261   = torch.jit.tra
+0001f5e0: 6365 2871 5f6d 6f64 656c 2c20 7365 6c66  ce(q_model, self
+0001f5f0: 2e65 7861 6d70 6c65 5f69 6e70 7574 732c  .example_inputs,
+0001f600: 2073 7472 6963 743d 4661 6c73 6529 0a20   strict=False). 
+0001f610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f630: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
+0001f640: 2074 6f72 6368 2e6a 6974 2e66 7265 657a   torch.jit.freez
+0001f650: 6528 715f 6d6f 6465 6c2e 6576 616c 2829  e(q_model.eval()
+0001f660: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0001f670: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+0001f680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f690: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
+0001f6a0: 6465 6c20 3d20 6970 6578 2e71 7561 6e74  del = ipex.quant
+0001f6b0: 697a 6174 696f 6e2e 636f 6e76 6572 7428  ization.convert(
+0001f6c0: 715f 6d6f 6465 6c2c 2069 6e70 6c61 6365  q_model, inplace
+0001f6d0: 3d54 7275 6529 0a20 2020 2020 2020 2020  =True).         
+0001f6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f6f0: 2020 2077 6974 6820 746f 7263 682e 6e6f     with torch.no
+0001f700: 5f67 7261 6428 293a 0a20 2020 2020 2020  _grad():.       
+0001f710: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f720: 2020 2020 2020 2020 2074 7279 3a0a 2020           try:.  
+0001f730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f750: 2020 715f 6d6f 6465 6c20 3d20 746f 7263    q_model = torc
+0001f760: 682e 6a69 742e 7472 6163 6528 715f 6d6f  h.jit.trace(q_mo
+0001f770: 6465 6c2c 2073 656c 662e 6578 616d 706c  del, self.exampl
+0001f780: 655f 696e 7075 7473 290a 2020 2020 2020  e_inputs).      
+0001f790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f7a0: 2020 2020 2020 2020 2020 2020 2020 715f                q_
+0001f7b0: 6d6f 6465 6c20 3d20 746f 7263 682e 6a69  model = torch.ji
+0001f7c0: 742e 6672 6565 7a65 2871 5f6d 6f64 656c  t.freeze(q_model
+0001f7d0: 2e65 7661 6c28 2929 0a20 2020 2020 2020  .eval()).       
+0001f7e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f7f0: 2020 2020 2020 2020 2065 7863 6570 743a           except:
+0001f800: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001f810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f820: 2020 2020 2071 5f6d 6f64 656c 203d 2074       q_model = t
+0001f830: 6f72 6368 2e6a 6974 2e74 7261 6365 2871  orch.jit.trace(q
+0001f840: 5f6d 6f64 656c 2c20 7365 6c66 2e65 7861  _model, self.exa
+0001f850: 6d70 6c65 5f69 6e70 7574 732c 2073 7472  mple_inputs, str
+0001f860: 6963 743d 4661 6c73 6529 0a20 2020 2020  ict=False).     
+0001f870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f880: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+0001f890: 5f6d 6f64 656c 203d 2074 6f72 6368 2e6a  _model = torch.j
+0001f8a0: 6974 2e66 7265 657a 6528 715f 6d6f 6465  it.freeze(q_mode
+0001f8b0: 6c2e 6576 616c 2829 290a 2020 2020 2020  l.eval()).      
+0001f8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f8d0: 2020 2320 4166 7465 7220 6672 6565 7a69    # After freezi
+0001f8e0: 6e67 2c20 7275 6e20 3120 7469 6d65 2074  ng, run 1 time t
+0001f8f0: 6f20 7761 726d 2075 7020 7468 6520 7072  o warm up the pr
+0001f900: 6f66 696c 696e 6720 6772 6170 6820 6578  ofiling graph ex
+0001f910: 6563 7574 6f72 2074 6f20 696e 7365 7274  ecutor to insert
+0001f920: 2070 7269 6d3a 3a70 726f 6669 6c65 0a20   prim::profile. 
+0001f930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f940: 2020 2020 2020 2023 2041 7420 7468 6520         # At the 
+0001f950: 326e 6420 7275 6e2c 2074 6865 206c 6c67  2nd run, the llg
+0001f960: 6120 7061 7373 2077 696c 6c20 6265 2074  a pass will be t
+0001f970: 7269 6767 6572 6564 2061 6e64 2074 6865  riggered and the
+0001f980: 206d 6f64 656c 2069 7320 7475 726e 6564   model is turned
+0001f990: 2069 6e74 6f0a 2020 2020 2020 2020 2020   into.          
+0001f9a0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+0001f9b0: 616e 2069 6e74 3820 6d6f 6465 6c3a 2070  an int8 model: p
+0001f9c0: 7269 6d3a 3a70 726f 6669 6c65 2077 696c  rim::profile wil
+0001f9d0: 6c20 6265 2072 656d 6f76 6564 2061 6e64  l be removed and
+0001f9e0: 2077 696c 6c20 6861 7665 204c 6c67 6146   will have LlgaF
+0001f9f0: 7573 696f 6e47 726f 7570 2069 6e20 7468  usionGroup in th
+0001fa00: 6520 6772 6170 680a 2020 2020 2020 2020  e graph.        
+0001fa10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fa20: 7365 6c66 2e63 616c 6962 5f66 756e 6328  self.calib_func(
+0001fa30: 715f 6d6f 6465 6c2c 2064 6174 616c 6f61  q_model, dataloa
+0001fa40: 6465 722c 2074 6d70 5f69 7465 7261 7469  der, tmp_iterati
+0001fa50: 6f6e 733d 3229 0a0a 2020 2020 2020 2020  ons=2)..        
+0001fa60: 2020 2020 7365 6c66 2e74 6d70 5f6d 6f64      self.tmp_mod
+0001fa70: 656c 2e5f 6d6f 6465 6c20 3d20 715f 6d6f  el._model = q_mo
+0001fa80: 6465 6c0a 2020 2020 2020 2020 2020 2020  del.            
+0001fa90: 7769 7468 206f 7065 6e28 7365 6c66 2e69  with open(self.i
+0001faa0: 7065 785f 636f 6e66 6967 5f70 6174 682c  pex_config_path,
+0001fab0: 2027 7227 2920 6173 2066 3a0a 2020 2020   'r') as f:.    
+0001fac0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0001fad0: 2e74 6d70 5f6d 6f64 656c 2e74 756e 655f  .tmp_model.tune_
+0001fae0: 6366 6720 3d20 6a73 6f6e 2e6c 6f61 6428  cfg = json.load(
+0001faf0: 6629 0a20 2020 2020 2020 2020 2020 2073  f).            s
+0001fb00: 656c 662e 746d 705f 6d6f 6465 6c2e 6970  elf.tmp_model.ip
+0001fb10: 6578 5f63 6f6e 6669 675f 7061 7468 203d  ex_config_path =
+0001fb20: 2073 656c 662e 6970 6578 5f63 6f6e 6669   self.ipex_confi
+0001fb30: 675f 7061 7468 0a20 2020 2020 2020 2020  g_path.         
+0001fb40: 2020 2072 6574 7572 6e20 7365 6c66 2e74     return self.t
+0001fb50: 6d70 5f6d 6f64 656c 0a0a 2020 2020 6465  mp_model..    de
+0001fb60: 6620 5f63 6667 5f74 6f5f 7163 6f6e 6669  f _cfg_to_qconfi
+0001fb70: 6728 7365 6c66 2c20 7475 6e65 5f63 6667  g(self, tune_cfg
+0001fb80: 293a 0a20 2020 2020 2020 2022 2222 436f  ):.        """Co
+0001fb90: 6e76 6572 7420 7475 6e65 2063 6f6e 6669  nvert tune confi
+0001fba0: 6775 7265 2074 6f20 7175 616e 7469 7a61  gure to quantiza
+0001fbb0: 7469 6f6e 2063 6f6e 6669 6720 666f 7220  tion config for 
+0001fbc0: 6561 6368 206f 702e 0a0a 2020 2020 2020  each op...      
+0001fbd0: 2020 2020 2020 4172 6773 3a0a 2020 2020        Args:.    
+0001fbe0: 2020 2020 2020 2020 2020 2020 7475 6e65              tune
+0001fbf0: 5f63 6667 2028 6469 6374 293a 2064 6963  _cfg (dict): dic
+0001fc00: 7469 6f6e 6172 7920 6f66 2074 756e 6520  tionary of tune 
+0001fc10: 636f 6e66 6967 7572 6520 666f 7220 6561  configure for ea
+0001fc20: 6368 206f 700a 2020 2020 2020 2020 2020  ch op.          
+0001fc30: 2020 2020 2020 6970 6578 5f63 6f6e 6669        ipex_confi
+0001fc40: 675f 7061 7468 3a20 636f 6e66 6967 7572  g_path: configur
+0001fc50: 6520 6669 6c65 206f 6620 496e 7465 6c20  e file of Intel 
+0001fc60: 5079 546f 7263 6820 4578 7465 6e73 696f  PyTorch Extensio
+0001fc70: 6e0a 0a20 2020 2020 2020 2020 2020 2074  n..            t
+0001fc80: 756e 655f 6366 6720 7368 6f75 6c64 2062  une_cfg should b
+0001fc90: 6520 6120 666f 726d 6174 206c 696b 6520  e a format like 
+0001fca0: 6265 6c6f 773a 0a20 2020 2020 2020 2020  below:.         
+0001fcb0: 2020 207b 0a20 2020 2020 2020 2020 2020     {.           
+0001fcc0: 2020 2027 6361 6c69 625f 6974 6572 6174     'calib_iterat
+0001fcd0: 696f 6e27 3a20 3130 2c0a 2020 2020 2020  ion': 10,.      
+0001fce0: 2020 2020 2020 2020 276f 7027 3a20 7b0a          'op': {.
+0001fcf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fd00: 2028 276f 7031 272c 2027 434f 4e56 3244   ('op1', 'CONV2D
+0001fd10: 2729 3a20 7b0a 2020 2020 2020 2020 2020  '): {.          
+0001fd20: 2020 2020 2020 2020 2027 6163 7469 7661           'activa
+0001fd30: 7469 6f6e 273a 2020 7b27 6474 7970 6527  tion':  {'dtype'
+0001fd40: 3a20 2775 696e 7438 272c 0a20 2020 2020  : 'uint8',.     
+0001fd50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fd60: 2020 2020 2020 2020 2020 2020 2020 2761                'a
+0001fd70: 6c67 6f72 6974 686d 273a 2027 6d69 6e6d  lgorithm': 'minm
+0001fd80: 6178 272c 0a20 2020 2020 2020 2020 2020  ax',.           
+0001fd90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fda0: 2020 2020 2020 2020 2773 6368 656d 6527          'scheme'
+0001fdb0: 3a27 7379 6d27 2c0a 2020 2020 2020 2020  :'sym',.        
+0001fdc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fdd0: 2020 2020 2020 2020 2020 2027 6772 616e             'gran
+0001fde0: 756c 6172 6974 7927 3a20 2770 6572 5f74  ularity': 'per_t
+0001fdf0: 656e 736f 7227 7d2c 0a20 2020 2020 2020  ensor'},.       
+0001fe00: 2020 2020 2020 2020 2020 2020 2777 6569              'wei
+0001fe10: 6768 7427 3a20 7b27 6474 7970 6527 3a20  ght': {'dtype': 
+0001fe20: 2769 6e74 3827 2c0a 2020 2020 2020 2020  'int8',.        
+0001fe30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fe40: 2020 2020 2020 2761 6c67 6f72 6974 686d        'algorithm
+0001fe50: 273a 2027 6b6c 272c 0a20 2020 2020 2020  ': 'kl',.       
+0001fe60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fe70: 2020 2020 2020 2027 7363 6865 6d65 273a         'scheme':
+0001fe80: 2761 7379 6d27 2c0a 2020 2020 2020 2020  'asym',.        
 0001fe90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001fea0: 2020 2020 2020 2020 2250 6c65 6173 6520          "Please 
-0001feb0: 7573 6520 4950 4558 203e 3d20 312e 3132  use IPEX >= 1.12
-0001fec0: 2e30 2122 290a 2020 2020 2020 2020 2020  .0!").          
-0001fed0: 2020 2020 2020 6970 6578 5f63 6f6e 6620        ipex_conf 
-0001fee0: 3d20 6970 6578 2e71 7561 6e74 697a 6174  = ipex.quantizat
-0001fef0: 696f 6e2e 5175 616e 7443 6f6e 6628 7173  ion.QuantConf(qs
-0001ff00: 6368 656d 653d 746f 7263 682e 7065 725f  cheme=torch.per_
-0001ff10: 7465 6e73 6f72 5f73 796d 6d65 7472 6963  tensor_symmetric
-0001ff20: 2920 2020 2320 7079 6c69 6e74 3a20 6469  )   # pylint: di
-0001ff30: 7361 626c 653d 4531 3130 310a 2020 2020  sable=E1101.    
-0001ff40: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0001ff50: 2e6d 6f64 656c 5f63 616c 6962 7261 7469  .model_calibrati
-0001ff60: 6f6e 280a 2020 2020 2020 2020 2020 2020  on(.            
-0001ff70: 2020 2020 2020 2020 746d 705f 6d6f 6465          tmp_mode
-0001ff80: 6c2c 0a20 2020 2020 2020 2020 2020 2020  l,.             
-0001ff90: 2020 2020 2020 2073 656c 662e 715f 6461         self.q_da
-0001ffa0: 7461 6c6f 6164 6572 2c0a 2020 2020 2020  taloader,.      
-0001ffb0: 2020 2020 2020 2020 2020 2020 2020 636f                co
-0001ffc0: 6e66 3d69 7065 785f 636f 6e66 2c0a 2020  nf=ipex_conf,.  
-0001ffd0: 2020 2020 2020 2020 2020 2020 2020 290a                ).
-0001ffe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001fff0: 6970 6578 5f63 6f6e 662e 7361 7665 2873  ipex_conf.save(s
-00020000: 656c 662e 6970 6578 5f63 6f6e 6669 675f  elf.ipex_config_
-00020010: 7061 7468 290a 2020 2020 2020 2020 2020  path).          
-00020020: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00020030: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00020040: 6170 7072 6f61 6368 2069 6e20 5b27 706f  approach in ['po
-00020050: 7374 5f74 7261 696e 696e 675f 7374 6174  st_training_stat
-00020060: 6963 5f71 7561 6e74 272c 2027 706f 7374  ic_quant', 'post
-00020070: 5f74 7261 696e 696e 675f 6175 746f 5f71  _training_auto_q
-00020080: 7561 6e74 275d 3a0a 2020 2020 2020 2020  uant']:.        
-00020090: 2020 2020 2020 2020 2020 2020 6173 7365              asse
-000200a0: 7274 2073 656c 662e 715f 6461 7461 6c6f  rt self.q_datalo
-000200b0: 6164 6572 2069 7320 6e6f 7420 4e6f 6e65  ader is not None
-000200c0: 2c20 2249 5045 5820 6e65 6564 2071 5f64  , "IPEX need q_d
-000200d0: 6174 616c 6f61 6465 7220 746f 2070 7265  ataloader to pre
-000200e0: 7061 7265 2074 6865 206d 6f64 656c 220a  pare the model".
-000200f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020100: 2020 2020 6672 6f6d 2074 6f72 6368 2e61      from torch.a
-00020110: 6f2e 7175 616e 7469 7a61 7469 6f6e 2069  o.quantization i
-00020120: 6d70 6f72 7420 4d69 6e4d 6178 4f62 7365  mport MinMaxObse
-00020130: 7276 6572 2c20 5065 7243 6861 6e6e 656c  rver, PerChannel
-00020140: 4d69 6e4d 6178 4f62 7365 7276 6572 2c20  MinMaxObserver, 
-00020150: 5143 6f6e 6669 670a 2020 2020 2020 2020  QConfig.        
-00020160: 2020 2020 2020 2020 2020 2020 7374 6174              stat
-00020170: 6963 5f71 636f 6e66 6967 203d 2051 436f  ic_qconfig = QCo
-00020180: 6e66 6967 2861 6374 6976 6174 696f 6e3d  nfig(activation=
-00020190: 4d69 6e4d 6178 4f62 7365 7276 6572 2e77  MinMaxObserver.w
-000201a0: 6974 685f 6172 6773 280a 2020 2020 2020  ith_args(.      
-000201b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000201c0: 2020 7173 6368 656d 653d 746f 7263 682e    qscheme=torch.
-000201d0: 7065 725f 7465 6e73 6f72 5f61 6666 696e  per_tensor_affin
-000201e0: 652c 2064 7479 7065 3d74 6f72 6368 2e71  e, dtype=torch.q
-000201f0: 7569 6e74 3829 2c0a 2020 2020 2020 2020  uint8),.        
-00020200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020210: 7765 6967 6874 3d50 6572 4368 616e 6e65  weight=PerChanne
-00020220: 6c4d 696e 4d61 784f 6273 6572 7665 722e  lMinMaxObserver.
-00020230: 7769 7468 5f61 7267 7328 6474 7970 653d  with_args(dtype=
-00020240: 746f 7263 682e 7169 6e74 382c 205c 0a20  torch.qint8, \. 
-00020250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020270: 2020 7173 6368 656d 653d 746f 7263 682e    qscheme=torch.
-00020280: 7065 725f 6368 616e 6e65 6c5f 7379 6d6d  per_channel_symm
-00020290: 6574 7269 6329 290a 2020 2020 2020 2020  etric)).        
-000202a0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-000202b0: 656c 662e 6578 616d 706c 655f 696e 7075  elf.example_inpu
-000202c0: 7473 2069 7320 4e6f 6e65 3a0a 2020 2020  ts is None:.    
-000202d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000202e0: 2020 2020 7365 6c66 2e65 7861 6d70 6c65      self.example
-000202f0: 5f69 6e70 7574 7320 3d20 6765 745f 6578  _inputs = get_ex
-00020300: 616d 706c 655f 696e 7075 7473 2874 6d70  ample_inputs(tmp
-00020310: 5f6d 6f64 656c 2c20 7365 6c66 2e71 5f64  _model, self.q_d
-00020320: 6174 616c 6f61 6465 7229 0a20 2020 2020  ataloader).     
-00020330: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00020340: 6d70 5f6d 6f64 656c 203d 2069 7065 782e  mp_model = ipex.
-00020350: 7175 616e 7469 7a61 7469 6f6e 2e70 7265  quantization.pre
-00020360: 7061 7265 2874 6d70 5f6d 6f64 656c 2c20  pare(tmp_model, 
-00020370: 7374 6174 6963 5f71 636f 6e66 6967 2c20  static_qconfig, 
-00020380: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00020390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000203a0: 2020 2020 2020 2020 2020 2020 2020 6578                ex
-000203b0: 616d 706c 655f 696e 7075 7473 3d73 656c  ample_inputs=sel
-000203c0: 662e 6578 616d 706c 655f 696e 7075 7473  f.example_inputs
-000203d0: 2c20 696e 706c 6163 653d 5472 7565 290a  , inplace=True).
-000203e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000203f0: 6966 2073 656c 662e 715f 6675 6e63 2069  if self.q_func i
-00020400: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-00020410: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00020420: 2e6d 6f64 656c 5f63 616c 6962 7261 7469  .model_calibrati
-00020430: 6f6e 2874 6d70 5f6d 6f64 656c 2c20 7365  on(tmp_model, se
-00020440: 6c66 2e71 5f64 6174 616c 6f61 6465 7229  lf.q_dataloader)
-00020450: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00020460: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00020470: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00020480: 715f 6675 6e63 2874 6d70 5f6d 6f64 656c  q_func(tmp_model
-00020490: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-000204a0: 2020 746d 705f 6d6f 6465 6c2e 7361 7665    tmp_model.save
-000204b0: 5f71 636f 6e66 5f73 756d 6d61 7279 2871  _qconf_summary(q
-000204c0: 636f 6e66 5f73 756d 6d61 7279 3d73 656c  conf_summary=sel
-000204d0: 662e 6970 6578 5f63 6f6e 6669 675f 7061  f.ipex_config_pa
-000204e0: 7468 290a 2020 2020 2020 2020 2020 2020  th).            
-000204f0: 6966 2069 7369 6e73 7461 6e63 6528 7365  if isinstance(se
-00020500: 6c66 2e71 5f64 6174 616c 6f61 6465 722c  lf.q_dataloader,
-00020510: 2042 6173 6544 6174 614c 6f61 6465 7229   BaseDataLoader)
-00020520: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00020530: 2020 7365 6c66 2e71 5f64 6174 616c 6f61    self.q_dataloa
-00020540: 6465 722e 6261 7463 6828 6261 7463 685f  der.batch(batch_
-00020550: 7369 7a65 290a 2020 2020 2020 2020 2020  size).          
-00020560: 2020 2020 2020 6c6f 6767 6572 2e69 6e66        logger.inf
-00020570: 6f28 2752 6563 6f76 6572 7920 6063 616c  o('Recovery `cal
-00020580: 6962 7261 7469 6f6e 2e64 6174 616c 6f61  ibration.dataloa
-00020590: 6465 722e 6261 7463 6873 697a 6560 207b  der.batchsize` {
-000205a0: 7d20 6163 636f 7264 696e 6720 5c0a 2020  } according \.  
-000205b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000205c0: 2020 2020 2020 2020 2020 746f 2063 6f6e            to con
-000205d0: 6669 672e 7961 6d6c 272e 666f 726d 6174  fig.yaml'.format
-000205e0: 2862 6174 6368 5f73 697a 6529 290a 2020  (batch_size)).  
-000205f0: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
-00020600: 2073 656c 662e 7065 7266 6f72 6d61 6e63   self.performanc
-00020610: 655f 6f6e 6c79 3a0a 2020 2020 2020 2020  e_only:.        
-00020620: 2020 2020 2020 2020 6465 6c20 746d 705f          del tmp_
-00020630: 6d6f 6465 6c0a 2020 2020 2020 2020 2020  model.          
-00020640: 2020 2020 2020 696d 706f 7274 2067 630a        import gc.
+0001fea0: 2020 2020 2020 2767 7261 6e75 6c61 7269        'granulari
+0001feb0: 7479 273a 2027 7065 725f 6368 616e 6e65  ty': 'per_channe
+0001fec0: 6c27 7d0a 2020 2020 2020 2020 2020 2020  l'}.            
+0001fed0: 2020 2020 207d 2c0a 2020 2020 2020 2020       },.        
+0001fee0: 2020 2020 2020 2020 2028 276f 7032 272c           ('op2',
+0001fef0: 2027 5245 4c55 293a 207b 0a20 2020 2020   'RELU): {.     
+0001ff00: 2020 2020 2020 2020 2020 2020 2020 2761                'a
+0001ff10: 6374 6976 6174 696f 6e27 3a20 7b27 6474  ctivation': {'dt
+0001ff20: 7970 6527 3a20 2769 6e74 3827 2c0a 2020  ype': 'int8',.  
+0001ff30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ff40: 2027 7363 6865 6d65 273a 2027 6173 796d   'scheme': 'asym
+0001ff50: 272c 0a20 2020 2020 2020 2020 2020 2020  ',.             
+0001ff60: 2020 2020 2020 2767 7261 6e75 6c61 7269        'granulari
+0001ff70: 7479 273a 2027 7065 725f 7465 6e73 6f72  ty': 'per_tensor
+0001ff80: 272c 0a20 2020 2020 2020 2020 2020 2020  ',.             
+0001ff90: 2020 2020 2020 2761 6c67 6f72 6974 686d        'algorithm
+0001ffa0: 273a 2027 6d69 6e6d 6178 277d 0a20 2020  ': 'minmax'}.   
+0001ffb0: 2020 2020 2020 2020 2020 2020 2020 7d2c                },
+0001ffc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001ffd0: 2020 2827 6f70 3327 2c20 2743 4f4e 5632    ('op3', 'CONV2
+0001ffe0: 4427 293a 207b 0a20 2020 2020 2020 2020  D'): {.         
+0001fff0: 2020 2020 2020 2020 2020 2761 6374 6976            'activ
+00020000: 6174 696f 6e27 3a20 207b 2764 7479 7065  ation':  {'dtype
+00020010: 273a 2027 6670 3332 277d 2c0a 2020 2020  ': 'fp32'},.    
+00020020: 2020 2020 2020 2020 2020 2020 2020 2027                 '
+00020030: 7765 6967 6874 273a 207b 2764 7479 7065  weight': {'dtype
+00020040: 273a 2027 6670 3332 277d 0a20 2020 2020  ': 'fp32'}.     
+00020050: 2020 2020 2020 2020 2020 2020 7d2c 0a20              },. 
+00020060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020070: 2e2e 2e0a 2020 2020 2020 2020 2020 2020  ....            
+00020080: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
+00020090: 7d0a 2020 2020 2020 2020 2222 220a 2020  }.        """.  
+000200a0: 2020 2020 2020 6173 7365 7274 2073 656c        assert sel
+000200b0: 662e 6366 6773 2069 7320 6e6f 7420 4e6f  f.cfgs is not No
+000200c0: 6e65 2c20 224e 6f20 636f 6e66 6967 7572  ne, "No configur
+000200d0: 6520 666f 7220 4950 4558 2069 6e74 3820  e for IPEX int8 
+000200e0: 6d6f 6465 6c2e 2e2e 220a 2020 2020 2020  model...".      
+000200f0: 2020 6966 2073 656c 662e 7665 7273 696f    if self.versio
+00020100: 6e2e 7265 6c65 6173 6520 3c20 5665 7273  n.release < Vers
+00020110: 696f 6e28 2231 2e31 322e 3022 292e 7265  ion("1.12.0").re
+00020120: 6c65 6173 653a 0a20 2020 2020 2020 2020  lease:.         
+00020130: 2020 2066 6f72 206b 6579 2069 6e20 7475     for key in tu
+00020140: 6e65 5f63 6667 5b27 6f70 275d 3a0a 2020  ne_cfg['op']:.  
+00020150: 2020 2020 2020 2020 2020 2020 2020 7472                tr
+00020160: 793a 0a20 2020 2020 2020 2020 2020 2020  y:.             
+00020170: 2020 2020 2020 2073 6368 656d 6520 3d20         scheme = 
+00020180: 7475 6e65 5f63 6667 5b27 6f70 275d 5b6b  tune_cfg['op'][k
+00020190: 6579 5d5b 2761 6374 6976 6174 696f 6e27  ey]['activation'
+000201a0: 5d5b 2773 6368 656d 6527 5d0a 2020 2020  ]['scheme'].    
+000201b0: 2020 2020 2020 2020 2020 2020 6578 6365              exce
+000201c0: 7074 3a0a 2020 2020 2020 2020 2020 2020  pt:.            
+000201d0: 2020 2020 2020 2020 7363 6865 6d65 203d          scheme =
+000201e0: 2027 6173 796d 270a 2020 2020 2020 2020   'asym'.        
+000201f0: 2020 2020 2020 2020 6966 2073 6368 656d          if schem
+00020200: 6520 6e6f 7420 696e 205b 2761 7379 6d27  e not in ['asym'
+00020210: 2c20 2773 796d 275d 3a0a 2020 2020 2020  , 'sym']:.      
+00020220: 2020 2020 2020 2020 2020 2020 2020 7363                sc
+00020230: 6865 6d65 203d 2027 6173 796d 270a 2020  heme = 'asym'.  
+00020240: 2020 2020 2020 2020 2020 2020 2020 6272                br
+00020250: 6561 6b0a 2020 2020 2020 2020 2020 2020  eak.            
+00020260: 666f 7220 6b65 7920 696e 2074 756e 655f  for key in tune_
+00020270: 6366 675b 276f 7027 5d3a 0a20 2020 2020  cfg['op']:.     
+00020280: 2020 2020 2020 2020 2020 2076 616c 7565             value
+00020290: 203d 2074 756e 655f 6366 675b 276f 7027   = tune_cfg['op'
+000202a0: 5d5b 6b65 795d 0a20 2020 2020 2020 2020  ][key].         
+000202b0: 2020 2020 2020 2070 6174 7465 726e 203d         pattern =
+000202c0: 2073 656c 662e 6765 745f 7061 7474 6572   self.get_patter
+000202d0: 6e28 6b65 792c 2073 656c 662e 6675 7365  n(key, self.fuse
+000202e0: 5f6f 7073 290a 2020 2020 2020 2020 2020  _ops).          
+000202f0: 2020 2020 2020 6173 7365 7274 2069 7369        assert isi
+00020300: 6e73 7461 6e63 6528 7661 6c75 652c 2064  nstance(value, d
+00020310: 6963 7429 0a20 2020 2020 2020 2020 2020  ict).           
+00020320: 2020 2020 2061 7373 6572 7420 2761 6374       assert 'act
+00020330: 6976 6174 696f 6e27 2069 6e20 7661 6c75  ivation' in valu
+00020340: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+00020350: 2020 6966 2076 616c 7565 5b27 6163 7469    if value['acti
+00020360: 7661 7469 6f6e 275d 5b27 6474 7970 6527  vation']['dtype'
+00020370: 5d20 3d3d 2027 6670 3332 273a 0a20 2020  ] == 'fp32':.   
+00020380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020390: 2069 6620 2777 6569 6768 7427 2069 6e20   if 'weight' in 
+000203a0: 7661 6c75 653a 0a20 2020 2020 2020 2020  value:.         
+000203b0: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+000203c0: 7373 6572 7420 7661 6c75 655b 2777 6569  ssert value['wei
+000203d0: 6768 7427 5d5b 2764 7479 7065 275d 203d  ght']['dtype'] =
+000203e0: 3d20 2766 7033 3227 0a20 2020 2020 2020  = 'fp32'.       
+000203f0: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+00020400: 206f 705f 6366 6720 696e 2073 656c 662e   op_cfg in self.
+00020410: 6366 6773 3a0a 2020 2020 2020 2020 2020  cfgs:.          
+00020420: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00020430: 206f 705f 6366 675b 2269 6422 5d20 3d3d   op_cfg["id"] ==
+00020440: 206b 6579 5b30 5d3a 0a20 2020 2020 2020   key[0]:.       
+00020450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020460: 2020 2020 2069 6620 6b65 795b 315d 2069       if key[1] i
+00020470: 6e20 5b27 7265 6c75 5f27 2c20 2761 6464  n ['relu_', 'add
+00020480: 5f27 5d3a 0a20 2020 2020 2020 2020 2020  _']:.           
+00020490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000204a0: 2020 2020 2063 6f6e 7469 6e75 650a 2020       continue.  
+000204b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000204c0: 2020 2020 2020 2020 2020 6e75 6d5f 696e            num_in
+000204d0: 7075 7473 203d 206c 656e 286f 705f 6366  puts = len(op_cf
+000204e0: 675b 2269 6e70 7574 735f 7175 616e 7469  g["inputs_quanti
+000204f0: 7a65 6422 5d29 0a20 2020 2020 2020 2020  zed"]).         
+00020500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020510: 2020 206e 756d 5f6f 7574 7075 7473 203d     num_outputs =
+00020520: 206c 656e 286f 705f 6366 675b 226f 7574   len(op_cfg["out
+00020530: 7075 7473 5f71 7561 6e74 697a 6564 225d  puts_quantized"]
+00020540: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00020550: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+00020560: 7220 695f 6e75 6d20 696e 2072 616e 6765  r i_num in range
+00020570: 286e 756d 5f69 6e70 7574 7329 3a0a 2020  (num_inputs):.  
+00020580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020590: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+000205a0: 5f63 6667 5b22 696e 7075 7473 5f71 7561  _cfg["inputs_qua
+000205b0: 6e74 697a 6564 225d 5b69 5f6e 756d 5d20  ntized"][i_num] 
+000205c0: 3d20 4661 6c73 650a 2020 2020 2020 2020  = False.        
+000205d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000205e0: 2020 2020 666f 7220 6f5f 6e75 6d20 696e      for o_num in
+000205f0: 2072 616e 6765 286e 756d 5f6f 7574 7075   range(num_outpu
+00020600: 7473 293a 0a20 2020 2020 2020 2020 2020  ts):.           
+00020610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020620: 2020 2020 206f 705f 6366 675b 226f 7574       op_cfg["out
+00020630: 7075 7473 5f71 7561 6e74 697a 6564 225d  puts_quantized"]
+00020640: 5b6f 5f6e 756d 5d20 3d20 4661 6c73 650a  [o_num] = False.
 00020650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020660: 6763 2e63 6f6c 6c65 6374 2829 0a0a 2020  gc.collect()..  
-00020670: 2020 2020 2020 7769 7468 206f 7065 6e28        with open(
-00020680: 7365 6c66 2e69 7065 785f 636f 6e66 6967  self.ipex_config
-00020690: 5f70 6174 682c 2027 7227 2920 6173 2066  _path, 'r') as f
-000206a0: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
-000206b0: 6c66 2e63 6667 7320 3d20 6a73 6f6e 2e6c  lf.cfgs = json.l
-000206c0: 6f61 6428 6629 0a20 2020 2020 2020 2020  oad(f).         
-000206d0: 2020 2069 6620 7365 6c66 2e76 6572 7369     if self.versi
-000206e0: 6f6e 2e72 656c 6561 7365 203c 2056 6572  on.release < Ver
-000206f0: 7369 6f6e 2822 312e 3132 2e30 2229 2e72  sion("1.12.0").r
-00020700: 656c 6561 7365 3a0a 2020 2020 2020 2020  elease:.        
-00020710: 2020 2020 2020 2020 7365 6c66 2e64 6566          self.def
-00020720: 6175 6c74 5f63 6667 7320 3d20 636f 7079  ault_cfgs = copy
-00020730: 2e64 6565 7063 6f70 7928 7365 6c66 2e63  .deepcopy(self.c
-00020740: 6667 7329 0a20 2020 2020 2020 2020 2020  fgs).           
-00020750: 2020 2020 2073 656c 662e 6675 7365 5f6f       self.fuse_o
-00020760: 7073 203d 2073 656c 662e 6765 745f 6675  ps = self.get_fu
-00020770: 7365 5f6f 7073 2873 656c 662e 6366 6773  se_ops(self.cfgs
-00020780: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00020790: 2020 666f 7220 6f70 5f63 6667 2069 6e20    for op_cfg in 
-000207a0: 7365 6c66 2e63 6667 733a 0a20 2020 2020  self.cfgs:.     
-000207b0: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-000207c0: 7561 6e74 697a 6162 6c65 5f6f 7073 2e61  uantizable_ops.a
-000207d0: 7070 656e 6428 0a20 2020 2020 2020 2020  ppend(.         
-000207e0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-000207f0: 6f70 5f63 6667 5b22 6964 225d 2c20 756e  op_cfg["id"], un
-00020800: 6966 795f 6f70 5f74 7970 655f 6d61 7070  ify_op_type_mapp
-00020810: 696e 675f 6970 6578 5b6f 705f 6366 675b  ing_ipex[op_cfg[
-00020820: 226e 616d 6522 5d5d 0a20 2020 2020 2020  "name"]].       
-00020830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020840: 2020 6966 206f 705f 6366 675b 226e 616d    if op_cfg["nam
-00020850: 6522 5d20 696e 2075 6e69 6679 5f6f 705f  e"] in unify_op_
-00020860: 7479 7065 5f6d 6170 7069 6e67 5f69 7065  type_mapping_ipe
-00020870: 7820 656c 7365 206f 705f 6366 675b 226e  x else op_cfg["n
-00020880: 616d 6522 5d29 290a 2020 2020 2020 2020  ame"])).        
-00020890: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-000208a0: 2020 2020 2020 2020 2020 6f70 735f 6e61            ops_na
-000208b0: 6d65 2c20 6f70 5f69 6e66 6f73 5f66 726f  me, op_infos_fro
-000208c0: 6d5f 6366 6773 2c20 696e 7075 745f 7465  m_cfgs, input_te
-000208d0: 6e73 6f72 5f69 645f 6f70 5f6e 616d 652c  nsor_id_op_name,
-000208e0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-000208f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020900: 2020 206f 7574 7075 745f 7465 6e73 6f72     output_tensor
-00020910: 5f69 645f 6f70 5f6e 616d 6520 3d20 746f  _id_op_name = to
-00020920: 7263 685f 7574 696c 732e 7574 696c 2e70  rch_utils.util.p
-00020930: 6173 6572 5f63 6667 7328 7365 6c66 2e63  aser_cfgs(self.c
-00020940: 6667 7329 0a20 2020 2020 2020 2020 2020  fgs).           
-00020950: 2020 2020 2071 7561 6e74 697a 6162 6c65       quantizable
-00020960: 5f6f 705f 6e61 6d65 7320 3d20 746f 7263  _op_names = torc
-00020970: 685f 7574 696c 732e 7574 696c 2e67 6574  h_utils.util.get
-00020980: 5f71 7561 6e74 697a 6162 6c65 5f6f 7073  _quantizable_ops
-00020990: 5f66 726f 6d5f 6366 6773 286f 7073 5f6e  _from_cfgs(ops_n
-000209a0: 616d 652c 0a20 2020 2020 2020 2020 2020  ame,.           
-000209b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000209c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000209d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000209e0: 2020 2020 2020 2020 2020 6f70 5f69 6e66            op_inf
-000209f0: 6f73 5f66 726f 6d5f 6366 6773 2c0a 2020  os_from_cfgs,.  
-00020a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020a40: 2020 2069 6e70 7574 5f74 656e 736f 725f     input_tensor_
-00020a50: 6964 5f6f 705f 6e61 6d65 290a 2020 2020  id_op_name).    
-00020a60: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00020a70: 6e61 6d65 2069 6e20 7175 616e 7469 7a61  name in quantiza
-00020a80: 626c 655f 6f70 5f6e 616d 6573 3a0a 2020  ble_op_names:.  
-00020a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020aa0: 2020 2320 6e61 6d65 203a 206c 6973 740a    # name : list.
-00020ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020ac0: 2020 2020 6966 206c 656e 286e 616d 6529      if len(name)
-00020ad0: 203d 3d20 313a 0a20 2020 2020 2020 2020   == 1:.         
-00020ae0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-00020af0: 6f64 756c 655f 6b65 7920 3d20 6e61 6d65  odule_key = name
-00020b00: 5b30 5d5b 305d 0a20 2020 2020 2020 2020  [0][0].         
-00020b10: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00020b20: 705f 6366 675f 6964 203d 206e 616d 655b  p_cfg_id = name[
-00020b30: 305d 5b32 5d0a 2020 2020 2020 2020 2020  0][2].          
-00020b40: 2020 2020 2020 2020 2020 2020 2020 7175                qu
-00020b50: 616e 7469 7a61 626c 655f 6f70 732e 6170  antizable_ops.ap
-00020b60: 7065 6e64 2828 7475 706c 6528 6e61 6d65  pend((tuple(name
-00020b70: 292c 2075 6e69 6679 5f6f 705f 7479 7065  ), unify_op_type
-00020b80: 5f6d 6170 7069 6e67 5f69 7065 7820 5c0a  _mapping_ipex \.
-00020b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020bb0: 2020 2020 2020 2020 2020 2020 2020 205b                 [
-00020bc0: 7365 6c66 2e63 6667 735b 6d6f 6475 6c65  self.cfgs[module
-00020bd0: 5f6b 6579 5d5b 2771 5f6f 705f 696e 666f  _key]['q_op_info
-00020be0: 7327 5d5b 6f70 5f63 6667 5f69 645d 5b27  s'][op_cfg_id]['
-00020bf0: 6f70 5f74 7970 6527 5d5d 205c 0a20 2020  op_type']] \.   
-00020c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020c20: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-00020c30: 656c 662e 6366 6773 5b6d 6f64 756c 655f  elf.cfgs[module_
-00020c40: 6b65 795d 5b27 715f 6f70 5f69 6e66 6f73  key]['q_op_infos
-00020c50: 275d 5b6f 705f 6366 675f 6964 5d5b 276f  '][op_cfg_id]['o
-00020c60: 705f 7479 7065 275d 205c 0a20 2020 2020  p_type'] \.     
-00020c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020660: 2020 2020 2020 2020 2020 2020 6966 2070              if p
+00020670: 6174 7465 726e 3a0a 2020 2020 2020 2020  attern:.        
+00020680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020690: 2020 2020 2020 2020 6966 2070 6174 7465          if patte
+000206a0: 726e 5b31 5d20 696e 205b 2772 656c 755f  rn[1] in ['relu_
+000206b0: 272c 2027 6164 645f 275d 3a0a 2020 2020  ', 'add_']:.    
+000206c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000206d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000206e0: 636f 6e74 696e 7565 0a20 2020 2020 2020  continue.       
+000206f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020700: 2020 2020 2020 2020 2074 756e 655f 6366           tune_cf
+00020710: 675b 276f 7027 5d5b 7061 7474 6572 6e5d  g['op'][pattern]
+00020720: 5b27 6163 7469 7661 7469 6f6e 275d 5b27  ['activation']['
+00020730: 6474 7970 6527 5d20 3d20 2766 7033 3227  dtype'] = 'fp32'
+00020740: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00020750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020760: 2069 6620 2777 6569 6768 7427 2069 6e20   if 'weight' in 
+00020770: 7475 6e65 5f63 6667 5b27 6f70 275d 5b70  tune_cfg['op'][p
+00020780: 6174 7465 726e 5d3a 0a20 2020 2020 2020  attern]:.       
+00020790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000207a0: 2020 2020 2020 2020 2020 2020 2074 756e               tun
+000207b0: 655f 6366 675b 276f 7027 5d5b 7061 7474  e_cfg['op'][patt
+000207c0: 6572 6e5d 5b27 7765 6967 6874 275d 5b27  ern]['weight']['
+000207d0: 6474 7970 6527 5d20 3d20 2766 7033 3227  dtype'] = 'fp32'
+000207e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000207f0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00020800: 2020 2020 2020 2020 2020 2066 6f72 206f             for o
+00020810: 705f 6366 6720 696e 2073 656c 662e 6366  p_cfg in self.cf
+00020820: 6773 3a0a 2020 2020 2020 2020 2020 2020  gs:.            
+00020830: 2020 2020 2020 2020 2020 2020 6966 206f              if o
+00020840: 705f 6366 675b 2269 6422 5d20 3d3d 206b  p_cfg["id"] == k
+00020850: 6579 5b30 5d3a 0a20 2020 2020 2020 2020  ey[0]:.         
+00020860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020870: 2020 2069 6620 6b65 795b 315d 2069 6e20     if key[1] in 
+00020880: 5b27 7265 6c75 5f27 2c20 2761 6464 5f27  ['relu_', 'add_'
+00020890: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
+000208a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000208b0: 2020 2063 6f6e 7469 6e75 650a 2020 2020     continue.    
+000208c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000208d0: 2020 2020 2020 2020 6e75 6d5f 696e 7075          num_inpu
+000208e0: 7473 203d 206c 656e 286f 705f 6366 675b  ts = len(op_cfg[
+000208f0: 2269 6e70 7574 735f 7175 616e 7469 7a65  "inputs_quantize
+00020900: 6422 5d29 0a20 2020 2020 2020 2020 2020  d"]).           
+00020910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020920: 206e 756d 5f6f 7574 7075 7473 203d 206c   num_outputs = l
+00020930: 656e 286f 705f 6366 675b 226f 7574 7075  en(op_cfg["outpu
+00020940: 7473 5f71 7561 6e74 697a 6564 225d 290a  ts_quantized"]).
+00020950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020960: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+00020970: 695f 6e75 6d20 696e 2072 616e 6765 286e  i_num in range(n
+00020980: 756d 5f69 6e70 7574 7329 3a0a 2020 2020  um_inputs):.    
+00020990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000209a0: 2020 2020 2020 2020 2020 2020 6f70 5f63              op_c
+000209b0: 6667 5b22 696e 7075 7473 5f71 7561 6e74  fg["inputs_quant
+000209c0: 697a 6564 225d 5b69 5f6e 756d 5d20 3d20  ized"][i_num] = 
+000209d0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+000209e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000209f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020a00: 7365 6c66 2e64 6566 6175 6c74 5f63 6667  self.default_cfg
+00020a10: 735b 6b65 795b 305d 5d5b 2269 6e70 7574  s[key[0]]["input
+00020a20: 735f 7175 616e 7469 7a65 6422 5d5b 695f  s_quantized"][i_
+00020a30: 6e75 6d5d 0a20 2020 2020 2020 2020 2020  num].           
+00020a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020a50: 2066 6f72 206f 5f6e 756d 2069 6e20 7261   for o_num in ra
+00020a60: 6e67 6528 6e75 6d5f 6f75 7470 7574 7329  nge(num_outputs)
+00020a70: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00020a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020a90: 2020 6f70 5f63 6667 5b22 6f75 7470 7574    op_cfg["output
+00020aa0: 735f 7175 616e 7469 7a65 6422 5d5b 6f5f  s_quantized"][o_
+00020ab0: 6e75 6d5d 203d 205c 0a20 2020 2020 2020  num] = \.       
+00020ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020ae0: 2020 2020 2020 7365 6c66 2e64 6566 6175        self.defau
+00020af0: 6c74 5f63 6667 735b 6b65 795b 305d 5d5b  lt_cfgs[key[0]][
+00020b00: 226f 7574 7075 7473 5f71 7561 6e74 697a  "outputs_quantiz
+00020b10: 6564 225d 5b6f 5f6e 756d 5d0a 2020 2020  ed"][o_num].    
+00020b20: 2020 2020 2020 2020 7769 7468 206f 7065          with ope
+00020b30: 6e28 7365 6c66 2e69 7065 785f 636f 6e66  n(self.ipex_conf
+00020b40: 6967 5f70 6174 682c 2022 7722 2920 6173  ig_path, "w") as
+00020b50: 2077 7269 7465 5f66 3a0a 2020 2020 2020   write_f:.      
+00020b60: 2020 2020 2020 2020 2020 6a73 6f6e 2e64            json.d
+00020b70: 756d 7028 7365 6c66 2e63 6667 732c 2077  ump(self.cfgs, w
+00020b80: 7269 7465 5f66 290a 2020 2020 2020 2020  rite_f).        
+00020b90: 2020 2020 6966 2073 6368 656d 6520 3d3d      if scheme ==
+00020ba0: 2022 6173 796d 223a 0a20 2020 2020 2020   "asym":.       
+00020bb0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00020bc0: 746f 7263 682e 7065 725f 7465 6e73 6f72  torch.per_tensor
+00020bd0: 5f61 6666 696e 650a 2020 2020 2020 2020  _affine.        
+00020be0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00020bf0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00020c00: 2074 6f72 6368 2e70 6572 5f74 656e 736f   torch.per_tenso
+00020c10: 725f 7379 6d6d 6574 7269 630a 2020 2020  r_symmetric.    
+00020c20: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00020c30: 2020 2020 2020 7365 6c66 2e63 6667 7320        self.cfgs 
+00020c40: 3d20 746f 7263 685f 7574 696c 732e 7574  = torch_utils.ut
+00020c50: 696c 2e63 6865 636b 5f63 6667 5f61 6e64  il.check_cfg_and
+00020c60: 5f71 636f 6e66 6967 2874 756e 655f 6366  _qconfig(tune_cf
+00020c70: 675b 276f 7027 5d2c 0a20 2020 2020 2020  g['op'],.       
 00020c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020c90: 2020 2020 2020 2020 2020 696e 2075 6e69            in uni
-00020ca0: 6679 5f6f 705f 7479 7065 5f6d 6170 7069  fy_op_type_mappi
-00020cb0: 6e67 5f69 7065 7820 656c 7365 205c 0a20  ng_ipex else \. 
+00020c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020ca0: 2020 2020 2020 2073 656c 662e 6366 6773         self.cfgs
+00020cb0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
 00020cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00020cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020ce0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00020cf0: 6c66 2e63 6667 735b 6d6f 6475 6c65 5f6b  lf.cfgs[module_k
-00020d00: 6579 5d5b 2771 5f6f 705f 696e 666f 7327  ey]['q_op_infos'
-00020d10: 5d5b 6f70 5f63 6667 5f69 645d 5b27 6f70  ][op_cfg_id]['op
-00020d20: 5f74 7970 6527 5d29 290a 2020 2020 2020  _type'])).      
-00020d30: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00020d40: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00020d50: 2020 2020 2020 2020 2020 2020 6f70 5f74              op_t
-00020d60: 7970 6520 3d20 2222 0a20 2020 2020 2020  ype = "".       
-00020d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020d80: 2066 6f72 206f 705f 6e61 6d65 2069 6e20   for op_name in 
-00020d90: 6e61 6d65 3a0a 2020 2020 2020 2020 2020  name:.          
-00020da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020db0: 2020 6d6f 6475 6c65 5f6b 6579 203d 206f    module_key = o
-00020dc0: 705f 6e61 6d65 5b30 5d0a 2020 2020 2020  p_name[0].      
-00020dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020de0: 2020 2020 2020 6f70 5f63 6667 5f69 6420        op_cfg_id 
-00020df0: 3d20 6f70 5f6e 616d 655b 325d 0a20 2020  = op_name[2].   
-00020e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020e10: 2020 2020 2020 2020 206f 705f 7479 7065           op_type
-00020e20: 202b 3d20 7365 6c66 2e63 6667 735b 6d6f   += self.cfgs[mo
-00020e30: 6475 6c65 5f6b 6579 5d5b 2771 5f6f 705f  dule_key]['q_op_
-00020e40: 696e 666f 7327 5d5b 6f70 5f63 6667 5f69  infos'][op_cfg_i
-00020e50: 645d 5b27 6f70 5f74 7970 6527 5d0a 2020  d]['op_type'].  
-00020e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020e70: 2020 2020 2020 7175 616e 7469 7a61 626c        quantizabl
-00020e80: 655f 6f70 732e 6170 7065 6e64 2828 7475  e_ops.append((tu
-00020e90: 706c 6528 6e61 6d65 292c 206f 705f 7479  ple(name), op_ty
-00020ea0: 7065 2929 0a20 2020 2020 2020 2020 2020  pe)).           
-00020eb0: 2020 2020 2073 656c 662e 6f70 5f69 6e66       self.op_inf
-00020ec0: 6f73 5f66 726f 6d5f 6366 6773 203d 206f  os_from_cfgs = o
-00020ed0: 705f 696e 666f 735f 6672 6f6d 5f63 6667  p_infos_from_cfg
-00020ee0: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
-00020ef0: 2020 7365 6c66 2e6f 7574 7075 745f 7465    self.output_te
-00020f00: 6e73 6f72 5f69 645f 6f70 5f6e 616d 6520  nsor_id_op_name 
-00020f10: 3d20 6f75 7470 7574 5f74 656e 736f 725f  = output_tensor_
-00020f20: 6964 5f6f 705f 6e61 6d65 0a20 2020 2020  id_op_name.     
-00020f30: 2020 206f 732e 7265 6d6f 7665 2873 656c     os.remove(sel
-00020f40: 662e 6970 6578 5f63 6f6e 6669 675f 7061  f.ipex_config_pa
-00020f50: 7468 290a 0a20 2020 2064 6566 2067 6574  th)..    def get
-00020f60: 5f66 7573 655f 6f70 7328 7365 6c66 2c20  _fuse_ops(self, 
-00020f70: 6465 6661 756c 745f 6366 6773 293a 0a20  default_cfgs):. 
-00020f80: 2020 2020 2020 2065 6c74 5f77 6973 6520         elt_wise 
-00020f90: 3d20 5b27 7265 6c75 272c 2027 7369 676d  = ['relu', 'sigm
-00020fa0: 6f69 6427 2c20 2767 656c 7527 5d0a 2020  oid', 'gelu'].  
-00020fb0: 2020 2020 2020 696e 706c 6163 655f 6f70        inplace_op
-00020fc0: 7320 3d20 5b27 7265 6c75 5f27 2c20 2761  s = ['relu_', 'a
-00020fd0: 6464 5f27 5d0a 2020 2020 2020 2020 6f70  dd_'].        op
-00020fe0: 5f70 6174 7465 726e 7320 3d20 5b5d 0a20  _patterns = []. 
-00020ff0: 2020 2020 2020 206e 756d 5f6f 7073 203d         num_ops =
-00021000: 206c 656e 2864 6566 6175 6c74 5f63 6667   len(default_cfg
-00021010: 7329 0a20 2020 2020 2020 2066 6f72 2063  s).        for c
-00021020: 7572 5f69 6420 696e 2072 616e 6765 286e  ur_id in range(n
-00021030: 756d 5f6f 7073 293a 0a20 2020 2020 2020  um_ops):.       
-00021040: 2020 2020 2063 7572 5f6f 7020 3d20 6465       cur_op = de
-00021050: 6661 756c 745f 6366 6773 5b63 7572 5f69  fault_cfgs[cur_i
-00021060: 645d 5b27 6e61 6d65 275d 0a20 2020 2020  d]['name'].     
-00021070: 2020 2020 2020 2069 6620 6375 725f 6f70         if cur_op
-00021080: 203d 3d20 2764 726f 706f 7574 273a 0a20   == 'dropout':. 
-00021090: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-000210a0: 6f6e 7469 6e75 650a 2020 2020 2020 2020  ontinue.        
-000210b0: 2020 2020 696e 7075 7473 203d 2064 6566      inputs = def
-000210c0: 6175 6c74 5f63 6667 735b 6375 725f 6964  ault_cfgs[cur_id
-000210d0: 5d5b 2769 6e70 7574 735f 666c 6f77 275d  ]['inputs_flow']
-000210e0: 0a20 2020 2020 2020 2020 2020 206e 756d  .            num
-000210f0: 5f69 6e70 7574 203d 206c 656e 2869 6e70  _input = len(inp
-00021100: 7574 7329 0a20 2020 2020 2020 2020 2020  uts).           
-00021110: 2070 7265 5f6f 7073 203d 207b 7d0a 2020   pre_ops = {}.  
-00021120: 2020 2020 2020 2020 2020 666f 7220 695f            for i_
-00021130: 6e75 6d20 696e 2072 616e 6765 286e 756d  num in range(num
-00021140: 5f69 6e70 7574 293a 0a20 2020 2020 2020  _input):.       
-00021150: 2020 2020 2020 2020 2069 6e70 203d 2069           inp = i
-00021160: 6e70 7574 735b 695f 6e75 6d5d 0a20 2020  nputs[i_num].   
-00021170: 2020 2020 2020 2020 2020 2020 2066 6f72               for
-00021180: 2070 7265 5f69 6420 696e 2072 616e 6765   pre_id in range
-00021190: 2863 7572 5f69 6429 3a0a 2020 2020 2020  (cur_id):.      
-000211a0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-000211b0: 655f 6f70 203d 2064 6566 6175 6c74 5f63  e_op = default_c
-000211c0: 6667 735b 7072 655f 6964 5d5b 276e 616d  fgs[pre_id]['nam
-000211d0: 6527 5d0a 2020 2020 2020 2020 2020 2020  e'].            
-000211e0: 2020 2020 2020 2020 7072 655f 6f75 7420          pre_out 
-000211f0: 3d20 6465 6661 756c 745f 6366 6773 5b70  = default_cfgs[p
-00021200: 7265 5f69 645d 5b27 6f75 7470 7574 735f  re_id]['outputs_
-00021210: 666c 6f77 275d 0a20 2020 2020 2020 2020  flow'].         
-00021220: 2020 2020 2020 2020 2020 206e 756d 5f6f             num_o
-00021230: 7574 203d 206c 656e 2870 7265 5f6f 7574  ut = len(pre_out
-00021240: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00021250: 2020 2020 2020 666f 7220 6f5f 6e75 6d20        for o_num 
-00021260: 696e 2072 616e 6765 286e 756d 5f6f 7574  in range(num_out
-00021270: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00021280: 2020 2020 2020 2020 2020 2069 6620 7072             if pr
-00021290: 655f 6f75 745b 6f5f 6e75 6d5d 203d 3d20  e_out[o_num] == 
-000212a0: 696e 703a 0a20 2020 2020 2020 2020 2020  inp:.           
-000212b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000212c0: 2069 6620 6375 725f 6f70 2069 6e20 696e   if cur_op in in
-000212d0: 706c 6163 655f 6f70 7320 616e 6420 2870  place_ops and (p
-000212e0: 7265 5f6f 7020 696e 205b 2763 6f6e 7632  re_op in ['conv2
-000212f0: 6427 2c20 2763 6f6e 7633 6427 2c20 276c  d', 'conv3d', 'l
-00021300: 696e 6561 7227 0a20 2020 2020 2020 2020  inear'.         
-00021310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021340: 2020 2020 2020 2020 2020 2020 5d29 3a0a              ]):.
-00021350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021370: 6f70 5f70 6174 7465 726e 732e 6170 7065  op_patterns.appe
-00021380: 6e64 285b 2870 7265 5f69 642c 2070 7265  nd([(pre_id, pre
-00021390: 5f6f 7029 2c20 2863 7572 5f69 642c 2063  _op), (cur_id, c
-000213a0: 7572 5f6f 7029 5d29 0a20 2020 2020 2020  ur_op)]).       
-000213b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000213c0: 2020 2020 2069 6620 6375 725f 6f70 2069       if cur_op i
-000213d0: 6e20 656c 745f 7769 7365 2061 6e64 2028  n elt_wise and (
-000213e0: 7072 655f 6f70 0a20 2020 2020 2020 2020  pre_op.         
-000213f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021410: 2020 2020 2020 2020 2020 2020 2020 696e                in
-00021420: 205b 2763 6f6e 7632 6427 2c20 2763 6f6e   ['conv2d', 'con
-00021430: 7633 6427 2c20 276c 696e 6561 7227 2c20  v3d', 'linear', 
-00021440: 2761 6464 275d 293a 0a20 2020 2020 2020  'add']):.       
-00021450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021460: 2020 2020 2020 2020 206f 705f 7061 7474           op_patt
-00021470: 6572 6e73 2e61 7070 656e 6428 5b28 7072  erns.append([(pr
-00021480: 655f 6964 2c20 7072 655f 6f70 292c 2028  e_id, pre_op), (
-00021490: 6375 725f 6964 2c20 6375 725f 6f70 295d  cur_id, cur_op)]
-000214a0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-000214b0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-000214c0: 2063 7572 5f6f 7020 3d3d 2027 6164 6427   cur_op == 'add'
-000214d0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000214e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000214f0: 2020 7072 655f 6f70 735b 695f 6e75 6d5d    pre_ops[i_num]
-00021500: 203d 205b 7072 655f 6964 2c20 7072 655f   = [pre_id, pre_
-00021510: 6f70 5d0a 2020 2020 2020 2020 2020 2020  op].            
-00021520: 6966 206c 656e 2870 7265 5f6f 7073 2920  if len(pre_ops) 
-00021530: 3e20 303a 0a20 2020 2020 2020 2020 2020  > 0:.           
-00021540: 2020 2020 2066 6f72 206b 6579 2c20 7661       for key, va
-00021550: 6c75 6520 696e 2070 7265 5f6f 7073 2e69  lue in pre_ops.i
-00021560: 7465 6d73 2829 3a0a 2020 2020 2020 2020  tems():.        
-00021570: 2020 2020 2020 2020 2020 2020 6966 2076              if v
-00021580: 616c 7565 5b31 5d20 696e 205b 2763 6f6e  alue[1] in ['con
-00021590: 7632 6427 2c20 2763 6f6e 7633 6427 2c20  v2d', 'conv3d', 
-000215a0: 276c 696e 6561 7227 5d20 616e 6420 5c0a  'linear'] and \.
-000215b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000215c0: 2020 2020 2020 2020 2020 2020 6465 6661              defa
-000215d0: 756c 745f 6366 6773 5b63 7572 5f69 645d  ult_cfgs[cur_id]
-000215e0: 5b27 696e 7075 7473 5f71 7561 6e74 697a  ['inputs_quantiz
-000215f0: 6564 275d 5b6b 6579 5d20 3d3d 2046 616c  ed'][key] == Fal
-00021600: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00021610: 2020 2020 2020 2020 2020 2020 6f70 5f70              op_p
-00021620: 6174 7465 726e 732e 6170 7065 6e64 285b  atterns.append([
-00021630: 2876 616c 7565 5b30 5d2c 2076 616c 7565  (value[0], value
-00021640: 5b31 5d29 2c20 2863 7572 5f69 642c 2063  [1]), (cur_id, c
-00021650: 7572 5f6f 7029 5d29 0a20 2020 2020 2020  ur_op)]).       
-00021660: 2072 6574 7572 6e20 6f70 5f70 6174 7465   return op_patte
-00021670: 726e 730a 0a20 2020 2040 6475 6d70 5f65  rns..    @dump_e
-00021680: 6c61 7073 6564 5f74 696d 6528 2250 6173  lapsed_time("Pas
-00021690: 7320 7361 7665 2071 7561 6e74 697a 6564  s save quantized
-000216a0: 206d 6f64 656c 2229 0a20 2020 2064 6566   model").    def
-000216b0: 2073 6176 6528 7365 6c66 2c20 6d6f 6465   save(self, mode
-000216c0: 6c2c 2070 6174 683d 4e6f 6e65 293a 0a20  l, path=None):. 
-000216d0: 2020 2020 2020 2022 2222 5468 6520 6675         """The fu
-000216e0: 6e63 7469 6f6e 2069 7320 7573 6564 2062  nction is used b
-000216f0: 7920 7475 6e65 2073 7472 6174 6567 7920  y tune strategy 
-00021700: 636c 6173 7320 666f 7220 7365 7420 6265  class for set be
-00021710: 7374 2063 6f6e 6669 6775 7265 2069 6e20  st configure in 
-00021720: 4e65 7572 616c 2043 6f6d 7072 6573 736f  Neural Compresso
-00021730: 7220 6d6f 6465 6c2e 0a0a 2020 2020 2020  r model...      
-00021740: 2020 2020 2041 7267 733a 0a20 2020 2020       Args:.     
-00021750: 2020 2020 2020 2020 2020 6d6f 6465 6c20            model 
-00021760: 286f 626a 6563 7429 3a20 5468 6520 4e65  (object): The Ne
-00021770: 7572 616c 2043 6f6d 7072 6573 736f 7220  ural Compressor 
-00021780: 6d6f 6465 6c20 7768 6963 6820 6973 2062  model which is b
-00021790: 6573 7420 7265 7375 6c74 732e 0a20 2020  est results..   
-000217a0: 2020 2020 2020 2020 2020 2020 7061 7468              path
-000217b0: 2028 7374 7269 6e67 293a 204e 6f20 7573   (string): No us
-000217c0: 6564 2e0a 0a20 2020 2020 2020 2052 6574  ed...        Ret
-000217d0: 7572 6e73 3a0a 2020 2020 2020 2020 2020  urns:.          
-000217e0: 2020 4e6f 6e65 0a20 2020 2020 2020 2022    None.        "
-000217f0: 2222 0a0a 2020 2020 2020 2020 7061 7373  ""..        pass
-00021800: 0a0a 2020 2020 6465 6620 696e 7370 6563  ..    def inspec
-00021810: 745f 7465 6e73 6f72 2873 656c 662c 0a20  t_tensor(self,. 
-00021820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021830: 2020 2020 2020 6d6f 6465 6c2c 0a20 2020        model,.   
-00021840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021850: 2020 2020 6461 7461 6c6f 6164 6572 2c0a      dataloader,.
-00021860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021870: 2020 2020 2020 206f 705f 6c69 7374 3d4e         op_list=N
-00021880: 6f6e 652c 0a20 2020 2020 2020 2020 2020  one,.           
-00021890: 2020 2020 2020 2020 2020 2020 6974 6572              iter
-000218a0: 6174 696f 6e5f 6c69 7374 3d4e 6f6e 652c  ation_list=None,
-000218b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000218c0: 2020 2020 2020 2020 696e 7370 6563 745f          inspect_
-000218d0: 7479 7065 3d27 6163 7469 7661 7469 6f6e  type='activation
-000218e0: 272c 0a20 2020 2020 2020 2020 2020 2020  ',.             
-000218f0: 2020 2020 2020 2020 2020 7361 7665 5f74            save_t
-00021900: 6f5f 6469 736b 3d46 616c 7365 293a 0a20  o_disk=False):. 
-00021910: 2020 2020 2020 2061 7373 6572 7420 4661         assert Fa
-00021920: 6c73 652c 2022 496e 7370 6563 745f 7465  lse, "Inspect_te
-00021930: 6e73 6f72 2064 6964 6e27 7420 7375 7070  nsor didn't supp
-00021940: 6f72 7420 4950 4558 2062 6163 6b65 6e64  ort IPEX backend
-00021950: 206e 6f77 2122 0a0a 0a40 6164 6170 746f   now!"...@adapto
-00021960: 725f 7265 6769 7374 7279 0a63 6c61 7373  r_registry.class
-00021970: 2050 7954 6f72 6368 5f46 5841 6461 7074   PyTorch_FXAdapt
-00021980: 6f72 2854 656d 706c 6174 6541 6461 7074  or(TemplateAdapt
-00021990: 6f72 293a 0a20 2020 2022 2222 4164 6170  or):.    """Adap
-000219a0: 746f 7220 6f66 2050 7954 6f72 6368 2066  tor of PyTorch f
-000219b0: 7261 6d65 776f 726b 2077 6974 6820 4658  ramework with FX
-000219c0: 2067 7261 7068 206d 6f64 652c 2061 6c6c   graph mode, all
-000219d0: 2050 7954 6f72 6368 2041 5049 2069 7320   PyTorch API is 
-000219e0: 696e 2074 6869 7320 636c 6173 732e 0a0a  in this class...
-000219f0: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
-00021a00: 2020 6672 616d 6577 6f72 6b5f 7370 6563    framework_spec
-00021a10: 6966 6963 5f69 6e66 6f20 2864 6963 7429  ific_info (dict)
-00021a20: 3a20 6469 6374 696f 6e61 7279 206f 6620  : dictionary of 
-00021a30: 7475 6e69 6e67 2063 6f6e 6669 6775 7265  tuning configure
-00021a40: 2066 726f 6d20 7961 6d6c 2066 696c 652e   from yaml file.
-00021a50: 0a20 2020 2022 2222 0a20 2020 2064 6566  .    """.    def
-00021a60: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
-00021a70: 6672 616d 6577 6f72 6b5f 7370 6563 6966  framework_specif
-00021a80: 6963 5f69 6e66 6f29 3a0a 2020 2020 2020  ic_info):.      
-00021a90: 2020 7375 7065 7228 5079 546f 7263 685f    super(PyTorch_
-00021aa0: 4658 4164 6170 746f 722c 2073 656c 6629  FXAdaptor, self)
-00021ab0: 2e5f 5f69 6e69 745f 5f28 6672 616d 6577  .__init__(framew
-00021ac0: 6f72 6b5f 7370 6563 6966 6963 5f69 6e66  ork_specific_inf
-00021ad0: 6f29 0a20 2020 2020 2020 2061 7373 6572  o).        asser
-00021ae0: 7420 7365 6c66 2e76 6572 7369 6f6e 2e72  t self.version.r
-00021af0: 656c 6561 7365 203e 3d20 5665 7273 696f  elease >= Versio
-00021b00: 6e28 2231 2e38 2e30 2229 2e72 656c 6561  n("1.8.0").relea
-00021b10: 7365 2c20 5c0a 2020 2020 2020 2020 2020  se, \.          
-00021b20: 2020 2020 2020 2020 2020 2020 2250 6c65              "Ple
-00021b30: 6173 6520 7573 6520 5079 5472 6f63 6820  ase use PyTroch 
-00021b40: 312e 3820 6f72 2068 6967 6865 7220 7665  1.8 or higher ve
-00021b50: 7273 696f 6e20 7769 7468 2070 7974 6f72  rsion with pytor
-00021b60: 6368 5f66 7820 6261 636b 656e 64ef bc81  ch_fx backend...
-00021b70: 220a 2020 2020 2020 2020 6966 2073 656c  ".        if sel
-00021b80: 662e 6170 7072 6f61 6368 203d 3d20 2770  f.approach == 'p
-00021b90: 6f73 745f 7472 6169 6e69 6e67 5f64 796e  ost_training_dyn
-00021ba0: 616d 6963 5f71 7561 6e74 273a 0a20 2020  amic_quant':.   
-00021bb0: 2020 2020 2020 2020 2061 7373 6572 7420           assert 
-00021bc0: 7365 6c66 2e76 6572 7369 6f6e 2e72 656c  self.version.rel
-00021bd0: 6561 7365 203e 3d20 5665 7273 696f 6e28  ease >= Version(
-00021be0: 2231 2e39 2e30 2229 2e72 656c 6561 7365  "1.9.0").release
-00021bf0: 2c20 5c0a 2020 2020 2020 2020 2020 2020  , \.            
-00021c00: 2020 2020 2020 2020 2020 2020 2250 6c65              "Ple
-00021c10: 6173 6520 7573 6520 5079 5472 6f63 6820  ase use PyTroch 
-00021c20: 312e 3920 6f72 2068 6967 6865 7220 7665  1.9 or higher ve
-00021c30: 7273 696f 6e20 666f 7220 6479 6e61 6d69  rsion for dynami
-00021c40: 6320 2220 5c0a 2020 2020 2020 2020 2020  c " \.          
-00021c50: 2020 2020 2020 2020 2020 2020 2020 2271                "q
-00021c60: 7561 6e74 697a 6174 696f 6e20 7769 7468  uantization with
-00021c70: 2070 7974 6f72 6368 5f66 7820 6261 636b   pytorch_fx back
-00021c80: 656e 64ef bc81 220a 2020 2020 2020 2020  end...".        
-00021c90: 696d 706f 7274 2074 6f72 6368 2e71 7561  import torch.qua
-00021ca0: 6e74 697a 6174 696f 6e20 6173 2074 710a  ntization as tq.
-00021cb0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00021cc0: 2020 2020 2320 4d61 7020 666f 7220 7377      # Map for sw
-00021cd0: 6170 7069 6e67 2066 6c6f 6174 206d 6f64  apping float mod
-00021ce0: 756c 6520 746f 2071 7561 6e74 697a 6564  ule to quantized
-00021cf0: 206f 6e65 732c 0a20 2020 2020 2020 2023   ones,.        #
-00021d00: 2061 6e64 2074 6869 7320 6469 6374 696f   and this dictio
-00021d10: 6e61 7279 2077 696c 6c20 6368 616e 6765  nary will change
-00021d20: 2077 6974 6820 6469 6666 6572 656e 7420   with different 
-00021d30: 506f 546f 7263 6820 7665 7273 696f 6e73  PoTorch versions
-00021d40: 0a20 2020 2020 2020 2044 4546 4155 4c54  .        DEFAULT
-00021d50: 5f4d 4f44 554c 455f 4d41 5050 494e 4720  _MODULE_MAPPING 
-00021d60: 3d20 7b0a 2020 2020 2020 2020 2020 2020  = {.            
-00021d70: 6e6e 2e4c 696e 6561 723a 206e 6e71 2e4c  nn.Linear: nnq.L
-00021d80: 696e 6561 722c 0a20 2020 2020 2020 2020  inear,.         
-00021d90: 2020 206e 6e2e 5265 4c55 3a20 6e6e 712e     nn.ReLU: nnq.
-00021da0: 5265 4c55 2c0a 2020 2020 2020 2020 2020  ReLU,.          
-00021db0: 2020 6e6e 2e52 654c 5536 3a20 6e6e 712e    nn.ReLU6: nnq.
-00021dc0: 5265 4c55 362c 0a20 2020 2020 2020 2020  ReLU6,.         
-00021dd0: 2020 206e 6e2e 436f 6e76 3264 3a20 6e6e     nn.Conv2d: nn
-00021de0: 712e 436f 6e76 3264 2c0a 2020 2020 2020  q.Conv2d,.      
-00021df0: 2020 2020 2020 6e6e 2e43 6f6e 7633 643a        nn.Conv3d:
-00021e00: 206e 6e71 2e43 6f6e 7633 642c 0a20 2020   nnq.Conv3d,.   
-00021e10: 2020 2020 2020 2020 2051 7561 6e74 5374           QuantSt
-00021e20: 7562 3a20 6e6e 712e 5175 616e 7469 7a65  ub: nnq.Quantize
-00021e30: 2c0a 2020 2020 2020 2020 2020 2020 4465  ,.            De
-00021e40: 5175 616e 7453 7475 623a 206e 6e71 2e44  QuantStub: nnq.D
-00021e50: 6551 7561 6e74 697a 652c 0a20 2020 2020  eQuantize,.     
-00021e60: 2020 2020 2020 2023 2057 7261 7070 6572         # Wrapper
-00021e70: 204d 6f64 756c 6573 3a0a 2020 2020 2020   Modules:.      
-00021e80: 2020 2020 2020 6e6e 712e 466c 6f61 7446        nnq.FloatF
-00021e90: 756e 6374 696f 6e61 6c3a 206e 6e71 2e51  unctional: nnq.Q
-00021ea0: 4675 6e63 7469 6f6e 616c 2c0a 2020 2020  Functional,.    
-00021eb0: 2020 2020 2020 2020 2320 496e 7472 696e          # Intrin
-00021ec0: 7369 6320 6d6f 6475 6c65 733a 0a20 2020  sic modules:.   
-00021ed0: 2020 2020 2020 2020 206e 6e69 2e43 6f6e           nni.Con
-00021ee0: 7652 654c 5532 643a 206e 6e69 712e 436f  vReLU2d: nniq.Co
-00021ef0: 6e76 5265 4c55 3264 2c0a 2020 2020 2020  nvReLU2d,.      
-00021f00: 2020 2020 2020 6e6e 692e 436f 6e76 5265        nni.ConvRe
-00021f10: 4c55 3364 3a20 6e6e 6971 2e43 6f6e 7652  LU3d: nniq.ConvR
-00021f20: 654c 5533 642c 0a20 2020 2020 2020 2020  eLU3d,.         
-00021f30: 2020 206e 6e69 2e4c 696e 6561 7252 654c     nni.LinearReL
-00021f40: 553a 206e 6e69 712e 4c69 6e65 6172 5265  U: nniq.LinearRe
-00021f50: 4c55 2c0a 2020 2020 2020 2020 2020 2020  LU,.            
-00021f60: 6e6e 6971 6174 2e43 6f6e 7652 654c 5532  nniqat.ConvReLU2
-00021f70: 643a 206e 6e69 712e 436f 6e76 5265 4c55  d: nniq.ConvReLU
-00021f80: 3264 2c0a 2020 2020 2020 2020 2020 2020  2d,.            
-00021f90: 6e6e 6971 6174 2e4c 696e 6561 7252 654c  nniqat.LinearReL
-00021fa0: 553a 206e 6e69 712e 4c69 6e65 6172 5265  U: nniq.LinearRe
-00021fb0: 4c55 2c0a 2020 2020 2020 2020 2020 2020  LU,.            
-00021fc0: 6e6e 6971 6174 2e43 6f6e 7642 6e32 643a  nniqat.ConvBn2d:
-00021fd0: 206e 6e71 2e43 6f6e 7632 642c 0a20 2020   nnq.Conv2d,.   
-00021fe0: 2020 2020 2020 2020 206e 6e69 7161 742e           nniqat.
-00021ff0: 436f 6e76 426e 5265 4c55 3264 3a20 6e6e  ConvBnReLU2d: nn
-00022000: 6971 2e43 6f6e 7652 654c 5532 642c 0a20  iq.ConvReLU2d,. 
-00022010: 2020 2020 2020 2020 2020 2023 2051 4154             # QAT
-00022020: 206d 6f64 756c 6573 3a0a 2020 2020 2020   modules:.      
-00022030: 2020 2020 2020 6e6e 7161 742e 4c69 6e65        nnqat.Line
-00022040: 6172 3a20 6e6e 712e 4c69 6e65 6172 2c0a  ar: nnq.Linear,.
-00022050: 2020 2020 2020 2020 2020 2020 6e6e 7161              nnqa
-00022060: 742e 436f 6e76 3264 3a20 6e6e 712e 436f  t.Conv2d: nnq.Co
-00022070: 6e76 3264 2c0a 2020 2020 2020 2020 7d0a  nv2d,.        }.
-00022080: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
-00022090: 2020 2020 2073 656c 662e 7475 6e65 5f63       self.tune_c
-000220a0: 6667 203d 204e 6f6e 650a 2020 2020 2020  fg = None.      
-000220b0: 2020 6966 2073 656c 662e 6465 7669 6365    if self.device
-000220c0: 203d 3d20 2263 7075 223a 0a20 2020 2020   == "cpu":.     
-000220d0: 2020 2020 2020 2071 7565 7279 5f63 6f6e         query_con
-000220e0: 6669 675f 6669 6c65 203d 2022 7079 746f  fig_file = "pyto
-000220f0: 7263 685f 6370 752e 7961 6d6c 220a 2020  rch_cpu.yaml".  
-00022100: 2020 2020 2020 656c 7365 3a20 2023 2070        else:  # p
-00022110: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
-00022120: 2020 2020 2020 2020 2020 2020 6173 7365              asse
-00022130: 7274 2046 616c 7365 2c20 2255 6e73 7570  rt False, "Unsup
-00022140: 706f 7274 2074 6869 7320 6465 7669 6365  port this device
-00022150: 207b 7d22 2e66 6f72 6d61 7428 7365 6c66   {}".format(self
-00022160: 2e64 6576 6963 6529 0a20 2020 2020 2020  .device).       
-00022170: 2073 656c 662e 7175 6572 795f 6861 6e64   self.query_hand
-00022180: 6c65 7220 3d20 5079 546f 7263 6851 7565  ler = PyTorchQue
-00022190: 7279 280a 2020 2020 2020 2020 2020 2020  ry(.            
-000221a0: 6c6f 6361 6c5f 636f 6e66 6967 5f66 696c  local_config_fil
-000221b0: 653d 6f73 2e70 6174 682e 6a6f 696e 286f  e=os.path.join(o
-000221c0: 732e 7061 7468 2e64 6972 6e61 6d65 285f  s.path.dirname(_
-000221d0: 5f66 696c 655f 5f29 2c20 7175 6572 795f  _file__), query_
-000221e0: 636f 6e66 6967 5f66 696c 6529 290a 0a20  config_file)).. 
-000221f0: 2020 2020 2020 2069 6620 7365 6c66 2e61         if self.a
-00022200: 7070 726f 6163 6820 3d3d 2027 706f 7374  pproach == 'post
-00022210: 5f74 7261 696e 696e 675f 6479 6e61 6d69  _training_dynami
-00022220: 635f 7175 616e 7427 3a0a 2020 2020 2020  c_quant':.      
-00022230: 2020 2020 2020 7365 6c66 2e77 6869 7465        self.white
-00022240: 5f6c 6973 7420 3d20 5c0a 2020 2020 2020  _list = \.      
-00022250: 2020 2020 2020 2020 2020 7471 2e71 7561            tq.qua
-00022260: 6e74 697a 6174 696f 6e5f 6d61 7070 696e  ntization_mappin
-00022270: 6773 2e67 6574 5f64 6566 6175 6c74 5f64  gs.get_default_d
-00022280: 796e 616d 6963 5f71 7561 6e74 5f6d 6f64  ynamic_quant_mod
-00022290: 756c 655f 6d61 7070 696e 6773 2829 0a20  ule_mappings(). 
-000222a0: 2020 2020 2020 2065 6c69 6620 7365 6c66         elif self
-000222b0: 2e61 7070 726f 6163 6820 3d3d 2027 706f  .approach == 'po
-000222c0: 7374 5f74 7261 696e 696e 675f 7374 6174  st_training_stat
-000222d0: 6963 5f71 7561 6e74 273a 0a20 2020 2020  ic_quant':.     
-000222e0: 2020 2020 2020 2073 656c 662e 7768 6974         self.whit
-000222f0: 655f 6c69 7374 203d 2074 712e 7175 616e  e_list = tq.quan
-00022300: 7469 7a61 7469 6f6e 5f6d 6170 7069 6e67  tization_mapping
-00022310: 732e 6765 745f 6465 6661 756c 745f 7374  s.get_default_st
-00022320: 6174 6963 5f71 7561 6e74 5f6d 6f64 756c  atic_quant_modul
-00022330: 655f 6d61 7070 696e 6773 2829 0a20 2020  e_mappings().   
-00022340: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00022350: 2020 2020 2020 2073 656c 662e 7768 6974         self.whit
-00022360: 655f 6c69 7374 203d 2074 712e 7175 616e  e_list = tq.quan
-00022370: 7469 7a61 7469 6f6e 5f6d 6170 7069 6e67  tization_mapping
-00022380: 732e 6765 745f 6465 6661 756c 745f 7163  s.get_default_qc
-00022390: 6f6e 6669 675f 7072 6f70 6167 6174 696f  onfig_propagatio
-000223a0: 6e5f 6c69 7374 2829 0a0a 2020 2020 4064  n_list()..    @d
-000223b0: 756d 705f 656c 6170 7365 645f 7469 6d65  ump_elapsed_time
-000223c0: 2822 5061 7373 2071 7561 6e74 697a 6520  ("Pass quantize 
-000223d0: 6d6f 6465 6c22 290a 2020 2020 6465 6620  model").    def 
-000223e0: 7175 616e 7469 7a65 2873 656c 662c 2074  quantize(self, t
-000223f0: 756e 655f 6366 672c 206d 6f64 656c 2c20  une_cfg, model, 
-00022400: 6461 7461 6c6f 6164 6572 2c20 715f 6675  dataloader, q_fu
-00022410: 6e63 3d4e 6f6e 6529 3a0a 2020 2020 2020  nc=None):.      
-00022420: 2020 2222 2245 7865 6375 7465 2074 6865    """Execute the
-00022430: 2071 7561 6e74 697a 6520 7072 6f63 6573   quantize proces
-00022440: 7320 6f6e 2074 6865 2073 7065 6369 6669  s on the specifi
-00022450: 6564 206d 6f64 656c 2e0a 0a20 2020 2020  ed model...     
-00022460: 2020 2041 7267 733a 0a20 2020 2020 2020     Args:.       
-00022470: 2020 2020 2074 756e 655f 6366 6720 2864       tune_cfg (d
-00022480: 6963 7429 3a20 7175 616e 7469 7a61 7469  ict): quantizati
-00022490: 6f6e 2063 6f6e 6669 672e 0a20 2020 2020  on config..     
-000224a0: 2020 2020 2020 206d 6f64 656c 2028 6f62         model (ob
-000224b0: 6a65 6374 293a 206d 6f64 656c 206e 6565  ject): model nee
-000224c0: 6420 746f 2064 6f20 7175 616e 7469 7a61  d to do quantiza
-000224d0: 7469 6f6e 2e0a 2020 2020 2020 2020 2020  tion..          
-000224e0: 2020 6461 7461 6c6f 6164 6572 2028 6f62    dataloader (ob
-000224f0: 6a65 6374 293a 2063 616c 6962 7261 7469  ject): calibrati
-00022500: 6f6e 2064 6174 6173 6574 2e0a 2020 2020  on dataset..    
-00022510: 2020 2020 2020 2020 715f 6675 6e63 2028          q_func (
-00022520: 6f62 6a65 7874 2c20 6f70 7469 6f6e 616c  objext, optional
-00022530: 293a 2074 7261 696e 696e 6720 6675 6e63  ): training func
-00022540: 7469 6f6e 2066 6f72 2071 7561 6e74 697a  tion for quantiz
-00022550: 6174 696f 6e20 6177 6172 6520 7472 6169  ation aware trai
-00022560: 6e69 6e67 206d 6f64 652e 0a0a 2020 2020  ning mode...    
-00022570: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
-00022580: 2020 2020 2020 2020 2028 6f62 6a65 6374           (object
-00022590: 293a 2071 7561 6e74 697a 6564 206d 6f64  ): quantized mod
-000225a0: 656c 0a20 2020 2020 2020 2022 2222 0a0a  el.        """..
-000225b0: 2020 2020 2020 2020 6173 7365 7274 2069          assert i
-000225c0: 7369 6e73 7461 6e63 6528 6d6f 6465 6c2e  sinstance(model.
-000225d0: 5f6d 6f64 656c 2c20 746f 7263 682e 6e6e  _model, torch.nn
-000225e0: 2e4d 6f64 756c 6529 2c20 5c0a 2020 2020  .Module), \.    
-000225f0: 2020 2020 2020 2020 2020 2022 5468 6520             "The 
-00022600: 6d6f 6465 6c20 7061 7373 6564 2069 6e20  model passed in 
-00022610: 6973 206e 6f74 2074 6865 2069 6e73 7461  is not the insta
-00022620: 6e63 6520 6f66 2074 6f72 6368 2e6e 6e2e  nce of torch.nn.
-00022630: 4d6f 6475 6c65 220a 2020 2020 2020 2020  Module".        
-00022640: 7365 6c66 2e74 756e 655f 6366 6720 3d20  self.tune_cfg = 
-00022650: 7475 6e65 5f63 6667 0a20 2020 2020 2020  tune_cfg.       
-00022660: 2073 656c 662e 7475 6e65 5f63 6667 5b22   self.tune_cfg["
-00022670: 6170 7072 6f61 6368 225d 203d 2073 656c  approach"] = sel
-00022680: 662e 6170 7072 6f61 6368 0a20 2020 2020  f.approach.     
-00022690: 2020 2073 656c 662e 7475 6e65 5f63 6667     self.tune_cfg
-000226a0: 5b22 7265 6475 6365 5f72 616e 6765 225d  ["reduce_range"]
-000226b0: 203d 2052 4544 5543 455f 5241 4e47 450a   = REDUCE_RANGE.
-000226c0: 2020 2020 2020 2020 7365 6c66 2e74 756e          self.tun
-000226d0: 655f 6366 675b 2266 7261 6d65 776f 726b  e_cfg["framework
-000226e0: 225d 203d 2022 7079 746f 7263 685f 6678  "] = "pytorch_fx
-000226f0: 220a 0a20 2020 2020 2020 2023 2050 7954  "..        # PyT
-00022700: 6f72 6368 2031 2e31 3320 616e 6420 6162  orch 1.13 and ab
-00022710: 6f76 6520 7665 7273 696f 6e2c 206e 6565  ove version, nee
-00022720: 6420 6578 616d 706c 655f 696e 7075 7473  d example_inputs
-00022730: 2066 6f72 2066 7820 7472 6163 652c 2062   for fx trace, b
-00022740: 7574 2069 7420 6e6f 7420 7265 616c 7920  ut it not realy 
-00022750: 7573 6564 2c0a 2020 2020 2020 2020 2320  used,.        # 
-00022760: 736f 2073 6574 2069 7420 746f 204e 6f6e  so set it to Non
-00022770: 652e 0a20 2020 2020 2020 2073 656c 662e  e..        self.
-00022780: 6578 616d 706c 655f 696e 7075 7473 203d  example_inputs =
-00022790: 204e 6f6e 650a 0a20 2020 2020 2020 2069   None..        i
-000227a0: 6620 7365 6c66 2e64 6566 6175 6c74 5f71  f self.default_q
-000227b0: 636f 6e66 6967 2069 7320 6e6f 7420 4e6f  config is not No
-000227c0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-000227d0: 6465 6661 756c 745f 7163 6f6e 6669 6720  default_qconfig 
-000227e0: 3d20 636f 7079 2e64 6565 7063 6f70 7928  = copy.deepcopy(
-000227f0: 7365 6c66 2e64 6566 6175 6c74 5f71 636f  self.default_qco
-00022800: 6e66 6967 290a 2020 2020 2020 2020 2020  nfig).          
-00022810: 2020 6465 6661 756c 745f 7163 6f6e 6669    default_qconfi
-00022820: 675b 2761 6374 6976 6174 696f 6e27 5d5b  g['activation'][
-00022830: 2764 7479 7065 275d 203d 205c 0a20 2020  'dtype'] = \.   
-00022840: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-00022850: 662e 6465 6661 756c 745f 7163 6f6e 6669  f.default_qconfi
-00022860: 675b 2761 6374 6976 6174 696f 6e27 5d5b  g['activation'][
-00022870: 2764 7479 7065 275d 5b30 5d0a 2020 2020  'dtype'][0].    
-00022880: 2020 2020 2020 2020 6465 6661 756c 745f          default_
-00022890: 7163 6f6e 6669 675b 2777 6569 6768 7427  qconfig['weight'
-000228a0: 5d5b 2764 7479 7065 275d 203d 2073 656c  ]['dtype'] = sel
-000228b0: 662e 6465 6661 756c 745f 7163 6f6e 6669  f.default_qconfi
-000228c0: 675b 2777 6569 6768 7427 5d5b 2764 7479  g['weight']['dty
-000228d0: 7065 275d 5b30 5d0a 2020 2020 2020 2020  pe'][0].        
-000228e0: 2020 2020 7365 6c66 2e74 756e 655f 6366      self.tune_cf
-000228f0: 675b 226f 7022 5d5b 2822 6465 6661 756c  g["op"][("defaul
-00022900: 745f 7163 6f6e 6669 6722 2c20 2222 295d  t_qconfig", "")]
-00022910: 203d 2064 6566 6175 6c74 5f71 636f 6e66   = default_qconf
-00022920: 6967 0a20 2020 2020 2020 206f 705f 6366  ig.        op_cf
-00022930: 6773 203d 205f 6366 675f 746f 5f71 636f  gs = _cfg_to_qco
-00022940: 6e66 6967 2873 656c 662e 7475 6e65 5f63  nfig(self.tune_c
-00022950: 6667 2c20 7365 6c66 2e61 7070 726f 6163  fg, self.approac
-00022960: 6829 0a20 2020 2020 2020 2073 656c 662e  h).        self.
-00022970: 7475 6e65 5f63 6667 5b27 6266 3136 5f6f  tune_cfg['bf16_o
-00022980: 7073 5f6c 6973 7427 5d20 3d20 6f70 5f63  ps_list'] = op_c
-00022990: 6667 735b 2762 6631 365f 6f70 735f 6c69  fgs['bf16_ops_li
-000229a0: 7374 275d 0a20 2020 2020 2020 2064 656c  st'].        del
-000229b0: 206f 705f 6366 6773 5b27 6266 3136 5f6f   op_cfgs['bf16_o
-000229c0: 7073 5f6c 6973 7427 5d0a 2020 2020 2020  ps_list'].      
-000229d0: 2020 6763 2e63 6f6c 6c65 6374 2829 0a0a    gc.collect()..
-000229e0: 2020 2020 2020 2020 6672 6f6d 2074 6f72          from tor
-000229f0: 6368 2e71 7561 6e74 697a 6174 696f 6e2e  ch.quantization.
-00022a00: 7175 616e 7469 7a65 5f66 7820 696d 706f  quantize_fx impo
-00022a10: 7274 2070 7265 7061 7265 5f66 782c 2063  rt prepare_fx, c
-00022a20: 6f6e 7665 7274 5f66 782c 2070 7265 7061  onvert_fx, prepa
-00022a30: 7265 5f71 6174 5f66 780a 2020 2020 2020  re_qat_fx.      
-00022a40: 2020 6966 2073 656c 662e 7065 7266 6f72    if self.perfor
-00022a50: 6d61 6e63 655f 6f6e 6c79 3a0a 2020 2020  mance_only:.    
-00022a60: 2020 2020 2020 2020 715f 6d6f 6465 6c20          q_model 
-00022a70: 3d20 6d6f 6465 6c0a 2020 2020 2020 2020  = model.        
-00022a80: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00022a90: 2020 7472 793a 0a20 2020 2020 2020 2020    try:.         
-00022aa0: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
-00022ab0: 2063 6f70 792e 6465 6570 636f 7079 286d   copy.deepcopy(m
-00022ac0: 6f64 656c 290a 2020 2020 2020 2020 2020  odel).          
-00022ad0: 2020 2020 2020 715f 6d6f 6465 6c2e 6670        q_model.fp
-00022ae0: 3332 5f6d 6f64 656c 203d 206d 6f64 656c  32_model = model
-00022af0: 2e66 7033 325f 6d6f 6465 6c0a 2020 2020  .fp32_model.    
-00022b00: 2020 2020 2020 2020 6578 6365 7074 2045          except E
-00022b10: 7863 6570 7469 6f6e 2061 7320 653a 2020  xception as e:  
-00022b20: 2320 7072 6167 6d61 3a20 6e6f 2063 6f76  # pragma: no cov
-00022b30: 6572 0a20 2020 2020 2020 2020 2020 2020  er.             
-00022b40: 2020 206c 6f67 6765 722e 7761 726e 696e     logger.warnin
-00022b50: 6728 2246 6169 6c20 746f 2064 6565 7020  g("Fail to deep 
-00022b60: 636f 7079 2074 6865 206d 6f64 656c 2064  copy the model d
-00022b70: 7565 2074 6f20 7b7d 2c20 696e 706c 6163  ue to {}, inplac
-00022b80: 6520 6973 2075 7365 6420 6e6f 772e 222e  e is used now.".
-00022b90: 666f 726d 6174 280a 2020 2020 2020 2020  format(.        
-00022ba0: 2020 2020 2020 2020 2020 2020 7265 7072              repr
-00022bb0: 2865 2929 290a 2020 2020 2020 2020 2020  (e))).          
-00022bc0: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
-00022bd0: 6d6f 6465 6c0a 2020 2020 2020 2020 715f  model.        q_
-00022be0: 6d6f 6465 6c2e 5f6d 6f64 656c 2e65 7661  model._model.eva
-00022bf0: 6c28 290a 2020 2020 2020 2020 6966 2071  l().        if q
-00022c00: 5f6d 6f64 656c 2e6b 7761 7267 7320 6973  _model.kwargs is
-00022c10: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
-00022c20: 2020 2020 2020 2073 656c 662e 7072 6570         self.prep
-00022c30: 6172 655f 6375 7374 6f6d 5f63 6f6e 6669  are_custom_confi
-00022c40: 675f 6469 6374 203d 2071 5f6d 6f64 656c  g_dict = q_model
-00022c50: 2e6b 7761 7267 732e 6765 7428 2770 7265  .kwargs.get('pre
-00022c60: 7061 7265 5f63 7573 746f 6d5f 636f 6e66  pare_custom_conf
-00022c70: 6967 5f64 6963 7427 2c0a 2020 2020 2020  ig_dict',.      
+00020ce0: 7365 6c66 2e6f 705f 696e 666f 735f 6672  self.op_infos_fr
+00020cf0: 6f6d 5f63 6667 732c 0a20 2020 2020 2020  om_cfgs,.       
+00020d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020d20: 2020 2020 2020 2073 656c 662e 6f75 7470         self.outp
+00020d30: 7574 5f74 656e 736f 725f 6964 5f6f 705f  ut_tensor_id_op_
+00020d40: 6e61 6d65 290a 0a20 2020 2020 2020 2020  name)..         
+00020d50: 2020 2077 6974 6820 6f70 656e 2873 656c     with open(sel
+00020d60: 662e 6970 6578 5f63 6f6e 6669 675f 7061  f.ipex_config_pa
+00020d70: 7468 2c20 2277 2229 2061 7320 7772 6974  th, "w") as writ
+00020d80: 655f 663a 0a20 2020 2020 2020 2020 2020  e_f:.           
+00020d90: 2020 2020 206a 736f 6e2e 6475 6d70 2873       json.dump(s
+00020da0: 656c 662e 6366 6773 2c20 7772 6974 655f  elf.cfgs, write_
+00020db0: 662c 2069 6e64 656e 743d 3429 0a20 2020  f, indent=4).   
+00020dc0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00020dd0: 4e6f 6e65 0a0a 2020 2020 6465 6620 6765  None..    def ge
+00020de0: 745f 7061 7474 6572 6e28 7365 6c66 2c20  t_pattern(self, 
+00020df0: 6661 6c6c 6261 636b 5f6f 702c 2066 7573  fallback_op, fus
+00020e00: 655f 6f70 7329 3a0a 2020 2020 2020 2020  e_ops):.        
+00020e10: 666f 7220 6675 7365 5f70 6174 7465 726e  for fuse_pattern
+00020e20: 2069 6e20 6675 7365 5f6f 7073 3a0a 2020   in fuse_ops:.  
+00020e30: 2020 2020 2020 2020 2020 6966 2066 7573            if fus
+00020e40: 655f 7061 7474 6572 6e5b 305d 203d 3d20  e_pattern[0] == 
+00020e50: 6661 6c6c 6261 636b 5f6f 703a 0a20 2020  fallback_op:.   
+00020e60: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00020e70: 6675 7365 5f70 6174 7465 726e 5b31 5d20  fuse_pattern[1] 
+00020e80: 696e 205b 2772 656c 755f 272c 2027 6164  in ['relu_', 'ad
+00020e90: 645f 275d 3a0a 2020 2020 2020 2020 2020  d_']:.          
+00020ea0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00020eb0: 204e 6f6e 650a 2020 2020 2020 2020 2020   None.          
+00020ec0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00020ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020ee0: 7265 7475 726e 2066 7573 655f 7061 7474  return fuse_patt
+00020ef0: 6572 6e5b 315d 0a20 2020 2020 2020 2072  ern[1].        r
+00020f00: 6574 7572 6e20 4e6f 6e65 0a0a 2020 2020  eturn None..    
+00020f10: 6465 6620 6576 616c 7561 7465 2873 656c  def evaluate(sel
+00020f20: 662c 0a20 2020 2020 2020 2020 2020 2020  f,.             
+00020f30: 2020 2020 6d6f 6465 6c2c 0a20 2020 2020      model,.     
+00020f40: 2020 2020 2020 2020 2020 2020 6461 7461              data
+00020f50: 6c6f 6164 6572 2c0a 2020 2020 2020 2020  loader,.        
+00020f60: 2020 2020 2020 2020 2070 6f73 7470 726f           postpro
+00020f70: 6365 7373 3d4e 6f6e 652c 0a20 2020 2020  cess=None,.     
+00020f80: 2020 2020 2020 2020 2020 2020 6d65 7472              metr
+00020f90: 6963 733d 4e6f 6e65 2c0a 2020 2020 2020  ics=None,.      
+00020fa0: 2020 2020 2020 2020 2020 206d 6561 7375             measu
+00020fb0: 7265 723d 4e6f 6e65 2c0a 2020 2020 2020  rer=None,.      
+00020fc0: 2020 2020 2020 2020 2020 2069 7465 7261             itera
+00020fd0: 7469 6f6e 3d2d 312c 0a20 2020 2020 2020  tion=-1,.       
+00020fe0: 2020 2020 2020 2020 2020 7465 6e73 6f72            tensor
+00020ff0: 626f 6172 643d 4661 6c73 652c 0a20 2020  board=False,.   
+00021000: 2020 2020 2020 2020 2020 2020 2020 6670                fp
+00021010: 3332 5f62 6173 656c 696e 653d 4661 6c73  32_baseline=Fals
+00021020: 6529 3a0a 2020 2020 2020 2020 2222 2245  e):.        """E
+00021030: 7865 6375 7465 2074 6865 2065 7661 6c75  xecute the evalu
+00021040: 6174 6520 7072 6f63 6573 7320 6f6e 2074  ate process on t
+00021050: 6865 2073 7065 6369 6669 6564 206d 6f64  he specified mod
+00021060: 656c 2e0a 0a20 2020 2020 2020 2041 7267  el...        Arg
+00021070: 733a 0a20 2020 2020 2020 2020 2020 206d  s:.            m
+00021080: 6f64 656c 2028 6f62 6a65 6374 293a 204e  odel (object): N
+00021090: 6575 7261 6c20 436f 6d70 7265 7373 6f72  eural Compressor
+000210a0: 206d 6f64 656c 2074 6f20 7275 6e20 6576   model to run ev
+000210b0: 616c 7561 7469 6f6e 2e0a 2020 2020 2020  aluation..      
+000210c0: 2020 2020 2020 6461 7461 6c6f 6164 6572        dataloader
+000210d0: 2028 6f62 6a65 6374 293a 2065 7661 6c75   (object): evalu
+000210e0: 6174 696f 6e20 6461 7461 7365 742e 0a20  ation dataset.. 
+000210f0: 2020 2020 2020 2020 2020 2070 6f73 7470             postp
+00021100: 726f 6365 7373 2028 6f62 6a65 6374 2c20  rocess (object, 
+00021110: 6f70 7469 6f6e 616c 293a 2070 726f 6365  optional): proce
+00021120: 7373 2066 756e 6374 696f 6e20 6166 7465  ss function afte
+00021130: 7220 6576 616c 7561 7469 6f6e 2e0a 2020  r evaluation..  
+00021140: 2020 2020 2020 2020 2020 6d65 7472 6963            metric
+00021150: 7320 286c 6973 742c 206f 7074 696f 6e61  s (list, optiona
+00021160: 6c29 3a20 6c69 7374 206f 6620 6d65 7472  l): list of metr
+00021170: 6963 2066 756e 6374 696f 6e2e 0a20 2020  ic function..   
+00021180: 2020 2020 2020 2020 206d 6561 7375 7265           measure
+00021190: 7220 286f 626a 6563 742c 206f 7074 696f  r (object, optio
+000211a0: 6e61 6c29 3a20 6d65 6173 7572 6572 2066  nal): measurer f
+000211b0: 756e 6374 696f 6e2e 0a20 2020 2020 2020  unction..       
+000211c0: 2020 2020 2069 7465 7261 7469 6f6e 2028       iteration (
+000211d0: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
+000211e0: 6e75 6d62 6572 206f 6620 6974 6572 6174  number of iterat
+000211f0: 696f 6e73 2074 6f20 6576 616c 7561 7465  ions to evaluate
+00021200: 2e0a 2020 2020 2020 2020 2020 2020 7465  ..            te
+00021210: 6e73 6f72 626f 6172 6420 2862 6f6f 6c2c  nsorboard (bool,
+00021220: 206f 7074 696f 6e61 6c29 3a20 6475 6d70   optional): dump
+00021230: 206f 7574 7075 7420 7465 6e73 6f72 2074   output tensor t
+00021240: 6f20 7465 6e73 6f72 626f 6172 6420 7375  o tensorboard su
+00021250: 6d6d 6172 790a 2020 2020 2020 2020 2020  mmary.          
+00021260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021280: 6669 6c65 7328 4950 4558 2075 6e73 7070  files(IPEX unspp
+00021290: 6f72 7429 2e0a 2020 2020 2020 2020 2020  ort)..          
+000212a0: 2020 6670 3332 5f62 6173 656c 696e 6520    fp32_baseline 
+000212b0: 2862 6f6f 6c65 6e2c 206f 7074 696f 6e61  (boolen, optiona
+000212c0: 6c29 3a20 6f6e 6c79 2066 6f72 2063 6f6d  l): only for com
+000212d0: 7061 7265 5f6c 6162 656c 3d46 616c 7365  pare_label=False
+000212e0: 2070 6970 656c 696e 650a 0a20 2020 2020   pipeline..     
+000212f0: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
+00021300: 2020 2020 2020 2020 2864 6963 7429 3a20          (dict): 
+00021310: 7175 616e 7469 7a65 6420 6d6f 6465 6c0a  quantized model.
+00021320: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
+00021330: 2020 2020 2061 7373 6572 7420 6e6f 7420       assert not 
+00021340: 7465 6e73 6f72 626f 6172 642c 2022 496e  tensorboard, "In
+00021350: 7465 6c20 5079 546f 7263 6820 4578 7465  tel PyTorch Exte
+00021360: 6e73 696f 6e20 6469 646e 2774 2074 656e  nsion didn't ten
+00021370: 736f 7220 6475 6d70 220a 2020 2020 2020  sor dump".      
+00021380: 2020 7365 6c66 2e69 735f 6261 7365 6c69    self.is_baseli
+00021390: 6e65 203d 2066 7033 325f 6261 7365 6c69  ne = fp32_baseli
+000213a0: 6e65 0a0a 2020 2020 2020 2020 6d6f 6465  ne..        mode
+000213b0: 6c5f 203d 206d 6f64 656c 2e5f 6d6f 6465  l_ = model._mode
+000213c0: 6c0a 2020 2020 2020 2020 6d6f 6465 6c5f  l.        model_
+000213d0: 2e65 7661 6c28 290a 0a20 2020 2020 2020  .eval()..       
+000213e0: 2069 6620 6d65 7472 6963 733a 0a20 2020   if metrics:.   
+000213f0: 2020 2020 2020 2020 2073 656c 662e 6670           self.fp
+00021400: 3332 5f70 7265 6473 5f61 735f 6c61 6265  32_preds_as_labe
+00021410: 6c20 3d20 616e 7928 5b68 6173 6174 7472  l = any([hasattr
+00021420: 286d 6574 7269 632c 2022 636f 6d70 6172  (metric, "compar
+00021430: 655f 6c61 6265 6c22 2920 616e 6420 5c0a  e_label") and \.
+00021440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021450: 6e6f 7420 6d65 7472 6963 2e63 6f6d 7061  not metric.compa
+00021460: 7265 5f6c 6162 656c 2066 6f72 206d 6574  re_label for met
+00021470: 7269 6320 696e 206d 6574 7269 6373 5d29  ric in metrics])
+00021480: 0a0a 2020 2020 2020 2020 6970 6578 5f63  ..        ipex_c
+00021490: 6f6e 6669 6720 3d20 2873 656c 662e 6970  onfig = (self.ip
+000214a0: 6578 5f63 6f6e 6669 675f 7061 7468 2069  ex_config_path i
+000214b0: 6620 6e6f 7420 7365 6c66 2e62 656e 6368  f not self.bench
+000214c0: 6d61 726b 2065 6c73 6520 4e6f 6e65 290a  mark else None).
+000214d0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+000214e0: 7665 7273 696f 6e2e 7265 6c65 6173 6520  version.release 
+000214f0: 3c20 5665 7273 696f 6e28 2231 2e31 322e  < Version("1.12.
+00021500: 3022 292e 7265 6c65 6173 653a 0a20 2020  0").release:.   
+00021510: 2020 2020 2020 2020 2063 6f6e 6620 3d20           conf = 
+00021520: 2869 7065 782e 7175 616e 7469 7a61 7469  (ipex.quantizati
+00021530: 6f6e 2e51 7561 6e74 436f 6e66 2863 6f6e  on.QuantConf(con
+00021540: 6669 6775 7265 5f66 696c 653d 6970 6578  figure_file=ipex
+00021550: 5f63 6f6e 6669 6729 2020 2023 2070 796c  _config)   # pyl
+00021560: 696e 743a 2064 6973 6162 6c65 3d45 3131  int: disable=E11
+00021570: 3031 0a20 2020 2020 2020 2020 2020 2020  01.             
+00021580: 2020 2020 2020 2069 6620 6e6f 7420 7365         if not se
+00021590: 6c66 2e69 735f 6261 7365 6c69 6e65 2065  lf.is_baseline e
+000215a0: 6c73 6520 4e6f 6e65 290a 2020 2020 2020  lse None).      
+000215b0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+000215c0: 2020 2020 636f 6e66 203d 204e 6f6e 650a      conf = None.
+000215d0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000215e0: 7365 6c66 2e6d 6f64 656c 5f65 7661 6c28  self.model_eval(
+000215f0: 6d6f 6465 6c5f 2c20 6461 7461 6c6f 6164  model_, dataload
+00021600: 6572 2c20 706f 7374 7072 6f63 6573 732c  er, postprocess,
+00021610: 206d 6574 7269 6373 2c20 6d65 6173 7572   metrics, measur
+00021620: 6572 2c20 6974 6572 6174 696f 6e2c 2063  er, iteration, c
+00021630: 6f6e 6629 0a0a 2020 2020 4064 756d 705f  onf)..    @dump_
+00021640: 656c 6170 7365 645f 7469 6d65 2822 5061  elapsed_time("Pa
+00021650: 7373 2071 7565 7279 2066 7261 6d65 776f  ss query framewo
+00021660: 726b 2063 6170 6162 696c 6974 7922 290a  rk capability").
+00021670: 2020 2020 6465 6620 7175 6572 795f 6677      def query_fw
+00021680: 5f63 6170 6162 696c 6974 7928 7365 6c66  _capability(self
+00021690: 2c20 6d6f 6465 6c29 3a0a 2020 2020 2020  , model):.      
+000216a0: 2020 2222 2254 6869 7320 6973 2061 2068    """This is a h
+000216b0: 656c 7065 7220 6675 6e63 7469 6f6e 2074  elper function t
+000216c0: 6f20 6765 7420 616c 6c20 7175 616e 7469  o get all quanti
+000216d0: 7a61 626c 6520 6f70 7320 6672 6f6d 206d  zable ops from m
+000216e0: 6f64 656c 2e0a 0a20 2020 2020 2020 2041  odel...        A
+000216f0: 7267 733a 0a20 2020 2020 2020 2020 2020  rgs:.           
+00021700: 206d 6f64 656c 2028 6f62 6a65 6374 293a   model (object):
+00021710: 2069 6e70 7574 206d 6f64 656c 2077 6869   input model whi
+00021720: 6368 2069 7320 4e65 7572 616c 2043 6f6d  ch is Neural Com
+00021730: 7072 6573 736f 7220 6d6f 6465 6c0a 0a20  pressor model.. 
+00021740: 2020 2020 2020 2052 6574 7572 6e73 3a0a         Returns:.
+00021750: 2020 2020 2020 2020 2020 2020 715f 6361              q_ca
+00021760: 7061 6269 6c69 7479 2028 6469 6374 696f  pability (dictio
+00021770: 6e61 7279 293a 2074 756e 696e 6720 6361  nary): tuning ca
+00021780: 7061 6269 6c69 7479 2066 6f72 2065 6163  pability for eac
+00021790: 6820 6f70 2066 726f 6d20 6d6f 6465 6c2e  h op from model.
+000217a0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+000217b0: 2020 2020 2073 656c 662e 7072 655f 6f70       self.pre_op
+000217c0: 7469 6d69 7a65 645f 6d6f 6465 6c20 3d20  timized_model = 
+000217d0: 6d6f 6465 6c0a 2020 2020 2020 2020 7265  model.        re
+000217e0: 7475 726e 2073 656c 662e 5f67 6574 5f71  turn self._get_q
+000217f0: 7561 6e74 697a 6162 6c65 5f6f 7073 286d  uantizable_ops(m
+00021800: 6f64 656c 2e6d 6f64 656c 290a 0a20 2020  odel.model)..   
+00021810: 2064 6566 205f 6765 745f 7175 616e 7469   def _get_quanti
+00021820: 7a61 626c 655f 6f70 735f 7265 6375 7273  zable_ops_recurs
+00021830: 6976 656c 7928 7365 6c66 2c20 6d6f 6465  ively(self, mode
+00021840: 6c2c 2070 7265 6669 782c 2071 7561 6e74  l, prefix, quant
+00021850: 697a 6162 6c65 5f6f 7073 293a 0a20 2020  izable_ops):.   
+00021860: 2020 2020 2022 2222 5468 6973 2069 7320       """This is 
+00021870: 6120 6865 6c70 6572 2066 756e 6374 696f  a helper functio
+00021880: 6e20 666f 7220 6071 7565 7279 5f66 775f  n for `query_fw_
+00021890: 6361 7061 6269 6c69 7479 602c 0a20 2020  capability`,.   
+000218a0: 2020 2020 2020 2020 616e 6420 6974 2077          and it w
+000218b0: 696c 6c20 6765 7420 616c 6c20 7175 616e  ill get all quan
+000218c0: 7469 7a61 626c 6520 6f70 7320 6672 6f6d  tizable ops from
+000218d0: 206d 6f64 656c 2e0a 2020 2020 2020 2020   model..        
+000218e0: 4172 6773 3a0a 2020 2020 2020 2020 2020  Args:.          
+000218f0: 2020 6d6f 6465 6c20 286f 626a 6563 7429    model (object)
+00021900: 3a20 696e 7075 7420 6d6f 6465 6c0a 2020  : input model.  
+00021910: 2020 2020 2020 2020 2020 7072 6566 6978            prefix
+00021920: 2028 7374 7269 6e67 293a 2070 7265 6669   (string): prefi
+00021930: 7820 6f66 206f 7020 6e61 6d65 0a20 2020  x of op name.   
+00021940: 2020 2020 2020 2020 2071 7561 6e74 697a           quantiz
+00021950: 6162 6c65 5f6f 7073 2028 6c69 7374 293a  able_ops (list):
+00021960: 206c 6973 7420 6f66 2071 7561 6e74 697a   list of quantiz
+00021970: 6162 6c65 206f 7073 2066 726f 6d20 6d6f  able ops from mo
+00021980: 6465 6c20 696e 636c 7564 6520 6f70 206e  del include op n
+00021990: 616d 6520 616e 6420 7479 7065 2e0a 2020  ame and type..  
+000219a0: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
+000219b0: 2020 2020 2020 2020 2020 204e 6f6e 650a             None.
+000219c0: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
+000219d0: 2020 2020 2069 6620 6e6f 7420 6f73 2e70       if not os.p
+000219e0: 6174 682e 6578 6973 7473 2873 656c 662e  ath.exists(self.
+000219f0: 6970 6578 5f63 6f6e 6669 675f 7061 7468  ipex_config_path
+00021a00: 293a 0a20 2020 2020 2020 2020 2020 2061  ):.            a
+00021a10: 7373 6572 7420 6973 696e 7374 616e 6365  ssert isinstance
+00021a20: 286d 6f64 656c 2c20 746f 7263 682e 6e6e  (model, torch.nn
+00021a30: 2e4d 6f64 756c 6529 2c20 5c0a 2020 2020  .Module), \.    
+00021a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021a50: 2254 6865 206d 6f64 656c 2070 6173 7365  "The model passe
+00021a60: 6420 696e 2069 7320 6e6f 7420 7468 6520  d in is not the 
+00021a70: 696e 7374 616e 6365 206f 6620 746f 7263  instance of torc
+00021a80: 682e 6e6e 2e4d 6f64 756c 6522 0a0a 2020  h.nn.Module"..  
+00021a90: 2020 2020 2020 6966 2068 6173 6174 7472        if hasattr
+00021aa0: 286d 6f64 656c 2c20 2273 6176 655f 7163  (model, "save_qc
+00021ab0: 6f6e 665f 7375 6d6d 6172 7922 293a 0a20  onf_summary"):. 
+00021ac0: 2020 2020 2020 2020 2020 206f 732e 6d61             os.ma
+00021ad0: 6b65 6469 7273 286f 732e 7061 7468 2e64  kedirs(os.path.d
+00021ae0: 6972 6e61 6d65 2873 656c 662e 6970 6578  irname(self.ipex
+00021af0: 5f63 6f6e 6669 675f 7061 7468 292c 2065  _config_path), e
+00021b00: 7869 7374 5f6f 6b3d 5472 7565 290a 2020  xist_ok=True).  
+00021b10: 2020 2020 2020 2020 2020 6d6f 6465 6c2e            model.
+00021b20: 7361 7665 5f71 636f 6e66 5f73 756d 6d61  save_qconf_summa
+00021b30: 7279 2871 636f 6e66 5f73 756d 6d61 7279  ry(qconf_summary
+00021b40: 3d73 656c 662e 6970 6578 5f63 6f6e 6669  =self.ipex_confi
+00021b50: 675f 7061 7468 290a 2020 2020 2020 2020  g_path).        
+00021b60: 2020 2020 6966 2073 656c 662e 6578 616d      if self.exam
+00021b70: 706c 655f 696e 7075 7473 2069 7320 4e6f  ple_inputs is No
+00021b80: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00021b90: 2020 2020 7365 6c66 2e65 7861 6d70 6c65      self.example
+00021ba0: 5f69 6e70 7574 7320 3d20 6765 745f 6578  _inputs = get_ex
+00021bb0: 616d 706c 655f 696e 7075 7473 286d 6f64  ample_inputs(mod
+00021bc0: 656c 2c20 7365 6c66 2e71 5f64 6174 616c  el, self.q_datal
+00021bd0: 6f61 6465 7229 0a20 2020 2020 2020 2065  oader).        e
+00021be0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00021bf0: 2069 6620 7365 6c66 2e70 6572 666f 726d   if self.perform
+00021c00: 616e 6365 5f6f 6e6c 793a 0a20 2020 2020  ance_only:.     
+00021c10: 2020 2020 2020 2020 2020 2074 6d70 5f6d             tmp_m
+00021c20: 6f64 656c 203d 206d 6f64 656c 0a20 2020  odel = model.   
+00021c30: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+00021c40: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+00021c50: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
+00021c60: 2020 2020 2020 2020 746d 705f 6d6f 6465          tmp_mode
+00021c70: 6c20 3d20 636f 7079 2e64 6565 7063 6f70  l = copy.deepcop
+00021c80: 7928 6d6f 6465 6c29 0a20 2020 2020 2020  y(model).       
+00021c90: 2020 2020 2020 2020 2065 7863 6570 7420           except 
+00021ca0: 4578 6365 7074 696f 6e20 6173 2065 3a20  Exception as e: 
+00021cb0: 2023 2070 7261 676d 613a 206e 6f20 636f   # pragma: no co
+00021cc0: 7665 720a 2020 2020 2020 2020 2020 2020  ver.            
+00021cd0: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
+00021ce0: 6172 6e69 6e67 2822 4661 696c 2074 6f20  arning("Fail to 
+00021cf0: 6465 6570 2063 6f70 7920 7468 6520 6d6f  deep copy the mo
+00021d00: 6465 6c20 6475 6520 746f 207b 7d2c 2069  del due to {}, i
+00021d10: 6e70 6c61 6365 2069 7320 7573 6564 206e  nplace is used n
+00021d20: 6f77 2e22 2e66 6f72 6d61 7428 0a20 2020  ow.".format(.   
+00021d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021d40: 2020 2020 2072 6570 7228 6529 2929 0a20       repr(e))). 
+00021d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021d60: 2020 2072 6169 7365 0a20 2020 2020 2020     raise.       
+00021d70: 2020 2020 2074 6d70 5f6d 6f64 656c 2e65       tmp_model.e
+00021d80: 7661 6c28 290a 2020 2020 2020 2020 2020  val().          
+00021d90: 2020 2320 746f 2072 6563 6f72 6420 7468    # to record th
+00021da0: 6520 6f72 6967 696e 2062 6174 6368 5f73  e origin batch_s
+00021db0: 697a 650a 2020 2020 2020 2020 2020 2020  ize.            
+00021dc0: 6966 2069 7369 6e73 7461 6e63 6528 7365  if isinstance(se
+00021dd0: 6c66 2e71 5f64 6174 616c 6f61 6465 722c  lf.q_dataloader,
+00021de0: 2042 6173 6544 6174 614c 6f61 6465 7229   BaseDataLoader)
+00021df0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00021e00: 2020 6261 7463 685f 7369 7a65 203d 2073    batch_size = s
+00021e10: 656c 662e 715f 6461 7461 6c6f 6164 6572  elf.q_dataloader
+00021e20: 2e62 6174 6368 5f73 697a 650a 0a20 2020  .batch_size..   
+00021e30: 2020 2020 2020 2020 2023 2063 7265 6174           # creat
+00021e40: 6520 6120 7175 616e 7469 7a61 7469 6f6e  e a quantization
+00021e50: 2063 6f6e 6669 6720 6669 6c65 2066 6f72   config file for
+00021e60: 2069 6e74 656c 2070 7974 6f72 6368 2065   intel pytorch e
+00021e70: 7874 656e 7369 6f6e 206d 6f64 656c 0a20  xtension model. 
+00021e80: 2020 2020 2020 2020 2020 206f 732e 6d61             os.ma
+00021e90: 6b65 6469 7273 286f 732e 7061 7468 2e64  kedirs(os.path.d
+00021ea0: 6972 6e61 6d65 2873 656c 662e 6970 6578  irname(self.ipex
+00021eb0: 5f63 6f6e 6669 675f 7061 7468 292c 2065  _config_path), e
+00021ec0: 7869 7374 5f6f 6b3d 5472 7565 290a 2020  xist_ok=True).  
+00021ed0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+00021ee0: 662e 7665 7273 696f 6e2e 7265 6c65 6173  f.version.releas
+00021ef0: 6520 3c20 5665 7273 696f 6e28 2231 2e31  e < Version("1.1
+00021f00: 322e 3022 292e 7265 6c65 6173 653a 0a20  2.0").release:. 
+00021f10: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+00021f20: 7373 6572 7420 7365 6c66 2e71 5f66 756e  ssert self.q_fun
+00021f30: 6320 6973 204e 6f6e 652c 2028 2249 5045  c is None, ("IPE
+00021f40: 5820 3c20 312e 3132 2e30 2064 6964 6e27  X < 1.12.0 didn'
+00021f50: 7420 7375 7070 6f72 7420 6361 6c69 6272  t support calibr
+00021f60: 6174 696f 6e20 6675 6e63 7469 6f6e 2c20  ation function, 
+00021f70: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00021f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021fa0: 2020 2022 506c 6561 7365 2075 7365 2049     "Please use I
+00021fb0: 5045 5820 3e3d 2031 2e31 322e 3021 2229  PEX >= 1.12.0!")
+00021fc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00021fd0: 2069 7065 785f 636f 6e66 203d 2069 7065   ipex_conf = ipe
+00021fe0: 782e 7175 616e 7469 7a61 7469 6f6e 2e51  x.quantization.Q
+00021ff0: 7561 6e74 436f 6e66 2871 7363 6865 6d65  uantConf(qscheme
+00022000: 3d74 6f72 6368 2e70 6572 5f74 656e 736f  =torch.per_tenso
+00022010: 725f 7379 6d6d 6574 7269 6329 2020 2023  r_symmetric)   #
+00022020: 2070 796c 696e 743a 2064 6973 6162 6c65   pylint: disable
+00022030: 3d45 3131 3031 0a20 2020 2020 2020 2020  =E1101.         
+00022040: 2020 2020 2020 2073 656c 662e 6d6f 6465         self.mode
+00022050: 6c5f 6361 6c69 6272 6174 696f 6e28 0a20  l_calibration(. 
+00022060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022070: 2020 2074 6d70 5f6d 6f64 656c 2c0a 2020     tmp_model,.  
+00022080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022090: 2020 7365 6c66 2e71 5f64 6174 616c 6f61    self.q_dataloa
+000220a0: 6465 722c 0a20 2020 2020 2020 2020 2020  der,.           
+000220b0: 2020 2020 2020 2020 2063 6f6e 663d 6970           conf=ip
+000220c0: 6578 5f63 6f6e 662c 0a20 2020 2020 2020  ex_conf,.       
+000220d0: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+000220e0: 2020 2020 2020 2020 2020 2069 7065 785f             ipex_
+000220f0: 636f 6e66 2e73 6176 6528 7365 6c66 2e69  conf.save(self.i
+00022100: 7065 785f 636f 6e66 6967 5f70 6174 6829  pex_config_path)
+00022110: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
+00022120: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00022130: 2020 2069 6620 7365 6c66 2e61 7070 726f     if self.appro
+00022140: 6163 6820 696e 205b 2770 6f73 745f 7472  ach in ['post_tr
+00022150: 6169 6e69 6e67 5f73 7461 7469 635f 7175  aining_static_qu
+00022160: 616e 7427 2c20 2770 6f73 745f 7472 6169  ant', 'post_trai
+00022170: 6e69 6e67 5f61 7574 6f5f 7175 616e 7427  ning_auto_quant'
+00022180: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
+00022190: 2020 2020 2020 2061 7373 6572 7420 7365         assert se
+000221a0: 6c66 2e71 5f64 6174 616c 6f61 6465 7220  lf.q_dataloader 
+000221b0: 6973 206e 6f74 204e 6f6e 652c 2022 4950  is not None, "IP
+000221c0: 4558 206e 6565 6420 715f 6461 7461 6c6f  EX need q_datalo
+000221d0: 6164 6572 2074 6f20 7072 6570 6172 6520  ader to prepare 
+000221e0: 7468 6520 6d6f 6465 6c22 0a20 2020 2020  the model".     
+000221f0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00022200: 726f 6d20 746f 7263 682e 616f 2e71 7561  rom torch.ao.qua
+00022210: 6e74 697a 6174 696f 6e20 696d 706f 7274  ntization import
+00022220: 204d 696e 4d61 784f 6273 6572 7665 722c   MinMaxObserver,
+00022230: 2050 6572 4368 616e 6e65 6c4d 696e 4d61   PerChannelMinMa
+00022240: 784f 6273 6572 7665 722c 2051 436f 6e66  xObserver, QConf
+00022250: 6967 0a20 2020 2020 2020 2020 2020 2020  ig.             
+00022260: 2020 2020 2020 2023 2046 6f72 2073 6d6f         # For smo
+00022270: 6f74 6871 7561 6e74 206f 7074 696d 697a  othquant optimiz
+00022280: 6564 206d 6f64 656c 0a20 2020 2020 2020  ed model.       
+00022290: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000222a0: 7365 6c66 2e72 6563 6970 6573 2061 6e64  self.recipes and
+000222b0: 2073 656c 662e 7265 6369 7065 732e 6765   self.recipes.ge
+000222c0: 7428 2773 6d6f 6f74 685f 7175 616e 7427  t('smooth_quant'
+000222d0: 2c20 4661 6c73 6529 205c 0a20 2020 2020  , False) \.     
+000222e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000222f0: 2061 6e64 2073 656c 662e 7665 7273 696f   and self.versio
+00022300: 6e2e 7265 6c65 6173 6520 3e3d 2056 6572  n.release >= Ver
+00022310: 7369 6f6e 2822 322e 3122 292e 7265 6c65  sion("2.1").rele
+00022320: 6173 653a 0a20 2020 2020 2020 2020 2020  ase:.           
+00022330: 2020 2020 2020 2020 2020 2020 2073 7461               sta
+00022340: 7469 635f 7163 6f6e 6669 6720 3d20 6970  tic_qconfig = ip
+00022350: 6578 2e71 7561 6e74 697a 6174 696f 6e2e  ex.quantization.
+00022360: 6765 745f 736d 6f6f 7468 5f71 7561 6e74  get_smooth_quant
+00022370: 5f71 636f 6e66 6967 5f6d 6170 7069 6e67  _qconfig_mapping
+00022380: 2861 6c70 6861 3d30 2e35 290a 2020 2020  (alpha=0.5).    
+00022390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000223a0: 2020 2020 6966 206e 6f74 2068 6173 6174      if not hasat
+000223b0: 7472 2874 6d70 5f6d 6f64 656c 2c20 275f  tr(tmp_model, '_
+000223c0: 736d 6f6f 7468 7175 616e 745f 6f70 7469  smoothquant_opti
+000223d0: 6d69 7a65 6427 2920 5c0a 2020 2020 2020  mized') \.      
+000223e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000223f0: 2020 2020 6f72 206e 6f74 2074 6d70 5f6d      or not tmp_m
+00022400: 6f64 656c 2e5f 736d 6f6f 7468 7175 616e  odel._smoothquan
+00022410: 745f 6f70 7469 6d69 7a65 643a 0a20 2020  t_optimized:.   
+00022420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022430: 2020 2020 2020 2020 2023 2074 6f20 6d61           # to ma
+00022440: 6b65 2073 7572 6520 6970 6578 5f63 6f6e  ke sure ipex_con
+00022450: 6669 672e 6a73 6f6e 2069 7320 6261 7365  fig.json is base
+00022460: 6420 6f6e 2070 7265 2d6f 7074 696d 697a  d on pre-optimiz
+00022470: 6564 206d 6f64 656c 0a20 2020 2020 2020  ed model.       
+00022480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022490: 2020 2020 2074 6d70 5f6d 6f64 656c 203d       tmp_model =
+000224a0: 2073 656c 662e 5f77 7261 7070 6572 5f73   self._wrapper_s
+000224b0: 715f 6c69 6e65 6172 2874 6d70 5f6d 6f64  q_linear(tmp_mod
+000224c0: 656c 290a 2020 2020 2020 2020 2020 2020  el).            
+000224d0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+000224e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000224f0: 2020 2020 2020 7374 6174 6963 5f71 636f        static_qco
+00022500: 6e66 6967 203d 2051 436f 6e66 6967 2861  nfig = QConfig(a
+00022510: 6374 6976 6174 696f 6e3d 4d69 6e4d 6178  ctivation=MinMax
+00022520: 4f62 7365 7276 6572 2e77 6974 685f 6172  Observer.with_ar
+00022530: 6773 280a 2020 2020 2020 2020 2020 2020  gs(.            
+00022540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022550: 7173 6368 656d 653d 746f 7263 682e 7065  qscheme=torch.pe
+00022560: 725f 7465 6e73 6f72 5f61 6666 696e 652c  r_tensor_affine,
+00022570: 2064 7479 7065 3d74 6f72 6368 2e71 7569   dtype=torch.qui
+00022580: 6e74 3829 2c0a 2020 2020 2020 2020 2020  nt8),.          
+00022590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000225a0: 2020 7765 6967 6874 3d50 6572 4368 616e    weight=PerChan
+000225b0: 6e65 6c4d 696e 4d61 784f 6273 6572 7665  nelMinMaxObserve
+000225c0: 722e 7769 7468 5f61 7267 7328 6474 7970  r.with_args(dtyp
+000225d0: 653d 746f 7263 682e 7169 6e74 382c 205c  e=torch.qint8, \
+000225e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000225f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022600: 2020 2020 2071 7363 6865 6d65 3d74 6f72       qscheme=tor
+00022610: 6368 2e70 6572 5f63 6861 6e6e 656c 5f73  ch.per_channel_s
+00022620: 796d 6d65 7472 6963 2929 0a20 2020 2020  ymmetric)).     
+00022630: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00022640: 6620 7365 6c66 2e65 7861 6d70 6c65 5f69  f self.example_i
+00022650: 6e70 7574 7320 6973 204e 6f6e 653a 0a20  nputs is None:. 
+00022660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022670: 2020 2020 2020 2073 656c 662e 6578 616d         self.exam
+00022680: 706c 655f 696e 7075 7473 203d 2067 6574  ple_inputs = get
+00022690: 5f65 7861 6d70 6c65 5f69 6e70 7574 7328  _example_inputs(
+000226a0: 746d 705f 6d6f 6465 6c2c 2073 656c 662e  tmp_model, self.
+000226b0: 715f 6461 7461 6c6f 6164 6572 290a 2020  q_dataloader).  
+000226c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000226d0: 2020 746d 705f 6d6f 6465 6c20 3d20 6970    tmp_model = ip
+000226e0: 6578 2e71 7561 6e74 697a 6174 696f 6e2e  ex.quantization.
+000226f0: 7072 6570 6172 6528 746d 705f 6d6f 6465  prepare(tmp_mode
+00022700: 6c2c 2073 7461 7469 635f 7163 6f6e 6669  l, static_qconfi
+00022710: 672c 205c 0a20 2020 2020 2020 2020 2020  g, \.           
+00022720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022740: 2065 7861 6d70 6c65 5f69 6e70 7574 733d   example_inputs=
+00022750: 7365 6c66 2e65 7861 6d70 6c65 5f69 6e70  self.example_inp
+00022760: 7574 732c 2069 6e70 6c61 6365 3d54 7275  uts, inplace=Tru
+00022770: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+00022780: 2020 2069 6620 7365 6c66 2e71 5f66 756e     if self.q_fun
+00022790: 6320 6973 204e 6f6e 653a 0a20 2020 2020  c is None:.     
+000227a0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000227b0: 656c 662e 6d6f 6465 6c5f 6361 6c69 6272  elf.model_calibr
+000227c0: 6174 696f 6e28 746d 705f 6d6f 6465 6c2c  ation(tmp_model,
+000227d0: 2073 656c 662e 715f 6461 7461 6c6f 6164   self.q_dataload
+000227e0: 6572 290a 2020 2020 2020 2020 2020 2020  er).            
+000227f0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00022800: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00022810: 6c66 2e71 5f66 756e 6328 746d 705f 6d6f  lf.q_func(tmp_mo
+00022820: 6465 6c29 0a20 2020 2020 2020 2020 2020  del).           
+00022830: 2020 2020 2074 6d70 5f6d 6f64 656c 2e73       tmp_model.s
+00022840: 6176 655f 7163 6f6e 665f 7375 6d6d 6172  ave_qconf_summar
+00022850: 7928 7163 6f6e 665f 7375 6d6d 6172 793d  y(qconf_summary=
+00022860: 7365 6c66 2e69 7065 785f 636f 6e66 6967  self.ipex_config
+00022870: 5f70 6174 6829 0a20 2020 2020 2020 2020  _path).         
+00022880: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+00022890: 2873 656c 662e 715f 6461 7461 6c6f 6164  (self.q_dataload
+000228a0: 6572 2c20 4261 7365 4461 7461 4c6f 6164  er, BaseDataLoad
+000228b0: 6572 293a 0a20 2020 2020 2020 2020 2020  er):.           
+000228c0: 2020 2020 2073 656c 662e 715f 6461 7461       self.q_data
+000228d0: 6c6f 6164 6572 2e62 6174 6368 2862 6174  loader.batch(bat
+000228e0: 6368 5f73 697a 6529 0a20 2020 2020 2020  ch_size).       
+000228f0: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+00022900: 696e 666f 2827 5265 636f 7665 7279 2060  info('Recovery `
+00022910: 6361 6c69 6272 6174 696f 6e2e 6461 7461  calibration.data
+00022920: 6c6f 6164 6572 2e62 6174 6368 7369 7a65  loader.batchsize
+00022930: 6020 7b7d 2061 6363 6f72 6469 6e67 205c  ` {} according \
+00022940: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00022950: 2020 2020 2020 2020 2020 2020 2074 6f20               to 
+00022960: 636f 6e66 6967 2e79 616d 6c27 2e66 6f72  config.yaml'.for
+00022970: 6d61 7428 6261 7463 685f 7369 7a65 2929  mat(batch_size))
+00022980: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00022990: 6e6f 7420 7365 6c66 2e70 6572 666f 726d  not self.perform
+000229a0: 616e 6365 5f6f 6e6c 793a 0a20 2020 2020  ance_only:.     
+000229b0: 2020 2020 2020 2020 2020 2064 656c 2074             del t
+000229c0: 6d70 5f6d 6f64 656c 0a20 2020 2020 2020  mp_model.       
+000229d0: 2020 2020 2020 2020 2069 6d70 6f72 7420           import 
+000229e0: 6763 0a20 2020 2020 2020 2020 2020 2020  gc.             
+000229f0: 2020 2067 632e 636f 6c6c 6563 7428 290a     gc.collect().
+00022a00: 0a20 2020 2020 2020 2077 6974 6820 6f70  .        with op
+00022a10: 656e 2873 656c 662e 6970 6578 5f63 6f6e  en(self.ipex_con
+00022a20: 6669 675f 7061 7468 2c20 2772 2729 2061  fig_path, 'r') a
+00022a30: 7320 663a 0a20 2020 2020 2020 2020 2020  s f:.           
+00022a40: 2073 656c 662e 6366 6773 203d 206a 736f   self.cfgs = jso
+00022a50: 6e2e 6c6f 6164 2866 290a 2020 2020 2020  n.load(f).      
+00022a60: 2020 2020 2020 6966 2073 656c 662e 7665        if self.ve
+00022a70: 7273 696f 6e2e 7265 6c65 6173 6520 3c20  rsion.release < 
+00022a80: 5665 7273 696f 6e28 2231 2e31 322e 3022  Version("1.12.0"
+00022a90: 292e 7265 6c65 6173 653a 0a20 2020 2020  ).release:.     
+00022aa0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00022ab0: 6465 6661 756c 745f 6366 6773 203d 2063  default_cfgs = c
+00022ac0: 6f70 792e 6465 6570 636f 7079 2873 656c  opy.deepcopy(sel
+00022ad0: 662e 6366 6773 290a 2020 2020 2020 2020  f.cfgs).        
+00022ae0: 2020 2020 2020 2020 7365 6c66 2e66 7573          self.fus
+00022af0: 655f 6f70 7320 3d20 7365 6c66 2e67 6574  e_ops = self.get
+00022b00: 5f66 7573 655f 6f70 7328 7365 6c66 2e63  _fuse_ops(self.c
+00022b10: 6667 7329 0a20 2020 2020 2020 2020 2020  fgs).           
+00022b20: 2020 2020 2066 6f72 206f 705f 6366 6720       for op_cfg 
+00022b30: 696e 2073 656c 662e 6366 6773 3a0a 2020  in self.cfgs:.  
+00022b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022b50: 2020 7175 616e 7469 7a61 626c 655f 6f70    quantizable_op
+00022b60: 732e 6170 7065 6e64 280a 2020 2020 2020  s.append(.      
+00022b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022b80: 2020 286f 705f 6366 675b 2269 6422 5d2c    (op_cfg["id"],
+00022b90: 2075 6e69 6679 5f6f 705f 7479 7065 5f6d   unify_op_type_m
+00022ba0: 6170 7069 6e67 5f69 7065 785b 6f70 5f63  apping_ipex[op_c
+00022bb0: 6667 5b22 6e61 6d65 225d 5d0a 2020 2020  fg["name"]].    
+00022bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022bd0: 2020 2020 2069 6620 6f70 5f63 6667 5b22       if op_cfg["
+00022be0: 6e61 6d65 225d 2069 6e20 756e 6966 795f  name"] in unify_
+00022bf0: 6f70 5f74 7970 655f 6d61 7070 696e 675f  op_type_mapping_
+00022c00: 6970 6578 2065 6c73 6520 6f70 5f63 6667  ipex else op_cfg
+00022c10: 5b22 6e61 6d65 225d 2929 0a20 2020 2020  ["name"])).     
+00022c20: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00022c30: 2020 2020 2020 2020 2020 2020 206f 7073               ops
+00022c40: 5f6e 616d 652c 206f 705f 696e 666f 735f  _name, op_infos_
+00022c50: 6672 6f6d 5f63 6667 732c 2069 6e70 7574  from_cfgs, input
+00022c60: 5f74 656e 736f 725f 6964 5f6f 705f 6e61  _tensor_id_op_na
+00022c70: 6d65 2c20 5c0a 2020 2020 2020 2020 2020  me, \.          
 00022c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022cb0: 2020 2020 2020 2020 2020 204e 6f6e 6529             None)
-00022cc0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00022cd0: 662e 636f 6e76 6572 745f 6375 7374 6f6d  f.convert_custom
-00022ce0: 5f63 6f6e 6669 675f 6469 6374 203d 2071  _config_dict = q
-00022cf0: 5f6d 6f64 656c 2e6b 7761 7267 732e 6765  _model.kwargs.ge
-00022d00: 7428 2763 6f6e 7665 7274 5f63 7573 746f  t('convert_custo
-00022d10: 6d5f 636f 6e66 6967 5f64 6963 7427 2c0a  m_config_dict',.
-00022d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022c90: 2020 2020 2020 6f75 7470 7574 5f74 656e        output_ten
+00022ca0: 736f 725f 6964 5f6f 705f 6e61 6d65 203d  sor_id_op_name =
+00022cb0: 2074 6f72 6368 5f75 7469 6c73 2e75 7469   torch_utils.uti
+00022cc0: 6c2e 7061 7365 725f 6366 6773 2873 656c  l.paser_cfgs(sel
+00022cd0: 662e 6366 6773 290a 2020 2020 2020 2020  f.cfgs).        
+00022ce0: 2020 2020 2020 2020 7175 616e 7469 7a61          quantiza
+00022cf0: 626c 655f 6f70 5f6e 616d 6573 203d 2074  ble_op_names = t
+00022d00: 6f72 6368 5f75 7469 6c73 2e75 7469 6c2e  orch_utils.util.
+00022d10: 6765 745f 7175 616e 7469 7a61 626c 655f  get_quantizable_
+00022d20: 6f70 735f 6672 6f6d 5f63 6667 7328 6f70  ops_from_cfgs(op
+00022d30: 735f 6e61 6d65 2c0a 2020 2020 2020 2020  s_name,.        
 00022d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00022d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022d60: 204e 6f6e 6529 0a20 2020 2020 2020 2065   None).        e
-00022d70: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00022d80: 2073 656c 662e 7072 6570 6172 655f 6375   self.prepare_cu
-00022d90: 7374 6f6d 5f63 6f6e 6669 675f 6469 6374  stom_config_dict
-00022da0: 2c20 7365 6c66 2e63 6f6e 7665 7274 5f63  , self.convert_c
-00022db0: 7573 746f 6d5f 636f 6e66 6967 5f64 6963  ustom_config_dic
-00022dc0: 7420 3d20 4e6f 6e65 2c20 4e6f 6e65 0a20  t = None, None. 
-00022dd0: 2020 2020 2020 2073 656c 662e 6678 5f6f         self.fx_o
-00022de0: 705f 6366 6773 203d 205f 6366 6773 5f74  p_cfgs = _cfgs_t
-00022df0: 6f5f 6678 5f63 6667 7328 6f70 5f63 6667  o_fx_cfgs(op_cfg
-00022e00: 732c 2073 656c 662e 6170 7072 6f61 6368  s, self.approach
-00022e10: 290a 2020 2020 2020 2020 7365 6c66 2e74  ).        self.t
-00022e20: 756e 655f 6366 675b 2766 785f 7375 625f  une_cfg['fx_sub_
-00022e30: 6d6f 6475 6c65 5f6c 6973 7427 5d20 3d20  module_list'] = 
-00022e40: 7365 6c66 2e73 7562 5f6d 6f64 756c 655f  self.sub_module_
-00022e50: 6c69 7374 0a20 2020 2020 2020 2069 6620  list.        if 
-00022e60: 7365 6c66 2e61 7070 726f 6163 6820 3d3d  self.approach ==
-00022e70: 2027 7175 616e 745f 6177 6172 655f 7472   'quant_aware_tr
-00022e80: 6169 6e69 6e67 273a 0a20 2020 2020 2020  aining':.       
-00022e90: 2020 2020 2071 5f6d 6f64 656c 2e5f 6d6f       q_model._mo
-00022ea0: 6465 6c2e 7472 6169 6e28 290a 2020 2020  del.train().    
-00022eb0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00022ec0: 7375 625f 6d6f 6475 6c65 5f6c 6973 7420  sub_module_list 
-00022ed0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
-00022ee0: 2020 2020 2020 2020 2074 6d70 5f6d 6f64           tmp_mod
-00022ef0: 656c 203d 2071 5f6d 6f64 656c 2e5f 6d6f  el = q_model._mo
-00022f00: 6465 6c0a 2020 2020 2020 2020 2020 2020  del.            
-00022f10: 2020 2020 6966 2073 656c 662e 7665 7273      if self.vers
-00022f20: 696f 6e20 3e20 5665 7273 696f 6e28 2231  ion > Version("1
-00022f30: 2e31 322e 3122 293a 2020 2320 7072 6167  .12.1"):  # prag
-00022f40: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
-00022f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022f60: 2023 2070 796c 696e 743a 2064 6973 6162   # pylint: disab
-00022f70: 6c65 3d45 3131 3233 0a20 2020 2020 2020  le=E1123.       
-00022f80: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
-00022f90: 6f64 656c 2e5f 6d6f 6465 6c20 3d20 7072  odel._model = pr
-00022fa0: 6570 6172 655f 7161 745f 6678 280a 2020  epare_qat_fx(.  
-00022fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022fc0: 2020 2020 2020 715f 6d6f 6465 6c2e 5f6d        q_model._m
-00022fd0: 6f64 656c 2c0a 2020 2020 2020 2020 2020  odel,.          
-00022fe0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00022ff0: 6c66 2e66 785f 6f70 5f63 6667 732c 0a20  lf.fx_op_cfgs,. 
+00022d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022d70: 2020 2020 2020 2020 2020 2020 206f 705f               op_
+00022d80: 696e 666f 735f 6672 6f6d 5f63 6667 732c  infos_from_cfgs,
+00022d90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00022da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022dd0: 2020 2020 2020 696e 7075 745f 7465 6e73        input_tens
+00022de0: 6f72 5f69 645f 6f70 5f6e 616d 6529 0a20  or_id_op_name). 
+00022df0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00022e00: 6f72 206e 616d 6520 696e 2071 7561 6e74  or name in quant
+00022e10: 697a 6162 6c65 5f6f 705f 6e61 6d65 733a  izable_op_names:
+00022e20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00022e30: 2020 2020 2023 206e 616d 6520 3a20 6c69       # name : li
+00022e40: 7374 0a20 2020 2020 2020 2020 2020 2020  st.             
+00022e50: 2020 2020 2020 2069 6620 6c65 6e28 6e61         if len(na
+00022e60: 6d65 2920 3d3d 2031 3a0a 2020 2020 2020  me) == 1:.      
+00022e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022e80: 2020 6d6f 6475 6c65 5f6b 6579 203d 206e    module_key = n
+00022e90: 616d 655b 305d 5b30 5d0a 2020 2020 2020  ame[0][0].      
+00022ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022eb0: 2020 6f70 5f63 6667 5f69 6420 3d20 6e61    op_cfg_id = na
+00022ec0: 6d65 5b30 5d5b 325d 0a20 2020 2020 2020  me[0][2].       
+00022ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022ee0: 2071 7561 6e74 697a 6162 6c65 5f6f 7073   quantizable_ops
+00022ef0: 2e61 7070 656e 6428 2874 7570 6c65 286e  .append((tuple(n
+00022f00: 616d 6529 2c20 756e 6966 795f 6f70 5f74  ame), unify_op_t
+00022f10: 7970 655f 6d61 7070 696e 675f 6970 6578  ype_mapping_ipex
+00022f20: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+00022f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022f50: 2020 5b73 656c 662e 6366 6773 5b6d 6f64    [self.cfgs[mod
+00022f60: 756c 655f 6b65 795d 5b27 715f 6f70 5f69  ule_key]['q_op_i
+00022f70: 6e66 6f73 275d 5b6f 705f 6366 675f 6964  nfos'][op_cfg_id
+00022f80: 5d5b 276f 705f 7479 7065 275d 5d20 5c0a  ]['op_type']] \.
+00022f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022fb0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00022fc0: 6620 7365 6c66 2e63 6667 735b 6d6f 6475  f self.cfgs[modu
+00022fd0: 6c65 5f6b 6579 5d5b 2771 5f6f 705f 696e  le_key]['q_op_in
+00022fe0: 666f 7327 5d5b 6f70 5f63 6667 5f69 645d  fos'][op_cfg_id]
+00022ff0: 5b27 6f70 5f74 7970 6527 5d20 5c0a 2020  ['op_type'] \.  
 00023000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023010: 2020 2020 2020 2065 7861 6d70 6c65 5f69         example_i
-00023020: 6e70 7574 733d 7365 6c66 2e65 7861 6d70  nputs=self.examp
-00023030: 6c65 5f69 6e70 7574 732c 0a20 2020 2020  le_inputs,.     
-00023040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023050: 2020 2070 7265 7061 7265 5f63 7573 746f     prepare_custo
-00023060: 6d5f 636f 6e66 6967 3d73 656c 662e 7072  m_config=self.pr
-00023070: 6570 6172 655f 6375 7374 6f6d 5f63 6f6e  epare_custom_con
-00023080: 6669 675f 6469 6374 0a20 2020 2020 2020  fig_dict.       
-00023090: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
-000230a0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-000230b0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-000230c0: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
-000230d0: 2e5f 6d6f 6465 6c20 3d20 7072 6570 6172  ._model = prepar
-000230e0: 655f 7161 745f 6678 280a 2020 2020 2020  e_qat_fx(.      
-000230f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023100: 2020 715f 6d6f 6465 6c2e 5f6d 6f64 656c    q_model._model
-00023110: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00023120: 2020 2020 2020 2020 2020 7365 6c66 2e66            self.f
-00023130: 785f 6f70 5f63 6667 732c 0a20 2020 2020  x_op_cfgs,.     
-00023140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023150: 2020 2070 7265 7061 7265 5f63 7573 746f     prepare_custo
-00023160: 6d5f 636f 6e66 6967 5f64 6963 743d 7365  m_config_dict=se
-00023170: 6c66 2e70 7265 7061 7265 5f63 7573 746f  lf.prepare_custo
-00023180: 6d5f 636f 6e66 6967 5f64 6963 740a 2020  m_config_dict.  
+00023010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023020: 2020 2020 2020 2020 2020 2020 2069 6e20               in 
+00023030: 756e 6966 795f 6f70 5f74 7970 655f 6d61  unify_op_type_ma
+00023040: 7070 696e 675f 6970 6578 2065 6c73 6520  pping_ipex else 
+00023050: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00023060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023080: 2073 656c 662e 6366 6773 5b6d 6f64 756c   self.cfgs[modul
+00023090: 655f 6b65 795d 5b27 715f 6f70 5f69 6e66  e_key]['q_op_inf
+000230a0: 6f73 275d 5b6f 705f 6366 675f 6964 5d5b  os'][op_cfg_id][
+000230b0: 276f 705f 7479 7065 275d 2929 0a20 2020  'op_type'])).   
+000230c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000230d0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+000230e0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+000230f0: 705f 7479 7065 203d 2022 220a 2020 2020  p_type = "".    
+00023100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023110: 2020 2020 666f 7220 6f70 5f6e 616d 6520      for op_name 
+00023120: 696e 206e 616d 653a 0a20 2020 2020 2020  in name:.       
+00023130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023140: 2020 2020 206d 6f64 756c 655f 6b65 7920       module_key 
+00023150: 3d20 6f70 5f6e 616d 655b 305d 0a20 2020  = op_name[0].   
+00023160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023170: 2020 2020 2020 2020 206f 705f 6366 675f           op_cfg_
+00023180: 6964 203d 206f 705f 6e61 6d65 5b32 5d0a  id = op_name[2].
 00023190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000231a0: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
-000231b0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-000231c0: 2020 2020 2020 6c6f 6767 6572 2e69 6e66        logger.inf
-000231d0: 6f28 2746 7820 7472 6163 6520 6f66 2074  o('Fx trace of t
-000231e0: 6865 2065 6e74 6972 6520 6d6f 6465 6c20  he entire model 
-000231f0: 6661 696c 6564 2e20 2720 2b20 5c0a 2020  failed. ' + \.  
-00023200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023210: 2020 2020 2020 2020 2020 2757 6520 7769            'We wi
-00023220: 6c6c 2063 6f6e 6475 6374 2061 7574 6f20  ll conduct auto 
-00023230: 7175 616e 7469 7a61 7469 6f6e 2729 0a20  quantization'). 
-00023240: 2020 2020 2020 2020 2020 2020 2020 2050                 P
-00023250: 7954 6f72 6368 5f46 5841 6461 7074 6f72  yTorch_FXAdaptor
-00023260: 2e70 7265 7061 7265 5f73 7562 5f67 7261  .prepare_sub_gra
-00023270: 7068 280a 2020 2020 2020 2020 2020 2020  ph(.            
-00023280: 2020 2020 2020 2020 7365 6c66 2e73 7562          self.sub
-00023290: 5f6d 6f64 756c 655f 6c69 7374 2c0a 2020  _module_list,.  
-000232a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000232b0: 2020 7365 6c66 2e66 785f 6f70 5f63 6667    self.fx_op_cfg
-000232c0: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
-000232d0: 2020 2020 2020 2071 5f6d 6f64 656c 2e5f         q_model._
-000232e0: 6d6f 6465 6c2c 0a20 2020 2020 2020 2020  model,.         
-000232f0: 2020 2020 2020 2020 2020 2070 7265 6669             prefi
-00023300: 783d 2727 2c0a 2020 2020 2020 2020 2020  x='',.          
-00023310: 2020 2020 2020 2020 2020 6973 5f71 6174            is_qat
-00023320: 3d54 7275 652c 0a20 2020 2020 2020 2020  =True,.         
-00023330: 2020 2020 2020 2020 2020 2065 7861 6d70             examp
-00023340: 6c65 5f69 6e70 7574 733d 7365 6c66 2e65  le_inputs=self.e
-00023350: 7861 6d70 6c65 5f69 6e70 7574 732c 0a20  xample_inputs,. 
-00023360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023370: 2020 2063 7573 746f 6d5f 636f 6e66 6967     custom_config
-00023380: 3d73 656c 662e 7072 6570 6172 655f 6375  =self.prepare_cu
-00023390: 7374 6f6d 5f63 6f6e 6669 675f 6469 6374  stom_config_dict
-000233a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000233b0: 2029 0a20 2020 2020 2020 2020 2020 2023   ).            #
-000233c0: 2071 5f66 756e 6320 6361 6e20 6265 2063   q_func can be c
-000233d0: 7265 6174 6564 2062 7920 6e65 7572 616c  reated by neural
-000233e0: 5f63 6f6d 7072 6573 736f 7220 696e 7465  _compressor inte
-000233f0: 726e 616c 206f 7220 7061 7373 6564 2062  rnal or passed b
-00023400: 7920 7573 6572 2e20 4974 2773 2063 7269  y user. It's cri
-00023410: 7469 6361 6c20 746f 0a20 2020 2020 2020  tical to.       
-00023420: 2020 2020 2023 2064 6973 7469 6e67 7569       # distingui
-00023430: 7368 2068 6f77 2071 5f66 756e 6320 6973  sh how q_func is
-00023440: 2070 6173 7365 6420 7369 6e63 6520 6e65   passed since ne
-00023450: 7572 616c 5f63 6f6d 7072 6573 736f 7220  ural_compressor 
-00023460: 6275 696c 742d 696e 2066 756e 6374 696f  built-in functio
-00023470: 6e73 2061 6363 6570 740a 2020 2020 2020  ns accept.      
-00023480: 2020 2020 2020 2320 6e65 7572 616c 5f63        # neural_c
-00023490: 6f6d 7072 6573 736f 7220 6d6f 6465 6c20  ompressor model 
-000234a0: 616e 6420 7573 6572 2064 6566 696e 6564  and user defined
-000234b0: 2066 756e 6320 7368 6f75 6c64 2061 6363   func should acc
-000234c0: 6570 7420 6672 616d 6577 6f72 6b20 6d6f  ept framework mo
-000234d0: 6465 6c2e 0a20 2020 2020 2020 2020 2020  del..           
-000234e0: 2023 2046 6f72 2065 7870 6f72 7420 4150   # For export AP
-000234f0: 490a 2020 2020 2020 2020 2020 2020 686f  I.            ho
-00023500: 6f6b 5f6c 6973 7420 3d20 746f 7263 685f  ok_list = torch_
-00023510: 7574 696c 732e 7574 696c 2e5f 7365 745f  utils.util._set_
-00023520: 696e 7075 745f 7363 616c 655f 686f 6f6b  input_scale_hook
-00023530: 2871 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c  (q_model._model,
-00023540: 206f 705f 6366 6773 290a 2020 2020 2020   op_cfgs).      
-00023550: 2020 2020 2020 715f 6d6f 6465 6c2e 5f6d        q_model._m
-00023560: 6f64 656c 203d 2071 5f66 756e 6328 0a20  odel = q_func(. 
-00023570: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-00023580: 5f6d 6f64 656c 2069 6620 6765 7461 7474  _model if getatt
-00023590: 7228 715f 6675 6e63 2c20 2762 7569 6c74  r(q_func, 'built
-000235a0: 696e 272c 204e 6f6e 6529 2065 6c73 6520  in', None) else 
-000235b0: 715f 6d6f 6465 6c2e 5f6d 6f64 656c 290a  q_model._model).
-000235c0: 2020 2020 2020 2020 2020 2020 6173 7365              asse
-000235d0: 7274 2071 5f6d 6f64 656c 2e5f 6d6f 6465  rt q_model._mode
-000235e0: 6c20 6973 206e 6f74 204e 6f6e 652c 2022  l is not None, "
-000235f0: 506c 6561 7365 2072 6574 7572 6e20 6120  Please return a 
-00023600: 7472 6169 6e65 6420 6d6f 6465 6c20 696e  trained model in
-00023610: 2074 7261 696e 2066 756e 6374 696f 6e21   train function!
-00023620: 220a 2020 2020 2020 2020 2020 2020 715f  ".            q_
-00023630: 6d6f 6465 6c2e 5f6d 6f64 656c 2e65 7661  model._model.eva
-00023640: 6c28 290a 2020 2020 2020 2020 656c 7365  l().        else
-00023650: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
-00023660: 2073 656c 662e 7375 625f 6d6f 6475 6c65   self.sub_module
-00023670: 5f6c 6973 7420 6973 204e 6f6e 653a 0a20  _list is None:. 
-00023680: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00023690: 6d70 5f6d 6f64 656c 203d 2071 5f6d 6f64  mp_model = q_mod
-000236a0: 656c 2e5f 6d6f 6465 6c0a 2020 2020 2020  el._model.      
-000236b0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-000236c0: 662e 7665 7273 696f 6e2e 7265 6c65 6173  f.version.releas
-000236d0: 6520 3e3d 2056 6572 7369 6f6e 2822 312e  e >= Version("1.
-000236e0: 3133 2e30 2229 2e72 656c 6561 7365 3a20  13.0").release: 
-000236f0: 2023 2070 7261 676d 613a 206e 6f20 636f   # pragma: no co
-00023700: 7665 720a 2020 2020 2020 2020 2020 2020  ver.            
-00023710: 2020 2020 2020 2020 2320 7079 6c69 6e74          # pylint
-00023720: 3a20 6469 7361 626c 653d 4531 3132 330a  : disable=E1123.
-00023730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023740: 2020 2020 715f 6d6f 6465 6c2e 5f6d 6f64      q_model._mod
-00023750: 656c 203d 2070 7265 7061 7265 5f66 7828  el = prepare_fx(
-00023760: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00023770: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
-00023780: 2e5f 6d6f 6465 6c2c 0a20 2020 2020 2020  ._model,.       
+000231a0: 2020 2020 2020 2020 2020 2020 6f70 5f74              op_t
+000231b0: 7970 6520 2b3d 2073 656c 662e 6366 6773  ype += self.cfgs
+000231c0: 5b6d 6f64 756c 655f 6b65 795d 5b27 715f  [module_key]['q_
+000231d0: 6f70 5f69 6e66 6f73 275d 5b6f 705f 6366  op_infos'][op_cf
+000231e0: 675f 6964 5d5b 276f 705f 7479 7065 275d  g_id]['op_type']
+000231f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00023200: 2020 2020 2020 2020 2071 7561 6e74 697a           quantiz
+00023210: 6162 6c65 5f6f 7073 2e61 7070 656e 6428  able_ops.append(
+00023220: 2874 7570 6c65 286e 616d 6529 2c20 6f70  (tuple(name), op
+00023230: 5f74 7970 6529 290a 2020 2020 2020 2020  _type)).        
+00023240: 2020 2020 2020 2020 7365 6c66 2e6f 705f          self.op_
+00023250: 696e 666f 735f 6672 6f6d 5f63 6667 7320  infos_from_cfgs 
+00023260: 3d20 6f70 5f69 6e66 6f73 5f66 726f 6d5f  = op_infos_from_
+00023270: 6366 6773 0a20 2020 2020 2020 2020 2020  cfgs.           
+00023280: 2020 2020 2073 656c 662e 6f75 7470 7574       self.output
+00023290: 5f74 656e 736f 725f 6964 5f6f 705f 6e61  _tensor_id_op_na
+000232a0: 6d65 203d 206f 7574 7075 745f 7465 6e73  me = output_tens
+000232b0: 6f72 5f69 645f 6f70 5f6e 616d 650a 2020  or_id_op_name.  
+000232c0: 2020 2020 2020 6f73 2e72 656d 6f76 6528        os.remove(
+000232d0: 7365 6c66 2e69 7065 785f 636f 6e66 6967  self.ipex_config
+000232e0: 5f70 6174 6829 0a0a 2020 2020 6465 6620  _path)..    def 
+000232f0: 6765 745f 6675 7365 5f6f 7073 2873 656c  get_fuse_ops(sel
+00023300: 662c 2064 6566 6175 6c74 5f63 6667 7329  f, default_cfgs)
+00023310: 3a0a 2020 2020 2020 2020 656c 745f 7769  :.        elt_wi
+00023320: 7365 203d 205b 2772 656c 7527 2c20 2773  se = ['relu', 's
+00023330: 6967 6d6f 6964 272c 2027 6765 6c75 275d  igmoid', 'gelu']
+00023340: 0a20 2020 2020 2020 2069 6e70 6c61 6365  .        inplace
+00023350: 5f6f 7073 203d 205b 2772 656c 755f 272c  _ops = ['relu_',
+00023360: 2027 6164 645f 275d 0a20 2020 2020 2020   'add_'].       
+00023370: 206f 705f 7061 7474 6572 6e73 203d 205b   op_patterns = [
+00023380: 5d0a 2020 2020 2020 2020 6e75 6d5f 6f70  ].        num_op
+00023390: 7320 3d20 6c65 6e28 6465 6661 756c 745f  s = len(default_
+000233a0: 6366 6773 290a 2020 2020 2020 2020 666f  cfgs).        fo
+000233b0: 7220 6375 725f 6964 2069 6e20 7261 6e67  r cur_id in rang
+000233c0: 6528 6e75 6d5f 6f70 7329 3a0a 2020 2020  e(num_ops):.    
+000233d0: 2020 2020 2020 2020 6375 725f 6f70 203d          cur_op =
+000233e0: 2064 6566 6175 6c74 5f63 6667 735b 6375   default_cfgs[cu
+000233f0: 725f 6964 5d5b 276e 616d 6527 5d0a 2020  r_id]['name'].  
+00023400: 2020 2020 2020 2020 2020 6966 2063 7572            if cur
+00023410: 5f6f 7020 3d3d 2027 6472 6f70 6f75 7427  _op == 'dropout'
+00023420: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00023430: 2020 636f 6e74 696e 7565 0a20 2020 2020    continue.     
+00023440: 2020 2020 2020 2069 6e70 7574 7320 3d20         inputs = 
+00023450: 6465 6661 756c 745f 6366 6773 5b63 7572  default_cfgs[cur
+00023460: 5f69 645d 5b27 696e 7075 7473 5f66 6c6f  _id]['inputs_flo
+00023470: 7727 5d0a 2020 2020 2020 2020 2020 2020  w'].            
+00023480: 6e75 6d5f 696e 7075 7420 3d20 6c65 6e28  num_input = len(
+00023490: 696e 7075 7473 290a 2020 2020 2020 2020  inputs).        
+000234a0: 2020 2020 7072 655f 6f70 7320 3d20 7b7d      pre_ops = {}
+000234b0: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+000234c0: 2069 5f6e 756d 2069 6e20 7261 6e67 6528   i_num in range(
+000234d0: 6e75 6d5f 696e 7075 7429 3a0a 2020 2020  num_input):.    
+000234e0: 2020 2020 2020 2020 2020 2020 696e 7020              inp 
+000234f0: 3d20 696e 7075 7473 5b69 5f6e 756d 5d0a  = inputs[i_num].
+00023500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023510: 666f 7220 7072 655f 6964 2069 6e20 7261  for pre_id in ra
+00023520: 6e67 6528 6375 725f 6964 293a 0a20 2020  nge(cur_id):.   
+00023530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023540: 2070 7265 5f6f 7020 3d20 6465 6661 756c   pre_op = defaul
+00023550: 745f 6366 6773 5b70 7265 5f69 645d 5b27  t_cfgs[pre_id]['
+00023560: 6e61 6d65 275d 0a20 2020 2020 2020 2020  name'].         
+00023570: 2020 2020 2020 2020 2020 2070 7265 5f6f             pre_o
+00023580: 7574 203d 2064 6566 6175 6c74 5f63 6667  ut = default_cfg
+00023590: 735b 7072 655f 6964 5d5b 276f 7574 7075  s[pre_id]['outpu
+000235a0: 7473 5f66 6c6f 7727 5d0a 2020 2020 2020  ts_flow'].      
+000235b0: 2020 2020 2020 2020 2020 2020 2020 6e75                nu
+000235c0: 6d5f 6f75 7420 3d20 6c65 6e28 7072 655f  m_out = len(pre_
+000235d0: 6f75 7429 0a20 2020 2020 2020 2020 2020  out).           
+000235e0: 2020 2020 2020 2020 2066 6f72 206f 5f6e           for o_n
+000235f0: 756d 2069 6e20 7261 6e67 6528 6e75 6d5f  um in range(num_
+00023600: 6f75 7429 3a0a 2020 2020 2020 2020 2020  out):.          
+00023610: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00023620: 2070 7265 5f6f 7574 5b6f 5f6e 756d 5d20   pre_out[o_num] 
+00023630: 3d3d 2069 6e70 3a0a 2020 2020 2020 2020  == inp:.        
+00023640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023650: 2020 2020 6966 2063 7572 5f6f 7020 696e      if cur_op in
+00023660: 2069 6e70 6c61 6365 5f6f 7073 2061 6e64   inplace_ops and
+00023670: 2028 7072 655f 6f70 2069 6e20 5b27 636f   (pre_op in ['co
+00023680: 6e76 3264 272c 2027 636f 6e76 3364 272c  nv2d', 'conv3d',
+00023690: 2027 6c69 6e65 6172 270a 2020 2020 2020   'linear'.      
+000236a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000236b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000236c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000236d0: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
+000236e0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+000236f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023700: 2020 206f 705f 7061 7474 6572 6e73 2e61     op_patterns.a
+00023710: 7070 656e 6428 5b28 7072 655f 6964 2c20  ppend([(pre_id, 
+00023720: 7072 655f 6f70 292c 2028 6375 725f 6964  pre_op), (cur_id
+00023730: 2c20 6375 725f 6f70 295d 290a 2020 2020  , cur_op)]).    
+00023740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023750: 2020 2020 2020 2020 6966 2063 7572 5f6f          if cur_o
+00023760: 7020 696e 2065 6c74 5f77 6973 6520 616e  p in elt_wise an
+00023770: 6420 2870 7265 5f6f 700a 2020 2020 2020  d (pre_op.      
+00023780: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00023790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000237a0: 2073 656c 662e 6678 5f6f 705f 6366 6773   self.fx_op_cfgs
-000237b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000237c0: 2020 2020 2020 2020 2020 6578 616d 706c            exampl
-000237d0: 655f 696e 7075 7473 3d73 656c 662e 6578  e_inputs=self.ex
-000237e0: 616d 706c 655f 696e 7075 7473 2c0a 2020  ample_inputs,.  
-000237f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023800: 2020 2020 2020 7072 6570 6172 655f 6375        prepare_cu
-00023810: 7374 6f6d 5f63 6f6e 6669 673d 7365 6c66  stom_config=self
-00023820: 2e70 7265 7061 7265 5f63 7573 746f 6d5f  .prepare_custom_
-00023830: 636f 6e66 6967 5f64 6963 740a 2020 2020  config_dict.    
+000237a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000237b0: 2069 6e20 5b27 636f 6e76 3264 272c 2027   in ['conv2d', '
+000237c0: 636f 6e76 3364 272c 2027 6c69 6e65 6172  conv3d', 'linear
+000237d0: 272c 2027 6164 6427 5d29 3a0a 2020 2020  ', 'add']):.    
+000237e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000237f0: 2020 2020 2020 2020 2020 2020 6f70 5f70              op_p
+00023800: 6174 7465 726e 732e 6170 7065 6e64 285b  atterns.append([
+00023810: 2870 7265 5f69 642c 2070 7265 5f6f 7029  (pre_id, pre_op)
+00023820: 2c20 2863 7572 5f69 642c 2063 7572 5f6f  , (cur_id, cur_o
+00023830: 7029 5d29 0a20 2020 2020 2020 2020 2020  p)]).           
 00023840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023850: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00023860: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00023870: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
-00023880: 6465 6c2e 5f6d 6f64 656c 203d 2070 7265  del._model = pre
-00023890: 7061 7265 5f66 7828 0a20 2020 2020 2020  pare_fx(.       
-000238a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000238b0: 2071 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c   q_model._model,
-000238c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000238d0: 2020 2020 2020 2020 2073 656c 662e 6678           self.fx
-000238e0: 5f6f 705f 6366 6773 2c0a 2020 2020 2020  _op_cfgs,.      
-000238f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023900: 2020 7072 6570 6172 655f 6375 7374 6f6d    prepare_custom
-00023910: 5f63 6f6e 6669 675f 6469 6374 3d73 656c  _config_dict=sel
-00023920: 662e 7072 6570 6172 655f 6375 7374 6f6d  f.prepare_custom
-00023930: 5f63 6f6e 6669 675f 6469 6374 0a20 2020  _config_dict.   
-00023940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023950: 2029 0a20 2020 2020 2020 2020 2020 2065   ).            e
-00023960: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00023970: 2020 2020 206c 6f67 6765 722e 696e 666f       logger.info
-00023980: 2827 4678 2074 7261 6365 206f 6620 7468  ('Fx trace of th
-00023990: 6520 656e 7469 7265 206d 6f64 656c 2066  e entire model f
-000239a0: 6169 6c65 642c 2027 202b 205c 0a20 2020  ailed, ' + \.   
-000239b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000239c0: 2020 2020 2020 2020 2027 5765 2077 696c           'We wil
-000239d0: 6c20 636f 6e64 7563 7420 6175 746f 2071  l conduct auto q
-000239e0: 7561 6e74 697a 6174 696f 6e27 290a 2020  uantization').  
-000239f0: 2020 2020 2020 2020 2020 2020 2020 5079                Py
-00023a00: 546f 7263 685f 4658 4164 6170 746f 722e  Torch_FXAdaptor.
-00023a10: 7072 6570 6172 655f 7375 625f 6772 6170  prepare_sub_grap
-00023a20: 6828 0a20 2020 2020 2020 2020 2020 2020  h(.             
-00023a30: 2020 2020 2020 2073 656c 662e 7375 625f         self.sub_
-00023a40: 6d6f 6475 6c65 5f6c 6973 742c 0a20 2020  module_list,.   
-00023a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023a60: 2073 656c 662e 6678 5f6f 705f 6366 6773   self.fx_op_cfgs
-00023a70: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00023a80: 2020 2020 2020 715f 6d6f 6465 6c2e 5f6d        q_model._m
-00023a90: 6f64 656c 2c0a 2020 2020 2020 2020 2020  odel,.          
-00023aa0: 2020 2020 2020 2020 2020 7072 6566 6978            prefix
-00023ab0: 3d27 272c 0a20 2020 2020 2020 2020 2020  ='',.           
-00023ac0: 2020 2020 2020 2020 2065 7861 6d70 6c65           example
-00023ad0: 5f69 6e70 7574 733d 7365 6c66 2e65 7861  _inputs=self.exa
-00023ae0: 6d70 6c65 5f69 6e70 7574 732c 0a20 2020  mple_inputs,.   
-00023af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023b00: 2063 7573 746f 6d5f 636f 6e66 6967 3d73   custom_config=s
-00023b10: 656c 662e 7072 6570 6172 655f 6375 7374  elf.prepare_cust
-00023b20: 6f6d 5f63 6f6e 6669 675f 6469 6374 0a20  om_config_dict. 
-00023b30: 2020 2020 2020 2020 2020 2020 2020 2029                 )
-00023b40: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00023b50: 7365 6c66 2e61 7070 726f 6163 6820 696e  self.approach in
-00023b60: 205b 2770 6f73 745f 7472 6169 6e69 6e67   ['post_training
-00023b70: 5f73 7461 7469 635f 7175 616e 7427 2c20  _static_quant', 
-00023b80: 2770 6f73 745f 7472 6169 6e69 6e67 5f61  'post_training_a
-00023b90: 7574 6f5f 7175 616e 7427 5d3a 0a20 2020  uto_quant']:.   
-00023ba0: 2020 2020 2020 2020 2020 2020 2023 2046               # F
-00023bb0: 6f72 2065 7870 6f72 7420 4150 490a 2020  or export API.  
-00023bc0: 2020 2020 2020 2020 2020 2020 2020 686f                ho
-00023bd0: 6f6b 5f6c 6973 7420 3d20 746f 7263 685f  ok_list = torch_
-00023be0: 7574 696c 732e 7574 696c 2e5f 7365 745f  utils.util._set_
-00023bf0: 696e 7075 745f 7363 616c 655f 686f 6f6b  input_scale_hook
-00023c00: 2871 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c  (q_model._model,
-00023c10: 206f 705f 6366 6773 290a 2020 2020 2020   op_cfgs).      
-00023c20: 2020 2020 2020 2020 2020 6974 6572 6174            iterat
-00023c30: 696f 6e73 203d 2074 756e 655f 6366 672e  ions = tune_cfg.
-00023c40: 6765 7428 2763 616c 6962 5f69 7465 7261  get('calib_itera
-00023c50: 7469 6f6e 272c 2031 290a 2020 2020 2020  tion', 1).      
-00023c60: 2020 2020 2020 2020 2020 6966 2071 5f66            if q_f
-00023c70: 756e 6320 6973 206e 6f74 204e 6f6e 653a  unc is not None:
-00023c80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00023c90: 2020 2020 2071 5f66 756e 6328 715f 6d6f       q_func(q_mo
-00023ca0: 6465 6c2e 5f6d 6f64 656c 290a 2020 2020  del._model).    
-00023cb0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00023cc0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00023cd0: 2020 2020 2020 7365 6c66 2e6d 6f64 656c        self.model
-00023ce0: 5f63 616c 6962 7261 7469 6f6e 280a 2020  _calibration(.  
-00023cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023d00: 2020 2020 2020 715f 6d6f 6465 6c2e 5f6d        q_model._m
-00023d10: 6f64 656c 2c0a 2020 2020 2020 2020 2020  odel,.          
-00023d20: 2020 2020 2020 2020 2020 2020 2020 6461                da
-00023d30: 7461 6c6f 6164 6572 2c0a 2020 2020 2020  taloader,.      
-00023d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023d50: 2020 6974 6572 6174 696f 6e73 2c0a 2020    iterations,.  
-00023d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023d70: 2020 2020 2020 6361 6c69 625f 7361 6d70        calib_samp
-00023d80: 6c69 6e67 5f73 697a 653d 7475 6e65 5f63  ling_size=tune_c
-00023d90: 6667 2e67 6574 2827 6361 6c69 625f 7361  fg.get('calib_sa
-00023da0: 6d70 6c69 6e67 5f73 697a 6527 2c20 3129  mpling_size', 1)
-00023db0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00023dc0: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
-00023dd0: 6966 2073 656c 662e 6170 7072 6f61 6368  if self.approach
-00023de0: 2021 3d20 2770 6f73 745f 7472 6169 6e69   != 'post_traini
-00023df0: 6e67 5f64 796e 616d 6963 5f71 7561 6e74  ng_dynamic_quant
-00023e00: 273a 0a20 2020 2020 2020 2020 2020 2023  ':.            #
-00023e10: 2046 6f72 2065 7870 6f72 7420 4150 490a   For export API.
-00023e20: 2020 2020 2020 2020 2020 2020 7363 616c              scal
-00023e30: 655f 696e 666f 203d 2074 6f72 6368 5f75  e_info = torch_u
-00023e40: 7469 6c73 2e75 7469 6c2e 5f67 6574 5f69  tils.util._get_i
-00023e50: 6e70 7574 5f73 6361 6c65 2871 5f6d 6f64  nput_scale(q_mod
-00023e60: 656c 2e5f 6d6f 6465 6c2c 2068 6f6f 6b5f  el._model, hook_
-00023e70: 6c69 7374 290a 0a20 2020 2020 2020 2069  list)..        i
-00023e80: 6620 7365 6c66 2e73 7562 5f6d 6f64 756c  f self.sub_modul
-00023e90: 655f 6c69 7374 2069 7320 4e6f 6e65 3a0a  e_list is None:.
-00023ea0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-00023eb0: 656c 662e 7665 7273 696f 6e2e 7265 6c65  elf.version.rele
-00023ec0: 6173 6520 3e3d 2056 6572 7369 6f6e 2822  ase >= Version("
-00023ed0: 312e 3133 2e30 2229 2e72 656c 6561 7365  1.13.0").release
-00023ee0: 3a20 2023 2070 7261 676d 613a 206e 6f20  :  # pragma: no 
-00023ef0: 636f 7665 720a 2020 2020 2020 2020 2020  cover.          
-00023f00: 2020 2020 2020 2320 7079 6c69 6e74 3a20        # pylint: 
-00023f10: 6469 7361 626c 653d 4531 3132 330a 2020  disable=E1123.  
-00023f20: 2020 2020 2020 2020 2020 2020 2020 715f                q_
-00023f30: 6d6f 6465 6c2e 5f6d 6f64 656c 203d 2063  model._model = c
-00023f40: 6f6e 7665 7274 5f66 7828 0a20 2020 2020  onvert_fx(.     
-00023f50: 2020 2020 2020 2020 2020 2020 2020 2071                 q
-00023f60: 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c 0a20  _model._model,. 
-00023f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023f80: 2020 2063 6f6e 7665 7274 5f63 7573 746f     convert_custo
-00023f90: 6d5f 636f 6e66 6967 3d73 656c 662e 636f  m_config=self.co
-00023fa0: 6e76 6572 745f 6375 7374 6f6d 5f63 6f6e  nvert_custom_con
-00023fb0: 6669 675f 6469 6374 0a20 2020 2020 2020  fig_dict.       
-00023fc0: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
-00023fd0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-00023fe0: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
-00023ff0: 6f64 656c 2e5f 6d6f 6465 6c20 3d20 636f  odel._model = co
-00024000: 6e76 6572 745f 6678 280a 2020 2020 2020  nvert_fx(.      
-00024010: 2020 2020 2020 2020 2020 2020 2020 715f                q_
-00024020: 6d6f 6465 6c2e 5f6d 6f64 656c 2c20 0a20  model._model, . 
-00024030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024040: 2020 2063 6f6e 7665 7274 5f63 7573 746f     convert_custo
-00024050: 6d5f 636f 6e66 6967 5f64 6963 743d 7365  m_config_dict=se
-00024060: 6c66 2e63 6f6e 7665 7274 5f63 7573 746f  lf.convert_custo
-00024070: 6d5f 636f 6e66 6967 5f64 6963 740a 2020  m_config_dict.  
-00024080: 2020 2020 2020 2020 2020 2020 2020 290a                ).
-00024090: 2020 2020 2020 2020 2020 2020 746f 7263              torc
-000240a0: 685f 7574 696c 732e 7574 696c 2e61 7070  h_utils.util.app
-000240b0: 656e 645f 6174 7472 2871 5f6d 6f64 656c  end_attr(q_model
-000240c0: 2e5f 6d6f 6465 6c2c 2074 6d70 5f6d 6f64  ._model, tmp_mod
-000240d0: 656c 290a 2020 2020 2020 2020 2020 2020  el).            
-000240e0: 6465 6c20 746d 705f 6d6f 6465 6c0a 2020  del tmp_model.  
-000240f0: 2020 2020 2020 2020 2020 6763 2e63 6f6c            gc.col
-00024100: 6c65 6374 2829 0a20 2020 2020 2020 2065  lect().        e
-00024110: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00024120: 2050 7954 6f72 6368 5f46 5841 6461 7074   PyTorch_FXAdapt
-00024130: 6f72 2e63 6f6e 7665 7274 5f73 7562 5f67  or.convert_sub_g
-00024140: 7261 7068 280a 2020 2020 2020 2020 2020  raph(.          
-00024150: 2020 2020 2020 7365 6c66 2e73 7562 5f6d        self.sub_m
-00024160: 6f64 756c 655f 6c69 7374 2c0a 2020 2020  odule_list,.    
-00024170: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
-00024180: 6465 6c2e 5f6d 6f64 656c 2c0a 2020 2020  del._model,.    
-00024190: 2020 2020 2020 2020 2020 2020 7072 6566              pref
-000241a0: 6978 3d27 272c 0a20 2020 2020 2020 2020  ix='',.         
-000241b0: 2020 2020 2020 2063 7573 746f 6d5f 636f         custom_co
-000241c0: 6e66 6967 3d73 656c 662e 7072 6570 6172  nfig=self.prepar
-000241d0: 655f 6375 7374 6f6d 5f63 6f6e 6669 675f  e_custom_config_
-000241e0: 6469 6374 0a20 2020 2020 2020 2020 2020  dict.           
-000241f0: 2029 0a0a 2020 2020 2020 2020 6966 206c   )..        if l
-00024200: 656e 2873 656c 662e 7475 6e65 5f63 6667  en(self.tune_cfg
-00024210: 5b27 6266 3136 5f6f 7073 5f6c 6973 7427  ['bf16_ops_list'
-00024220: 5d29 203e 2030 2061 6e64 205c 0a20 2020  ]) > 0 and \.   
-00024230: 2020 2020 2020 2020 2073 656c 662e 7665           self.ve
-00024240: 7273 696f 6e2e 7265 6c65 6173 6520 3e3d  rsion.release >=
-00024250: 2056 6572 7369 6f6e 2822 312e 3131 2e30   Version("1.11.0
-00024260: 2229 2e72 656c 6561 7365 2061 6e64 2073  ").release and s
-00024270: 656c 662e 7573 655f 6266 3136 2061 6e64  elf.use_bf16 and
-00024280: 205c 0a20 2020 2020 2020 2020 2020 2028   \.            (
-00024290: 4370 7549 6e66 6f28 292e 6266 3136 206f  CpuInfo().bf16 o
-000242a0: 7220 6f73 2e67 6574 656e 7628 2746 4f52  r os.getenv('FOR
-000242b0: 4345 5f42 4631 3627 2920 3d3d 2027 3127  CE_BF16') == '1'
-000242c0: 293a 2023 2070 7261 676d 613a 206e 6f20  ): # pragma: no 
-000242d0: 636f 7665 720a 2020 2020 2020 2020 2020  cover.          
-000242e0: 2020 715f 6d6f 6465 6c2e 5f6d 6f64 656c    q_model._model
-000242f0: 203d 2074 6f72 6368 5f75 7469 6c73 2e62   = torch_utils.b
-00024300: 6631 365f 636f 6e76 6572 742e 436f 6e76  f16_convert.Conv
-00024310: 6572 7428 715f 6d6f 6465 6c2e 5f6d 6f64  ert(q_model._mod
-00024320: 656c 2c20 7365 6c66 2e74 756e 655f 6366  el, self.tune_cf
-00024330: 6729 0a0a 2020 2020 2020 2020 715f 6d6f  g)..        q_mo
-00024340: 6465 6c2e 715f 636f 6e66 6967 203d 2063  del.q_config = c
-00024350: 6f70 792e 6465 6570 636f 7079 2873 656c  opy.deepcopy(sel
-00024360: 662e 7475 6e65 5f63 6667 290a 2020 2020  f.tune_cfg).    
-00024370: 2020 2020 6966 2073 656c 662e 6170 7072      if self.appr
-00024380: 6f61 6368 2021 3d20 2770 6f73 745f 7472  oach != 'post_tr
-00024390: 6169 6e69 6e67 5f64 796e 616d 6963 5f71  aining_dynamic_q
-000243a0: 7561 6e74 273a 0a20 2020 2020 2020 2020  uant':.         
-000243b0: 2020 2073 656c 662e 5f67 6574 5f73 6361     self._get_sca
-000243c0: 6c65 5f7a 6572 6f70 6f69 6e74 2871 5f6d  le_zeropoint(q_m
-000243d0: 6f64 656c 2e5f 6d6f 6465 6c2c 2071 5f6d  odel._model, q_m
-000243e0: 6f64 656c 2e71 5f63 6f6e 6669 6729 0a20  odel.q_config). 
-000243f0: 2020 2020 2020 2020 2020 2071 5f6d 6f64             q_mod
-00024400: 656c 2e71 5f63 6f6e 6669 675b 2773 6361  el.q_config['sca
-00024410: 6c65 5f69 6e66 6f27 5d20 3d20 7363 616c  le_info'] = scal
-00024420: 655f 696e 666f 0a0a 2020 2020 2020 2020  e_info..        
-00024430: 7365 6c66 2e5f 6475 6d70 5f6d 6f64 656c  self._dump_model
-00024440: 5f6f 705f 7374 6174 7328 715f 6d6f 6465  _op_stats(q_mode
-00024450: 6c2e 5f6d 6f64 656c 2c20 715f 6d6f 6465  l._model, q_mode
-00024460: 6c2e 715f 636f 6e66 6967 2c20 7365 6c66  l.q_config, self
-00024470: 2e61 7070 726f 6163 6829 0a20 2020 2020  .approach).     
-00024480: 2020 2074 6f72 6368 5f75 7469 6c73 2e75     torch_utils.u
-00024490: 7469 6c2e 6765 745f 656d 6265 6464 696e  til.get_embeddin
-000244a0: 675f 636f 6e74 6967 756f 7573 2871 5f6d  g_contiguous(q_m
-000244b0: 6f64 656c 2e5f 6d6f 6465 6c29 0a20 2020  odel._model).   
-000244c0: 2020 2020 2072 6574 7572 6e20 715f 6d6f       return q_mo
-000244d0: 6465 6c0a 0a20 2020 2064 6566 2065 7661  del..    def eva
-000244e0: 6c75 6174 6528 7365 6c66 2c0a 2020 2020  luate(self,.    
-000244f0: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
-00024500: 656c 2c0a 2020 2020 2020 2020 2020 2020  el,.            
-00024510: 2020 2020 2064 6174 616c 6f61 6465 722c       dataloader,
-00024520: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00024530: 2020 706f 7374 7072 6f63 6573 733d 4e6f    postprocess=No
-00024540: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
-00024550: 2020 2020 206d 6574 7269 6373 3d4e 6f6e       metrics=Non
-00024560: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-00024570: 2020 2020 6d65 6173 7572 6572 3d4e 6f6e      measurer=Non
-00024580: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-00024590: 2020 2020 6974 6572 6174 696f 6e3d 2d31      iteration=-1
-000245a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000245b0: 2020 2074 656e 736f 7262 6f61 7264 3d46     tensorboard=F
-000245c0: 616c 7365 2c0a 2020 2020 2020 2020 2020  alse,.          
-000245d0: 2020 2020 2020 2066 7033 325f 6261 7365         fp32_base
-000245e0: 6c69 6e65 3d46 616c 7365 293a 0a20 2020  line=False):.   
-000245f0: 2020 2020 2022 2222 4578 6563 7574 6520       """Execute 
-00024600: 7468 6520 6576 616c 7561 7465 2070 726f  the evaluate pro
-00024610: 6365 7373 206f 6e20 7468 6520 7370 6563  cess on the spec
-00024620: 6966 6965 6420 6d6f 6465 6c2e 0a0a 2020  ified model...  
-00024630: 2020 2020 2020 4172 6773 3a0a 2020 2020        Args:.    
-00024640: 2020 2020 2020 2020 6d6f 6465 6c20 286f          model (o
-00024650: 626a 6563 7429 3a20 6d6f 6465 6c20 746f  bject): model to
-00024660: 2072 756e 2065 7661 6c75 6174 696f 6e2e   run evaluation.
-00024670: 0a20 2020 2020 2020 2020 2020 2064 6174  .            dat
-00024680: 616c 6f61 6465 7220 286f 626a 6563 7429  aloader (object)
-00024690: 3a20 6576 616c 7561 7469 6f6e 2064 6174  : evaluation dat
-000246a0: 6173 6574 2e0a 2020 2020 2020 2020 2020  aset..          
-000246b0: 2020 706f 7374 7072 6f63 6573 7320 286f    postprocess (o
-000246c0: 626a 6563 742c 206f 7074 696f 6e61 6c29  bject, optional)
-000246d0: 3a20 7072 6f63 6573 7320 6675 6e63 7469  : process functi
-000246e0: 6f6e 2061 6674 6572 2065 7661 6c75 6174  on after evaluat
-000246f0: 696f 6e2e 0a20 2020 2020 2020 2020 2020  ion..           
-00024700: 206d 6574 7269 6320 286f 626a 6563 742c   metric (object,
-00024710: 206f 7074 696f 6e61 6c29 3a20 6d65 7472   optional): metr
-00024720: 6963 2066 756e 6374 696f 6e2e 0a20 2020  ic function..   
-00024730: 2020 2020 2020 2020 206d 6561 7375 7265           measure
-00024740: 7220 286f 626a 6563 742c 206f 7074 696f  r (object, optio
-00024750: 6e61 6c29 3a20 6d65 6173 7572 6572 2066  nal): measurer f
-00024760: 756e 6374 696f 6e2e 0a20 2020 2020 2020  unction..       
-00024770: 2020 2020 2069 7465 7261 7469 6f6e 2028       iteration (
-00024780: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
-00024790: 6e75 6d62 6572 206f 6620 6974 6572 6174  number of iterat
-000247a0: 696f 6e73 2074 6f20 6576 616c 7561 7465  ions to evaluate
-000247b0: 2e0a 2020 2020 2020 2020 2020 2020 7465  ..            te
-000247c0: 6e73 6f72 626f 6172 6420 2862 6f6f 6c2c  nsorboard (bool,
-000247d0: 206f 7074 696f 6e61 6c29 3a20 6475 6d70   optional): dump
-000247e0: 206f 7574 7075 7420 7465 6e73 6f72 2074   output tensor t
-000247f0: 6f20 7465 6e73 6f72 626f 6172 6420 7375  o tensorboard su
-00024800: 6d6d 6172 7920 6669 6c65 732e 0a20 2020  mmary files..   
-00024810: 2020 2020 2020 2020 2066 7033 325f 6261           fp32_ba
-00024820: 7365 6c69 6e65 2028 626f 6f6c 656e 2c20  seline (boolen, 
-00024830: 6f70 7469 6f6e 616c 293a 206f 6e6c 7920  optional): only 
-00024840: 666f 7220 636f 6d70 6172 655f 6c61 6265  for compare_labe
-00024850: 6c3d 4661 6c73 6520 7069 7065 6c69 6e65  l=False pipeline
-00024860: 0a0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
-00024870: 733a 0a20 2020 2020 2020 2020 2020 2028  s:.            (
-00024880: 6f62 6a65 6374 293a 2061 6363 7572 6163  object): accurac
-00024890: 790a 2020 2020 2020 2020 2222 220a 2020  y.        """.  
-000248a0: 2020 2020 2020 6966 2074 656e 736f 7262        if tensorb
-000248b0: 6f61 7264 3a20 2023 2070 7261 676d 613a  oard:  # pragma:
-000248c0: 206e 6f20 636f 7665 720a 2020 2020 2020   no cover.      
-000248d0: 2020 2020 2020 6173 7365 7274 2046 616c        assert Fal
-000248e0: 7365 2c20 2250 7954 6f72 6368 2046 5820  se, "PyTorch FX 
-000248f0: 6d6f 6465 2064 6964 6e27 7420 7375 7070  mode didn't supp
-00024900: 6f72 7420 7465 6e73 6f72 626f 6172 6420  ort tensorboard 
-00024910: 666c 6167 206e 6f77 2122 0a20 2020 2020  flag now!".     
-00024920: 2020 2073 656c 662e 6973 5f62 6173 656c     self.is_basel
-00024930: 696e 6520 3d20 6670 3332 5f62 6173 656c  ine = fp32_basel
-00024940: 696e 650a 0a20 2020 2020 2020 206d 6f64  ine..        mod
-00024950: 656c 5f20 3d20 6d6f 6465 6c2e 5f6d 6f64  el_ = model._mod
-00024960: 656c 0a20 2020 2020 2020 2061 7373 6572  el.        asser
-00024970: 7420 6973 696e 7374 616e 6365 280a 2020  t isinstance(.  
-00024980: 2020 2020 2020 2020 2020 6d6f 6465 6c5f            model_
-00024990: 2c20 746f 7263 682e 6e6e 2e4d 6f64 756c  , torch.nn.Modul
-000249a0: 6529 2c20 2254 6865 206d 6f64 656c 2070  e), "The model p
-000249b0: 6173 7365 6420 696e 2069 7320 6e6f 7420  assed in is not 
-000249c0: 7468 6520 696e 7374 616e 6365 206f 6620  the instance of 
-000249d0: 746f 7263 682e 6e6e 2e4d 6f64 756c 6522  torch.nn.Module"
-000249e0: 0a20 2020 2020 2020 206d 6f64 656c 5f2e  .        model_.
-000249f0: 6576 616c 2829 0a20 2020 2020 2020 206d  eval().        m
-00024a00: 6f64 656c 5f2e 746f 2873 656c 662e 6465  odel_.to(self.de
-00024a10: 7669 6365 290a 0a20 2020 2020 2020 2069  vice)..        i
-00024a20: 6620 6d65 7472 6963 733a 0a20 2020 2020  f metrics:.     
-00024a30: 2020 2020 2020 2073 656c 662e 6670 3332         self.fp32
-00024a40: 5f70 7265 6473 5f61 735f 6c61 6265 6c20  _preds_as_label 
-00024a50: 3d20 616e 7928 5b68 6173 6174 7472 286d  = any([hasattr(m
-00024a60: 6574 7269 632c 2022 636f 6d70 6172 655f  etric, "compare_
-00024a70: 6c61 6265 6c22 2920 616e 6420 5c0a 2020  label") and \.  
-00024a80: 2020 2020 2020 2020 2020 2020 2020 6e6f                no
-00024a90: 7420 6d65 7472 6963 2e63 6f6d 7061 7265  t metric.compare
-00024aa0: 5f6c 6162 656c 2066 6f72 206d 6574 7269  _label for metri
-00024ab0: 6320 696e 206d 6574 7269 6373 5d29 0a0a  c in metrics])..
-00024ac0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00024ad0: 656c 662e 6d6f 6465 6c5f 6576 616c 286d  elf.model_eval(m
-00024ae0: 6f64 656c 5f2c 2064 6174 616c 6f61 6465  odel_, dataloade
-00024af0: 722c 2070 6f73 7470 726f 6365 7373 2c20  r, postprocess, 
-00024b00: 6d65 7472 6963 732c 206d 6561 7375 7265  metrics, measure
-00024b10: 722c 2069 7465 7261 7469 6f6e 290a 0a20  r, iteration).. 
-00024b20: 2020 2064 6566 205f 7072 655f 686f 6f6b     def _pre_hook
-00024b30: 5f66 6f72 5f71 6174 2873 656c 662c 2064  _for_qat(self, d
-00024b40: 6174 616c 6f61 6465 723d 4e6f 6e65 293a  ataloader=None):
-00024b50: 0a20 2020 2020 2020 2071 5f63 6667 7320  .        q_cfgs 
-00024b60: 3d20 746f 7263 682e 7175 616e 7469 7a61  = torch.quantiza
-00024b70: 7469 6f6e 2e51 436f 6e66 6967 280a 2020  tion.QConfig(.  
-00024b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024b90: 2020 2020 2020 2020 2020 6163 7469 7661            activa
-00024ba0: 7469 6f6e 3d74 6f72 6368 2e71 7561 6e74  tion=torch.quant
-00024bb0: 697a 6174 696f 6e2e 4661 6b65 5175 616e  ization.FakeQuan
-00024bc0: 7469 7a65 2e77 6974 685f 6172 6773 280a  tize.with_args(.
-00024bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024bf0: 2020 2020 6474 7970 653d 746f 7263 682e      dtype=torch.
-00024c00: 7175 696e 7438 2c0a 2020 2020 2020 2020  quint8,.        
-00024c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024c20: 2020 2020 2020 2020 2020 2020 7173 6368              qsch
-00024c30: 656d 653d 746f 7263 682e 7065 725f 7465  eme=torch.per_te
-00024c40: 6e73 6f72 5f61 6666 696e 652c 0a20 2020  nsor_affine,.   
-00024c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023850: 2069 6620 6375 725f 6f70 203d 3d20 2761   if cur_op == 'a
+00023860: 6464 273a 0a20 2020 2020 2020 2020 2020  dd':.           
+00023870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023880: 2020 2020 2070 7265 5f6f 7073 5b69 5f6e       pre_ops[i_n
+00023890: 756d 5d20 3d20 5b70 7265 5f69 642c 2070  um] = [pre_id, p
+000238a0: 7265 5f6f 705d 0a20 2020 2020 2020 2020  re_op].         
+000238b0: 2020 2069 6620 6c65 6e28 7072 655f 6f70     if len(pre_op
+000238c0: 7329 203e 2030 3a0a 2020 2020 2020 2020  s) > 0:.        
+000238d0: 2020 2020 2020 2020 666f 7220 6b65 792c          for key,
+000238e0: 2076 616c 7565 2069 6e20 7072 655f 6f70   value in pre_op
+000238f0: 732e 6974 656d 7328 293a 0a20 2020 2020  s.items():.     
+00023900: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00023910: 6620 7661 6c75 655b 315d 2069 6e20 5b27  f value[1] in ['
+00023920: 636f 6e76 3264 272c 2027 636f 6e76 3364  conv2d', 'conv3d
+00023930: 272c 2027 6c69 6e65 6172 275d 2061 6e64  ', 'linear'] and
+00023940: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+00023950: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00023960: 6566 6175 6c74 5f63 6667 735b 6375 725f  efault_cfgs[cur_
+00023970: 6964 5d5b 2769 6e70 7574 735f 7175 616e  id]['inputs_quan
+00023980: 7469 7a65 6427 5d5b 6b65 795d 203d 3d20  tized'][key] == 
+00023990: 4661 6c73 653a 0a20 2020 2020 2020 2020  False:.         
+000239a0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+000239b0: 705f 7061 7474 6572 6e73 2e61 7070 656e  p_patterns.appen
+000239c0: 6428 5b28 7661 6c75 655b 305d 2c20 7661  d([(value[0], va
+000239d0: 6c75 655b 315d 292c 2028 6375 725f 6964  lue[1]), (cur_id
+000239e0: 2c20 6375 725f 6f70 295d 290a 2020 2020  , cur_op)]).    
+000239f0: 2020 2020 7265 7475 726e 206f 705f 7061      return op_pa
+00023a00: 7474 6572 6e73 0a0a 2020 2020 6465 6620  tterns..    def 
+00023a10: 7164 715f 7175 616e 7469 7a65 2873 656c  qdq_quantize(sel
+00023a20: 662c 206d 6f64 656c 2c20 7475 6e65 5f63  f, model, tune_c
+00023a30: 6667 2c20 6461 7461 6c6f 6164 6572 293a  fg, dataloader):
+00023a40: 0a20 2020 2020 2020 2061 7373 6572 7420  .        assert 
+00023a50: 6e6f 7420 7365 6c66 2e76 6572 7369 6f6e  not self.version
+00023a60: 2e72 656c 6561 7365 203c 2056 6572 7369  .release < Versi
+00023a70: 6f6e 2822 322e 3122 292e 7265 6c65 6173  on("2.1").releas
+00023a80: 652c 205c 0a20 2020 2020 2020 2020 2020  e, \.           
+00023a90: 2022 4950 4558 2076 6572 7369 6f6e 203e   "IPEX version >
+00023aa0: 3d20 322e 3120 6973 2072 6571 7569 7265  = 2.1 is require
+00023ab0: 6420 666f 7220 536d 6f6f 7468 5175 616e  d for SmoothQuan
+00023ac0: 742e 220a 0a20 2020 2020 2020 2069 6620  t."..        if 
+00023ad0: 6e6f 7420 7365 6c66 2e70 6572 666f 726d  not self.perform
+00023ae0: 616e 6365 5f6f 6e6c 793a 0a20 2020 2020  ance_only:.     
+00023af0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
+00023b00: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00023b10: 2e74 6d70 5f6d 6f64 656c 203d 2063 6f70  .tmp_model = cop
+00023b20: 792e 6465 6570 636f 7079 286d 6f64 656c  y.deepcopy(model
+00023b30: 290a 2020 2020 2020 2020 2020 2020 6578  ).            ex
+00023b40: 6365 7074 2045 7863 6570 7469 6f6e 2061  cept Exception a
+00023b50: 7320 653a 2020 2320 7072 6167 6d61 3a20  s e:  # pragma: 
+00023b60: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
+00023b70: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+00023b80: 7761 726e 696e 6728 2246 6169 6c20 746f  warning("Fail to
+00023b90: 2064 6565 7020 636f 7079 2074 6865 206d   deep copy the m
+00023ba0: 6f64 656c 2064 7565 2074 6f20 7b7d 2c20  odel due to {}, 
+00023bb0: 696e 706c 6163 6520 6973 2075 7365 6420  inplace is used 
+00023bc0: 6e6f 772e 222e 666f 726d 6174 280a 2020  now.".format(.  
+00023bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023be0: 2020 7265 7072 2865 2929 290a 2020 2020    repr(e))).    
+00023bf0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00023c00: 2e74 6d70 5f6d 6f64 656c 203d 206d 6f64  .tmp_model = mod
+00023c10: 656c 0a20 2020 2020 2020 2065 6c73 653a  el.        else:
+00023c20: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00023c30: 662e 746d 705f 6d6f 6465 6c20 3d20 6d6f  f.tmp_model = mo
+00023c40: 6465 6c0a 2020 2020 2020 2020 715f 6d6f  del.        q_mo
+00023c50: 6465 6c20 3d20 7365 6c66 2e74 6d70 5f6d  del = self.tmp_m
+00023c60: 6f64 656c 2e5f 6d6f 6465 6c0a 0a20 2020  odel._model..   
+00023c70: 2020 2020 2023 2066 6574 6368 2053 6d6f       # fetch Smo
+00023c80: 6f74 6851 7561 6e74 2073 6361 6c65 2069  othQuant scale i
+00023c90: 6e66 6f20 6672 6f6d 2070 7265 2d6f 7074  nfo from pre-opt
+00023ca0: 696d 697a 6564 206d 6f64 656c 0a20 2020  imized model.   
+00023cb0: 2020 2020 2066 726f 6d20 2e74 6f72 6368       from .torch
+00023cc0: 5f75 7469 6c73 2e6d 6f64 656c 5f77 7261  _utils.model_wra
+00023cd0: 7070 6572 2069 6d70 6f72 7420 5351 4c69  pper import SQLi
+00023ce0: 6e65 6172 5772 6170 7065 720a 2020 2020  nearWrapper.    
+00023cf0: 2020 2020 6672 6f6d 202e 746f 7263 685f      from .torch_
+00023d00: 7574 696c 732e 736d 6f6f 7468 5f71 7561  utils.smooth_qua
+00023d10: 6e74 2069 6d70 6f72 7420 7570 6461 7465  nt import update
+00023d20: 5f73 715f 7363 616c 650a 2020 2020 2020  _sq_scale.      
+00023d30: 2020 736d 6f6f 7468 7175 616e 745f 7363    smoothquant_sc
+00023d40: 616c 655f 696e 666f 203d 207b 7d0a 2020  ale_info = {}.  
+00023d50: 2020 2020 2020 666f 7220 6e61 6d65 2c20        for name, 
+00023d60: 6d6f 6475 6c65 2069 6e20 715f 6d6f 6465  module in q_mode
+00023d70: 6c2e 6e61 6d65 645f 6d6f 6475 6c65 7328  l.named_modules(
+00023d80: 293a 0a20 2020 2020 2020 2020 2020 2069  ):.            i
+00023d90: 6620 6973 696e 7374 616e 6365 286d 6f64  f isinstance(mod
+00023da0: 756c 652c 2053 514c 696e 6561 7257 7261  ule, SQLinearWra
+00023db0: 7070 6572 293a 0a20 2020 2020 2020 2020  pper):.         
+00023dc0: 2020 2020 2020 2077 6569 6768 745f 7363         weight_sc
+00023dd0: 616c 6520 3d20 6d6f 6475 6c65 2e5f 6765  ale = module._ge
+00023de0: 745f 7765 6967 6874 5f73 6361 6c65 2829  t_weight_scale()
+00023df0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00023e00: 2073 6d6f 6f74 6871 7561 6e74 5f73 6361   smoothquant_sca
+00023e10: 6c65 5f69 6e66 6f5b 6e61 6d65 202b 2027  le_info[name + '
+00023e20: 2e73 715f 6c69 6e65 6172 275d 203d 207b  .sq_linear'] = {
+00023e30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00023e40: 2020 2020 2027 696e 7075 745f 7363 616c       'input_scal
+00023e50: 655f 666f 725f 6d75 6c27 3a20 6d6f 6475  e_for_mul': modu
+00023e60: 6c65 2e69 6e70 7574 5f73 6361 6c65 2c0a  le.input_scale,.
+00023e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023e80: 2020 2020 2769 6e70 7574 5f73 6361 6c65      'input_scale
+00023e90: 5f61 6674 6572 5f6d 756c 273a 206d 6f64  _after_mul': mod
+00023ea0: 756c 652e 7363 616c 652c 0a20 2020 2020  ule.scale,.     
+00023eb0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
+00023ec0: 696e 7075 745f 7a65 726f 5f70 6f69 6e74  input_zero_point
+00023ed0: 5f61 6674 6572 5f6d 756c 273a 206d 6f64  _after_mul': mod
+00023ee0: 756c 652e 7a65 726f 5f70 6f69 6e74 2c0a  ule.zero_point,.
+00023ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023f00: 2020 2020 2769 6e70 7574 5f64 7479 7065      'input_dtype
+00023f10: 273a 206d 6f64 756c 652e 6474 7970 652c  ': module.dtype,
+00023f20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00023f30: 2020 2020 2027 7765 6967 6874 5f73 6361       'weight_sca
+00023f40: 6c65 5f61 6674 6572 5f6d 756c 273a 2077  le_after_mul': w
+00023f50: 6569 6768 745f 7363 616c 652c 0a20 2020  eight_scale,.   
+00023f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023f70: 207d 0a20 2020 2020 2020 2020 2020 2020   }.             
+00023f80: 2020 206d 6f64 756c 652e 6970 6578 203d     module.ipex =
+00023f90: 2054 7275 650a 2020 2020 2020 2020 2020   True.          
+00023fa0: 2020 2020 2020 2320 4e6f 7465 3a20 7361        # Note: sa
+00023fb0: 7665 2077 6569 6768 7420 7363 616c 6520  ve weight scale 
+00023fc0: 6265 666f 7265 2072 6563 6f76 6572 0a20  before recover. 
+00023fd0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
+00023fe0: 6f64 756c 652e 5f72 6563 6f76 6572 5f73  odule._recover_s
+00023ff0: 715f 6c69 6e65 6172 2829 0a0a 2020 2020  q_linear()..    
+00024000: 2020 2020 2320 5265 6275 696c 6420 7468      # Rebuild th
+00024010: 6520 636f 6e66 6967 206a 736f 6e20 6166  e config json af
+00024020: 7465 7220 7072 652d 6f70 7469 6d69 7a65  ter pre-optimize
+00024030: 2061 6c67 6f20 2853 6d6f 6f74 6851 7561   algo (SmoothQua
+00024040: 6e74 292c 206d 6f64 656c 2069 7320 6368  nt), model is ch
+00024050: 616e 6765 642e 0a20 2020 2020 2020 2073  anged..        s
+00024060: 7461 7469 635f 7163 6f6e 6669 6720 3d20  tatic_qconfig = 
+00024070: 6970 6578 2e71 7561 6e74 697a 6174 696f  ipex.quantizatio
+00024080: 6e2e 6765 745f 736d 6f6f 7468 5f71 7561  n.get_smooth_qua
+00024090: 6e74 5f71 636f 6e66 6967 5f6d 6170 7069  nt_qconfig_mappi
+000240a0: 6e67 2861 6c70 6861 3d30 2e35 290a 2020  ng(alpha=0.5).  
+000240b0: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
+000240c0: 6970 6578 2e71 7561 6e74 697a 6174 696f  ipex.quantizatio
+000240d0: 6e2e 7072 6570 6172 6528 715f 6d6f 6465  n.prepare(q_mode
+000240e0: 6c2c 2073 7461 7469 635f 7163 6f6e 6669  l, static_qconfi
+000240f0: 672c 205c 0a20 2020 2020 2020 2020 2020  g, \.           
+00024100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00024110: 2020 2020 2065 7861 6d70 6c65 5f69 6e70       example_inp
+00024120: 7574 733d 7365 6c66 2e65 7861 6d70 6c65  uts=self.example
+00024130: 5f69 6e70 7574 732c 2069 6e70 6c61 6365  _inputs, inplace
+00024140: 3d54 7275 6529 0a20 2020 2020 2020 2073  =True).        s
+00024150: 656c 662e 6361 6c69 625f 6675 6e63 2871  elf.calib_func(q
+00024160: 5f6d 6f64 656c 2c20 6461 7461 6c6f 6164  _model, dataload
+00024170: 6572 2c20 746d 705f 6974 6572 6174 696f  er, tmp_iteratio
+00024180: 6e73 3d31 2920 2320 6661 6b65 2063 616c  ns=1) # fake cal
+00024190: 6962 7261 7469 6f6e 0a20 2020 2020 2020  ibration.       
+000241a0: 2071 5f6d 6f64 656c 2e73 6176 655f 7163   q_model.save_qc
+000241b0: 6f6e 665f 7375 6d6d 6172 7928 7163 6f6e  onf_summary(qcon
+000241c0: 665f 7375 6d6d 6172 793d 7365 6c66 2e69  f_summary=self.i
+000241d0: 7065 785f 636f 6e66 6967 5f70 6174 6829  pex_config_path)
+000241e0: 0a0a 2020 2020 2020 2020 2320 7570 6461  ..        # upda
+000241f0: 7465 2069 7065 785f 636f 6e66 6967 2e6a  te ipex_config.j
+00024200: 736f 6e20 7769 7468 2073 6d6f 6f74 6871  son with smoothq
+00024210: 7561 6e74 5f73 6361 6c65 5f69 6e66 6f0a  uant_scale_info.
+00024220: 2020 2020 2020 2020 7570 6461 7465 5f73          update_s
+00024230: 715f 7363 616c 6528 7365 6c66 2e69 7065  q_scale(self.ipe
+00024240: 785f 636f 6e66 6967 5f70 6174 682c 2073  x_config_path, s
+00024250: 6d6f 6f74 6871 7561 6e74 5f73 6361 6c65  moothquant_scale
+00024260: 5f69 6e66 6f29 0a20 2020 2020 2020 2023  _info).        #
+00024270: 2065 6e61 626c 6520 6661 6c6c 6261 636b   enable fallback
+00024280: 0a20 2020 2020 2020 2073 656c 662e 5f63  .        self._c
+00024290: 6667 5f74 6f5f 7163 6f6e 6669 6728 7475  fg_to_qconfig(tu
+000242a0: 6e65 5f63 6667 290a 2020 2020 2020 2020  ne_cfg).        
+000242b0: 715f 6d6f 6465 6c2e 6c6f 6164 5f71 636f  q_model.load_qco
+000242c0: 6e66 5f73 756d 6d61 7279 2871 636f 6e66  nf_summary(qconf
+000242d0: 5f73 756d 6d61 7279 3d73 656c 662e 6970  _summary=self.ip
+000242e0: 6578 5f63 6f6e 6669 675f 7061 7468 290a  ex_config_path).
+000242f0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00024300: 2e75 7365 5f62 6631 3620 616e 6420 2843  .use_bf16 and (C
+00024310: 7075 496e 666f 2829 2e62 6631 3620 6f72  puInfo().bf16 or
+00024320: 206f 732e 6765 7465 6e76 2827 464f 5243   os.getenv('FORC
+00024330: 455f 4246 3136 2729 203d 3d20 2731 2729  E_BF16') == '1')
+00024340: 2061 6e64 205c 0a20 2020 2020 2020 2020   and \.         
+00024350: 2020 2028 7365 6c66 2e76 6572 7369 6f6e     (self.version
+00024360: 2e72 656c 6561 7365 203e 3d20 5665 7273  .release >= Vers
+00024370: 696f 6e28 2231 2e31 312e 3022 292e 7265  ion("1.11.0").re
+00024380: 6c65 6173 6529 3a0a 2020 2020 2020 2020  lease):.        
+00024390: 2020 2020 7769 7468 2074 6f72 6368 2e6e      with torch.n
+000243a0: 6f5f 6772 6164 2829 3a0a 2020 2020 2020  o_grad():.      
+000243b0: 2020 2020 2020 2020 2020 7769 7468 2074            with t
+000243c0: 6f72 6368 2e63 7075 2e61 6d70 2e61 7574  orch.cpu.amp.aut
+000243d0: 6f63 6173 7428 293a 0a20 2020 2020 2020  ocast():.       
+000243e0: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+000243f0: 6f64 656c 203d 2069 7065 782e 7175 616e  odel = ipex.quan
+00024400: 7469 7a61 7469 6f6e 2e63 6f6e 7665 7274  tization.convert
+00024410: 2871 5f6d 6f64 656c 2c20 696e 706c 6163  (q_model, inplac
+00024420: 653d 5472 7565 290a 2020 2020 2020 2020  e=True).        
+00024430: 2020 2020 2020 2020 2020 2020 2320 696e              # in
+00024440: 6665 7265 6e63 6520 6f6e 6365 2061 6674  ference once aft
+00024450: 6572 2063 6f6e 7665 7274 2066 6f72 2053  er convert for S
+00024460: 6d6f 6f74 6851 7561 6e74 0a20 2020 2020  moothQuant.     
+00024470: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00024480: 656c 662e 6361 6c69 625f 6675 6e63 2871  elf.calib_func(q
+00024490: 5f6d 6f64 656c 2c20 6461 7461 6c6f 6164  _model, dataload
+000244a0: 6572 2c20 746d 705f 6974 6572 6174 696f  er, tmp_iteratio
+000244b0: 6e73 3d31 290a 2020 2020 2020 2020 2020  ns=1).          
+000244c0: 2020 2020 2020 2020 2020 7472 793a 0a20            try:. 
+000244d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000244e0: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
+000244f0: 2074 6f72 6368 2e6a 6974 2e74 7261 6365   torch.jit.trace
+00024500: 2871 5f6d 6f64 656c 2c20 7365 6c66 2e65  (q_model, self.e
+00024510: 7861 6d70 6c65 5f69 6e70 7574 7329 0a20  xample_inputs). 
+00024520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00024530: 2020 2020 2020 2071 5f6d 6f64 656c 203d         q_model =
+00024540: 2074 6f72 6368 2e6a 6974 2e66 7265 657a   torch.jit.freez
+00024550: 6528 715f 6d6f 6465 6c2e 6576 616c 2829  e(q_model.eval()
+00024560: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00024570: 2020 2020 2020 6578 6365 7074 3a0a 2020        except:.  
+00024580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00024590: 2020 2020 2020 715f 6d6f 6465 6c20 3d20        q_model = 
+000245a0: 746f 7263 682e 6a69 742e 7472 6163 6528  torch.jit.trace(
+000245b0: 715f 6d6f 6465 6c2c 2073 656c 662e 6578  q_model, self.ex
+000245c0: 616d 706c 655f 696e 7075 7473 2c20 7374  ample_inputs, st
+000245d0: 7269 6374 3d46 616c 7365 290a 2020 2020  rict=False).    
+000245e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000245f0: 2020 2020 715f 6d6f 6465 6c20 3d20 746f      q_model = to
+00024600: 7263 682e 6a69 742e 6672 6565 7a65 2871  rch.jit.freeze(q
+00024610: 5f6d 6f64 656c 2e65 7661 6c28 2929 0a20  _model.eval()). 
+00024620: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00024630: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
+00024640: 203d 2069 7065 782e 7175 616e 7469 7a61   = ipex.quantiza
+00024650: 7469 6f6e 2e63 6f6e 7665 7274 2871 5f6d  tion.convert(q_m
+00024660: 6f64 656c 2c20 696e 706c 6163 653d 5472  odel, inplace=Tr
+00024670: 7565 290a 2020 2020 2020 2020 2020 2020  ue).            
+00024680: 2320 696e 6665 7265 6e63 6520 6f6e 6365  # inference once
+00024690: 2061 6674 6572 2063 6f6e 7665 7274 2066   after convert f
+000246a0: 6f72 2053 6d6f 6f74 6851 7561 6e74 0a20  or SmoothQuant. 
+000246b0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000246c0: 6361 6c69 625f 6675 6e63 2871 5f6d 6f64  calib_func(q_mod
+000246d0: 656c 2c20 6461 7461 6c6f 6164 6572 2c20  el, dataloader, 
+000246e0: 746d 705f 6974 6572 6174 696f 6e73 3d31  tmp_iterations=1
+000246f0: 290a 2020 2020 2020 2020 2020 2020 7769  ).            wi
+00024700: 7468 2074 6f72 6368 2e6e 6f5f 6772 6164  th torch.no_grad
+00024710: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+00024720: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
+00024730: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+00024740: 6f64 656c 203d 2074 6f72 6368 2e6a 6974  odel = torch.jit
+00024750: 2e74 7261 6365 2871 5f6d 6f64 656c 2c20  .trace(q_model, 
+00024760: 7365 6c66 2e65 7861 6d70 6c65 5f69 6e70  self.example_inp
+00024770: 7574 7329 0a20 2020 2020 2020 2020 2020  uts).           
+00024780: 2020 2020 2020 2020 2071 5f6d 6f64 656c           q_model
+00024790: 203d 2074 6f72 6368 2e6a 6974 2e66 7265   = torch.jit.fre
+000247a0: 657a 6528 715f 6d6f 6465 6c2e 6576 616c  eze(q_model.eval
+000247b0: 2829 290a 2020 2020 2020 2020 2020 2020  ()).            
+000247c0: 2020 2020 6578 6365 7074 3a0a 2020 2020      except:.    
+000247d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000247e0: 715f 6d6f 6465 6c20 3d20 746f 7263 682e  q_model = torch.
+000247f0: 6a69 742e 7472 6163 6528 715f 6d6f 6465  jit.trace(q_mode
+00024800: 6c2c 2073 656c 662e 6578 616d 706c 655f  l, self.example_
+00024810: 696e 7075 7473 2c20 7374 7269 6374 3d46  inputs, strict=F
+00024820: 616c 7365 290a 2020 2020 2020 2020 2020  alse).          
+00024830: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
+00024840: 6c20 3d20 746f 7263 682e 6a69 742e 6672  l = torch.jit.fr
+00024850: 6565 7a65 2871 5f6d 6f64 656c 2e65 7661  eeze(q_model.eva
+00024860: 6c28 2929 0a20 2020 2020 2020 2023 2041  l()).        # A
+00024870: 6674 6572 2066 7265 657a 696e 672c 2072  fter freezing, r
+00024880: 756e 2031 2074 696d 6520 746f 2077 6172  un 1 time to war
+00024890: 6d20 7570 2074 6865 2070 726f 6669 6c69  m up the profili
+000248a0: 6e67 2067 7261 7068 2065 7865 6375 746f  ng graph executo
+000248b0: 7220 746f 2069 6e73 6572 7420 7072 696d  r to insert prim
+000248c0: 3a3a 7072 6f66 696c 650a 2020 2020 2020  ::profile.      
+000248d0: 2020 2320 4174 2074 6865 2032 6e64 2072    # At the 2nd r
+000248e0: 756e 2c20 7468 6520 6c6c 6761 2070 6173  un, the llga pas
+000248f0: 7320 7769 6c6c 2062 6520 7472 6967 6765  s will be trigge
+00024900: 7265 6420 616e 6420 7468 6520 6d6f 6465  red and the mode
+00024910: 6c20 6973 2074 7572 6e65 6420 696e 746f  l is turned into
+00024920: 0a20 2020 2020 2020 2023 2061 6e20 696e  .        # an in
+00024930: 7438 206d 6f64 656c 3a20 7072 696d 3a3a  t8 model: prim::
+00024940: 7072 6f66 696c 6520 7769 6c6c 2062 6520  profile will be 
+00024950: 7265 6d6f 7665 6420 616e 6420 7769 6c6c  removed and will
+00024960: 2068 6176 6520 4c6c 6761 4675 7369 6f6e   have LlgaFusion
+00024970: 4772 6f75 7020 696e 2074 6865 2067 7261  Group in the gra
+00024980: 7068 0a20 2020 2020 2020 2073 656c 662e  ph.        self.
+00024990: 6361 6c69 625f 6675 6e63 2871 5f6d 6f64  calib_func(q_mod
+000249a0: 656c 2c20 6461 7461 6c6f 6164 6572 2c20  el, dataloader, 
+000249b0: 746d 705f 6974 6572 6174 696f 6e73 3d32  tmp_iterations=2
+000249c0: 290a 2020 2020 2020 2020 7365 6c66 2e74  ).        self.t
+000249d0: 6d70 5f6d 6f64 656c 2e5f 6d6f 6465 6c20  mp_model._model 
+000249e0: 3d20 715f 6d6f 6465 6c0a 0a20 2020 2020  = q_model..     
+000249f0: 2020 2077 6974 6820 6f70 656e 2873 656c     with open(sel
+00024a00: 662e 6970 6578 5f63 6f6e 6669 675f 7061  f.ipex_config_pa
+00024a10: 7468 2c20 2772 2729 2061 7320 663a 0a20  th, 'r') as f:. 
+00024a20: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00024a30: 746d 705f 6d6f 6465 6c2e 7475 6e65 5f63  tmp_model.tune_c
+00024a40: 6667 203d 206a 736f 6e2e 6c6f 6164 2866  fg = json.load(f
+00024a50: 290a 2020 2020 2020 2020 7365 6c66 2e74  ).        self.t
+00024a60: 6d70 5f6d 6f64 656c 2e69 7065 785f 636f  mp_model.ipex_co
+00024a70: 6e66 6967 5f70 6174 6820 3d20 7365 6c66  nfig_path = self
+00024a80: 2e69 7065 785f 636f 6e66 6967 5f70 6174  .ipex_config_pat
+00024a90: 680a 2020 2020 2020 2020 7265 7475 726e  h.        return
+00024aa0: 2073 656c 662e 746d 705f 6d6f 6465 6c0a   self.tmp_model.
+00024ab0: 0a20 2020 2040 6475 6d70 5f65 6c61 7073  .    @dump_elaps
+00024ac0: 6564 5f74 696d 6528 2250 6173 7320 7361  ed_time("Pass sa
+00024ad0: 7665 2071 7561 6e74 697a 6564 206d 6f64  ve quantized mod
+00024ae0: 656c 2229 0a20 2020 2064 6566 2073 6176  el").    def sav
+00024af0: 6528 7365 6c66 2c20 6d6f 6465 6c2c 2070  e(self, model, p
+00024b00: 6174 683d 4e6f 6e65 293a 0a20 2020 2020  ath=None):.     
+00024b10: 2020 2022 2222 5468 6520 6675 6e63 7469     """The functi
+00024b20: 6f6e 2069 7320 7573 6564 2062 7920 7475  on is used by tu
+00024b30: 6e65 2073 7472 6174 6567 7920 636c 6173  ne strategy clas
+00024b40: 7320 666f 7220 7365 7420 6265 7374 2063  s for set best c
+00024b50: 6f6e 6669 6775 7265 2069 6e20 4e65 7572  onfigure in Neur
+00024b60: 616c 2043 6f6d 7072 6573 736f 7220 6d6f  al Compressor mo
+00024b70: 6465 6c2e 0a0a 2020 2020 2020 2020 2020  del...          
+00024b80: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
+00024b90: 2020 2020 2020 6d6f 6465 6c20 286f 626a        model (obj
+00024ba0: 6563 7429 3a20 5468 6520 4e65 7572 616c  ect): The Neural
+00024bb0: 2043 6f6d 7072 6573 736f 7220 6d6f 6465   Compressor mode
+00024bc0: 6c20 7768 6963 6820 6973 2062 6573 7420  l which is best 
+00024bd0: 7265 7375 6c74 732e 0a20 2020 2020 2020  results..       
+00024be0: 2020 2020 2020 2020 7061 7468 2028 7374          path (st
+00024bf0: 7269 6e67 293a 204e 6f20 7573 6564 2e0a  ring): No used..
+00024c00: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
+00024c10: 3a0a 2020 2020 2020 2020 2020 2020 4e6f  :.            No
+00024c20: 6e65 0a20 2020 2020 2020 2022 2222 0a0a  ne.        """..
+00024c30: 2020 2020 2020 2020 7061 7373 0a0a 2020          pass..  
+00024c40: 2020 6465 6620 696e 7370 6563 745f 7465    def inspect_te
+00024c50: 6e73 6f72 2873 656c 662c 0a20 2020 2020  nsor(self,.     
 00024c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024c70: 2072 6564 7563 655f 7261 6e67 653d 5245   reduce_range=RE
-00024c80: 4455 4345 5f52 414e 4745 2c0a 2020 2020  DUCE_RANGE,.    
-00024c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00024c70: 2020 6d6f 6465 6c2c 0a20 2020 2020 2020    model,.       
+00024c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00024c90: 6461 7461 6c6f 6164 6572 2c0a 2020 2020  dataloader,.    
 00024ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024cb0: 6f62 7365 7276 6572 3d74 6f72 6368 2e71  observer=torch.q
-00024cc0: 7561 6e74 697a 6174 696f 6e2e 4d6f 7669  uantization.Movi
-00024cd0: 6e67 4176 6572 6167 654d 696e 4d61 784f  ngAverageMinMaxO
-00024ce0: 6273 6572 7665 7229 2c0a 2020 2020 2020  bserver),.      
+00024cb0: 2020 206f 705f 6c69 7374 3d4e 6f6e 652c     op_list=None,
+00024cc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00024cd0: 2020 2020 2020 2020 6974 6572 6174 696f          iteratio
+00024ce0: 6e5f 6c69 7374 3d4e 6f6e 652c 0a20 2020  n_list=None,.   
 00024cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024d00: 2020 2020 2020 7765 6967 6874 3d74 6f72        weight=tor
-00024d10: 6368 2e71 7561 6e74 697a 6174 696f 6e2e  ch.quantization.
-00024d20: 6465 6661 756c 745f 7765 6967 6874 5f66  default_weight_f
-00024d30: 616b 655f 7175 616e 7429 205c 0a20 2020  ake_quant) \.   
-00024d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024d50: 2020 2020 2069 6620 7365 6c66 2e76 6572       if self.ver
-00024d60: 7369 6f6e 2e72 656c 6561 7365 203c 2056  sion.release < V
-00024d70: 6572 7369 6f6e 2822 312e 3130 2e30 2229  ersion("1.10.0")
-00024d80: 2e72 656c 6561 7365 2065 6c73 6520 5c0a  .release else \.
-00024d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024da0: 2020 2020 2020 2020 2020 746f 7263 682e            torch.
-00024db0: 7175 616e 7469 7a61 7469 6f6e 2e51 436f  quantization.QCo
-00024dc0: 6e66 6967 280a 2020 2020 2020 2020 2020  nfig(.          
-00024dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024de0: 2020 6163 7469 7661 7469 6f6e 3d74 6f72    activation=tor
-00024df0: 6368 2e71 7561 6e74 697a 6174 696f 6e2e  ch.quantization.
-00024e00: 4675 7365 644d 6f76 696e 6741 7667 4f62  FusedMovingAvgOb
-00024e10: 7346 616b 6551 7561 6e74 697a 652e 7769  sFakeQuantize.wi
-00024e20: 7468 5f61 7267 7328 0a20 2020 2020 2020  th_args(.       
-00024e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024e50: 6474 7970 653d 746f 7263 682e 7175 696e  dtype=torch.quin
-00024e60: 7438 2c0a 2020 2020 2020 2020 2020 2020  t8,.            
-00024e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024e80: 2020 2020 2020 2020 2020 2071 7363 6865             qsche
-00024e90: 6d65 3d74 6f72 6368 2e70 6572 5f74 656e  me=torch.per_ten
-00024ea0: 736f 725f 6166 6669 6e65 2c0a 2020 2020  sor_affine,.    
-00024eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024ed0: 2020 2072 6564 7563 655f 7261 6e67 653d     reduce_range=
-00024ee0: 5245 4455 4345 5f52 414e 4745 292c 0a20  REDUCE_RANGE),. 
-00024ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024f00: 2020 2020 2020 2020 2020 2077 6569 6768             weigh
-00024f10: 743d 746f 7263 682e 7175 616e 7469 7a61  t=torch.quantiza
-00024f20: 7469 6f6e 2e64 6566 6175 6c74 5f66 7573  tion.default_fus
-00024f30: 6564 5f70 6572 5f63 6861 6e6e 656c 5f77  ed_per_channel_w
-00024f40: 745f 6661 6b65 5f71 7561 6e74 290a 2020  t_fake_quant).  
-00024f50: 2020 2020 2020 7175 616e 7469 7a61 626c        quantizabl
-00024f60: 655f 6f70 7320 3d20 5b5d 0a20 2020 2020  e_ops = [].     
-00024f70: 2020 2074 6d70 5f6d 6f64 656c 203d 2073     tmp_model = s
-00024f80: 656c 662e 6675 7365 5f66 785f 6d6f 6465  elf.fuse_fx_mode
-00024f90: 6c28 7365 6c66 2e6d 6f64 656c 2c20 6973  l(self.model, is
-00024fa0: 5f71 6174 3d54 7275 6529 0a20 2020 2020  _qat=True).     
-00024fb0: 2020 2073 656c 662e 5f67 6574 5f71 7561     self._get_qua
-00024fc0: 6e74 697a 6162 6c65 5f6f 7073 5f72 6563  ntizable_ops_rec
-00024fd0: 7572 7369 7665 6c79 2874 6d70 5f6d 6f64  ursively(tmp_mod
-00024fe0: 656c 2c20 2727 2c20 7175 616e 7469 7a61  el, '', quantiza
-00024ff0: 626c 655f 6f70 7329 0a20 2020 2020 2020  ble_ops).       
-00025000: 2062 6631 365f 6f70 7320 3d20 5b5d 0a20   bf16_ops = []. 
-00025010: 2020 2020 2020 2069 6620 7365 6c66 2e76         if self.v
-00025020: 6572 7369 6f6e 2e72 656c 6561 7365 203e  ersion.release >
-00025030: 3d20 5665 7273 696f 6e28 2231 2e31 312e  = Version("1.11.
-00025040: 3022 292e 7265 6c65 6173 6520 616e 6420  0").release and 
-00025050: 7365 6c66 2e75 7365 5f62 6631 3620 616e  self.use_bf16 an
-00025060: 6420 5c0a 2020 2020 2020 2020 2020 2020  d \.            
-00025070: 2843 7075 496e 666f 2829 2e62 6631 3620  (CpuInfo().bf16 
-00025080: 6f72 206f 732e 6765 7465 6e76 2827 464f  or os.getenv('FO
-00025090: 5243 455f 4246 3136 2729 203d 3d20 2731  RCE_BF16') == '1
-000250a0: 2729 3a20 2320 7072 6167 6d61 3a20 6e6f  '): # pragma: no
-000250b0: 2063 6f76 6572 0a20 2020 2020 2020 2020   cover.         
-000250c0: 2020 2073 656c 662e 6266 3136 5f6f 7073     self.bf16_ops
-000250d0: 203d 2073 656c 662e 7175 6572 795f 6861   = self.query_ha
-000250e0: 6e64 6c65 722e 6765 745f 6f70 5f74 7970  ndler.get_op_typ
-000250f0: 6573 5f62 795f 7072 6563 6973 696f 6e28  es_by_precision(
-00025100: 2262 6631 3622 290a 2020 2020 2020 2020  "bf16").        
-00025110: 2020 2020 7365 6c66 2e5f 6765 745f 6266      self._get_bf
-00025120: 3136 5f6f 7073 5f72 6563 7572 7369 7665  16_ops_recursive
-00025130: 6c79 2874 6d70 5f6d 6f64 656c 2c20 2727  ly(tmp_model, ''
-00025140: 2c20 6266 3136 5f6f 7073 290a 2020 2020  , bf16_ops).    
-00025150: 2020 2020 6266 3136 5f6f 7073 5f6c 6973      bf16_ops_lis
-00025160: 7420 3d20 5b28 6f70 2920 666f 7220 6f70  t = [(op) for op
-00025170: 2069 6e20 6266 3136 5f6f 7073 2069 6620   in bf16_ops if 
-00025180: 6f70 206e 6f74 2069 6e20 7175 616e 7469  op not in quanti
-00025190: 7a61 626c 655f 6f70 735d 0a20 2020 2020  zable_ops].     
-000251a0: 2020 2071 7561 6e74 697a 6564 5f6f 7073     quantized_ops
-000251b0: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
-000251c0: 0a20 2020 2020 2020 2066 6f72 206f 7020  .        for op 
-000251d0: 696e 2071 7561 6e74 697a 6162 6c65 5f6f  in quantizable_o
-000251e0: 7073 3a0a 2020 2020 2020 2020 2020 2020  ps:.            
-000251f0: 6966 206f 705b 315d 2069 6e20 5b0a 2020  if op[1] in [.  
-00025200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025210: 2020 2745 6d62 6564 6469 6e67 272c 2027    'Embedding', '
-00025220: 456d 6265 6464 696e 6742 6167 272c 2027  EmbeddingBag', '
-00025230: 4c53 544d 272c 2027 4752 5527 2c20 274c  LSTM', 'GRU', 'L
-00025240: 5354 4d43 656c 6c27 2c20 2747 5255 4365  STMCell', 'GRUCe
-00025250: 6c6c 272c 2027 524e 4e43 656c 6c27 0a20  ll', 'RNNCell'. 
-00025260: 2020 2020 2020 2020 2020 205d 3a0a 2020             ]:.  
-00025270: 2020 2020 2020 2020 2020 2020 2020 7175                qu
-00025280: 616e 7469 7a65 645f 6f70 735b 6f70 5b30  antized_ops[op[0
-00025290: 5d5d 203d 2074 6f72 6368 2e71 7561 6e74  ]] = torch.quant
-000252a0: 697a 6174 696f 6e2e 6465 6661 756c 745f  ization.default_
-000252b0: 6479 6e61 6d69 635f 7163 6f6e 6669 670a  dynamic_qconfig.
-000252c0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-000252d0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000252e0: 2020 7175 616e 7469 7a65 645f 6f70 735b    quantized_ops[
-000252f0: 6f70 5b30 5d5d 203d 2071 5f63 6667 730a  op[0]] = q_cfgs.
-00025300: 2020 2020 2020 2020 2320 6275 696c 6420          # build 
-00025310: 6f70 5f63 6f6e 6669 675f 6469 6374 2074  op_config_dict t
-00025320: 6f20 7361 7665 206d 6f64 756c 6520 7363  o save module sc
-00025330: 616c 6520 616e 6420 7a65 726f 706f 696e  ale and zeropoin
-00025340: 740a 2020 2020 2020 2020 6f70 5f63 6f6e  t.        op_con
-00025350: 6669 675f 6469 6374 203d 207b 7d0a 2020  fig_dict = {}.  
-00025360: 2020 2020 2020 666f 7220 6f70 2069 6e20        for op in 
-00025370: 7175 616e 7469 7a61 626c 655f 6f70 733a  quantizable_ops:
-00025380: 0a20 2020 2020 2020 2020 2020 206f 705f  .            op_
-00025390: 636f 6e66 6967 5f64 6963 745b 6f70 5d20  config_dict[op] 
-000253a0: 3d20 7b27 7765 6967 6874 273a 207b 2764  = {'weight': {'d
-000253b0: 7479 7065 273a 2027 696e 7438 277d 2c20  type': 'int8'}, 
-000253c0: 2761 6374 6976 6174 696f 6e27 3a20 7b27  'activation': {'
-000253d0: 6474 7970 6527 3a20 2775 696e 7438 277d  dtype': 'uint8'}
-000253e0: 7d0a 0a20 2020 2020 2020 2069 6620 7365  }..        if se
-000253f0: 6c66 2e76 6572 7369 6f6e 2e72 656c 6561  lf.version.relea
-00025400: 7365 203c 2056 6572 7369 6f6e 2822 312e  se < Version("1.
-00025410: 3131 2e30 2229 2e72 656c 6561 7365 3a0a  11.0").release:.
-00025420: 2020 2020 2020 2020 2020 2020 7175 616e              quan
-00025430: 7469 7a65 645f 6f70 735b 2264 6566 6175  tized_ops["defau
-00025440: 6c74 5f71 636f 6e66 6967 225d 203d 204e  lt_qconfig"] = N
-00025450: 6f6e 650a 2020 2020 2020 2020 656c 7365  one.        else
-00025460: 3a0a 2020 2020 2020 2020 2020 2020 6672  :.            fr
-00025470: 6f6d 2074 6f72 6368 2e61 6f2e 7175 616e  om torch.ao.quan
-00025480: 7469 7a61 7469 6f6e 2069 6d70 6f72 7420  tization import 
-00025490: 6465 6661 756c 745f 656d 6265 6464 696e  default_embeddin
-000254a0: 675f 7161 745f 7163 6f6e 6669 670a 2020  g_qat_qconfig.  
-000254b0: 2020 2020 2020 2020 2020 666f 7220 6f70            for op
-000254c0: 2069 6e20 7175 616e 7469 7a61 626c 655f   in quantizable_
-000254d0: 6f70 733a 0a20 2020 2020 2020 2020 2020  ops:.           
-000254e0: 2020 2020 2069 6620 6f70 5b31 5d20 696e       if op[1] in
-000254f0: 205b 2745 6d62 6564 6469 6e67 272c 2027   ['Embedding', '
-00025500: 456d 6265 6464 696e 6742 6167 275d 3a0a  EmbeddingBag']:.
-00025510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025520: 2020 2020 7175 616e 7469 7a65 645f 6f70      quantized_op
-00025530: 735b 6f70 5b30 5d5d 203d 2064 6566 6175  s[op[0]] = defau
-00025540: 6c74 5f65 6d62 6564 6469 6e67 5f71 6174  lt_embedding_qat
-00025550: 5f71 636f 6e66 6967 0a20 2020 2020 2020  _qconfig.       
-00025560: 2066 726f 6d20 746f 7263 682e 7175 616e   from torch.quan
-00025570: 7469 7a61 7469 6f6e 2e71 7561 6e74 697a  tization.quantiz
-00025580: 655f 6678 2069 6d70 6f72 7420 7072 6570  e_fx import prep
-00025590: 6172 655f 7161 745f 6678 0a20 2020 2020  are_qat_fx.     
-000255a0: 2020 2066 785f 6f70 5f63 6667 7320 3d20     fx_op_cfgs = 
-000255b0: 5f63 6667 735f 746f 5f66 785f 6366 6773  _cfgs_to_fx_cfgs
-000255c0: 2871 7561 6e74 697a 6564 5f6f 7073 2c20  (quantized_ops, 
-000255d0: 2771 7561 6e74 5f61 7761 7265 5f74 7261  'quant_aware_tra
-000255e0: 696e 696e 6727 290a 2020 2020 2020 2020  ining').        
-000255f0: 7365 6c66 2e6d 6f64 656c 2e5f 6d6f 6465  self.model._mode
-00025600: 6c2e 7472 6169 6e28 290a 0a20 2020 2020  l.train()..     
-00025610: 2020 2023 2050 7954 6f72 6368 2031 2e31     # PyTorch 1.1
-00025620: 3320 616e 6420 6162 6f76 6520 7665 7273  3 and above vers
-00025630: 696f 6e2c 206e 6565 6420 6578 616d 706c  ion, need exampl
-00025640: 655f 696e 7075 7473 2066 6f72 2066 7820  e_inputs for fx 
-00025650: 7472 6163 652c 2062 7574 2069 7420 6e6f  trace, but it no
-00025660: 7420 7265 616c 7920 7573 6564 2c0a 2020  t realy used,.  
-00025670: 2020 2020 2020 2320 736f 2073 6574 2069        # so set i
-00025680: 7420 746f 204e 6f6e 652e 0a20 2020 2020  t to None..     
-00025690: 2020 2073 656c 662e 6578 616d 706c 655f     self.example_
-000256a0: 696e 7075 7473 203d 204e 6f6e 650a 0a20  inputs = None.. 
-000256b0: 2020 2020 2020 2023 2046 6f72 2065 7870         # For exp
-000256c0: 6f72 7420 4150 492c 2064 6565 7063 6f70  ort API, deepcop
-000256d0: 7920 6670 3332 5f6d 6f64 656c 0a20 2020  y fp32_model.   
-000256e0: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
-000256f0: 2020 2020 2020 7365 6c66 2e6d 6f64 656c        self.model
-00025700: 2e66 7033 325f 6d6f 6465 6c20 3d20 636f  .fp32_model = co
-00025710: 7079 2e64 6565 7063 6f70 7928 7365 6c66  py.deepcopy(self
-00025720: 2e6d 6f64 656c 2e66 7033 325f 6d6f 6465  .model.fp32_mode
-00025730: 6c29 0a20 2020 2020 2020 2065 7863 6570  l).        excep
-00025740: 7420 4578 6365 7074 696f 6e20 6173 2065  t Exception as e
-00025750: 3a20 2023 2070 7261 676d 613a 206e 6f20  :  # pragma: no 
-00025760: 636f 7665 720a 2020 2020 2020 2020 2020  cover.          
-00025770: 2020 6c6f 6767 6572 2e77 6172 6e69 6e67    logger.warning
-00025780: 2822 4661 696c 2074 6f20 6465 6570 2063  ("Fail to deep c
-00025790: 6f70 7920 7468 6520 6d6f 6465 6c20 6475  opy the model du
-000257a0: 6520 746f 207b 7d2c 2069 6e70 6c61 6365  e to {}, inplace
-000257b0: 2069 7320 7573 6564 206e 6f77 2e22 2e66   is used now.".f
-000257c0: 6f72 6d61 7428 0a20 2020 2020 2020 2020  ormat(.         
-000257d0: 2020 2020 2020 2072 6570 7228 6529 2929         repr(e)))
-000257e0: 0a0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
-000257f0: 662e 7375 625f 6d6f 6475 6c65 5f6c 6973  f.sub_module_lis
-00025800: 7420 6973 204e 6f6e 653a 0a20 2020 2020  t is None:.     
-00025810: 2020 2020 2020 2069 6620 7365 6c66 2e76         if self.v
-00025820: 6572 7369 6f6e 2e72 656c 6561 7365 203e  ersion.release >
-00025830: 3d20 5665 7273 696f 6e28 2231 2e31 332e  = Version("1.13.
-00025840: 3022 292e 7265 6c65 6173 653a 2020 2320  0").release:  # 
-00025850: 7072 6167 6d61 3a20 6e6f 2063 6f76 6572  pragma: no cover
-00025860: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00025870: 2023 2070 796c 696e 743a 2064 6973 6162   # pylint: disab
-00025880: 6c65 3d45 3131 3233 0a20 2020 2020 2020  le=E1123.       
-00025890: 2020 2020 2020 2020 2073 656c 662e 6d6f           self.mo
-000258a0: 6465 6c2e 5f6d 6f64 656c 203d 2070 7265  del._model = pre
-000258b0: 7061 7265 5f71 6174 5f66 7828 0a20 2020  pare_qat_fx(.   
-000258c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000258d0: 2073 656c 662e 6d6f 6465 6c2e 5f6d 6f64   self.model._mod
-000258e0: 656c 2c0a 2020 2020 2020 2020 2020 2020  el,.            
-000258f0: 2020 2020 2020 2020 6678 5f6f 705f 6366          fx_op_cf
-00025900: 6773 2c0a 2020 2020 2020 2020 2020 2020  gs,.            
-00025910: 2020 2020 2020 2020 6578 616d 706c 655f          example_
-00025920: 696e 7075 7473 3d73 656c 662e 6578 616d  inputs=self.exam
-00025930: 706c 655f 696e 7075 7473 2c0a 2020 2020  ple_inputs,.    
-00025940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025950: 7072 6570 6172 655f 6375 7374 6f6d 5f63  prepare_custom_c
-00025960: 6f6e 6669 673d 7365 6c66 2e6d 6f64 656c  onfig=self.model
-00025970: 2e6b 7761 7267 732e 6765 7428 0a20 2020  .kwargs.get(.   
-00025980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025990: 2020 2020 2027 7072 6570 6172 655f 6375       'prepare_cu
-000259a0: 7374 6f6d 5f63 6f6e 6669 675f 6469 6374  stom_config_dict
-000259b0: 272c 204e 6f6e 6529 2069 6620 7365 6c66  ', None) if self
-000259c0: 2e6d 6f64 656c 2e6b 7761 7267 7320 6973  .model.kwargs is
-000259d0: 206e 6f74 204e 6f6e 6520 656c 7365 204e   not None else N
-000259e0: 6f6e 6529 0a20 2020 2020 2020 2020 2020  one).           
-000259f0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00025a00: 2020 2020 2020 2073 656c 662e 6d6f 6465         self.mode
-00025a10: 6c2e 5f6d 6f64 656c 203d 2070 7265 7061  l._model = prepa
-00025a20: 7265 5f71 6174 5f66 7828 0a20 2020 2020  re_qat_fx(.     
-00025a30: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00025a40: 656c 662e 6d6f 6465 6c2e 5f6d 6f64 656c  elf.model._model
-00025a50: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00025a60: 2020 2020 2020 6678 5f6f 705f 6366 6773        fx_op_cfgs
-00025a70: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00025a80: 2020 2020 2020 7072 6570 6172 655f 6375        prepare_cu
-00025a90: 7374 6f6d 5f63 6f6e 6669 675f 6469 6374  stom_config_dict
-00025aa0: 3d73 656c 662e 6d6f 6465 6c2e 6b77 6172  =self.model.kwar
-00025ab0: 6773 2e67 6574 280a 2020 2020 2020 2020  gs.get(.        
-00025ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025ad0: 2770 7265 7061 7265 5f63 7573 746f 6d5f  'prepare_custom_
-00025ae0: 636f 6e66 6967 5f64 6963 7427 2c20 4e6f  config_dict', No
-00025af0: 6e65 2920 6966 2073 656c 662e 6d6f 6465  ne) if self.mode
-00025b00: 6c2e 6b77 6172 6773 2069 7320 6e6f 7420  l.kwargs is not 
-00025b10: 4e6f 6e65 2065 6c73 6520 4e6f 6e65 290a  None else None).
-00025b20: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00025b30: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
-00025b40: 2e69 6e66 6f28 2746 7820 7472 6163 6520  .info('Fx trace 
-00025b50: 6f66 2074 6865 2065 6e74 6972 6520 6d6f  of the entire mo
-00025b60: 6465 6c20 6661 696c 6564 2e20 2720 2b20  del failed. ' + 
-00025b70: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00025b80: 2020 2020 2020 2020 2020 2757 6520 7769            'We wi
-00025b90: 6c6c 2063 6f6e 6475 6374 2061 7574 6f20  ll conduct auto 
-00025ba0: 7175 616e 7469 7a61 7469 6f6e 2729 0a20  quantization'). 
-00025bb0: 2020 2020 2020 2020 2020 2050 7954 6f72             PyTor
-00025bc0: 6368 5f46 5841 6461 7074 6f72 2e70 7265  ch_FXAdaptor.pre
-00025bd0: 7061 7265 5f73 7562 5f67 7261 7068 2873  pare_sub_graph(s
-00025be0: 656c 662e 7375 625f 6d6f 6475 6c65 5f6c  elf.sub_module_l
-00025bf0: 6973 742c 0a20 2020 2020 2020 2020 2020  ist,.           
-00025c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025c20: 2020 2020 2066 785f 6f70 5f63 6667 732c       fx_op_cfgs,
-00025c30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00025c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025c60: 2073 656c 662e 6d6f 6465 6c2e 5f6d 6f64   self.model._mod
-00025c70: 656c 2c0a 2020 2020 2020 2020 2020 2020  el,.            
-00025c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025ca0: 2020 2020 7072 6566 6978 3d27 272c 0a20      prefix='',. 
-00025cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025cd0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00025ce0: 735f 7161 743d 5472 7565 2c0a 2020 2020  s_qat=True,.    
-00025cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025d10: 2020 2020 2020 2020 2020 2020 6578 616d              exam
-00025d20: 706c 655f 696e 7075 7473 3d73 656c 662e  ple_inputs=self.
-00025d30: 6578 616d 706c 655f 696e 7075 7473 290a  example_inputs).
-00025d40: 2020 2020 2020 2020 2320 5468 6973 2069          # This i
-00025d50: 7320 6120 666c 6167 2066 6f72 2072 656c  s a flag for rel
-00025d60: 6f61 6469 6e67 0a20 2020 2020 2020 2073  oading.        s
-00025d70: 656c 662e 6d6f 6465 6c2e 715f 636f 6e66  elf.model.q_conf
-00025d80: 6967 203d 207b 0a20 2020 2020 2020 2020  ig = {.         
-00025d90: 2020 2027 6361 6c69 625f 7361 6d70 6c69     'calib_sampli
-00025da0: 6e67 5f73 697a 6527 3a20 3130 302c 2023  ng_size': 100, #
-00025db0: 2074 6d70 2061 7267 2066 6f72 2065 7870   tmp arg for exp
-00025dc0: 6f72 7420 4150 490a 2020 2020 2020 2020  ort API.        
-00025dd0: 2020 2020 2769 735f 6f6e 6573 686f 7427      'is_oneshot'
-00025de0: 3a20 5472 7565 2c0a 2020 2020 2020 2020  : True,.        
-00025df0: 2020 2020 2766 7261 6d65 776f 726b 273a      'framework':
-00025e00: 2027 7079 746f 7263 685f 6678 272c 0a20   'pytorch_fx',. 
-00025e10: 2020 2020 2020 2020 2020 2027 7265 6475             'redu
-00025e20: 6365 5f72 616e 6765 273a 2052 4544 5543  ce_range': REDUC
-00025e30: 455f 5241 4e47 452c 0a20 2020 2020 2020  E_RANGE,.       
-00025e40: 2020 2020 2027 7175 616e 7469 7a61 626c       'quantizabl
-00025e50: 655f 6f70 7327 3a20 7175 616e 7469 7a61  e_ops': quantiza
-00025e60: 626c 655f 6f70 732c 0a20 2020 2020 2020  ble_ops,.       
-00025e70: 2020 2020 2027 6266 3136 5f6f 7073 5f6c       'bf16_ops_l
-00025e80: 6973 7427 3a20 6266 3136 5f6f 7073 5f6c  ist': bf16_ops_l
-00025e90: 6973 742c 0a20 2020 2020 2020 2020 2020  ist,.           
-00025ea0: 2027 6f70 273a 206f 705f 636f 6e66 6967   'op': op_config
-00025eb0: 5f64 6963 742c 0a20 2020 2020 2020 2020  _dict,.         
-00025ec0: 2020 2027 7375 625f 6d6f 6475 6c65 5f6c     'sub_module_l
-00025ed0: 6973 7427 3a20 7365 6c66 2e73 7562 5f6d  ist': self.sub_m
-00025ee0: 6f64 756c 655f 6c69 7374 2c0a 2020 2020  odule_list,.    
-00025ef0: 2020 2020 2020 2020 2761 7070 726f 6163          'approac
-00025f00: 6827 3a20 2771 7561 6e74 5f61 7761 7265  h': 'quant_aware
-00025f10: 5f74 7261 696e 696e 6727 0a20 2020 2020  _training'.     
-00025f20: 2020 207d 0a20 2020 2020 2020 2023 2046     }.        # F
-00025f30: 6f72 2065 7870 6f72 7420 4150 490a 2020  or export API.  
-00025f40: 2020 2020 2020 676c 6f62 616c 2068 6f6f        global hoo
-00025f50: 6b5f 6c69 7374 0a20 2020 2020 2020 2068  k_list.        h
-00025f60: 6f6f 6b5f 6c69 7374 203d 2074 6f72 6368  ook_list = torch
-00025f70: 5f75 7469 6c73 2e75 7469 6c2e 5f73 6574  _utils.util._set
-00025f80: 5f69 6e70 7574 5f73 6361 6c65 5f68 6f6f  _input_scale_hoo
-00025f90: 6b28 7365 6c66 2e6d 6f64 656c 2e5f 6d6f  k(self.model._mo
-00025fa0: 6465 6c2c 2071 7561 6e74 697a 6564 5f6f  del, quantized_o
-00025fb0: 7073 290a 0a20 2020 2064 6566 205f 706f  ps)..    def _po
-00025fc0: 7374 5f68 6f6f 6b5f 666f 725f 7161 7428  st_hook_for_qat(
-00025fd0: 7365 6c66 293a 0a20 2020 2020 2020 2023  self):.        #
-00025fe0: 2046 6f72 2065 7870 6f72 7420 4150 490a   For export API.
-00025ff0: 2020 2020 2020 2020 7363 616c 655f 696e          scale_in
-00026000: 666f 203d 2074 6f72 6368 5f75 7469 6c73  fo = torch_utils
-00026010: 2e75 7469 6c2e 5f67 6574 5f69 6e70 7574  .util._get_input
-00026020: 5f73 6361 6c65 2873 656c 662e 6d6f 6465  _scale(self.mode
-00026030: 6c2e 5f6d 6f64 656c 2c20 686f 6f6b 5f6c  l._model, hook_l
-00026040: 6973 7429 0a20 2020 2020 2020 2073 656c  ist).        sel
-00026050: 662e 6d6f 6465 6c2e 715f 636f 6e66 6967  f.model.q_config
-00026060: 5b27 7363 616c 655f 696e 666f 275d 203d  ['scale_info'] =
-00026070: 2073 6361 6c65 5f69 6e66 6f0a 2020 2020   scale_info.    
-00026080: 2020 2020 6672 6f6d 2074 6f72 6368 2e71      from torch.q
-00026090: 7561 6e74 697a 6174 696f 6e2e 7175 616e  uantization.quan
-000260a0: 7469 7a65 5f66 7820 696d 706f 7274 2063  tize_fx import c
-000260b0: 6f6e 7665 7274 5f66 780a 2020 2020 2020  onvert_fx.      
-000260c0: 2020 6966 2073 656c 662e 7375 625f 6d6f    if self.sub_mo
-000260d0: 6475 6c65 5f6c 6973 7420 6973 204e 6f6e  dule_list is Non
-000260e0: 653a 0a20 2020 2020 2020 2020 2020 2069  e:.            i
-000260f0: 6620 7365 6c66 2e76 6572 7369 6f6e 203e  f self.version >
-00026100: 2056 6572 7369 6f6e 2822 312e 3132 2e31   Version("1.12.1
-00026110: 2229 3a20 2023 2070 7261 676d 613a 206e  "):  # pragma: n
-00026120: 6f20 636f 7665 720a 2020 2020 2020 2020  o cover.        
-00026130: 2020 2020 2020 2020 2320 7079 6c69 6e74          # pylint
-00026140: 3a20 6469 7361 626c 653d 4531 3132 330a  : disable=E1123.
-00026150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026160: 7365 6c66 2e6d 6f64 656c 2e5f 6d6f 6465  self.model._mode
-00026170: 6c20 3d20 636f 6e76 6572 745f 6678 280a  l = convert_fx(.
-00026180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026190: 2020 2020 7365 6c66 2e6d 6f64 656c 2e5f      self.model._
-000261a0: 6d6f 6465 6c2c 0a20 2020 2020 2020 2020  model,.         
-000261b0: 2020 2020 2020 2020 2020 2063 6f6e 7665             conve
-000261c0: 7274 5f63 7573 746f 6d5f 636f 6e66 6967  rt_custom_config
-000261d0: 3d73 656c 662e 6d6f 6465 6c2e 6b77 6172  =self.model.kwar
-000261e0: 6773 2e67 6574 280a 2020 2020 2020 2020  gs.get(.        
-000261f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026200: 2763 6f6e 7665 7274 5f63 7573 746f 6d5f  'convert_custom_
-00026210: 636f 6e66 6967 5f64 6963 7427 2c20 4e6f  config_dict', No
-00026220: 6e65 2920 6966 2073 656c 662e 6d6f 6465  ne) if self.mode
-00026230: 6c2e 6b77 6172 6773 2069 7320 6e6f 7420  l.kwargs is not 
-00026240: 4e6f 6e65 2065 6c73 6520 4e6f 6e65 290a  None else None).
-00026250: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00026260: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00026270: 2020 7365 6c66 2e6d 6f64 656c 2e5f 6d6f    self.model._mo
-00026280: 6465 6c20 3d20 636f 6e76 6572 745f 6678  del = convert_fx
-00026290: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-000262a0: 2020 2020 2020 7365 6c66 2e6d 6f64 656c        self.model
-000262b0: 2e5f 6d6f 6465 6c2c 0a20 2020 2020 2020  ._model,.       
-000262c0: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
-000262d0: 7665 7274 5f63 7573 746f 6d5f 636f 6e66  vert_custom_conf
-000262e0: 6967 5f64 6963 743d 7365 6c66 2e6d 6f64  ig_dict=self.mod
-000262f0: 656c 2e6b 7761 7267 732e 6765 7428 0a20  el.kwargs.get(. 
-00026300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026310: 2020 2020 2020 2027 636f 6e76 6572 745f         'convert_
-00026320: 6375 7374 6f6d 5f63 6f6e 6669 675f 6469  custom_config_di
-00026330: 6374 272c 204e 6f6e 6529 2069 6620 7365  ct', None) if se
-00026340: 6c66 2e6d 6f64 656c 2e6b 7761 7267 7320  lf.model.kwargs 
-00026350: 6973 206e 6f74 204e 6f6e 6520 656c 7365  is not None else
-00026360: 204e 6f6e 6529 0a20 2020 2020 2020 2065   None).        e
-00026370: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00026380: 2050 7954 6f72 6368 5f46 5841 6461 7074   PyTorch_FXAdapt
-00026390: 6f72 2e63 6f6e 7665 7274 5f73 7562 5f67  or.convert_sub_g
-000263a0: 7261 7068 2873 656c 662e 7375 625f 6d6f  raph(self.sub_mo
-000263b0: 6475 6c65 5f6c 6973 742c 205c 0a20 2020  dule_list, \.   
-000263c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000263d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000263e0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-000263f0: 662e 6d6f 6465 6c2e 5f6d 6f64 656c 2c20  f.model._model, 
-00026400: 7072 6566 6978 3d27 2729 0a0a 2020 2020  prefix='')..    
-00026410: 2020 2020 6966 2073 656c 662e 6170 7072      if self.appr
-00026420: 6f61 6368 2021 3d20 2770 6f73 745f 7472  oach != 'post_tr
-00026430: 6169 6e69 6e67 5f64 796e 616d 6963 5f71  aining_dynamic_q
-00026440: 7561 6e74 273a 0a20 2020 2020 2020 2020  uant':.         
-00026450: 2020 2073 656c 662e 5f67 6574 5f73 6361     self._get_sca
-00026460: 6c65 5f7a 6572 6f70 6f69 6e74 2873 656c  le_zeropoint(sel
-00026470: 662e 6d6f 6465 6c2e 5f6d 6f64 656c 2c20  f.model._model, 
-00026480: 7365 6c66 2e6d 6f64 656c 2e71 5f63 6f6e  self.model.q_con
-00026490: 6669 6729 0a20 2020 2020 2020 2069 6620  fig).        if 
-000264a0: 6c65 6e28 7365 6c66 2e6d 6f64 656c 2e71  len(self.model.q
-000264b0: 5f63 6f6e 6669 675b 2762 6631 365f 6f70  _config['bf16_op
-000264c0: 735f 6c69 7374 275d 2920 3e20 3020 616e  s_list']) > 0 an
-000264d0: 6420 5c0a 2020 2020 2020 2020 2020 2020  d \.            
-000264e0: 7365 6c66 2e76 6572 7369 6f6e 2e72 656c  self.version.rel
-000264f0: 6561 7365 203e 3d20 5665 7273 696f 6e28  ease >= Version(
-00026500: 2231 2e31 312e 3022 292e 7265 6c65 6173  "1.11.0").releas
-00026510: 6520 616e 6420 7365 6c66 2e75 7365 5f62  e and self.use_b
-00026520: 6631 3620 616e 6420 5c0a 2020 2020 2020  f16 and \.      
-00026530: 2020 2020 2020 2843 7075 496e 666f 2829        (CpuInfo()
-00026540: 2e62 6631 3620 6f72 206f 732e 6765 7465  .bf16 or os.gete
-00026550: 6e76 2827 464f 5243 455f 4246 3136 2729  nv('FORCE_BF16')
-00026560: 203d 3d20 2731 2729 3a20 2320 7072 6167   == '1'): # prag
-00026570: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
-00026580: 2020 2020 2020 2020 2073 656c 662e 6d6f           self.mo
-00026590: 6465 6c2e 5f6d 6f64 656c 203d 2074 6f72  del._model = tor
-000265a0: 6368 5f75 7469 6c73 2e62 6631 365f 636f  ch_utils.bf16_co
-000265b0: 6e76 6572 742e 436f 6e76 6572 7428 7365  nvert.Convert(se
-000265c0: 6c66 2e6d 6f64 656c 2e5f 6d6f 6465 6c2c  lf.model._model,
-000265d0: 2073 656c 662e 6d6f 6465 6c2e 715f 636f   self.model.q_co
-000265e0: 6e66 6967 290a 2020 2020 2020 2020 7365  nfig).        se
-000265f0: 6c66 2e5f 6475 6d70 5f6d 6f64 656c 5f6f  lf._dump_model_o
-00026600: 705f 7374 6174 7328 7365 6c66 2e6d 6f64  p_stats(self.mod
-00026610: 656c 2e5f 6d6f 6465 6c2c 2073 656c 662e  el._model, self.
-00026620: 6d6f 6465 6c2e 715f 636f 6e66 6967 2c20  model.q_config, 
-00026630: 7365 6c66 2e61 7070 726f 6163 6829 0a20  self.approach). 
-00026640: 2020 2020 2020 2074 6f72 6368 5f75 7469         torch_uti
-00026650: 6c73 2e75 7469 6c2e 6765 745f 656d 6265  ls.util.get_embe
-00026660: 6464 696e 675f 636f 6e74 6967 756f 7573  dding_contiguous
-00026670: 2873 656c 662e 6d6f 6465 6c2e 5f6d 6f64  (self.model._mod
-00026680: 656c 290a 0a20 2020 2064 6566 2074 7261  el)..    def tra
-00026690: 696e 2873 656c 662c 206d 6f64 656c 2c20  in(self, model, 
-000266a0: 6461 7461 6c6f 6164 6572 2c20 6f70 7469  dataloader, opti
-000266b0: 6d69 7a65 725f 7475 706c 652c 2063 7269  mizer_tuple, cri
-000266c0: 7465 7269 6f6e 5f74 7570 6c65 2c20 686f  terion_tuple, ho
-000266d0: 6f6b 732c 202a 2a6b 7761 7267 7329 3a0a  oks, **kwargs):.
-000266e0: 2020 2020 2020 2020 2222 2245 7865 6375          """Execu
-000266f0: 7465 2074 6865 2074 7261 696e 2070 726f  te the train pro
-00026700: 6365 7373 206f 6e20 7468 6520 7370 6563  cess on the spec
-00026710: 6966 6965 6420 6d6f 6465 6c2e 0a0a 2020  ified model...  
-00026720: 2020 2020 2020 4172 6773 3a0a 2020 2020        Args:.    
-00026730: 2020 2020 2020 2020 6d6f 6465 6c20 286f          model (o
-00026740: 626a 6563 7429 3a20 6d6f 6465 6c20 746f  bject): model to
-00026750: 2072 756e 2065 7661 6c75 6174 696f 6e2e   run evaluation.
-00026760: 0a20 2020 2020 2020 2020 2020 2064 6174  .            dat
-00026770: 616c 6f61 6465 7220 286f 626a 6563 7429  aloader (object)
-00026780: 3a20 7472 6169 6e69 6e67 2064 6174 6173  : training datas
-00026790: 6574 2e0a 2020 2020 2020 2020 2020 2020  et..            
-000267a0: 6f70 7469 6d69 7a65 7220 2874 7570 6c65  optimizer (tuple
-000267b0: 293a 2049 7420 6973 2061 2074 7570 6c65  ): It is a tuple
-000267c0: 206f 6620 2863 6c73 2c20 7061 7261 6d65   of (cls, parame
-000267d0: 7465 7273 2920 666f 7220 6f70 7469 6d69  ters) for optimi
-000267e0: 7a65 722e 0a20 2020 2020 2020 2020 2020  zer..           
-000267f0: 2063 7269 7465 7269 6f6e 2028 7475 706c   criterion (tupl
-00026800: 6529 3a20 4974 2069 7320 6120 7475 706c  e): It is a tupl
-00026810: 6520 6f66 2028 636c 732c 2070 6172 616d  e of (cls, param
-00026820: 6574 6572 7329 2066 6f72 2063 7269 7465  eters) for crite
-00026830: 7269 6f6e 2e0a 2020 2020 2020 2020 2020  rion..          
-00026840: 2020 6b77 6172 6773 2028 6469 6374 2c20    kwargs (dict, 
-00026850: 6f70 7469 6f6e 616c 293a 206f 7468 6572  optional): other
-00026860: 2070 6172 616d 6574 6572 732e 0a0a 2020   parameters...  
-00026870: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
-00026880: 2020 2020 2020 2020 2020 204e 6f6e 650a             None.
-00026890: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-000268a0: 2020 2020 6465 7669 6365 203d 2022 6375      device = "cu
-000268b0: 6461 3a30 2220 6966 2073 656c 662e 6465  da:0" if self.de
-000268c0: 7669 6365 2021 3d20 2247 5055 2220 616e  vice != "GPU" an
-000268d0: 6420 746f 7263 682e 6375 6461 2e69 735f  d torch.cuda.is_
-000268e0: 6176 6169 6c61 626c 6528 2920 656c 7365  available() else
-000268f0: 2073 656c 662e 6465 7669 6365 0a20 2020   self.device.   
-00026900: 2020 2020 2073 656c 662e 6d6f 6465 6c20       self.model 
-00026910: 3d20 6d6f 6465 6c0a 2020 2020 2020 2020  = model.        
-00026920: 6f70 7469 6d69 7a65 7220 3d20 6f70 7469  optimizer = opti
-00026930: 6d69 7a65 725f 7475 706c 655b 305d 286d  mizer_tuple[0](m
-00026940: 6f64 656c 2e5f 6d6f 6465 6c2e 7061 7261  odel._model.para
-00026950: 6d65 7465 7273 2829 2c20 2a2a 6f70 7469  meters(), **opti
-00026960: 6d69 7a65 725f 7475 706c 655b 315d 290a  mizer_tuple[1]).
-00026970: 2020 2020 2020 2020 6372 6974 6572 696f          criterio
-00026980: 6e20 3d20 6372 6974 6572 696f 6e5f 7475  n = criterion_tu
-00026990: 706c 655b 305d 282a 2a63 7269 7465 7269  ple[0](**criteri
-000269a0: 6f6e 5f74 7570 6c65 5b31 5d29 0a20 2020  on_tuple[1]).   
-000269b0: 2020 2020 2023 2070 7265 7061 7265 2068       # prepare h
-000269c0: 6f6f 6b73 2066 6972 7374 2074 6f20 656e  ooks first to en
-000269d0: 7375 7265 206d 6f64 656c 2077 696c 6c20  sure model will 
-000269e0: 6265 2063 6f6e 7665 7274 6564 2063 6f72  be converted cor
-000269f0: 7265 6374 6c79 0a20 2020 2020 2020 2069  rectly.        i
-00026a00: 6620 686f 6f6b 7320 6973 206e 6f74 204e  f hooks is not N
-00026a10: 6f6e 653a 2020 2320 7072 6167 6d61 3a20  one:  # pragma: 
-00026a20: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
-00026a30: 2020 2020 206f 6e5f 7472 6169 6e5f 6265       on_train_be
-00026a40: 6769 6e20 3d20 686f 6f6b 735b 276f 6e5f  gin = hooks['on_
-00026a50: 7472 6169 6e5f 6265 6769 6e27 5d0a 2020  train_begin'].  
-00026a60: 2020 2020 2020 2020 2020 6f6e 5f74 7261            on_tra
-00026a70: 696e 5f65 6e64 203d 2068 6f6f 6b73 5b27  in_end = hooks['
-00026a80: 6f6e 5f74 7261 696e 5f65 6e64 275d 0a20  on_train_end']. 
-00026a90: 2020 2020 2020 2020 2020 206f 6e5f 6570             on_ep
-00026aa0: 6f63 685f 6265 6769 6e20 3d20 686f 6f6b  och_begin = hook
-00026ab0: 735b 276f 6e5f 6570 6f63 685f 6265 6769  s['on_epoch_begi
-00026ac0: 6e27 5d0a 2020 2020 2020 2020 2020 2020  n'].            
-00026ad0: 6f6e 5f65 706f 6368 5f65 6e64 203d 2068  on_epoch_end = h
-00026ae0: 6f6f 6b73 5b27 6f6e 5f65 706f 6368 5f65  ooks['on_epoch_e
-00026af0: 6e64 275d 0a20 2020 2020 2020 2020 2020  nd'].           
-00026b00: 206f 6e5f 7374 6570 5f62 6567 696e 203d   on_step_begin =
-00026b10: 2068 6f6f 6b73 5b27 6f6e 5f73 7465 705f   hooks['on_step_
-00026b20: 6265 6769 6e27 5d0a 2020 2020 2020 2020  begin'].        
-00026b30: 2020 2020 6f6e 5f73 7465 705f 656e 6420      on_step_end 
-00026b40: 3d20 686f 6f6b 735b 276f 6e5f 7374 6570  = hooks['on_step
-00026b50: 5f65 6e64 275d 0a20 2020 2020 2020 2020  _end'].         
-00026b60: 2020 206f 6e5f 6166 7465 725f 636f 6d70     on_after_comp
-00026b70: 7574 655f 6c6f 7373 203d 2068 6f6f 6b73  ute_loss = hooks
-00026b80: 5b27 6f6e 5f61 6674 6572 5f63 6f6d 7075  ['on_after_compu
-00026b90: 7465 5f6c 6f73 7327 5d0a 2020 2020 2020  te_loss'].      
-00026ba0: 2020 2020 2020 6f6e 5f62 6566 6f72 655f        on_before_
-00026bb0: 6f70 7469 6d69 7a65 725f 7374 6570 203d  optimizer_step =
-00026bc0: 2068 6f6f 6b73 5b27 6f6e 5f62 6566 6f72   hooks['on_befor
-00026bd0: 655f 6f70 7469 6d69 7a65 725f 7374 6570  e_optimizer_step
-00026be0: 275d 0a20 2020 2020 2020 206d 6f64 656c  '].        model
-00026bf0: 2e5f 6d6f 6465 6c2e 7472 6169 6e28 290a  ._model.train().
-00026c00: 2020 2020 2020 2020 6966 2068 6f6f 6b73          if hooks
-00026c10: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-00026c20: 2020 2020 2020 2020 2020 6f6e 5f74 7261            on_tra
-00026c30: 696e 5f62 6567 696e 2864 6174 616c 6f61  in_begin(dataloa
-00026c40: 6465 7229 0a20 2020 2020 2020 2073 7461  der).        sta
-00026c50: 7274 5f65 706f 6368 7320 3d20 6b77 6172  rt_epochs = kwar
-00026c60: 6773 5b27 6b77 6172 6773 275d 5b27 7374  gs['kwargs']['st
-00026c70: 6172 745f 6570 6f63 6827 5d0a 2020 2020  art_epoch'].    
-00026c80: 2020 2020 656e 645f 6570 6f63 6873 203d      end_epochs =
-00026c90: 206b 7761 7267 735b 276b 7761 7267 7327   kwargs['kwargs'
-00026ca0: 5d5b 2765 6e64 5f65 706f 6368 275d 0a20  ]['end_epoch']. 
-00026cb0: 2020 2020 2020 2069 7465 7273 203d 206b         iters = k
-00026cc0: 7761 7267 735b 276b 7761 7267 7327 5d5b  wargs['kwargs'][
-00026cd0: 2769 7465 7261 7469 6f6e 275d 0a20 2020  'iteration'].   
-00026ce0: 2020 2020 206d 6f64 656c 2e5f 6d6f 6465       model._mode
-00026cf0: 6c2e 746f 2864 6576 6963 6529 0a20 2020  l.to(device).   
-00026d00: 2020 2020 2066 6f72 206e 6570 6f63 6820       for nepoch 
-00026d10: 696e 2072 616e 6765 2873 7461 7274 5f65  in range(start_e
-00026d20: 706f 6368 732c 2065 6e64 5f65 706f 6368  pochs, end_epoch
-00026d30: 7329 3a0a 2020 2020 2020 2020 2020 2020  s):.            
-00026d40: 636e 7420 3d20 300a 2020 2020 2020 2020  cnt = 0.        
-00026d50: 2020 2020 6966 2068 6f6f 6b73 2069 7320      if hooks is 
-00026d60: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-00026d70: 2020 2020 2020 2020 2020 6f6e 5f65 706f            on_epo
-00026d80: 6368 5f62 6567 696e 286e 6570 6f63 6829  ch_begin(nepoch)
-00026d90: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-00026da0: 2069 6e70 7574 2c20 7461 7267 6574 2069   input, target i
-00026db0: 6e20 6461 7461 6c6f 6164 6572 3a0a 2020  n dataloader:.  
-00026dc0: 2020 2020 2020 2020 2020 2020 2020 7461                ta
-00026dd0: 7267 6574 203d 2074 6172 6765 742e 746f  rget = target.to
-00026de0: 2864 6576 6963 6529 0a20 2020 2020 2020  (device).       
-00026df0: 2020 2020 2020 2020 2069 6620 686f 6f6b           if hook
-00026e00: 7320 6973 206e 6f74 204e 6f6e 653a 0a20  s is not None:. 
-00026e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026e20: 2020 206f 6e5f 7374 6570 5f62 6567 696e     on_step_begin
-00026e30: 2863 6e74 290a 2020 2020 2020 2020 2020  (cnt).          
-00026e40: 2020 2020 2020 7072 696e 7428 272e 272c        print('.',
-00026e50: 2065 6e64 3d27 272c 2066 6c75 7368 3d54   end='', flush=T
-00026e60: 7275 6529 0a20 2020 2020 2020 2020 2020  rue).           
-00026e70: 2020 2020 2063 6e74 202b 3d20 310a 2020       cnt += 1.  
-00026e80: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-00026e90: 7470 7574 203d 2070 7974 6f72 6368 5f66  tput = pytorch_f
-00026ea0: 6f72 7761 7264 5f77 7261 7070 6572 286d  orward_wrapper(m
-00026eb0: 6f64 656c 2e5f 6d6f 6465 6c2c 2069 6e70  odel._model, inp
-00026ec0: 7574 2c20 6465 7669 6365 3d64 6576 6963  ut, device=devic
-00026ed0: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
-00026ee0: 2020 206c 6f73 7320 3d20 6372 6974 6572     loss = criter
-00026ef0: 696f 6e28 6f75 7470 7574 2c20 7461 7267  ion(output, targ
-00026f00: 6574 290a 2020 2020 2020 2020 2020 2020  et).            
-00026f10: 2020 2020 6966 2068 6f6f 6b73 2069 7320      if hooks is 
-00026f20: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-00026f30: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-00026f40: 7373 203d 206f 6e5f 6166 7465 725f 636f  ss = on_after_co
-00026f50: 6d70 7574 655f 6c6f 7373 2869 6e70 7574  mpute_loss(input
-00026f60: 2c20 6f75 7470 7574 2c20 6c6f 7373 290a  , output, loss).
-00026f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026f80: 6f70 7469 6d69 7a65 722e 7a65 726f 5f67  optimizer.zero_g
-00026f90: 7261 6428 290a 2020 2020 2020 2020 2020  rad().          
-00026fa0: 2020 2020 2020 6c6f 7373 2e62 6163 6b77        loss.backw
-00026fb0: 6172 6428 290a 2020 2020 2020 2020 2020  ard().          
-00026fc0: 2020 2020 2020 6966 2068 6f6f 6b73 2069        if hooks i
-00026fd0: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
-00026fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026ff0: 6c6f 7373 203d 206f 6e5f 6265 666f 7265  loss = on_before
-00027000: 5f6f 7074 696d 697a 6572 5f73 7465 7028  _optimizer_step(
-00027010: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00027020: 2020 6f70 7469 6d69 7a65 722e 7374 6570    optimizer.step
-00027030: 2829 0a20 2020 2020 2020 2020 2020 2020  ().             
-00027040: 2020 2069 6620 686f 6f6b 7320 6973 206e     if hooks is n
-00027050: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
-00027060: 2020 2020 2020 2020 2020 2020 206f 6e5f               on_
-00027070: 7374 6570 5f65 6e64 2829 0a20 2020 2020  step_end().     
-00027080: 2020 2020 2020 2020 2020 2069 6620 636e             if cn
-00027090: 7420 3e3d 2069 7465 7273 3a0a 2020 2020  t >= iters:.    
-000270a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000270b0: 6272 6561 6b0a 2020 2020 2020 2020 2020  break.          
-000270c0: 2020 6966 2068 6f6f 6b73 2069 7320 6e6f    if hooks is no
-000270d0: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-000270e0: 2020 2020 2020 2020 6f6e 5f65 706f 6368          on_epoch
-000270f0: 5f65 6e64 2829 0a0a 2020 2020 2020 2020  _end()..        
-00027100: 6966 2064 6576 6963 6520 213d 2073 656c  if device != sel
-00027110: 662e 6465 7669 6365 3a20 2023 2070 7261  f.device:  # pra
-00027120: 676d 613a 206e 6f20 636f 7665 720a 2020  gma: no cover.  
-00027130: 2020 2020 2020 2020 2020 6d6f 6465 6c2e            model.
-00027140: 5f6d 6f64 656c 2e74 6f28 7365 6c66 2e64  _model.to(self.d
-00027150: 6576 6963 6529 0a0a 2020 2020 2020 2020  evice)..        
-00027160: 6966 2068 6f6f 6b73 2069 7320 6e6f 7420  if hooks is not 
-00027170: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00027180: 2020 6f6e 5f74 7261 696e 5f65 6e64 2829    on_train_end()
-00027190: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-000271a0: 206d 6f64 656c 2e5f 6d6f 6465 6c0a 0a20   model._model.. 
-000271b0: 2020 2064 6566 205f 6765 745f 6d6f 6475     def _get_modu
-000271c0: 6c65 5f6f 705f 7374 6174 7328 7365 6c66  le_op_stats(self
-000271d0: 2c20 6d6f 6465 6c2c 2074 756e 655f 6366  , model, tune_cf
-000271e0: 672c 2061 7070 726f 6163 6829 3a0a 2020  g, approach):.  
-000271f0: 2020 2020 2020 2222 2254 6869 7320 6973        """This is
-00027200: 2061 2066 756e 6374 696f 6e20 746f 2067   a function to g
-00027210: 6574 2071 7561 6e74 697a 6162 6c65 206f  et quantizable o
-00027220: 7073 206f 6620 6d6f 6465 6c20 746f 2075  ps of model to u
-00027230: 7365 722e 0a20 2020 2020 2020 2041 7267  ser..        Arg
-00027240: 733a 0a20 2020 2020 2020 2020 2020 206d  s:.            m
-00027250: 6f64 656c 2028 6f62 6a65 6374 293a 2069  odel (object): i
-00027260: 6e70 7574 206d 6f64 656c 0a20 2020 2020  nput model.     
-00027270: 2020 2020 2020 2074 756e 655f 6366 6720         tune_cfg 
-00027280: 2864 6963 7429 3a20 7175 616e 7469 7a61  (dict): quantiza
-00027290: 7469 6f6e 2063 6f6e 6669 670a 2020 2020  tion config.    
-000272a0: 2020 2020 2020 2020 6170 7072 6f61 6368          approach
-000272b0: 2028 7374 7229 3a20 7175 616e 7469 7a61   (str): quantiza
-000272c0: 7469 6f6e 2061 7070 726f 6163 680a 2020  tion approach.  
-000272d0: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
-000272e0: 2020 2020 2020 2020 2020 204e 6f6e 650a             None.
-000272f0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00027300: 2020 2020 6d6f 6475 6c65 7320 3d20 6469      modules = di
-00027310: 6374 286d 6f64 656c 2e6e 616d 6564 5f6d  ct(model.named_m
-00027320: 6f64 756c 6573 2829 290a 2020 2020 2020  odules()).      
-00027330: 2020 7265 7320 3d20 6469 6374 2829 0a0a    res = dict()..
-00027340: 2020 2020 2020 2020 6966 2061 7070 726f          if appro
-00027350: 6163 6820 3d3d 2027 706f 7374 5f74 7261  ach == 'post_tra
-00027360: 696e 696e 675f 6479 6e61 6d69 635f 7175  ining_dynamic_qu
-00027370: 616e 7427 3a0a 2020 2020 2020 2020 2020  ant':.          
-00027380: 2020 2320 6665 7463 6820 696e 7438 2061    # fetch int8 a
-00027390: 6e64 2066 7033 3220 6f70 7320 7365 7420  nd fp32 ops set 
-000273a0: 6279 204e 6575 7261 6c20 436f 6d70 7265  by Neural Compre
-000273b0: 7373 6f72 2066 726f 6d20 7475 6e65 5f63  ssor from tune_c
-000273c0: 6667 0a20 2020 2020 2020 2020 2020 2066  fg.            f
-000273d0: 6f72 206b 6579 2069 6e20 7475 6e65 5f63  or key in tune_c
-000273e0: 6667 5b27 6f70 275d 3a0a 2020 2020 2020  fg['op']:.      
-000273f0: 2020 2020 2020 2020 2020 6f70 5f74 7970            op_typ
-00027400: 6520 3d20 6b65 795b 315d 0a20 2020 2020  e = key[1].     
-00027410: 2020 2020 2020 2020 2020 2023 6275 696c             #buil
-00027420: 6420 696e 6974 6961 6c20 6469 6374 0a20  d initial dict. 
-00027430: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00027440: 6620 6f70 5f74 7970 6520 6e6f 7420 696e  f op_type not in
-00027450: 2072 6573 2e6b 6579 7328 293a 0a20 2020   res.keys():.   
-00027460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027470: 2072 6573 5b6f 705f 7479 7065 5d20 3d20   res[op_type] = 
-00027480: 7b27 494e 5438 273a 2030 2c20 2742 4631  {'INT8': 0, 'BF1
-00027490: 3627 3a20 302c 2027 4650 3332 273a 2030  6': 0, 'FP32': 0
-000274a0: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
-000274b0: 2020 7661 6c75 6520 3d20 7475 6e65 5f63    value = tune_c
-000274c0: 6667 5b27 6f70 275d 5b6b 6579 5d0a 2020  fg['op'][key].  
-000274d0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-000274e0: 5370 6563 6961 6c20 6361 7365 733a 2051  Special cases: Q
-000274f0: 7561 6e74 5374 7562 2c20 456d 6265 6464  uantStub, Embedd
-00027500: 696e 670a 2020 2020 2020 2020 2020 2020  ing.            
-00027510: 2020 2020 6966 2028 2777 6569 6768 7427      if ('weight'
-00027520: 2069 6e20 7661 6c75 6520 616e 6420 7661   in value and va
-00027530: 6c75 655b 2777 6569 6768 7427 5d5b 2764  lue['weight']['d
-00027540: 7479 7065 275d 203d 3d20 2766 7033 3227  type'] == 'fp32'
-00027550: 2920 6f72 205c 0a20 2020 2020 2020 2020  ) or \.         
-00027560: 2020 2020 2020 2020 2028 2777 6569 6768           ('weigh
-00027570: 7427 206e 6f74 2069 6e20 7661 6c75 6520  t' not in value 
-00027580: 616e 6420 7661 6c75 655b 2761 6374 6976  and value['activ
-00027590: 6174 696f 6e27 5d5b 2764 7479 7065 275d  ation']['dtype']
-000275a0: 203d 3d20 2766 7033 3227 293a 0a20 2020   == 'fp32'):.   
-000275b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000275c0: 2072 6573 5b6f 705f 7479 7065 5d5b 2746   res[op_type]['F
-000275d0: 5033 3227 5d20 2b3d 2031 0a20 2020 2020  P32'] += 1.     
-000275e0: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-000275f0: 7661 6c75 655b 2761 6374 6976 6174 696f  value['activatio
-00027600: 6e27 5d5b 2764 7479 7065 275d 203d 3d20  n']['dtype'] == 
-00027610: 2762 6631 3627 3a20 2023 2070 7261 676d  'bf16':  # pragm
-00027620: 613a 206e 6f20 636f 7665 720a 2020 2020  a: no cover.    
-00027630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027640: 7265 735b 6f70 5f74 7970 655d 5b27 4246  res[op_type]['BF
-00027650: 3136 275d 202b 3d20 310a 2020 2020 2020  16'] += 1.      
-00027660: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00027670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027680: 2020 2020 7265 735b 6f70 5f74 7970 655d      res[op_type]
-00027690: 5b27 494e 5438 275d 202b 3d20 310a 2020  ['INT8'] += 1.  
-000276a0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-000276b0: 2020 2020 2020 2020 7175 616e 7469 7a65          quantize
-000276c0: 645f 6d6f 6465 203d 2046 616c 7365 0a20  d_mode = False. 
-000276d0: 2020 2020 2020 2020 2020 2066 6f72 206e             for n
-000276e0: 6f64 6520 696e 206d 6f64 656c 2e67 7261  ode in model.gra
-000276f0: 7068 2e6e 6f64 6573 3a0a 2020 2020 2020  ph.nodes:.      
-00027700: 2020 2020 2020 2020 2020 6966 206e 6f64            if nod
-00027710: 652e 6f70 203d 3d20 2763 616c 6c5f 6d6f  e.op == 'call_mo
-00027720: 6475 6c65 273a 0a20 2020 2020 2020 2020  dule':.         
-00027730: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
-00027740: 6465 2e74 6172 6765 7420 6e6f 7420 696e  de.target not in
-00027750: 206d 6f64 756c 6573 3a20 2023 2070 7261   modules:  # pra
-00027760: 676d 613a 206e 6f20 636f 7665 720a 2020  gma: no cover.  
-00027770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027780: 2020 2020 2020 636f 6e74 696e 7565 0a20        continue. 
-00027790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000277a0: 2020 206f 705f 636c 6173 7320 3d20 7479     op_class = ty
-000277b0: 7065 286d 6f64 756c 6573 5b6e 6f64 652e  pe(modules[node.
-000277c0: 7461 7267 6574 5d29 0a20 2020 2020 2020  target]).       
-000277d0: 2020 2020 2020 2020 2020 2020 206f 705f               op_
-000277e0: 7479 7065 203d 2073 7472 286f 705f 636c  type = str(op_cl
-000277f0: 6173 732e 5f5f 6e61 6d65 5f5f 290a 2020  ass.__name__).  
-00027800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027810: 2020 6966 2027 7175 616e 7469 7a65 6427    if 'quantized'
-00027820: 2069 6e20 7374 7228 6f70 5f63 6c61 7373   in str(op_class
-00027830: 2920 6f72 2071 7561 6e74 697a 6564 5f6d  ) or quantized_m
-00027840: 6f64 653a 0a20 2020 2020 2020 2020 2020  ode:.           
-00027850: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00027860: 6f70 5f74 7970 6520 6e6f 7420 696e 2072  op_type not in r
-00027870: 6573 2e6b 6579 7328 293a 0a20 2020 2020  es.keys():.     
-00027880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027890: 2020 2020 2020 2072 6573 5b6f 705f 7479         res[op_ty
-000278a0: 7065 5d20 3d20 7b27 494e 5438 273a 2030  pe] = {'INT8': 0
-000278b0: 2c20 2742 4631 3627 3a20 302c 2027 4650  , 'BF16': 0, 'FP
-000278c0: 3332 273a 2030 7d0a 2020 2020 2020 2020  32': 0}.        
-000278d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000278e0: 7265 735b 6f70 5f74 7970 655d 5b27 494e  res[op_type]['IN
-000278f0: 5438 275d 202b 3d20 310a 2020 2020 2020  T8'] += 1.      
-00027900: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00027910: 6966 206f 705f 636c 6173 7320 696e 2073  if op_class in s
-00027920: 656c 662e 7768 6974 655f 6c69 7374 3a0a  elf.white_list:.
-00027930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027940: 2020 2020 2020 2020 6966 206f 705f 7479          if op_ty
-00027950: 7065 206e 6f74 2069 6e20 7265 732e 6b65  pe not in res.ke
-00027960: 7973 2829 3a0a 2020 2020 2020 2020 2020  ys():.          
-00027970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027980: 2020 7265 735b 6f70 5f74 7970 655d 203d    res[op_type] =
-00027990: 207b 2749 4e54 3827 3a20 302c 2027 4246   {'INT8': 0, 'BF
-000279a0: 3136 273a 2030 2c20 2746 5033 3227 3a20  16': 0, 'FP32': 
-000279b0: 307d 0a20 2020 2020 2020 2020 2020 2020  0}.             
-000279c0: 2020 2020 2020 2020 2020 2072 6573 5b6f             res[o
-000279d0: 705f 7479 7065 5d5b 2746 5033 3227 5d20  p_type]['FP32'] 
-000279e0: 2b3d 2031 0a20 2020 2020 2020 2020 2020  += 1.           
-000279f0: 2020 2020 2020 2020 2063 6f6e 7469 6e75           continu
-00027a00: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
-00027a10: 2020 656c 6966 206e 6f64 652e 6f70 203d    elif node.op =
-00027a20: 3d20 2763 616c 6c5f 6675 6e63 7469 6f6e  = 'call_function
-00027a30: 273a 0a20 2020 2020 2020 2020 2020 2020  ':.             
-00027a40: 2020 2020 2020 206f 705f 7479 7065 203d         op_type =
-00027a50: 2073 7472 286e 6f64 652e 7461 7267 6574   str(node.target
-00027a60: 2e5f 5f6e 616d 655f 5f29 0a20 2020 2020  .__name__).     
-00027a70: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-00027a80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00027a90: 2020 2020 206f 705f 7479 7065 203d 206e       op_type = n
-00027aa0: 6f64 652e 7461 7267 6574 0a20 2020 2020  ode.target.     
-00027ab0: 2020 2020 2020 2020 2020 2023 2073 6b69             # ski
-00027ac0: 7020 696e 7075 7420 616e 6420 6f75 7470  p input and outp
-00027ad0: 7574 0a20 2020 2020 2020 2020 2020 2020  ut.             
-00027ae0: 2020 2069 6620 6e6f 7420 2271 7561 6e74     if not "quant
-00027af0: 697a 655f 7065 7222 2069 6e20 6f70 5f74  ize_per" in op_t
-00027b00: 7970 6520 616e 6420 6e6f 7420 7175 616e  ype and not quan
-00027b10: 7469 7a65 645f 6d6f 6465 3a0a 2020 2020  tized_mode:.    
-00027b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027b30: 636f 6e74 696e 7565 0a20 2020 2020 2020  continue.       
-00027b40: 2020 2020 2020 2020 2023 2073 6b69 7020           # skip 
-00027b50: 7a65 726f 5f70 696f 696e 7420 616e 6420  zero_pioint and 
-00027b60: 7363 616c 650a 2020 2020 2020 2020 2020  scale.          
-00027b70: 2020 2020 2020 6966 2022 7a65 726f 5f70        if "zero_p
-00027b80: 6f69 6e74 2220 696e 206f 705f 7479 7065  oint" in op_type
-00027b90: 206f 7220 2273 6361 6c65 2220 696e 206f   or "scale" in o
-00027ba0: 705f 7479 7065 3a0a 2020 2020 2020 2020  p_type:.        
-00027bb0: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-00027bc0: 696e 7565 0a20 2020 2020 2020 2020 2020  inue.           
-00027bd0: 2020 2020 2023 6275 696c 6420 696e 6974       #build init
-00027be0: 6961 6c20 6469 6374 0a20 2020 2020 2020  ial dict.       
-00027bf0: 2020 2020 2020 2020 2069 6620 6f70 5f74           if op_t
-00027c00: 7970 6520 6e6f 7420 696e 2072 6573 2e6b  ype not in res.k
-00027c10: 6579 7328 293a 0a20 2020 2020 2020 2020  eys():.         
-00027c20: 2020 2020 2020 2020 2020 2072 6573 5b6f             res[o
-00027c30: 705f 7479 7065 5d20 3d20 7b27 494e 5438  p_type] = {'INT8
-00027c40: 273a 2030 2c20 2742 4631 3627 3a20 302c  ': 0, 'BF16': 0,
-00027c50: 2027 4650 3332 273a 2030 7d0a 0a20 2020   'FP32': 0}..   
-00027c60: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00027c70: 2271 7561 6e74 697a 655f 7065 7222 2069  "quantize_per" i
-00027c80: 6e20 6f70 5f74 7970 6520 616e 6420 6e6f  n op_type and no
-00027c90: 7420 7175 616e 7469 7a65 645f 6d6f 6465  t quantized_mode
-00027ca0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00027cb0: 2020 2020 2020 7175 616e 7469 7a65 645f        quantized_
-00027cc0: 6d6f 6465 203d 2054 7275 650a 2020 2020  mode = True.    
-00027cd0: 2020 2020 2020 2020 2020 2020 656c 6966              elif
-00027ce0: 2022 6465 7175 616e 7469 7a65 2220 696e   "dequantize" in
-00027cf0: 206f 705f 7479 7065 2061 6e64 2071 7561   op_type and qua
-00027d00: 6e74 697a 6564 5f6d 6f64 653a 0a20 2020  ntized_mode:.   
-00027d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00027d20: 2071 7561 6e74 697a 6564 5f6d 6f64 6520   quantized_mode 
-00027d30: 3d20 4661 6c73 650a 2020 2020 2020 2020  = False.        
-00027d40: 2020 2020 2020 2020 7265 735b 6f70 5f74          res[op_t
-00027d50: 7970 655d 5b27 494e 5438 275d 202b 3d20  ype]['INT8'] += 
-00027d60: 310a 2020 2020 2020 2020 7265 7475 726e  1.        return
-00027d70: 2072 6573 0a0a 2020 2020 6465 6620 5f67   res..    def _g
-00027d80: 6574 5f73 7562 5f6d 6f64 756c 655f 6f70  et_sub_module_op
-00027d90: 5f73 7461 7473 2873 656c 662c 206d 6f64  _stats(self, mod
-00027da0: 656c 2c20 7475 6e65 5f63 6667 2c20 6170  el, tune_cfg, ap
-00027db0: 7072 6f61 6368 2c20 7265 732c 2070 7265  proach, res, pre
-00027dc0: 6669 783d 2727 293a 0a20 2020 2020 2020  fix=''):.       
-00027dd0: 2022 2222 5468 6973 2069 7320 6120 6675   """This is a fu
-00027de0: 6e63 7469 6f6e 2074 6f20 6765 7420 7175  nction to get qu
-00027df0: 616e 7469 7a61 626c 6520 6f70 7320 6f66  antizable ops of
-00027e00: 2073 7562 206d 6f64 756c 6573 2074 6f20   sub modules to 
-00027e10: 7573 6572 2072 6563 7572 7369 7665 6c79  user recursively
-00027e20: 2e0a 2020 2020 2020 2020 4172 6773 3a0a  ..        Args:.
-00027e30: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
-00027e40: 6c20 286f 626a 6563 7429 3a20 696e 7075  l (object): inpu
-00027e50: 7420 6d6f 6465 6c0a 2020 2020 2020 2020  t model.        
-00027e60: 2020 2020 7475 6e65 5f63 6667 2028 6469      tune_cfg (di
-00027e70: 6374 293a 2071 7561 6e74 697a 6174 696f  ct): quantizatio
-00027e80: 6e20 636f 6e66 6967 0a20 2020 2020 2020  n config.       
-00027e90: 2020 2020 2061 7070 726f 6163 6820 2873       approach (s
-00027ea0: 7472 293a 2071 7561 6e74 697a 6174 696f  tr): quantizatio
-00027eb0: 6e20 6170 7072 6f61 6368 0a20 2020 2020  n approach.     
-00027ec0: 2020 2020 2020 2072 6573 2028 6469 6374         res (dict
-00027ed0: 2920 3a20 636f 6e74 6169 6e73 2072 6573  ) : contains res
-00027ee0: 756c 7420 6f66 2071 7561 6e74 697a 6162  ult of quantizab
-00027ef0: 6c65 206f 7073 0a20 2020 2020 2020 2020  le ops.         
-00027f00: 2020 2070 7265 6669 7820 2873 7472 696e     prefix (strin
-00027f10: 6729 3a20 7072 6566 6978 206f 6620 6f70  g): prefix of op
-00027f20: 206e 616d 650a 2020 2020 2020 2020 5265   name.        Re
-00027f30: 7475 726e 733a 0a20 2020 2020 2020 2020  turns:.         
-00027f40: 2020 204e 6f6e 650a 2020 2020 2020 2020     None.        
-00027f50: 2222 220a 2020 2020 2020 2020 666f 7220  """.        for 
-00027f60: 6e61 6d65 2c20 6d6f 6475 6c65 2069 6e20  name, module in 
-00027f70: 6d6f 6465 6c2e 6e61 6d65 645f 6368 696c  model.named_chil
-00027f80: 6472 656e 2829 3a0a 2020 2020 2020 2020  dren():.        
-00027f90: 2020 2020 6f70 5f6e 616d 6520 3d20 7072      op_name = pr
-00027fa0: 6566 6978 202b 2027 2e27 202b 206e 616d  efix + '.' + nam
-00027fb0: 6520 6966 2070 7265 6669 7820 213d 2027  e if prefix != '
-00027fc0: 2720 656c 7365 206e 616d 650a 2020 2020  ' else name.    
-00027fd0: 2020 2020 2020 2020 6966 206f 705f 6e61          if op_na
-00027fe0: 6d65 2069 6e20 7365 6c66 2e73 7562 5f6d  me in self.sub_m
-00027ff0: 6f64 756c 655f 6c69 7374 3a0a 2020 2020  odule_list:.    
-00028000: 2020 2020 2020 2020 2020 2020 6d6f 6475              modu
-00028010: 6c65 5f72 6573 203d 2073 656c 662e 5f67  le_res = self._g
-00028020: 6574 5f6d 6f64 756c 655f 6f70 5f73 7461  et_module_op_sta
-00028030: 7473 286d 6f64 756c 652c 2074 756e 655f  ts(module, tune_
-00028040: 6366 672c 2061 7070 726f 6163 6829 0a20  cfg, approach). 
-00028050: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00028060: 6f72 206b 6579 2c20 7661 6c75 6520 696e  or key, value in
-00028070: 206d 6f64 756c 655f 7265 732e 6974 656d   module_res.item
-00028080: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
-00028090: 2020 2020 2020 2020 2069 6620 6b65 7920           if key 
-000280a0: 696e 2072 6573 3a0a 2020 2020 2020 2020  in res:.        
-000280b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000280c0: 7265 735b 6b65 795d 203d 207b 6b3a 2072  res[key] = {k: r
-000280d0: 6573 5b6b 6579 5d5b 6b5d 202b 2076 2066  es[key][k] + v f
-000280e0: 6f72 206b 2c20 7620 696e 2076 616c 7565  or k, v in value
-000280f0: 2e69 7465 6d73 2829 7d0a 2020 2020 2020  .items()}.      
-00028100: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00028110: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00028120: 2020 2020 2020 2020 2020 2020 7265 735b              res[
-00028130: 6b65 795d 203d 2076 616c 7565 0a20 2020  key] = value.   
-00028140: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00028150: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00028160: 656c 662e 5f67 6574 5f73 7562 5f6d 6f64  elf._get_sub_mod
-00028170: 756c 655f 6f70 5f73 7461 7473 286d 6f64  ule_op_stats(mod
-00028180: 756c 652c 2074 756e 655f 6366 672c 2061  ule, tune_cfg, a
-00028190: 7070 726f 6163 682c 2072 6573 2c20 6f70  pproach, res, op
-000281a0: 5f6e 616d 6529 0a0a 2020 2020 6465 6620  _name)..    def 
-000281b0: 5f64 756d 705f 6d6f 6465 6c5f 6f70 5f73  _dump_model_op_s
-000281c0: 7461 7473 2873 656c 662c 206d 6f64 656c  tats(self, model
-000281d0: 2c20 7475 6e65 5f63 6667 2c20 6170 7072  , tune_cfg, appr
-000281e0: 6f61 6368 293a 0a20 2020 2020 2020 2022  oach):.        "
-000281f0: 2222 5468 6973 2069 7320 6120 6675 6e63  ""This is a func
-00028200: 7469 6f6e 2074 6f20 6475 6d70 2071 7561  tion to dump qua
-00028210: 6e74 697a 6162 6c65 206f 7073 206f 6620  ntizable ops of 
-00028220: 6d6f 6465 6c20 746f 2075 7365 722e 0a20  model to user.. 
-00028230: 2020 2020 2020 2041 7267 733a 0a20 2020         Args:.   
-00028240: 2020 2020 2020 2020 206d 6f64 656c 2028           model (
-00028250: 6f62 6a65 6374 293a 2069 6e70 7574 206d  object): input m
-00028260: 6f64 656c 0a20 2020 2020 2020 2020 2020  odel.           
-00028270: 2074 756e 655f 6366 6720 2864 6963 7429   tune_cfg (dict)
-00028280: 3a20 7175 616e 7469 7a61 7469 6f6e 2063  : quantization c
-00028290: 6f6e 6669 670a 2020 2020 2020 2020 2020  onfig.          
-000282a0: 2020 6170 7072 6f61 6368 2028 7374 7229    approach (str)
-000282b0: 3a20 7175 616e 7469 7a61 7469 6f6e 2061  : quantization a
-000282c0: 7070 726f 6163 680a 2020 2020 2020 2020  pproach.        
-000282d0: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
-000282e0: 2020 2020 204e 6f6e 650a 2020 2020 2020       None.      
-000282f0: 2020 2222 220a 2020 2020 2020 2020 6966    """.        if
-00028300: 2073 656c 662e 7375 625f 6d6f 6475 6c65   self.sub_module
-00028310: 5f6c 6973 7420 6973 204e 6f6e 6520 6f72  _list is None or
-00028320: 205c 0a20 2020 2020 2020 2020 2073 656c   \.          sel
-00028330: 662e 6170 7072 6f61 6368 203d 3d20 2770  f.approach == 'p
-00028340: 6f73 745f 7472 6169 6e69 6e67 5f64 796e  ost_training_dyn
-00028350: 616d 6963 5f71 7561 6e74 273a 0a20 2020  amic_quant':.   
-00028360: 2020 2020 2020 2020 2072 6573 203d 2073           res = s
-00028370: 656c 662e 5f67 6574 5f6d 6f64 756c 655f  elf._get_module_
-00028380: 6f70 5f73 7461 7473 286d 6f64 656c 2c20  op_stats(model, 
-00028390: 7475 6e65 5f63 6667 2c20 6170 7072 6f61  tune_cfg, approa
-000283a0: 6368 290a 2020 2020 2020 2020 656c 7365  ch).        else
-000283b0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
-000283c0: 7320 3d20 6469 6374 2829 0a20 2020 2020  s = dict().     
-000283d0: 2020 2020 2020 2073 656c 662e 5f67 6574         self._get
-000283e0: 5f73 7562 5f6d 6f64 756c 655f 6f70 5f73  _sub_module_op_s
-000283f0: 7461 7473 286d 6f64 656c 2c20 7475 6e65  tats(model, tune
-00028400: 5f63 6667 2c20 6170 7072 6f61 6368 2c20  _cfg, approach, 
-00028410: 7265 7329 0a0a 2020 2020 2020 2020 6966  res)..        if
-00028420: 2073 656c 662e 7573 655f 6266 3136 2061   self.use_bf16 a
-00028430: 6e64 2028 7365 6c66 2e76 6572 7369 6f6e  nd (self.version
-00028440: 2e72 656c 6561 7365 203e 3d20 5665 7273  .release >= Vers
-00028450: 696f 6e28 2231 2e31 312e 3022 292e 7265  ion("1.11.0").re
-00028460: 6c65 6173 6529 2061 6e64 205c 0a20 2020  lease) and \.   
-00028470: 2020 2020 2020 2020 2028 4370 7549 6e66           (CpuInf
-00028480: 6f28 292e 6266 3136 206f 7220 6f73 2e67  o().bf16 or os.g
-00028490: 6574 656e 7628 2746 4f52 4345 5f42 4631  etenv('FORCE_BF1
-000284a0: 3627 2920 3d3d 2027 3127 293a 2023 2070  6') == '1'): # p
-000284b0: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
-000284c0: 2020 2020 2020 2020 2020 2020 6266 3136              bf16
-000284d0: 5f6f 7073 5f6c 6973 7420 3d20 7475 6e65  _ops_list = tune
-000284e0: 5f63 6667 5b27 6266 3136 5f6f 7073 5f6c  _cfg['bf16_ops_l
-000284f0: 6973 7427 5d0a 2020 2020 2020 2020 2020  ist'].          
-00028500: 2020 6966 206c 656e 2862 6631 365f 6f70    if len(bf16_op
-00028510: 735f 6c69 7374 2920 3e20 303a 0a20 2020  s_list) > 0:.   
-00028520: 2020 2020 2020 2020 2020 2020 2066 6f72               for
-00028530: 2062 6631 365f 6f70 2069 6e20 6266 3136   bf16_op in bf16
-00028540: 5f6f 7073 5f6c 6973 743a 0a20 2020 2020  _ops_list:.     
-00028550: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00028560: 705f 7479 7065 203d 2062 6631 365f 6f70  p_type = bf16_op
-00028570: 5b31 5d0a 2020 2020 2020 2020 2020 2020  [1].            
-00028580: 2020 2020 2020 2020 6966 206f 705f 7479          if op_ty
-00028590: 7065 2069 6e20 7265 732e 6b65 7973 2829  pe in res.keys()
-000285a0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000285b0: 2020 2020 2020 2020 2020 7265 735b 6f70            res[op
-000285c0: 5f74 7970 655d 5b27 4246 3136 275d 202b  _type]['BF16'] +
-000285d0: 3d20 310a 2020 2020 2020 2020 2020 2020  = 1.            
-000285e0: 2020 2020 2020 2020 2020 2020 6966 2072              if r
-000285f0: 6573 5b6f 705f 7479 7065 5d5b 2746 5033  es[op_type]['FP3
-00028600: 3227 5d20 3e20 303a 0a20 2020 2020 2020  2'] > 0:.       
-00028610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028620: 2020 2020 2072 6573 5b6f 705f 7479 7065       res[op_type
-00028630: 5d5b 2746 5033 3227 5d20 2d3d 2031 0a20  ]['FP32'] -= 1. 
-00028640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028650: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00028660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028670: 2072 6573 5b6f 705f 7479 7065 5d20 3d20   res[op_type] = 
-00028680: 7b27 494e 5438 273a 2030 2c20 2742 4631  {'INT8': 0, 'BF1
-00028690: 3627 3a20 312c 2027 4650 3332 273a 2030  6': 1, 'FP32': 0
-000286a0: 7d0a 0a0a 2020 2020 2020 2020 6f75 7470  }...        outp
-000286b0: 7574 5f64 6174 6120 3d20 5b5b 0a20 2020  ut_data = [[.   
-000286c0: 2020 2020 2020 2020 206f 705f 7479 7065           op_type
-000286d0: 2c0a 2020 2020 2020 2020 2020 2020 7375  ,.            su
-000286e0: 6d28 7265 735b 6f70 5f74 7970 655d 2e76  m(res[op_type].v
-000286f0: 616c 7565 7328 2929 2c20 7265 735b 6f70  alues()), res[op
-00028700: 5f74 7970 655d 5b27 494e 5438 275d 2c20  _type]['INT8'], 
-00028710: 7265 735b 6f70 5f74 7970 655d 5b27 4246  res[op_type]['BF
-00028720: 3136 275d 2c0a 2020 2020 2020 2020 2020  16'],.          
-00028730: 2020 7265 735b 6f70 5f74 7970 655d 5b27    res[op_type]['
-00028740: 4650 3332 275d 0a20 2020 2020 2020 205d  FP32'].        ]
-00028750: 2066 6f72 206f 705f 7479 7065 2069 6e20   for op_type in 
-00028760: 7265 732e 6b65 7973 2829 5d0a 0a20 2020  res.keys()]..   
-00028770: 2020 2020 2053 7461 7469 7374 6963 7328       Statistics(
-00028780: 6f75 7470 7574 5f64 6174 612c 0a20 2020  output_data,.   
-00028790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000287a0: 6865 6164 6572 3d27 4d69 7865 6420 5072  header='Mixed Pr
-000287b0: 6563 6973 696f 6e20 5374 6174 6973 7469  ecision Statisti
-000287c0: 6373 272c 0a20 2020 2020 2020 2020 2020  cs',.           
-000287d0: 2020 2020 2020 2020 6669 656c 645f 6e61          field_na
-000287e0: 6d65 733d 5b22 4f70 2054 7970 6522 2c20  mes=["Op Type", 
-000287f0: 2254 6f74 616c 222c 2022 494e 5438 222c  "Total", "INT8",
-00028800: 2022 4246 3136 222c 2022 4650 3332 225d   "BF16", "FP32"]
-00028810: 292e 7072 696e 745f 7374 6174 2829 0a0a  ).print_stat()..
-00028820: 2020 2020 6465 6620 5f67 6574 5f71 7561      def _get_qua
-00028830: 6e74 697a 6162 6c65 5f6f 7073 5f72 6563  ntizable_ops_rec
-00028840: 7572 7369 7665 6c79 2873 656c 662c 206d  ursively(self, m
-00028850: 6f64 656c 2c20 7072 6566 6978 2c20 7175  odel, prefix, qu
-00028860: 616e 7469 7a61 626c 655f 6f70 7329 3a0a  antizable_ops):.
-00028870: 2020 2020 2020 2020 2222 2254 6869 7320          """This 
-00028880: 6973 2061 2068 656c 7065 7220 6675 6e63  is a helper func
-00028890: 7469 6f6e 2066 6f72 2060 7175 6572 795f  tion for `query_
-000288a0: 6677 5f63 6170 6162 696c 6974 7960 2c0a  fw_capability`,.
-000288b0: 2020 2020 2020 2020 2020 2061 6e64 2069             and i
-000288c0: 7420 7769 6c6c 2067 6574 2061 6c6c 2071  t will get all q
-000288d0: 7561 6e74 697a 6162 6c65 206f 7073 2066  uantizable ops f
-000288e0: 726f 6d20 6d6f 6465 6c2e 0a0a 2020 2020  rom model...    
-000288f0: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
-00028900: 2020 2020 2020 6d6f 6465 6c20 286f 626a        model (obj
-00028910: 6563 7429 3a20 696e 7075 7420 6d6f 6465  ect): input mode
-00028920: 6c0a 2020 2020 2020 2020 2020 2020 7072  l.            pr
-00028930: 6566 6978 2028 7374 7269 6e67 293a 2070  efix (string): p
-00028940: 7265 6669 7820 6f66 206f 7020 6e61 6d65  refix of op name
-00028950: 0a20 2020 2020 2020 2020 2020 2071 7561  .            qua
-00028960: 6e74 697a 6162 6c65 5f6f 7073 2028 6c69  ntizable_ops (li
-00028970: 7374 293a 206c 6973 7420 6f66 2071 7561  st): list of qua
-00028980: 6e74 697a 6162 6c65 206f 7073 2066 726f  ntizable ops fro
-00028990: 6d20 6d6f 6465 6c20 696e 636c 7564 6520  m model include 
-000289a0: 6f70 206e 616d 6520 616e 6420 7479 7065  op name and type
-000289b0: 2e0a 0a20 2020 2020 2020 2052 6574 7572  ...        Retur
-000289c0: 6e73 3a0a 2020 2020 2020 2020 2020 2020  ns:.            
-000289d0: 4e6f 6e65 0a20 2020 2020 2020 2022 2222  None.        """
-000289e0: 0a20 2020 2020 2020 206d 6f64 756c 655f  .        module_
-000289f0: 6469 6374 203d 2064 6963 7428 6d6f 6465  dict = dict(mode
-00028a00: 6c2e 6e61 6d65 645f 6d6f 6475 6c65 7328  l.named_modules(
-00028a10: 2929 0a20 2020 2020 2020 2066 6f72 206f  )).        for o
-00028a20: 705f 6e61 6d65 2c20 6368 696c 6420 696e  p_name, child in
-00028a30: 206d 6f64 656c 2e6e 616d 6564 5f6d 6f64   model.named_mod
-00028a40: 756c 6573 2829 3a0a 2020 2020 2020 2020  ules():.        
-00028a50: 2020 2020 6966 2073 656c 662e 6973 5f66      if self.is_f
-00028a60: 7573 6564 5f6d 6f64 756c 6528 6368 696c  used_module(chil
-00028a70: 6429 3a0a 2020 2020 2020 2020 2020 2020  d):.            
-00028a80: 2020 2020 666f 7220 6e61 6d65 2c20 5f20      for name, _ 
-00028a90: 696e 2063 6869 6c64 2e6e 616d 6564 5f63  in child.named_c
-00028aa0: 6869 6c64 7265 6e28 293a 0a20 2020 2020  hildren():.     
-00028ab0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-00028ac0: 6f64 756c 655f 7072 6566 6978 203d 206f  odule_prefix = o
-00028ad0: 705f 6e61 6d65 202b 2027 2e27 202b 206e  p_name + '.' + n
-00028ae0: 616d 650a 2020 2020 2020 2020 2020 2020  ame.            
-00028af0: 2020 2020 2020 2020 6966 206d 6f64 756c          if modul
-00028b00: 655f 7072 6566 6978 2069 6e20 6d6f 6475  e_prefix in modu
-00028b10: 6c65 5f64 6963 743a 0a20 2020 2020 2020  le_dict:.       
-00028b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028b30: 206d 6f64 756c 655f 6469 6374 2e70 6f70   module_dict.pop
-00028b40: 286d 6f64 756c 655f 7072 6566 6978 2920  (module_prefix) 
-00028b50: 2023 2072 656d 6f76 6520 7375 622d 6d6f   # remove sub-mo
-00028b60: 6475 6c65 7320 6f66 2066 7573 6564 206d  dules of fused m
-00028b70: 6f64 756c 6573 0a0a 2020 2020 2020 2020  odules..        
-00028b80: 666f 7220 6f70 5f6e 616d 652c 2063 6869  for op_name, chi
-00028b90: 6c64 2069 6e20 6d6f 6475 6c65 5f64 6963  ld in module_dic
-00028ba0: 742e 6974 656d 7328 293a 0a20 2020 2020  t.items():.     
-00028bb0: 2020 2020 2020 2069 6620 7479 7065 2863         if type(c
-00028bc0: 6869 6c64 2920 696e 2073 656c 662e 7768  hild) in self.wh
-00028bd0: 6974 655f 6c69 7374 205c 0a20 2020 2020  ite_list \.     
-00028be0: 2020 2020 2020 2020 2020 616e 6420 7479            and ty
-00028bf0: 7065 2863 6869 6c64 2920 213d 2074 6f72  pe(child) != tor
-00028c00: 6368 2e6e 6e2e 5365 7175 656e 7469 616c  ch.nn.Sequential
-00028c10: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00028c20: 2020 616e 6420 7479 7065 2863 6869 6c64    and type(child
-00028c30: 2920 213d 2074 6f72 6368 2e71 7561 6e74  ) != torch.quant
-00028c40: 697a 6174 696f 6e2e 7374 7562 732e 4465  ization.stubs.De
-00028c50: 5175 616e 7453 7475 623a 0a20 2020 2020  QuantStub:.     
-00028c60: 2020 2020 2020 2020 2020 2071 7561 6e74             quant
-00028c70: 697a 6162 6c65 5f6f 7073 2e61 7070 656e  izable_ops.appen
-00028c80: 6428 0a20 2020 2020 2020 2020 2020 2020  d(.             
-00028c90: 2020 2020 2020 2028 6f70 5f6e 616d 652c         (op_name,
-00028ca0: 2075 6e69 6679 5f6f 705f 7479 7065 5f6d   unify_op_type_m
-00028cb0: 6170 7069 6e67 5b73 7472 2863 6869 6c64  apping[str(child
-00028cc0: 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e 616d  .__class__.__nam
-00028cd0: 655f 5f29 5d0a 2020 2020 2020 2020 2020  e__)].          
-00028ce0: 2020 2020 2020 2020 2020 2069 6620 7374             if st
-00028cf0: 7228 6368 696c 642e 5f5f 636c 6173 735f  r(child.__class_
-00028d00: 5f2e 5f5f 6e61 6d65 5f5f 2920 696e 2075  _.__name__) in u
-00028d10: 6e69 6679 5f6f 705f 7479 7065 5f6d 6170  nify_op_type_map
-00028d20: 7069 6e67 2065 6c73 6520 7374 7228 0a20  ping else str(. 
-00028d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028d40: 2020 2020 2020 2020 6368 696c 642e 5f5f          child.__
-00028d50: 636c 6173 735f 5f2e 5f5f 6e61 6d65 5f5f  class__.__name__
-00028d60: 2929 290a 0a20 2020 2064 6566 205f 6765  )))..    def _ge
-00028d70: 745f 6d6f 6475 6c65 5f73 6361 6c65 5f7a  t_module_scale_z
-00028d80: 6572 6f70 6f69 6e74 2873 656c 662c 206d  eropoint(self, m
-00028d90: 6f64 656c 2c20 7475 6e65 5f63 6667 2c20  odel, tune_cfg, 
-00028da0: 7072 6566 6978 3d27 2729 3a0a 2020 2020  prefix=''):.    
-00028db0: 2020 2020 2222 2267 6574 2061 6374 6976      """get activ
-00028dc0: 6174 696f 6e20 7363 616c 6520 616e 6420  ation scale and 
-00028dd0: 7a65 726f 5f70 6f69 6e74 2066 6f72 2063  zero_point for c
-00028de0: 6f6e 7665 7274 6564 206d 6f64 756c 652e  onverted module.
-00028df0: 0a0a 2020 2020 2020 2020 4172 6773 3a0a  ..        Args:.
-00028e00: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
-00028e10: 6c20 2864 6972 293a 2049 6e74 3820 6d6f  l (dir): Int8 mo
-00028e20: 6465 6c20 636f 6e76 6572 7465 6420 6672  del converted fr
-00028e30: 6f6d 2066 7033 3220 6d6f 6465 6c2e 0a20  om fp32 model.. 
-00028e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028e50: 2020 2020 2020 2020 7363 616c 6520 616e          scale an
-00028e60: 6420 7a65 726f 5f70 6f69 6e74 2069 7320  d zero_point is 
-00028e70: 7365 7420 7769 7468 2063 616c 6962 7261  set with calibra
-00028e80: 7469 6f6e 2066 6f72 2065 6163 6820 6d6f  tion for each mo
-00028e90: 6475 6c65 0a20 2020 2020 2020 2020 2020  dule.           
-00028ea0: 2074 756e 655f 6366 6720 286f 626a 6563   tune_cfg (objec
-00028eb0: 7429 3a20 5468 6973 2066 696c 6520 7361  t): This file sa
-00028ec0: 7665 7320 7363 616c 6520 616e 6420 7a65  ves scale and ze
-00028ed0: 726f 5f70 6f69 6e74 206f 6620 0a20 2020  ro_point of .   
-00028ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028ef0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00028f00: 7574 2061 6374 6976 6174 696f 6e20 6f66  ut activation of
-00028f10: 2065 6163 6820 7175 616e 7469 7a65 6420   each quantized 
-00028f20: 6d6f 6475 6c65 2e0a 2020 2020 2020 2020  module..        
-00028f30: 2020 2020 7072 6566 6978 2028 7374 7269      prefix (stri
-00028f40: 6e67 293a 2070 7265 6669 7820 6f66 206f  ng): prefix of o
-00028f50: 7020 6e61 6d65 0a0a 2020 2020 2020 2020  p name..        
-00028f60: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
-00028f70: 2020 2020 204e 6f6e 650a 2020 2020 2020       None.      
-00028f80: 2020 2222 220a 2020 2020 2020 2020 2320    """.        # 
-00028f90: 6765 7420 7363 616c 6520 616e 6420 7a65  get scale and ze
-00028fa0: 726f 5f70 6f69 6e74 206f 6620 6d6f 6475  ro_point of modu
-00028fb0: 6c65 732e 0a20 2020 2020 2020 206d 6f64  les..        mod
-00028fc0: 756c 6573 203d 2064 6963 7428 6d6f 6465  ules = dict(mode
-00028fd0: 6c2e 6e61 6d65 645f 6d6f 6475 6c65 7328  l.named_modules(
-00028fe0: 2929 0a20 2020 2020 2020 2066 6f72 206b  )).        for k
-00028ff0: 6579 2069 6e20 7475 6e65 5f63 6667 5b27  ey in tune_cfg['
-00029000: 6f70 275d 3a0a 2020 2020 2020 2020 2020  op']:.          
-00029010: 2020 6966 2070 7265 6669 783a 0a20 2020    if prefix:.   
-00029020: 2020 2020 2020 2020 2020 2020 2073 7562               sub
-00029030: 5f6e 616d 6520 3d20 6b65 795b 305d 2e72  _name = key[0].r
-00029040: 6570 6c61 6365 2870 7265 6669 7820 2b20  eplace(prefix + 
-00029050: 272e 272c 2027 272c 2031 290a 2020 2020  '.', '', 1).    
-00029060: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00029070: 2020 2020 2020 2020 2020 2020 2020 7375                su
-00029080: 625f 6e61 6d65 203d 206b 6579 5b30 5d0a  b_name = key[0].
-00029090: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-000290a0: 7562 5f6e 616d 6520 696e 206d 6f64 756c  ub_name in modul
-000290b0: 6573 3a0a 2020 2020 2020 2020 2020 2020  es:.            
-000290c0: 2020 2020 7661 6c75 6520 3d20 7475 6e65      value = tune
-000290d0: 5f63 6667 5b27 6f70 275d 5b6b 6579 5d0a  _cfg['op'][key].
-000290e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000290f0: 6173 7365 7274 2069 7369 6e73 7461 6e63  assert isinstanc
-00029100: 6528 7661 6c75 652c 2064 6963 7429 0a20  e(value, dict). 
-00029110: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00029120: 6620 6861 7361 7474 7228 6d6f 6475 6c65  f hasattr(module
-00029130: 735b 7375 625f 6e61 6d65 5d2c 2027 7363  s[sub_name], 'sc
-00029140: 616c 6527 293a 0a20 2020 2020 2020 2020  ale'):.         
-00029150: 2020 2020 2020 2020 2020 2076 616c 7565             value
-00029160: 5b27 6163 7469 7661 7469 6f6e 275d 5b27  ['activation']['
-00029170: 7363 616c 6527 5d20 3d20 666c 6f61 7428  scale'] = float(
-00029180: 6d6f 6475 6c65 735b 7375 625f 6e61 6d65  modules[sub_name
-00029190: 5d2e 7363 616c 6529 0a20 2020 2020 2020  ].scale).       
-000291a0: 2020 2020 2020 2020 2069 6620 6861 7361           if hasa
-000291b0: 7474 7228 6d6f 6475 6c65 735b 7375 625f  ttr(modules[sub_
-000291c0: 6e61 6d65 5d2c 2027 7a65 726f 5f70 6f69  name], 'zero_poi
-000291d0: 6e74 2729 3a0a 2020 2020 2020 2020 2020  nt'):.          
-000291e0: 2020 2020 2020 2020 2020 7661 6c75 655b            value[
-000291f0: 2761 6374 6976 6174 696f 6e27 5d5b 277a  'activation']['z
-00029200: 6572 6f5f 706f 696e 7427 5d20 3d20 696e  ero_point'] = in
-00029210: 7428 6d6f 6475 6c65 735b 7375 625f 6e61  t(modules[sub_na
-00029220: 6d65 5d2e 7a65 726f 5f70 6f69 6e74 290a  me].zero_point).
-00029230: 2020 2020 2020 2020 2320 6765 7420 7363          # get sc
-00029240: 616c 6520 616e 6420 7a65 726f 5f70 6f69  ale and zero_poi
-00029250: 6e74 206f 6620 6765 7461 7474 7220 6f70  nt of getattr op
-00029260: 7320 286c 696b 6520 7175 616e 7469 7a65  s (like quantize
-00029270: 206f 7073 292e 0a20 2020 2020 2020 2066   ops)..        f
-00029280: 6f72 206e 6f64 6520 696e 206d 6f64 656c  or node in model
-00029290: 2e67 7261 7068 2e6e 6f64 6573 3a0a 2020  .graph.nodes:.  
-000292a0: 2020 2020 2020 2020 2020 6966 206e 6f64            if nod
-000292b0: 652e 6f70 203d 3d20 2767 6574 5f61 7474  e.op == 'get_att
-000292c0: 7227 3a0a 2020 2020 2020 2020 2020 2020  r':.            
-000292d0: 2020 2020 6966 2070 7265 6669 783a 0a20      if prefix:. 
-000292e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000292f0: 2020 2073 7562 5f6e 616d 6520 3d20 7072     sub_name = pr
-00029300: 6566 6978 202b 2027 2d2d 2720 2b20 6e6f  efix + '--' + no
-00029310: 6465 2e74 6172 6765 740a 2020 2020 2020  de.target.      
-00029320: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00029330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00029340: 2020 2020 7375 625f 6e61 6d65 203d 206e      sub_name = n
-00029350: 6f64 652e 7461 7267 6574 0a20 2020 2020  ode.target.     
-00029360: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
-00029370: 7420 6861 7361 7474 7228 6d6f 6465 6c2c  t hasattr(model,
-00029380: 206e 6f64 652e 7461 7267 6574 293a 0a20   node.target):. 
-00029390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000293a0: 2020 2063 6f6e 7469 6e75 650a 2020 2020     continue.    
-000293b0: 2020 2020 2020 2020 2020 2020 6966 2027              if '
-000293c0: 7363 616c 6527 2069 6e20 6e6f 6465 2e74  scale' in node.t
-000293d0: 6172 6765 743a 0a20 2020 2020 2020 2020  arget:.         
-000293e0: 2020 2020 2020 2020 2020 2074 756e 655f             tune_
-000293f0: 6366 675b 2767 6574 5f61 7474 7227 5d5b  cfg['get_attr'][
-00029400: 7375 625f 6e61 6d65 5d20 3d20 666c 6f61  sub_name] = floa
-00029410: 7428 6765 7461 7474 7228 6d6f 6465 6c2c  t(getattr(model,
-00029420: 206e 6f64 652e 7461 7267 6574 2929 0a20   node.target)). 
-00029430: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00029440: 6c69 6620 277a 6572 6f5f 706f 696e 7427  lif 'zero_point'
-00029450: 2069 6e20 6e6f 6465 2e74 6172 6765 743a   in node.target:
-00029460: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00029470: 2020 2020 2074 756e 655f 6366 675b 2767       tune_cfg['g
-00029480: 6574 5f61 7474 7227 5d5b 7375 625f 6e61  et_attr'][sub_na
-00029490: 6d65 5d20 3d20 696e 7428 6765 7461 7474  me] = int(getatt
-000294a0: 7228 6d6f 6465 6c2c 206e 6f64 652e 7461  r(model, node.ta
-000294b0: 7267 6574 2929 0a20 2020 2020 2020 2020  rget)).         
-000294c0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-000294d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000294e0: 2070 6173 730a 0a20 2020 2064 6566 205f   pass..    def _
-000294f0: 6765 745f 7375 625f 6d6f 6475 6c65 5f73  get_sub_module_s
-00029500: 6361 6c65 5f7a 6572 6f70 6f69 6e74 2873  cale_zeropoint(s
-00029510: 656c 662c 206d 6f64 656c 2c20 7475 6e65  elf, model, tune
-00029520: 5f63 6667 2c20 7072 6566 6978 3d27 2729  _cfg, prefix='')
-00029530: 3a0a 2020 2020 2020 2020 2222 2267 6574  :.        """get
-00029540: 2061 6374 6976 6174 696f 6e20 7363 616c   activation scal
-00029550: 6520 616e 6420 7a65 726f 5f70 6f69 6e74  e and zero_point
-00029560: 2066 6f72 2063 6f6e 7665 7274 6564 2073   for converted s
-00029570: 7562 206d 6f64 756c 6573 2072 6563 7572  ub modules recur
-00029580: 7369 7665 6c79 2e0a 0a20 2020 2020 2020  sively...       
-00029590: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
-000295a0: 2020 206d 6f64 656c 2028 6469 7229 3a20     model (dir): 
-000295b0: 496e 7438 206d 6f64 656c 2063 6f6e 7665  Int8 model conve
-000295c0: 7274 6564 2066 726f 6d20 6670 3332 206d  rted from fp32 m
-000295d0: 6f64 656c 2e0a 2020 2020 2020 2020 2020  odel..          
-000295e0: 2020 2020 2020 2020 2020 2020 2020 7363                sc
-000295f0: 616c 6520 616e 6420 7a65 726f 5f70 6f69  ale and zero_poi
-00029600: 6e74 2069 7320 7365 7420 7769 7468 2063  nt is set with c
-00029610: 616c 6962 7261 7469 6f6e 2066 6f72 2065  alibration for e
-00029620: 6163 6820 6d6f 6475 6c65 0a20 2020 2020  ach module.     
-00029630: 2020 2020 2020 2074 756e 655f 6366 6720         tune_cfg 
-00029640: 286f 626a 6563 7429 3a20 5468 6973 2066  (object): This f
-00029650: 696c 6520 7361 7665 7320 7363 616c 6520  ile saves scale 
-00029660: 616e 6420 7a65 726f 5f70 6f69 6e74 206f  and zero_point o
-00029670: 6620 5c0a 2020 2020 2020 2020 2020 2020  f \.            
-00029680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00029690: 6f75 7470 7574 2061 6374 6976 6174 696f  output activatio
-000296a0: 6e20 6f66 2065 6163 6820 7175 616e 7469  n of each quanti
-000296b0: 7a65 6420 6d6f 6475 6c65 2e0a 2020 2020  zed module..    
-000296c0: 2020 2020 2020 2020 7072 6566 6978 2028          prefix (
-000296d0: 7374 7269 6e67 293a 2070 7265 6669 7820  string): prefix 
-000296e0: 6f66 206f 7020 6e61 6d65 0a0a 2020 2020  of op name..    
-000296f0: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
-00029700: 2020 2020 2020 2020 204e 6f6e 650a 2020           None.  
-00029710: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-00029720: 2020 666f 7220 6e61 6d65 2c20 6d6f 6475    for name, modu
-00029730: 6c65 2069 6e20 6d6f 6465 6c2e 6e61 6d65  le in model.name
-00029740: 645f 6368 696c 6472 656e 2829 3a0a 2020  d_children():.  
-00029750: 2020 2020 2020 2020 2020 6f70 5f6e 616d            op_nam
-00029760: 6520 3d20 7072 6566 6978 202b 2027 2e27  e = prefix + '.'
-00029770: 202b 206e 616d 6520 6966 2070 7265 6669   + name if prefi
-00029780: 7820 213d 2027 2720 656c 7365 206e 616d  x != '' else nam
-00029790: 650a 2020 2020 2020 2020 2020 2020 6966  e.            if
-000297a0: 206f 705f 6e61 6d65 2069 6e20 7365 6c66   op_name in self
-000297b0: 2e73 7562 5f6d 6f64 756c 655f 6c69 7374  .sub_module_list
-000297c0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000297d0: 2020 7365 6c66 2e5f 6765 745f 6d6f 6475    self._get_modu
-000297e0: 6c65 5f73 6361 6c65 5f7a 6572 6f70 6f69  le_scale_zeropoi
-000297f0: 6e74 286d 6f64 756c 652c 2074 756e 655f  nt(module, tune_
-00029800: 6366 672c 206f 705f 6e61 6d65 290a 2020  cfg, op_name).  
-00029810: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00029820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00029830: 7365 6c66 2e5f 6765 745f 7375 625f 6d6f  self._get_sub_mo
-00029840: 6475 6c65 5f73 6361 6c65 5f7a 6572 6f70  dule_scale_zerop
-00029850: 6f69 6e74 286d 6f64 756c 652c 2074 756e  oint(module, tun
-00029860: 655f 6366 672c 206f 705f 6e61 6d65 290a  e_cfg, op_name).
-00029870: 0a20 2020 2064 6566 205f 6765 745f 7363  .    def _get_sc
-00029880: 616c 655f 7a65 726f 706f 696e 7428 7365  ale_zeropoint(se
-00029890: 6c66 2c20 6d6f 6465 6c2c 2074 756e 655f  lf, model, tune_
-000298a0: 6366 6729 3a0a 2020 2020 2020 2020 2222  cfg):.        ""
-000298b0: 2267 6574 2061 6374 6976 6174 696f 6e20  "get activation 
-000298c0: 7363 616c 6520 616e 6420 7a65 726f 5f70  scale and zero_p
-000298d0: 6f69 6e74 2066 6f72 2063 6f6e 7665 7274  oint for convert
-000298e0: 6564 206d 6f64 656c 2e0a 0a20 2020 2020  ed model...     
-000298f0: 2020 2041 7267 733a 0a20 2020 2020 2020     Args:.       
-00029900: 2020 2020 206d 6f64 656c 2028 6469 7229       model (dir)
-00029910: 3a20 496e 7438 206d 6f64 656c 2063 6f6e  : Int8 model con
-00029920: 7665 7274 6564 2066 726f 6d20 6670 3332  verted from fp32
-00029930: 206d 6f64 656c 2e0a 2020 2020 2020 2020   model..        
-00029940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00029950: 7363 616c 6520 616e 6420 7a65 726f 5f70  scale and zero_p
-00029960: 6f69 6e74 2069 7320 7365 7420 7769 7468  oint is set with
-00029970: 2063 616c 6962 7261 7469 6f6e 2066 6f72   calibration for
-00029980: 2065 6163 6820 6d6f 6475 6c65 0a20 2020   each module.   
-00029990: 2020 2020 2020 2020 2074 756e 655f 6366           tune_cf
-000299a0: 6720 286f 626a 6563 7429 3a20 5468 6973  g (object): This
-000299b0: 2066 696c 6520 7361 7665 7320 7363 616c   file saves scal
-000299c0: 6520 616e 6420 7a65 726f 5f70 6f69 6e74  e and zero_point
-000299d0: 206f 6620 5c0a 2020 2020 2020 2020 2020   of \.          
-000299e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000299f0: 2020 6f75 7470 7574 2061 6374 6976 6174    output activat
-00029a00: 696f 6e20 6f66 2065 6163 6820 7175 616e  ion of each quan
-00029a10: 7469 7a65 6420 6d6f 6475 6c65 2e0a 0a20  tized module... 
-00029a20: 2020 2020 2020 2052 6574 7572 6e73 3a0a         Returns:.
-00029a30: 2020 2020 2020 2020 2020 2020 4e6f 6e65              None
-00029a40: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00029a50: 2020 2020 2074 756e 655f 6366 675b 2767       tune_cfg['g
-00029a60: 6574 5f61 7474 7227 5d20 3d20 7b7d 0a20  et_attr'] = {}. 
-00029a70: 2020 2020 2020 2069 6620 7365 6c66 2e73         if self.s
-00029a80: 7562 5f6d 6f64 756c 655f 6c69 7374 2069  ub_module_list i
-00029a90: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-00029aa0: 2020 2020 7365 6c66 2e5f 6765 745f 6d6f      self._get_mo
-00029ab0: 6475 6c65 5f73 6361 6c65 5f7a 6572 6f70  dule_scale_zerop
-00029ac0: 6f69 6e74 286d 6f64 656c 2c20 7475 6e65  oint(model, tune
-00029ad0: 5f63 6667 290a 2020 2020 2020 2020 656c  _cfg).        el
-00029ae0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00029af0: 7365 6c66 2e5f 6765 745f 7375 625f 6d6f  self._get_sub_mo
-00029b00: 6475 6c65 5f73 6361 6c65 5f7a 6572 6f70  dule_scale_zerop
-00029b10: 6f69 6e74 286d 6f64 656c 2c20 7475 6e65  oint(model, tune
-00029b20: 5f63 6667 290a 0a20 2020 2040 7374 6174  _cfg)..    @stat
-00029b30: 6963 6d65 7468 6f64 0a20 2020 2064 6566  icmethod.    def
-00029b40: 2070 7265 7061 7265 5f73 7562 5f67 7261   prepare_sub_gra
-00029b50: 7068 2873 7562 5f6d 6f64 756c 655f 6c69  ph(sub_module_li
-00029b60: 7374 2c0a 2020 2020 2020 2020 2020 2020  st,.            
-00029b70: 2020 2020 2020 2020 2020 2020 2020 6678                fx
-00029b80: 5f6f 705f 6366 6773 2c0a 2020 2020 2020  _op_cfgs,.      
-00029b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00029ba0: 2020 2020 6d6f 6465 6c2c 0a20 2020 2020      model,.     
-00029bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00029bc0: 2020 2020 2070 7265 6669 782c 0a20 2020       prefix,.   
-00029bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00029be0: 2020 2020 2020 2069 735f 7161 743d 4661         is_qat=Fa
-00029bf0: 6c73 652c 0a20 2020 2020 2020 2020 2020  lse,.           
-00029c00: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00029c10: 7861 6d70 6c65 5f69 6e70 7574 733d 4e6f  xample_inputs=No
-00029c20: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
-00029c30: 2020 2020 2020 2020 2020 2020 2020 6375                cu
-00029c40: 7374 6f6d 5f63 6f6e 6669 673d 4e6f 6e65  stom_config=None
-00029c50: 293a 0a20 2020 2020 2020 2022 2222 5374  ):.        """St
-00029c60: 6174 6963 206d 6574 686f 6420 746f 2070  atic method to p
-00029c70: 7265 7061 7265 2073 7562 206d 6f64 756c  repare sub modul
-00029c80: 6573 2072 6563 7572 7369 7665 6c79 2e0a  es recursively..
-00029c90: 0a20 2020 2020 2020 2041 7267 733a 0a20  .        Args:. 
-00029ca0: 2020 2020 2020 2020 2020 2073 7562 5f6d             sub_m
-00029cb0: 6f64 756c 655f 6c69 7374 2028 6c69 7374  odule_list (list
-00029cc0: 293a 2063 6f6e 7461 696e 7320 7468 6520  ): contains the 
-00029cd0: 6e61 6d65 206f 6620 7472 6163 6561 626c  name of traceabl
-00029ce0: 6520 7375 6220 6d6f 6475 6c65 730a 2020  e sub modules.  
-00029cf0: 2020 2020 2020 2020 2020 6678 5f6f 705f            fx_op_
-00029d00: 6366 6773 2028 6469 6374 2c20 5143 6f6e  cfgs (dict, QCon
-00029d10: 6669 674d 6170 7069 6e67 293a 2074 6865  figMapping): the
-00029d20: 2063 6f6e 6669 6775 7261 7469 6f6e 2066   configuration f
-00029d30: 6f72 2070 7265 7061 7265 5f66 7820 7175  or prepare_fx qu
-00029d40: 616e 7469 7a61 7469 6f6e 2e0a 2020 2020  antization..    
-00029d50: 2020 2020 2020 2020 6d6f 6465 6c20 2864          model (d
-00029d60: 6972 293a 2069 6e70 7574 206d 6f64 656c  ir): input model
-00029d70: 2077 6869 6368 2069 7320 5079 546f 7263   which is PyTorc
-00029d80: 6820 6d6f 6465 6c2e 0a20 2020 2020 2020  h model..       
-00029d90: 2020 2020 2070 7265 6669 7820 2873 7472       prefix (str
-00029da0: 696e 6729 3a20 7072 6566 6978 206f 6620  ing): prefix of 
-00029db0: 6f70 206e 616d 650a 2020 2020 2020 2020  op name.        
-00029dc0: 2020 2020 6973 5f71 6174 2028 626f 6f6c      is_qat (bool
-00029dd0: 293a 2077 6865 7468 6572 2069 7420 6973  ): whether it is
-00029de0: 2061 2071 6174 2071 7561 6e74 697a 6174   a qat quantizat
-00029df0: 696f 6e0a 2020 2020 2020 2020 2020 2020  ion.            
-00029e00: 6578 616d 706c 655f 696e 7075 7473 2028  example_inputs (
-00029e10: 7465 6e73 6f72 202f 2074 7570 6520 6f66  tensor / tupe of
-00029e20: 2074 656e 736f 7229 3a20 6578 616d 706c   tensor): exampl
-00029e30: 6520 696e 7075 7473 0a20 2020 2020 2020  e inputs.       
-00029e40: 2020 2020 2063 7573 746f 6d5f 636f 6e66       custom_conf
-00029e50: 6967 2028 6469 6374 293a 2063 7573 746f  ig (dict): custo
-00029e60: 6d20 6e6f 6e20 7472 6163 6561 626c 6520  m non traceable 
-00029e70: 6d6f 6475 6c65 2064 6963 740a 0a20 2020  module dict..   
-00029e80: 2020 2020 2052 6574 7572 6e73 3a0a 2020       Returns:.  
-00029e90: 2020 2020 2020 2020 2020 6d6f 6465 6c20            model 
-00029ea0: 2864 6972 293a 206f 7574 7075 7420 6d6f  (dir): output mo
-00029eb0: 6465 6c20 7768 6963 6820 6973 2061 2070  del which is a p
-00029ec0: 7265 7061 7265 6420 5079 546f 7263 6820  repared PyTorch 
-00029ed0: 6d6f 6465 6c2e 0a20 2020 2020 2020 2022  model..        "
-00029ee0: 2222 0a20 2020 2020 2020 2066 726f 6d20  "".        from 
-00029ef0: 746f 7263 682e 7175 616e 7469 7a61 7469  torch.quantizati
-00029f00: 6f6e 2e71 7561 6e74 697a 655f 6678 2069  on.quantize_fx i
-00029f10: 6d70 6f72 7420 7072 6570 6172 655f 6678  mport prepare_fx
-00029f20: 2c20 7072 6570 6172 655f 7161 745f 6678  , prepare_qat_fx
-00029f30: 0a20 2020 2020 2020 2069 6d70 6f72 7420  .        import 
-00029f40: 746f 7263 682e 7175 616e 7469 7a61 7469  torch.quantizati
-00029f50: 6f6e 2e71 7561 6e74 697a 6174 696f 6e5f  on.quantization_
-00029f60: 6d61 7070 696e 6773 2061 7320 7471 716d  mappings as tqqm
-00029f70: 0a20 2020 2020 2020 2076 6572 7369 6f6e  .        version
-00029f80: 203d 2067 6574 5f74 6f72 6368 5f76 6572   = get_torch_ver
-00029f90: 7369 6f6e 2829 0a20 2020 2020 2020 2066  sion().        f
-00029fa0: 785f 7768 6974 655f 6c69 7374 203d 2074  x_white_list = t
-00029fb0: 7171 6d2e 6765 745f 6465 6661 756c 745f  qqm.get_default_
-00029fc0: 7163 6f6e 6669 675f 7072 6f70 6167 6174  qconfig_propagat
-00029fd0: 696f 6e5f 6c69 7374 2829 0a20 2020 2020  ion_list().     
-00029fe0: 2020 2066 6f72 206e 616d 652c 206d 6f64     for name, mod
-00029ff0: 756c 6520 696e 206d 6f64 656c 2e6e 616d  ule in model.nam
-0002a000: 6564 5f63 6869 6c64 7265 6e28 293a 0a20  ed_children():. 
-0002a010: 2020 2020 2020 2020 2020 206f 705f 6e61             op_na
-0002a020: 6d65 203d 2070 7265 6669 7820 2b20 272e  me = prefix + '.
-0002a030: 2720 2b20 6e61 6d65 2069 6620 7072 6566  ' + name if pref
-0002a040: 6978 2021 3d20 2727 2065 6c73 6520 6e61  ix != '' else na
-0002a050: 6d65 0a20 2020 2020 2020 2020 2020 2023  me.            #
-0002a060: 2073 6b69 7020 6375 7374 6f6d 206e 6f6e   skip custom non
-0002a070: 2074 7261 6365 6162 6c65 206d 6f64 756c   traceable modul
-0002a080: 6520 696e 2066 696e 652d 6772 6169 6e65  e in fine-graine
-0002a090: 6420 4658 0a20 2020 2020 2020 2020 2020  d FX.           
-0002a0a0: 2069 6620 6375 7374 6f6d 5f63 6f6e 6669   if custom_confi
-0002a0b0: 673a 0a20 2020 2020 2020 2020 2020 2020  g:.             
-0002a0c0: 2020 2069 6620 2827 6e6f 6e5f 7472 6163     if ('non_trac
-0002a0d0: 6561 626c 655f 6d6f 6475 6c65 5f6e 616d  eable_module_nam
-0002a0e0: 6527 2069 6e20 6375 7374 6f6d 5f63 6f6e  e' in custom_con
-0002a0f0: 6669 6720 5c0a 2020 2020 2020 2020 2020  fig \.          
-0002a100: 2020 2020 2020 2020 616e 6420 6f70 5f6e          and op_n
-0002a110: 616d 6520 696e 2063 7573 746f 6d5f 636f  ame in custom_co
-0002a120: 6e66 6967 5b27 6e6f 6e5f 7472 6163 6561  nfig['non_tracea
-0002a130: 626c 655f 6d6f 6475 6c65 5f6e 616d 6527  ble_module_name'
-0002a140: 5d29 205c 0a20 2020 2020 2020 2020 2020  ]) \.           
-0002a150: 2020 2020 2020 206f 7220 2827 6e6f 6e5f         or ('non_
-0002a160: 7472 6163 6561 626c 655f 6d6f 6475 6c65  traceable_module
-0002a170: 5f63 6c61 7373 2720 696e 2063 7573 746f  _class' in custo
-0002a180: 6d5f 636f 6e66 6967 205c 0a20 2020 2020  m_config \.     
-0002a190: 2020 2020 2020 2020 2020 2020 2061 6e64               and
-0002a1a0: 2069 7369 6e73 7461 6e63 6528 6d6f 6475   isinstance(modu
-0002a1b0: 6c65 2c20 7475 706c 6528 6375 7374 6f6d  le, tuple(custom
-0002a1c0: 5f63 6f6e 6669 675b 276e 6f6e 5f74 7261  _config['non_tra
-0002a1d0: 6365 6162 6c65 5f6d 6f64 756c 655f 636c  ceable_module_cl
-0002a1e0: 6173 7327 5d29 2929 3a0a 2020 2020 2020  ass']))):.      
-0002a1f0: 2020 2020 2020 2020 2020 2020 2020 636f                co
-0002a200: 6e74 696e 7565 0a20 2020 2020 2020 2020  ntinue.         
-0002a210: 2020 2069 6620 6f70 5f6e 616d 6520 696e     if op_name in
-0002a220: 2073 7562 5f6d 6f64 756c 655f 6c69 7374   sub_module_list
-0002a230: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0002a240: 2020 2320 7265 6d6f 7665 2070 7265 6669    # remove prefi
-0002a250: 7820 696e 2066 785f 6f70 5f63 6667 730a  x in fx_op_cfgs.
-0002a260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a270: 7665 7273 696f 6e20 3d20 6765 745f 746f  version = get_to
-0002a280: 7263 685f 7665 7273 696f 6e28 290a 2020  rch_version().  
-0002a290: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0002a2a0: 2076 6572 7369 6f6e 203e 2056 6572 7369   version > Versi
-0002a2b0: 6f6e 2822 312e 3132 2e31 2229 3a20 2023  on("1.12.1"):  #
-0002a2c0: 2070 7261 676d 613a 206e 6f20 636f 7665   pragma: no cove
-0002a2d0: 720a 2020 2020 2020 2020 2020 2020 2020  r.              
-0002a2e0: 2020 2020 2020 6672 6f6d 2074 6f72 6368        from torch
-0002a2f0: 2e61 6f2e 7175 616e 7469 7a61 7469 6f6e  .ao.quantization
-0002a300: 2069 6d70 6f72 7420 5143 6f6e 6669 674d   import QConfigM
-0002a310: 6170 7069 6e67 0a20 2020 2020 2020 2020  apping.         
-0002a320: 2020 2020 2020 2020 2020 2066 785f 7375             fx_su
-0002a330: 625f 6f70 5f63 6667 7320 3d20 5143 6f6e  b_op_cfgs = QCon
-0002a340: 6669 674d 6170 7069 6e67 2829 0a20 2020  figMapping().   
-0002a350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a360: 2066 785f 7375 625f 6f70 5f63 6667 732e   fx_sub_op_cfgs.
-0002a370: 7365 745f 676c 6f62 616c 284e 6f6e 6529  set_global(None)
-0002a380: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0002a390: 2020 2020 2066 785f 6f70 5f63 6667 735f       fx_op_cfgs_
-0002a3a0: 6469 6374 203d 2066 785f 6f70 5f63 6667  dict = fx_op_cfg
-0002a3b0: 732e 746f 5f64 6963 7428 290a 2020 2020  s.to_dict().    
-0002a3c0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0002a3d0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0002a3e0: 2020 2020 2020 6678 5f73 7562 5f6f 705f        fx_sub_op_
-0002a3f0: 6366 6773 203d 2064 6963 7428 290a 2020  cfgs = dict().  
-0002a400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a410: 2020 6678 5f73 7562 5f6f 705f 6366 6773    fx_sub_op_cfgs
-0002a420: 5b27 275d 203d 204e 6f6e 650a 2020 2020  [''] = None.    
-0002a430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a440: 6678 5f73 7562 5f6f 705f 6366 6773 5b27  fx_sub_op_cfgs['
-0002a450: 6d6f 6475 6c65 5f6e 616d 6527 5d20 3d20  module_name'] = 
-0002a460: 5b5d 0a20 2020 2020 2020 2020 2020 2020  [].             
-0002a470: 2020 2020 2020 2066 785f 6f70 5f63 6667         fx_op_cfg
-0002a480: 735f 6469 6374 203d 2066 785f 6f70 5f63  s_dict = fx_op_c
-0002a490: 6667 730a 0a20 2020 2020 2020 2020 2020  fgs..           
-0002a4a0: 2020 2020 2066 6f72 206b 2c20 7620 696e       for k, v in
-0002a4b0: 2066 785f 6f70 5f63 6667 735f 6469 6374   fx_op_cfgs_dict
-0002a4c0: 5b27 6d6f 6475 6c65 5f6e 616d 6527 5d3a  ['module_name']:
-0002a4d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0002a4e0: 2020 2020 2069 6620 6f70 5f6e 616d 6520       if op_name 
-0002a4f0: 696e 206b 3a0a 2020 2020 2020 2020 2020  in k:.          
-0002a500: 2020 2020 2020 2020 2020 2020 2020 7375                su
-0002a510: 625f 6e61 6d65 203d 206b 2e72 6570 6c61  b_name = k.repla
-0002a520: 6365 286f 705f 6e61 6d65 202b 2027 2e27  ce(op_name + '.'
-0002a530: 2c20 2727 2c20 3129 0a20 2020 2020 2020  , '', 1).       
-0002a540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a550: 2069 6620 7665 7273 696f 6e20 3e20 5665   if version > Ve
-0002a560: 7273 696f 6e28 2231 2e31 322e 3122 293a  rsion("1.12.1"):
-0002a570: 2020 2320 7072 6167 6d61 3a20 6e6f 2063    # pragma: no c
-0002a580: 6f76 6572 0a20 2020 2020 2020 2020 2020  over.           
-0002a590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a5a0: 2023 2070 796c 696e 743a 2064 6973 6162   # pylint: disab
-0002a5b0: 6c65 3d6e 6f2d 6d65 6d62 6572 0a20 2020  le=no-member.   
-0002a5c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a5d0: 2020 2020 2020 2020 2066 785f 7375 625f           fx_sub_
-0002a5e0: 6f70 5f63 6667 732e 7365 745f 6d6f 6475  op_cfgs.set_modu
-0002a5f0: 6c65 5f6e 616d 6528 7375 625f 6e61 6d65  le_name(sub_name
-0002a600: 2c20 7629 0a20 2020 2020 2020 2020 2020  , v).           
-0002a610: 2020 2020 2020 2020 2020 2020 2065 6c73               els
-0002a620: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-0002a630: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0002a640: 785f 7375 625f 6f70 5f63 6667 735b 276d  x_sub_op_cfgs['m
-0002a650: 6f64 756c 655f 6e61 6d65 275d 2e61 7070  odule_name'].app
-0002a660: 656e 6428 2873 7562 5f6e 616d 652c 2076  end((sub_name, v
-0002a670: 2929 0a0a 2020 2020 2020 2020 2020 2020  ))..            
-0002a680: 2020 2020 6966 2074 7970 6528 6d6f 6475      if type(modu
-0002a690: 6c65 2920 696e 2066 785f 7768 6974 655f  le) in fx_white_
-0002a6a0: 6c69 7374 2061 6e64 2074 7970 6528 6d6f  list and type(mo
-0002a6b0: 6475 6c65 2920 213d 2074 6f72 6368 2e6e  dule) != torch.n
-0002a6c0: 6e2e 5365 7175 656e 7469 616c 3a0a 2020  n.Sequential:.  
-0002a6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a6e0: 2020 2320 446f 6e27 7420 7265 616c 6c79    # Don't really
-0002a6f0: 206e 6565 6420 6120 7175 616e 742f 6465   need a quant/de
-0002a700: 7175 616e 742c 206a 7573 7420 6d6f 7665  quant, just move
-0002a710: 206e 6e2e 456d 6265 6464 696e 6720 5c0a   nn.Embedding \.
-0002a720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a730: 2020 2020 2320 746f 206c 6f77 6572 206c      # to lower l
-0002a740: 6576 656c 2066 6f72 2066 7820 6465 7465  evel for fx dete
-0002a750: 6374 696f 6e2e 0a20 2020 2020 2020 2020  ction..         
-0002a760: 2020 2020 2020 2020 2020 2074 6d70 5f6d             tmp_m
-0002a770: 6f64 756c 6520 3d20 746f 7263 682e 7175  odule = torch.qu
-0002a780: 616e 7469 7a61 7469 6f6e 2e51 7561 6e74  antization.Quant
-0002a790: 5772 6170 7065 7228 6d6f 6475 6c65 290a  Wrapper(module).
-0002a7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a7b0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0002a7c0: 2020 2020 2020 2020 2020 746d 705f 6d6f            tmp_mo
-0002a7d0: 6475 6c65 203d 206d 6f64 756c 650a 2020  dule = module.  
-0002a7e0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0002a7f0: 7079 6c69 6e74 3a20 6469 7361 626c 653d  pylint: disable=
-0002a800: 4531 3132 330a 2020 2020 2020 2020 2020  E1123.          
-0002a810: 2020 2020 2020 2320 7072 6167 6d61 3a20        # pragma: 
-0002a820: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
-0002a830: 2020 2020 2020 2020 2069 6620 6973 5f71           if is_q
-0002a840: 6174 3a0a 2020 2020 2020 2020 2020 2020  at:.            
-0002a850: 2020 2020 2020 2020 6d6f 6475 6c65 5f70          module_p
-0002a860: 7265 203d 2070 7265 7061 7265 5f71 6174  re = prepare_qat
-0002a870: 5f66 7828 0a20 2020 2020 2020 2020 2020  _fx(.           
-0002a880: 2020 2020 2020 2020 2020 2020 2074 6d70               tmp
-0002a890: 5f6d 6f64 756c 652c 0a20 2020 2020 2020  _module,.       
-0002a8a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a8b0: 2066 785f 7375 625f 6f70 5f63 6667 7329   fx_sub_op_cfgs)
-0002a8c0: 2069 6620 7665 7273 696f 6e20 3c3d 2056   if version <= V
-0002a8d0: 6572 7369 6f6e 2822 312e 3132 2e31 2229  ersion("1.12.1")
-0002a8e0: 2065 6c73 6520 7072 6570 6172 655f 7161   else prepare_qa
-0002a8f0: 745f 6678 280a 2020 2020 2020 2020 2020  t_fx(.          
-0002a900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a910: 2020 746d 705f 6d6f 6475 6c65 2c20 6678    tmp_module, fx
-0002a920: 5f73 7562 5f6f 705f 6366 6773 2c20 6578  _sub_op_cfgs, ex
-0002a930: 616d 706c 655f 696e 7075 7473 3d65 7861  ample_inputs=exa
-0002a940: 6d70 6c65 5f69 6e70 7574 7329 0a20 2020  mple_inputs).   
-0002a950: 2020 2020 2020 2020 2020 2020 2023 2070               # p
-0002a960: 796c 696e 743a 2064 6973 6162 6c65 3d45  ylint: disable=E
-0002a970: 3131 3233 0a20 2020 2020 2020 2020 2020  1123.           
-0002a980: 2020 2020 2023 2070 7261 676d 613a 206e       # pragma: n
-0002a990: 6f20 636f 7665 720a 2020 2020 2020 2020  o cover.        
-0002a9a0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0002a9b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a9c0: 2020 6d6f 6475 6c65 5f70 7265 203d 2070    module_pre = p
-0002a9d0: 7265 7061 7265 5f66 7828 0a20 2020 2020  repare_fx(.     
-0002a9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a9f0: 2020 2074 6d70 5f6d 6f64 756c 652c 0a20     tmp_module,. 
-0002aa00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002aa10: 2020 2020 2020 2066 785f 7375 625f 6f70         fx_sub_op
-0002aa20: 5f63 6667 7329 2069 6620 7665 7273 696f  _cfgs) if versio
-0002aa30: 6e20 3c3d 2056 6572 7369 6f6e 2822 312e  n <= Version("1.
-0002aa40: 3132 2e31 2229 2065 6c73 6520 7072 6570  12.1") else prep
-0002aa50: 6172 655f 6678 280a 2020 2020 2020 2020  are_fx(.        
-0002aa60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002aa70: 2020 2020 746d 705f 6d6f 6475 6c65 2c20      tmp_module, 
-0002aa80: 6678 5f73 7562 5f6f 705f 6366 6773 2c20  fx_sub_op_cfgs, 
-0002aa90: 6578 616d 706c 655f 696e 7075 7473 3d65  example_inputs=e
-0002aaa0: 7861 6d70 6c65 5f69 6e70 7574 7329 0a20  xample_inputs). 
-0002aab0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-0002aac0: 6f72 6368 5f75 7469 6c73 2e75 7469 6c2e  orch_utils.util.
-0002aad0: 6170 7065 6e64 5f61 7474 7228 6d6f 6475  append_attr(modu
-0002aae0: 6c65 5f70 7265 2c20 6d6f 6475 6c65 2c20  le_pre, module, 
-0002aaf0: 6678 5f77 6869 7465 5f6c 6973 7429 0a20  fx_white_list). 
-0002ab00: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0002ab10: 6574 6174 7472 286d 6f64 656c 2c20 6e61  etattr(model, na
-0002ab20: 6d65 2c20 6d6f 6475 6c65 5f70 7265 290a  me, module_pre).
-0002ab30: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0002ab40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0002ab50: 2020 5079 546f 7263 685f 4658 4164 6170    PyTorch_FXAdap
-0002ab60: 746f 722e 7072 6570 6172 655f 7375 625f  tor.prepare_sub_
-0002ab70: 6772 6170 6828 7375 625f 6d6f 6475 6c65  graph(sub_module
-0002ab80: 5f6c 6973 742c 0a20 2020 2020 2020 2020  _list,.         
-0002ab90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002aba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002abb0: 2020 2020 2020 2020 2020 2066 785f 6f70             fx_op
-0002abc0: 5f63 6667 732c 0a20 2020 2020 2020 2020  _cfgs,.         
-0002abd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002abe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002abf0: 2020 2020 2020 2020 2020 206d 6f64 756c             modul
-0002ac00: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-0002ac10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002ac20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002ac30: 2020 2020 2020 206f 705f 6e61 6d65 2c0a         op_name,.
-0002ac40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002ac50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002ac60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002ac70: 2020 2020 6973 5f71 6174 2c0a 2020 2020      is_qat,.    
-0002ac80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002ac90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002aca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002acb0: 6578 616d 706c 655f 696e 7075 7473 3d65  example_inputs=e
-0002acc0: 7861 6d70 6c65 5f69 6e70 7574 7329 0a0a  xample_inputs)..
-0002acd0: 2020 2020 4073 7461 7469 636d 6574 686f      @staticmetho
-0002ace0: 640a 2020 2020 6465 6620 636f 6e76 6572  d.    def conver
-0002acf0: 745f 7375 625f 6772 6170 6828 7375 625f  t_sub_graph(sub_
-0002ad00: 6d6f 6475 6c65 5f6c 6973 742c 206d 6f64  module_list, mod
-0002ad10: 656c 2c20 7072 6566 6978 2c20 6375 7374  el, prefix, cust
-0002ad20: 6f6d 5f63 6f6e 6669 673d 4e6f 6e65 293a  om_config=None):
-0002ad30: 0a20 2020 2020 2020 2022 2222 5374 6174  .        """Stat
-0002ad40: 6963 206d 6574 686f 6420 746f 2063 6f6e  ic method to con
-0002ad50: 7665 7274 2073 7562 206d 6f64 756c 6573  vert sub modules
-0002ad60: 2072 6563 7572 7369 7665 6c79 2e0a 0a20   recursively... 
-0002ad70: 2020 2020 2020 2041 7267 733a 0a20 2020         Args:.   
-0002ad80: 2020 2020 2020 2020 2073 7562 5f6d 6f64           sub_mod
-0002ad90: 756c 655f 6c69 7374 2028 6c69 7374 293a  ule_list (list):
-0002ada0: 2063 6f6e 7461 696e 7320 7468 6520 6e61   contains the na
-0002adb0: 6d65 206f 6620 7472 6163 6561 626c 6520  me of traceable 
-0002adc0: 7375 6220 6d6f 6475 6c65 730a 2020 2020  sub modules.    
-0002add0: 2020 2020 2020 2020 6d6f 6465 6c20 2864          model (d
-0002ade0: 6972 293a 2069 6e70 7574 206d 6f64 656c  ir): input model
-0002adf0: 2077 6869 6368 2069 7320 7072 6570 6172   which is prepar
-0002ae00: 6564 2050 7954 6f72 6368 206d 6f64 656c  ed PyTorch model
-0002ae10: 2e0a 2020 2020 2020 2020 2020 2020 7072  ..            pr
-0002ae20: 6566 6978 2028 7374 7269 6e67 293a 2070  efix (string): p
-0002ae30: 7265 6669 7820 6f66 206f 7020 6e61 6d65  refix of op name
-0002ae40: 0a20 2020 2020 2020 2020 2020 2063 7573  .            cus
-0002ae50: 746f 6d5f 636f 6e66 6967 2028 6469 6374  tom_config (dict
-0002ae60: 293a 2063 7573 746f 6d20 6e6f 6e20 7472  ): custom non tr
-0002ae70: 6163 6561 626c 6520 6d6f 6475 6c65 2064  aceable module d
-0002ae80: 6963 740a 0a20 2020 2020 2020 2052 6574  ict..        Ret
-0002ae90: 7572 6e73 3a0a 2020 2020 2020 2020 2020  urns:.          
-0002aea0: 2020 6d6f 6465 6c20 2864 6972 293a 206f    model (dir): o
-0002aeb0: 7574 7075 7420 6d6f 6465 6c20 7768 6963  utput model whic
-0002aec0: 6820 6973 2061 2063 6f6e 7665 7274 6564  h is a converted
-0002aed0: 2050 7954 6f72 6368 2069 6e74 3820 6d6f   PyTorch int8 mo
-0002aee0: 6465 6c2e 0a20 2020 2020 2020 2022 2222  del..        """
-0002aef0: 0a20 2020 2020 2020 2066 726f 6d20 746f  .        from to
-0002af00: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
-0002af10: 2e71 7561 6e74 697a 655f 6678 2069 6d70  .quantize_fx imp
-0002af20: 6f72 7420 636f 6e76 6572 745f 6678 0a20  ort convert_fx. 
-0002af30: 2020 2020 2020 2066 6f72 206e 616d 652c         for name,
-0002af40: 206d 6f64 756c 6520 696e 206d 6f64 656c   module in model
-0002af50: 2e6e 616d 6564 5f63 6869 6c64 7265 6e28  .named_children(
-0002af60: 293a 0a20 2020 2020 2020 2020 2020 206f  ):.            o
-0002af70: 705f 6e61 6d65 203d 2070 7265 6669 7820  p_name = prefix 
-0002af80: 2b20 272e 2720 2b20 6e61 6d65 2069 6620  + '.' + name if 
-0002af90: 7072 6566 6978 2021 3d20 2727 2065 6c73  prefix != '' els
-0002afa0: 6520 6e61 6d65 0a20 2020 2020 2020 2020  e name.         
-0002afb0: 2020 2023 2073 6b69 7020 6375 7374 6f6d     # skip custom
-0002afc0: 206e 6f6e 2074 7261 6365 6162 6c65 206d   non traceable m
-0002afd0: 6f64 756c 6520 696e 2066 696e 652d 6772  odule in fine-gr
-0002afe0: 6169 6e65 6420 4658 0a20 2020 2020 2020  ained FX.       
-0002aff0: 2020 2020 2069 6620 6375 7374 6f6d 5f63       if custom_c
-0002b000: 6f6e 6669 673a 0a20 2020 2020 2020 2020  onfig:.         
-0002b010: 2020 2020 2020 2069 6620 2827 6e6f 6e5f         if ('non_
-0002b020: 7472 6163 6561 626c 655f 6d6f 6475 6c65  traceable_module
-0002b030: 5f6e 616d 6527 2069 6e20 6375 7374 6f6d  _name' in custom
-0002b040: 5f63 6f6e 6669 6720 5c0a 2020 2020 2020  _config \.      
-0002b050: 2020 2020 2020 2020 2020 2020 616e 6420              and 
-0002b060: 6f70 5f6e 616d 6520 696e 2063 7573 746f  op_name in custo
-0002b070: 6d5f 636f 6e66 6967 5b27 6e6f 6e5f 7472  m_config['non_tr
-0002b080: 6163 6561 626c 655f 6d6f 6475 6c65 5f6e  aceable_module_n
-0002b090: 616d 6527 5d29 205c 0a20 2020 2020 2020  ame']) \.       
-0002b0a0: 2020 2020 2020 2020 2020 206f 7220 2827             or ('
-0002b0b0: 6e6f 6e5f 7472 6163 6561 626c 655f 6d6f  non_traceable_mo
-0002b0c0: 6475 6c65 5f63 6c61 7373 2720 696e 2063  dule_class' in c
-0002b0d0: 7573 746f 6d5f 636f 6e66 6967 205c 0a20  ustom_config \. 
-0002b0e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b0f0: 2061 6e64 2069 7369 6e73 7461 6e63 6528   and isinstance(
-0002b100: 6d6f 6475 6c65 2c20 7475 706c 6528 6375  module, tuple(cu
-0002b110: 7374 6f6d 5f63 6f6e 6669 675b 276e 6f6e  stom_config['non
-0002b120: 5f74 7261 6365 6162 6c65 5f6d 6f64 756c  _traceable_modul
-0002b130: 655f 636c 6173 7327 5d29 2929 3a0a 2020  e_class']))):.  
-0002b140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b150: 2020 636f 6e74 696e 7565 0a20 2020 2020    continue.     
-0002b160: 2020 2020 2020 2069 6620 6f70 5f6e 616d         if op_nam
-0002b170: 6520 696e 2073 7562 5f6d 6f64 756c 655f  e in sub_module_
-0002b180: 6c69 7374 3a0a 2020 2020 2020 2020 2020  list:.          
-0002b190: 2020 2020 2020 6d6f 6475 6c65 5f63 6f6e        module_con
-0002b1a0: 203d 2063 6f6e 7665 7274 5f66 7828 6d6f   = convert_fx(mo
-0002b1b0: 6475 6c65 290a 2020 2020 2020 2020 2020  dule).          
-0002b1c0: 2020 2020 2020 746f 7263 685f 7574 696c        torch_util
-0002b1d0: 732e 7574 696c 2e61 7070 656e 645f 6174  s.util.append_at
-0002b1e0: 7472 286d 6f64 756c 655f 636f 6e2c 206d  tr(module_con, m
-0002b1f0: 6f64 756c 6529 0a20 2020 2020 2020 2020  odule).         
-0002b200: 2020 2020 2020 2073 6574 6174 7472 286d         setattr(m
-0002b210: 6f64 656c 2c20 6e61 6d65 2c20 6d6f 6475  odel, name, modu
-0002b220: 6c65 5f63 6f6e 290a 2020 2020 2020 2020  le_con).        
-0002b230: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0002b240: 2020 2020 2020 2020 2020 5079 546f 7263            PyTorc
-0002b250: 685f 4658 4164 6170 746f 722e 636f 6e76  h_FXAdaptor.conv
-0002b260: 6572 745f 7375 625f 6772 6170 6828 7375  ert_sub_graph(su
-0002b270: 625f 6d6f 6475 6c65 5f6c 6973 742c 205c  b_module_list, \
-0002b280: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0002b290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b2a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b2b0: 2020 2020 206d 6f64 756c 652c 206f 705f       module, op_
-0002b2c0: 6e61 6d65 290a 0a20 2020 2040 6475 6d70  name)..    @dump
-0002b2d0: 5f65 6c61 7073 6564 5f74 696d 6528 2250  _elapsed_time("P
-0002b2e0: 6173 7320 7175 6572 7920 6672 616d 6577  ass query framew
-0002b2f0: 6f72 6b20 6361 7061 6269 6c69 7479 2229  ork capability")
-0002b300: 0a20 2020 2064 6566 2071 7565 7279 5f66  .    def query_f
-0002b310: 775f 6361 7061 6269 6c69 7479 2873 656c  w_capability(sel
-0002b320: 662c 206d 6f64 656c 293a 0a20 2020 2020  f, model):.     
-0002b330: 2020 2022 2222 5468 6973 2069 7320 6120     """This is a 
-0002b340: 6865 6c70 6572 2066 756e 6374 696f 6e20  helper function 
-0002b350: 746f 2067 6574 2061 6c6c 2071 7561 6e74  to get all quant
-0002b360: 697a 6162 6c65 206f 7073 2066 726f 6d20  izable ops from 
-0002b370: 6d6f 6465 6c2e 0a0a 2020 2020 2020 2020  model...        
-0002b380: 4172 6773 3a0a 2020 2020 2020 2020 2020  Args:.          
-0002b390: 2020 6d6f 6465 6c20 286f 626a 6563 7429    model (object)
-0002b3a0: 3a20 696e 7075 7420 6d6f 6465 6c20 7768  : input model wh
-0002b3b0: 6963 6820 6973 204e 6575 7261 6c20 436f  ich is Neural Co
-0002b3c0: 6d70 7265 7373 6f72 206d 6f64 656c 0a0a  mpressor model..
-0002b3d0: 2020 2020 2020 2020 5265 7475 726e 733a          Returns:
-0002b3e0: 0a20 2020 2020 2020 2020 2020 2071 5f63  .            q_c
-0002b3f0: 6170 6162 696c 6974 7920 2864 6963 7469  apability (dicti
-0002b400: 6f6e 6172 7929 3a20 7475 6e69 6e67 2063  onary): tuning c
-0002b410: 6170 6162 696c 6974 7920 666f 7220 6561  apability for ea
-0002b420: 6368 206f 7020 6672 6f6d 206d 6f64 656c  ch op from model
-0002b430: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
-0002b440: 2020 2020 2020 7365 6c66 2e70 7265 5f6f        self.pre_o
-0002b450: 7074 696d 697a 6564 5f6d 6f64 656c 203d  ptimized_model =
-0002b460: 206d 6f64 656c 0a20 2020 2020 2020 2074   model.        t
-0002b470: 6d70 5f6d 6f64 656c 203d 206d 6f64 656c  mp_model = model
-0002b480: 2e5f 6d6f 6465 6c0a 2020 2020 2020 2020  ._model.        
-0002b490: 746d 705f 6d6f 6465 6c20 3d20 7365 6c66  tmp_model = self
-0002b4a0: 2e66 7573 655f 6678 5f6d 6f64 656c 286d  .fuse_fx_model(m
-0002b4b0: 6f64 656c 2c20 6973 5f71 6174 3d28 7365  odel, is_qat=(se
-0002b4c0: 6c66 2e61 7070 726f 6163 6820 3d3d 2022  lf.approach == "
-0002b4d0: 7175 616e 745f 6177 6172 655f 7472 6169  quant_aware_trai
-0002b4e0: 6e69 6e67 2229 290a 2020 2020 2020 2020  ning")).        
-0002b4f0: 7265 7475 726e 2073 656c 662e 5f67 6574  return self._get
-0002b500: 5f71 7561 6e74 697a 6162 6c65 5f6f 7073  _quantizable_ops
-0002b510: 2874 6d70 5f6d 6f64 656c 290a 0a20 2020  (tmp_model)..   
-0002b520: 2064 6566 2066 7573 655f 6678 5f6d 6f64   def fuse_fx_mod
-0002b530: 656c 2873 656c 662c 206d 6f64 656c 2c20  el(self, model, 
-0002b540: 6973 5f71 6174 293a 0a20 2020 2020 2020  is_qat):.       
-0002b550: 2022 2222 5468 6973 2069 7320 6120 6865   """This is a he
-0002b560: 6c70 6572 2066 756e 6374 696f 6e20 746f  lper function to
-0002b570: 2067 6574 2066 7573 6564 2066 7820 6d6f   get fused fx mo
-0002b580: 6465 6c20 666f 7220 5079 546f 7263 685f  del for PyTorch_
-0002b590: 4658 4164 6170 746f 722e 0a0a 2020 2020  FXAdaptor...    
-0002b5a0: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
-0002b5b0: 2020 2020 2020 6d6f 6465 6c20 286f 626a        model (obj
-0002b5c0: 6563 7429 3a20 696e 7075 7420 6d6f 6465  ect): input mode
-0002b5d0: 6c20 7768 6963 6820 6973 204e 6575 7261  l which is Neura
-0002b5e0: 6c20 436f 6d70 7265 7373 6f72 206d 6f64  l Compressor mod
-0002b5f0: 656c 2e0a 2020 2020 2020 2020 2020 2020  el..            
-0002b600: 6973 5f71 6174 2028 626f 6f6c 293a 2063  is_qat (bool): c
-0002b610: 6865 636b 2071 7561 6e74 697a 6174 696f  heck quantizatio
-0002b620: 6e20 6170 7072 6f61 6368 2069 7320 7161  n approach is qa
-0002b630: 7420 6f72 206e 6f74 2e0a 0a20 2020 2020  t or not...     
-0002b640: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
-0002b650: 2020 2020 2020 2020 6675 7365 645f 6d6f          fused_mo
-0002b660: 6465 6c20 2847 7261 7068 4d6f 6475 6c65  del (GraphModule
-0002b670: 293a 2066 7573 6564 2047 7261 7068 4d6f  ): fused GraphMo
-0002b680: 6475 6c65 206d 6f64 656c 2066 726f 6d20  dule model from 
-0002b690: 746f 7263 682e 6678 2e0a 2020 2020 2020  torch.fx..      
-0002b6a0: 2020 2222 220a 2020 2020 2020 2020 7472    """.        tr
-0002b6b0: 793a 0a20 2020 2020 2020 2020 2020 2074  y:.            t
-0002b6c0: 6d70 5f6d 6f64 656c 203d 2063 6f70 792e  mp_model = copy.
-0002b6d0: 6465 6570 636f 7079 286d 6f64 656c 2e5f  deepcopy(model._
-0002b6e0: 6d6f 6465 6c29 0a20 2020 2020 2020 2065  model).        e
-0002b6f0: 7863 6570 7420 4578 6365 7074 696f 6e20  xcept Exception 
-0002b700: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
-0002b710: 2020 746d 705f 6d6f 6465 6c20 3d20 6d6f    tmp_model = mo
-0002b720: 6465 6c2e 5f6d 6f64 656c 0a20 2020 2020  del._model.     
-0002b730: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
-0002b740: 726e 696e 6728 2244 6565 7063 6f70 7920  rning("Deepcopy 
-0002b750: 6661 696c 6564 3a20 7b7d 2c20 696e 706c  failed: {}, inpl
-0002b760: 6163 653d 5472 7565 206e 6f77 2122 2e66  ace=True now!".f
-0002b770: 6f72 6d61 7428 7265 7072 2865 2929 290a  ormat(repr(e))).
-0002b780: 0a20 2020 2020 2020 2074 6d70 5f6d 6f64  .        tmp_mod
-0002b790: 656c 2e74 7261 696e 2829 2069 6620 6973  el.train() if is
-0002b7a0: 5f71 6174 2065 6c73 6520 746d 705f 6d6f  _qat else tmp_mo
-0002b7b0: 6465 6c2e 6576 616c 2829 0a20 2020 2020  del.eval().     
-0002b7c0: 2020 2066 726f 6d20 746f 7263 682e 6678     from torch.fx
-0002b7d0: 2069 6d70 6f72 7420 4772 6170 684d 6f64   import GraphMod
-0002b7e0: 756c 650a 2020 2020 2020 2020 6672 6f6d  ule.        from
-0002b7f0: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
-0002b800: 696f 6e2e 7175 616e 7469 7a65 5f66 7820  ion.quantize_fx 
-0002b810: 696d 706f 7274 205f 6675 7365 5f66 782c  import _fuse_fx,
-0002b820: 2051 7561 6e74 697a 6174 696f 6e54 7261   QuantizationTra
-0002b830: 6365 720a 2020 2020 2020 2020 6966 206d  cer.        if m
-0002b840: 6f64 656c 2e6b 7761 7267 7320 6973 206e  odel.kwargs is n
-0002b850: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
-0002b860: 2020 2020 2070 7265 7061 7265 5f63 7573       prepare_cus
-0002b870: 746f 6d5f 636f 6e66 6967 5f64 6963 7420  tom_config_dict 
-0002b880: 3d20 6d6f 6465 6c2e 6b77 6172 6773 2e67  = model.kwargs.g
-0002b890: 6574 2827 7072 6570 6172 655f 6375 7374  et('prepare_cust
-0002b8a0: 6f6d 5f63 6f6e 6669 675f 6469 6374 272c  om_config_dict',
-0002b8b0: 207b 7d29 0a20 2020 2020 2020 2065 6c73   {}).        els
-0002b8c0: 653a 0a20 2020 2020 2020 2020 2020 2070  e:.            p
-0002b8d0: 7265 7061 7265 5f63 7573 746f 6d5f 636f  repare_custom_co
-0002b8e0: 6e66 6967 5f64 6963 7420 3d20 7b7d 0a20  nfig_dict = {}. 
-0002b8f0: 2020 2020 2020 2073 6b69 7070 6564 5f6d         skipped_m
-0002b900: 6f64 756c 655f 6e61 6d65 7320 3d20 7072  odule_names = pr
-0002b910: 6570 6172 655f 6375 7374 6f6d 5f63 6f6e  epare_custom_con
-0002b920: 6669 675f 6469 6374 2e67 6574 285c 0a20  fig_dict.get(\. 
-0002b930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b950: 2020 2020 2020 2020 2020 2027 6e6f 6e5f             'non_
-0002b960: 7472 6163 6561 626c 655f 6d6f 6475 6c65  traceable_module
-0002b970: 5f6e 616d 6527 2c20 5b5d 290a 2020 2020  _name', []).    
-0002b980: 2020 2020 736b 6970 7065 645f 6d6f 6475      skipped_modu
-0002b990: 6c65 5f63 6c61 7373 6573 203d 2070 7265  le_classes = pre
-0002b9a0: 7061 7265 5f63 7573 746f 6d5f 636f 6e66  pare_custom_conf
-0002b9b0: 6967 5f64 6963 742e 6765 7428 5c0a 2020  ig_dict.get(\.  
-0002b9c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b9d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b9e0: 2020 2020 2020 2020 2020 276e 6f6e 5f74            'non_t
-0002b9f0: 7261 6365 6162 6c65 5f6d 6f64 756c 655f  raceable_module_
-0002ba00: 636c 6173 7327 2c20 5b5d 290a 2020 2020  class', []).    
-0002ba10: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0002ba20: 2020 2020 2074 7261 6365 7220 3d20 5175       tracer = Qu
-0002ba30: 616e 7469 7a61 7469 6f6e 5472 6163 6572  antizationTracer
-0002ba40: 2873 6b69 7070 6564 5f6d 6f64 756c 655f  (skipped_module_
-0002ba50: 6e61 6d65 732c 2073 6b69 7070 6564 5f6d  names, skipped_m
-0002ba60: 6f64 756c 655f 636c 6173 7365 7329 0a20  odule_classes). 
-0002ba70: 2020 2020 2020 2020 2020 2067 7261 7068             graph
-0002ba80: 5f6d 6f64 756c 6520 3d20 4772 6170 684d  _module = GraphM
-0002ba90: 6f64 756c 6528 746d 705f 6d6f 6465 6c2c  odule(tmp_model,
-0002baa0: 2074 7261 6365 722e 7472 6163 6528 746d   tracer.trace(tm
-0002bab0: 705f 6d6f 6465 6c29 290a 2020 2020 2020  p_model)).      
-0002bac0: 2020 2020 2020 6966 2073 656c 662e 7665        if self.ve
-0002bad0: 7273 696f 6e2e 7265 6c65 6173 6520 3e3d  rsion.release >=
-0002bae0: 2056 6572 7369 6f6e 2822 312e 3133 2e30   Version("1.13.0
-0002baf0: 2229 2e72 656c 6561 7365 3a20 2023 2070  ").release:  # p
-0002bb00: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
+00024d00: 2020 2020 696e 7370 6563 745f 7479 7065      inspect_type
+00024d10: 3d27 6163 7469 7661 7469 6f6e 272c 0a20  ='activation',. 
+00024d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00024d30: 2020 2020 2020 7361 7665 5f74 6f5f 6469        save_to_di
+00024d40: 736b 3d46 616c 7365 293a 0a20 2020 2020  sk=False):.     
+00024d50: 2020 2061 7373 6572 7420 4661 6c73 652c     assert False,
+00024d60: 2022 496e 7370 6563 745f 7465 6e73 6f72   "Inspect_tensor
+00024d70: 2064 6964 6e27 7420 7375 7070 6f72 7420   didn't support 
+00024d80: 4950 4558 2062 6163 6b65 6e64 206e 6f77  IPEX backend now
+00024d90: 2122 0a0a 0a40 6164 6170 746f 725f 7265  !"...@adaptor_re
+00024da0: 6769 7374 7279 0a63 6c61 7373 2050 7954  gistry.class PyT
+00024db0: 6f72 6368 5f46 5841 6461 7074 6f72 2854  orch_FXAdaptor(T
+00024dc0: 656d 706c 6174 6541 6461 7074 6f72 293a  emplateAdaptor):
+00024dd0: 0a20 2020 2022 2222 4164 6170 746f 7220  .    """Adaptor 
+00024de0: 6f66 2050 7954 6f72 6368 2066 7261 6d65  of PyTorch frame
+00024df0: 776f 726b 2077 6974 6820 4658 2067 7261  work with FX gra
+00024e00: 7068 206d 6f64 652c 2061 6c6c 2050 7954  ph mode, all PyT
+00024e10: 6f72 6368 2041 5049 2069 7320 696e 2074  orch API is in t
+00024e20: 6869 7320 636c 6173 732e 0a0a 2020 2020  his class...    
+00024e30: 4172 6773 3a0a 2020 2020 2020 2020 6672  Args:.        fr
+00024e40: 616d 6577 6f72 6b5f 7370 6563 6966 6963  amework_specific
+00024e50: 5f69 6e66 6f20 2864 6963 7429 3a20 6469  _info (dict): di
+00024e60: 6374 696f 6e61 7279 206f 6620 7475 6e69  ctionary of tuni
+00024e70: 6e67 2063 6f6e 6669 6775 7265 2066 726f  ng configure fro
+00024e80: 6d20 7961 6d6c 2066 696c 652e 0a20 2020  m yaml file..   
+00024e90: 2022 2222 0a20 2020 2064 6566 205f 5f69   """.    def __i
+00024ea0: 6e69 745f 5f28 7365 6c66 2c20 6672 616d  nit__(self, fram
+00024eb0: 6577 6f72 6b5f 7370 6563 6966 6963 5f69  ework_specific_i
+00024ec0: 6e66 6f29 3a0a 2020 2020 2020 2020 7375  nfo):.        su
+00024ed0: 7065 7228 5079 546f 7263 685f 4658 4164  per(PyTorch_FXAd
+00024ee0: 6170 746f 722c 2073 656c 6629 2e5f 5f69  aptor, self).__i
+00024ef0: 6e69 745f 5f28 6672 616d 6577 6f72 6b5f  nit__(framework_
+00024f00: 7370 6563 6966 6963 5f69 6e66 6f29 0a20  specific_info). 
+00024f10: 2020 2020 2020 2061 7373 6572 7420 7365         assert se
+00024f20: 6c66 2e76 6572 7369 6f6e 2e72 656c 6561  lf.version.relea
+00024f30: 7365 203e 3d20 5665 7273 696f 6e28 2231  se >= Version("1
+00024f40: 2e38 2e30 2229 2e72 656c 6561 7365 2c20  .8.0").release, 
+00024f50: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00024f60: 2020 2020 2020 2020 2250 6c65 6173 6520          "Please 
+00024f70: 7573 6520 5079 5472 6f63 6820 312e 3820  use PyTroch 1.8 
+00024f80: 6f72 2068 6967 6865 7220 7665 7273 696f  or higher versio
+00024f90: 6e20 7769 7468 2070 7974 6f72 6368 5f66  n with pytorch_f
+00024fa0: 7820 6261 636b 656e 6421 220a 2020 2020  x backend!".    
+00024fb0: 2020 2020 6966 2073 656c 662e 6170 7072      if self.appr
+00024fc0: 6f61 6368 203d 3d20 2770 6f73 745f 7472  oach == 'post_tr
+00024fd0: 6169 6e69 6e67 5f64 796e 616d 6963 5f71  aining_dynamic_q
+00024fe0: 7561 6e74 273a 0a20 2020 2020 2020 2020  uant':.         
+00024ff0: 2020 2061 7373 6572 7420 7365 6c66 2e76     assert self.v
+00025000: 6572 7369 6f6e 2e72 656c 6561 7365 203e  ersion.release >
+00025010: 3d20 5665 7273 696f 6e28 2231 2e39 2e30  = Version("1.9.0
+00025020: 2229 2e72 656c 6561 7365 2c20 5c0a 2020  ").release, \.  
+00025030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00025040: 2020 2020 2020 2250 6c65 6173 6520 7573        "Please us
+00025050: 6520 5079 5472 6f63 6820 312e 3920 6f72  e PyTroch 1.9 or
+00025060: 2068 6967 6865 7220 7665 7273 696f 6e20   higher version 
+00025070: 666f 7220 6479 6e61 6d69 6320 2220 5c0a  for dynamic " \.
+00025080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00025090: 2020 2020 2020 2020 2271 7561 6e74 697a          "quantiz
+000250a0: 6174 696f 6e20 7769 7468 2070 7974 6f72  ation with pytor
+000250b0: 6368 5f66 7820 6261 636b 656e 6421 220a  ch_fx backend!".
+000250c0: 2020 2020 2020 2020 696d 706f 7274 2074          import t
+000250d0: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
+000250e0: 6e20 6173 2074 710a 2020 2020 2020 2020  n as tq.        
+000250f0: 2222 220a 2020 2020 2020 2020 2320 4d61  """.        # Ma
+00025100: 7020 666f 7220 7377 6170 7069 6e67 2066  p for swapping f
+00025110: 6c6f 6174 206d 6f64 756c 6520 746f 2071  loat module to q
+00025120: 7561 6e74 697a 6564 206f 6e65 732c 0a20  uantized ones,. 
+00025130: 2020 2020 2020 2023 2061 6e64 2074 6869         # and thi
+00025140: 7320 6469 6374 696f 6e61 7279 2077 696c  s dictionary wil
+00025150: 6c20 6368 616e 6765 2077 6974 6820 6469  l change with di
+00025160: 6666 6572 656e 7420 506f 546f 7263 6820  fferent PoTorch 
+00025170: 7665 7273 696f 6e73 0a20 2020 2020 2020  versions.       
+00025180: 2044 4546 4155 4c54 5f4d 4f44 554c 455f   DEFAULT_MODULE_
+00025190: 4d41 5050 494e 4720 3d20 7b0a 2020 2020  MAPPING = {.    
+000251a0: 2020 2020 2020 2020 6e6e 2e4c 696e 6561          nn.Linea
+000251b0: 723a 206e 6e71 2e4c 696e 6561 722c 0a20  r: nnq.Linear,. 
+000251c0: 2020 2020 2020 2020 2020 206e 6e2e 5265             nn.Re
+000251d0: 4c55 3a20 6e6e 712e 5265 4c55 2c0a 2020  LU: nnq.ReLU,.  
+000251e0: 2020 2020 2020 2020 2020 6e6e 2e52 654c            nn.ReL
+000251f0: 5536 3a20 6e6e 712e 5265 4c55 362c 0a20  U6: nnq.ReLU6,. 
+00025200: 2020 2020 2020 2020 2020 206e 6e2e 436f             nn.Co
+00025210: 6e76 3264 3a20 6e6e 712e 436f 6e76 3264  nv2d: nnq.Conv2d
+00025220: 2c0a 2020 2020 2020 2020 2020 2020 6e6e  ,.            nn
+00025230: 2e43 6f6e 7633 643a 206e 6e71 2e43 6f6e  .Conv3d: nnq.Con
+00025240: 7633 642c 0a20 2020 2020 2020 2020 2020  v3d,.           
+00025250: 2051 7561 6e74 5374 7562 3a20 6e6e 712e   QuantStub: nnq.
+00025260: 5175 616e 7469 7a65 2c0a 2020 2020 2020  Quantize,.      
+00025270: 2020 2020 2020 4465 5175 616e 7453 7475        DeQuantStu
+00025280: 623a 206e 6e71 2e44 6551 7561 6e74 697a  b: nnq.DeQuantiz
+00025290: 652c 0a20 2020 2020 2020 2020 2020 2023  e,.            #
+000252a0: 2057 7261 7070 6572 204d 6f64 756c 6573   Wrapper Modules
+000252b0: 3a0a 2020 2020 2020 2020 2020 2020 6e6e  :.            nn
+000252c0: 712e 466c 6f61 7446 756e 6374 696f 6e61  q.FloatFunctiona
+000252d0: 6c3a 206e 6e71 2e51 4675 6e63 7469 6f6e  l: nnq.QFunction
+000252e0: 616c 2c0a 2020 2020 2020 2020 2020 2020  al,.            
+000252f0: 2320 496e 7472 696e 7369 6320 6d6f 6475  # Intrinsic modu
+00025300: 6c65 733a 0a20 2020 2020 2020 2020 2020  les:.           
+00025310: 206e 6e69 2e43 6f6e 7652 654c 5532 643a   nni.ConvReLU2d:
+00025320: 206e 6e69 712e 436f 6e76 5265 4c55 3264   nniq.ConvReLU2d
+00025330: 2c0a 2020 2020 2020 2020 2020 2020 6e6e  ,.            nn
+00025340: 692e 436f 6e76 5265 4c55 3364 3a20 6e6e  i.ConvReLU3d: nn
+00025350: 6971 2e43 6f6e 7652 654c 5533 642c 0a20  iq.ConvReLU3d,. 
+00025360: 2020 2020 2020 2020 2020 206e 6e69 2e4c             nni.L
+00025370: 696e 6561 7252 654c 553a 206e 6e69 712e  inearReLU: nniq.
+00025380: 4c69 6e65 6172 5265 4c55 2c0a 2020 2020  LinearReLU,.    
+00025390: 2020 2020 2020 2020 6e6e 6971 6174 2e43          nniqat.C
+000253a0: 6f6e 7652 654c 5532 643a 206e 6e69 712e  onvReLU2d: nniq.
+000253b0: 436f 6e76 5265 4c55 3264 2c0a 2020 2020  ConvReLU2d,.    
+000253c0: 2020 2020 2020 2020 6e6e 6971 6174 2e4c          nniqat.L
+000253d0: 696e 6561 7252 654c 553a 206e 6e69 712e  inearReLU: nniq.
+000253e0: 4c69 6e65 6172 5265 4c55 2c0a 2020 2020  LinearReLU,.    
+000253f0: 2020 2020 2020 2020 6e6e 6971 6174 2e43          nniqat.C
+00025400: 6f6e 7642 6e32 643a 206e 6e71 2e43 6f6e  onvBn2d: nnq.Con
+00025410: 7632 642c 0a20 2020 2020 2020 2020 2020  v2d,.           
+00025420: 206e 6e69 7161 742e 436f 6e76 426e 5265   nniqat.ConvBnRe
+00025430: 4c55 3264 3a20 6e6e 6971 2e43 6f6e 7652  LU2d: nniq.ConvR
+00025440: 654c 5532 642c 0a20 2020 2020 2020 2020  eLU2d,.         
+00025450: 2020 2023 2051 4154 206d 6f64 756c 6573     # QAT modules
+00025460: 3a0a 2020 2020 2020 2020 2020 2020 6e6e  :.            nn
+00025470: 7161 742e 4c69 6e65 6172 3a20 6e6e 712e  qat.Linear: nnq.
+00025480: 4c69 6e65 6172 2c0a 2020 2020 2020 2020  Linear,.        
+00025490: 2020 2020 6e6e 7161 742e 436f 6e76 3264      nnqat.Conv2d
+000254a0: 3a20 6e6e 712e 436f 6e76 3264 2c0a 2020  : nnq.Conv2d,.  
+000254b0: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
+000254c0: 2222 220a 0a20 2020 2020 2020 2073 656c  """..        sel
+000254d0: 662e 7475 6e65 5f63 6667 203d 204e 6f6e  f.tune_cfg = Non
+000254e0: 650a 2020 2020 2020 2020 6966 2073 656c  e.        if sel
+000254f0: 662e 6465 7669 6365 203d 3d20 2263 7075  f.device == "cpu
+00025500: 223a 0a20 2020 2020 2020 2020 2020 2071  ":.            q
+00025510: 7565 7279 5f63 6f6e 6669 675f 6669 6c65  uery_config_file
+00025520: 203d 2022 7079 746f 7263 685f 6370 752e   = "pytorch_cpu.
+00025530: 7961 6d6c 220a 2020 2020 2020 2020 656c  yaml".        el
+00025540: 7365 3a20 2023 2070 7261 676d 613a 206e  se:  # pragma: n
+00025550: 6f20 636f 7665 720a 2020 2020 2020 2020  o cover.        
+00025560: 2020 2020 6173 7365 7274 2046 616c 7365      assert False
+00025570: 2c20 2255 6e73 7570 706f 7274 2074 6869  , "Unsupport thi
+00025580: 7320 6465 7669 6365 207b 7d22 2e66 6f72  s device {}".for
+00025590: 6d61 7428 7365 6c66 2e64 6576 6963 6529  mat(self.device)
+000255a0: 0a20 2020 2020 2020 2073 656c 662e 7175  .        self.qu
+000255b0: 6572 795f 6861 6e64 6c65 7220 3d20 5079  ery_handler = Py
+000255c0: 546f 7263 6851 7565 7279 280a 2020 2020  TorchQuery(.    
+000255d0: 2020 2020 2020 2020 6c6f 6361 6c5f 636f          local_co
+000255e0: 6e66 6967 5f66 696c 653d 6f73 2e70 6174  nfig_file=os.pat
+000255f0: 682e 6a6f 696e 286f 732e 7061 7468 2e64  h.join(os.path.d
+00025600: 6972 6e61 6d65 285f 5f66 696c 655f 5f29  irname(__file__)
+00025610: 2c20 7175 6572 795f 636f 6e66 6967 5f66  , query_config_f
+00025620: 696c 6529 290a 0a20 2020 2020 2020 2069  ile))..        i
+00025630: 6620 7365 6c66 2e61 7070 726f 6163 6820  f self.approach 
+00025640: 3d3d 2027 706f 7374 5f74 7261 696e 696e  == 'post_trainin
+00025650: 675f 6479 6e61 6d69 635f 7175 616e 7427  g_dynamic_quant'
+00025660: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
+00025670: 6c66 2e77 6869 7465 5f6c 6973 7420 3d20  lf.white_list = 
+00025680: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00025690: 2020 7471 2e71 7561 6e74 697a 6174 696f    tq.quantizatio
+000256a0: 6e5f 6d61 7070 696e 6773 2e67 6574 5f64  n_mappings.get_d
+000256b0: 6566 6175 6c74 5f64 796e 616d 6963 5f71  efault_dynamic_q
+000256c0: 7561 6e74 5f6d 6f64 756c 655f 6d61 7070  uant_module_mapp
+000256d0: 696e 6773 2829 0a20 2020 2020 2020 2065  ings().        e
+000256e0: 6c69 6620 7365 6c66 2e61 7070 726f 6163  lif self.approac
+000256f0: 6820 3d3d 2027 706f 7374 5f74 7261 696e  h == 'post_train
+00025700: 696e 675f 7374 6174 6963 5f71 7561 6e74  ing_static_quant
+00025710: 273a 0a20 2020 2020 2020 2020 2020 2073  ':.            s
+00025720: 656c 662e 7768 6974 655f 6c69 7374 203d  elf.white_list =
+00025730: 2074 712e 7175 616e 7469 7a61 7469 6f6e   tq.quantization
+00025740: 5f6d 6170 7069 6e67 732e 6765 745f 6465  _mappings.get_de
+00025750: 6661 756c 745f 7374 6174 6963 5f71 7561  fault_static_qua
+00025760: 6e74 5f6d 6f64 756c 655f 6d61 7070 696e  nt_module_mappin
+00025770: 6773 2829 0a20 2020 2020 2020 2065 6c73  gs().        els
+00025780: 653a 0a20 2020 2020 2020 2020 2020 2073  e:.            s
+00025790: 656c 662e 7768 6974 655f 6c69 7374 203d  elf.white_list =
+000257a0: 2074 712e 7175 616e 7469 7a61 7469 6f6e   tq.quantization
+000257b0: 5f6d 6170 7069 6e67 732e 6765 745f 6465  _mappings.get_de
+000257c0: 6661 756c 745f 7163 6f6e 6669 675f 7072  fault_qconfig_pr
+000257d0: 6f70 6167 6174 696f 6e5f 6c69 7374 2829  opagation_list()
+000257e0: 0a0a 2020 2020 4064 756d 705f 656c 6170  ..    @dump_elap
+000257f0: 7365 645f 7469 6d65 2822 5061 7373 2071  sed_time("Pass q
+00025800: 7561 6e74 697a 6520 6d6f 6465 6c22 290a  uantize model").
+00025810: 2020 2020 6465 6620 7175 616e 7469 7a65      def quantize
+00025820: 2873 656c 662c 2074 756e 655f 6366 672c  (self, tune_cfg,
+00025830: 206d 6f64 656c 2c20 6461 7461 6c6f 6164   model, dataload
+00025840: 6572 2c20 715f 6675 6e63 3d4e 6f6e 6529  er, q_func=None)
+00025850: 3a0a 2020 2020 2020 2020 2222 2245 7865  :.        """Exe
+00025860: 6375 7465 2074 6865 2071 7561 6e74 697a  cute the quantiz
+00025870: 6520 7072 6f63 6573 7320 6f6e 2074 6865  e process on the
+00025880: 2073 7065 6369 6669 6564 206d 6f64 656c   specified model
+00025890: 2e0a 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
+000258a0: 0a20 2020 2020 2020 2020 2020 2074 756e  .            tun
+000258b0: 655f 6366 6720 2864 6963 7429 3a20 7175  e_cfg (dict): qu
+000258c0: 616e 7469 7a61 7469 6f6e 2063 6f6e 6669  antization confi
+000258d0: 672e 0a20 2020 2020 2020 2020 2020 206d  g..            m
+000258e0: 6f64 656c 2028 6f62 6a65 6374 293a 206d  odel (object): m
+000258f0: 6f64 656c 206e 6565 6420 746f 2064 6f20  odel need to do 
+00025900: 7175 616e 7469 7a61 7469 6f6e 2e0a 2020  quantization..  
+00025910: 2020 2020 2020 2020 2020 6461 7461 6c6f            datalo
+00025920: 6164 6572 2028 6f62 6a65 6374 293a 2063  ader (object): c
+00025930: 616c 6962 7261 7469 6f6e 2064 6174 6173  alibration datas
+00025940: 6574 2e0a 2020 2020 2020 2020 2020 2020  et..            
+00025950: 715f 6675 6e63 2028 6f62 6a65 7874 2c20  q_func (objext, 
+00025960: 6f70 7469 6f6e 616c 293a 2074 7261 696e  optional): train
+00025970: 696e 6720 6675 6e63 7469 6f6e 2066 6f72  ing function for
+00025980: 2071 7561 6e74 697a 6174 696f 6e20 6177   quantization aw
+00025990: 6172 6520 7472 6169 6e69 6e67 206d 6f64  are training mod
+000259a0: 652e 0a0a 2020 2020 2020 2020 5265 7475  e...        Retu
+000259b0: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
+000259c0: 2028 6f62 6a65 6374 293a 2071 7561 6e74   (object): quant
+000259d0: 697a 6564 206d 6f64 656c 0a20 2020 2020  ized model.     
+000259e0: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
+000259f0: 6173 7365 7274 2069 7369 6e73 7461 6e63  assert isinstanc
+00025a00: 6528 6d6f 6465 6c2e 5f6d 6f64 656c 2c20  e(model._model, 
+00025a10: 746f 7263 682e 6e6e 2e4d 6f64 756c 6529  torch.nn.Module)
+00025a20: 2c20 5c0a 2020 2020 2020 2020 2020 2020  , \.            
+00025a30: 2020 2022 5468 6520 6d6f 6465 6c20 7061     "The model pa
+00025a40: 7373 6564 2069 6e20 6973 206e 6f74 2074  ssed in is not t
+00025a50: 6865 2069 6e73 7461 6e63 6520 6f66 2074  he instance of t
+00025a60: 6f72 6368 2e6e 6e2e 4d6f 6475 6c65 220a  orch.nn.Module".
+00025a70: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00025a80: 7065 7266 6f72 6d61 6e63 655f 6f6e 6c79  performance_only
+00025a90: 3a0a 2020 2020 2020 2020 2020 2020 715f  :.            q_
+00025aa0: 6d6f 6465 6c20 3d20 6d6f 6465 6c0a 2020  model = model.  
+00025ab0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00025ac0: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+00025ad0: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+00025ae0: 6f64 656c 203d 2063 6f70 792e 6465 6570  odel = copy.deep
+00025af0: 636f 7079 286d 6f64 656c 290a 2020 2020  copy(model).    
+00025b00: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
+00025b10: 6465 6c2e 6670 3332 5f6d 6f64 656c 203d  del.fp32_model =
+00025b20: 206d 6f64 656c 2e66 7033 325f 6d6f 6465   model.fp32_mode
+00025b30: 6c0a 2020 2020 2020 2020 2020 2020 6578  l.            ex
+00025b40: 6365 7074 2045 7863 6570 7469 6f6e 2061  cept Exception a
+00025b50: 7320 653a 2020 2320 7072 6167 6d61 3a20  s e:  # pragma: 
+00025b60: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
+00025b70: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+00025b80: 7761 726e 696e 6728 2246 6169 6c20 746f  warning("Fail to
+00025b90: 2064 6565 7020 636f 7079 2074 6865 206d   deep copy the m
+00025ba0: 6f64 656c 2064 7565 2074 6f20 7b7d 2c20  odel due to {}, 
+00025bb0: 696e 706c 6163 6520 6973 2075 7365 6420  inplace is used 
+00025bc0: 6e6f 772e 222e 666f 726d 6174 280a 2020  now.".format(.  
+00025bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00025be0: 2020 7265 7072 2865 2929 290a 2020 2020    repr(e))).    
+00025bf0: 2020 2020 2020 2020 2020 2020 715f 6d6f              q_mo
+00025c00: 6465 6c20 3d20 6d6f 6465 6c0a 2020 2020  del = model.    
+00025c10: 2020 2020 715f 6d6f 6465 6c2e 5f6d 6f64      q_model._mod
+00025c20: 656c 2e65 7661 6c28 290a 0a20 2020 2020  el.eval()..     
+00025c30: 2020 2023 2046 6f72 2073 6d6f 6f74 6871     # For smoothq
+00025c40: 7561 6e74 206f 7074 696d 697a 6564 206d  uant optimized m
+00025c50: 6f64 656c 0a20 2020 2020 2020 2072 6563  odel.        rec
+00025c60: 6970 655f 6366 6773 203d 2074 756e 655f  ipe_cfgs = tune_
+00025c70: 6366 672e 6765 7428 2772 6563 6970 655f  cfg.get('recipe_
+00025c80: 6366 6773 272c 204e 6f6e 6529 0a20 2020  cfgs', None).   
+00025c90: 2020 2020 2069 6620 7265 6369 7065 5f63       if recipe_c
+00025ca0: 6667 7320 616e 6420 7265 6369 7065 5f63  fgs and recipe_c
+00025cb0: 6667 732e 6765 7428 2773 6d6f 6f74 685f  fgs.get('smooth_
+00025cc0: 7175 616e 7427 2c20 4661 6c73 6529 205c  quant', False) \
+00025cd0: 0a20 2020 2020 2020 2020 2061 6e64 206e  .          and n
+00025ce0: 6f74 2072 6563 6970 655f 6366 6773 5b27  ot recipe_cfgs['
+00025cf0: 736d 6f6f 7468 5f71 7561 6e74 5f61 7267  smooth_quant_arg
+00025d00: 7327 5d5b 2766 6f6c 6469 6e67 275d 205c  s']['folding'] \
+00025d10: 0a20 2020 2020 2020 2020 2061 6e64 2073  .          and s
+00025d20: 656c 662e 6170 7072 6f61 6368 2021 3d20  elf.approach != 
+00025d30: 2770 6f73 745f 7472 6169 6e69 6e67 5f64  'post_training_d
+00025d40: 796e 616d 6963 5f71 7561 6e74 273a 0a20  ynamic_quant':. 
+00025d50: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00025d60: 6574 7572 6e20 7365 6c66 2e71 6471 5f71  eturn self.qdq_q
+00025d70: 7561 6e74 697a 6528 715f 6d6f 6465 6c2c  uantize(q_model,
+00025d80: 2074 756e 655f 6366 6729 0a0a 2020 2020   tune_cfg)..    
+00025d90: 2020 2020 7365 6c66 2e74 756e 655f 6366      self.tune_cf
+00025da0: 6720 3d20 7475 6e65 5f63 6667 0a20 2020  g = tune_cfg.   
+00025db0: 2020 2020 2073 656c 662e 7475 6e65 5f63       self.tune_c
+00025dc0: 6667 5b22 6170 7072 6f61 6368 225d 203d  fg["approach"] =
+00025dd0: 2073 656c 662e 6170 7072 6f61 6368 0a20   self.approach. 
+00025de0: 2020 2020 2020 2073 656c 662e 7475 6e65         self.tune
+00025df0: 5f63 6667 5b22 7265 6475 6365 5f72 616e  _cfg["reduce_ran
+00025e00: 6765 225d 203d 2052 4544 5543 455f 5241  ge"] = REDUCE_RA
+00025e10: 4e47 450a 2020 2020 2020 2020 7365 6c66  NGE.        self
+00025e20: 2e74 756e 655f 6366 675b 2266 7261 6d65  .tune_cfg["frame
+00025e30: 776f 726b 225d 203d 2022 7079 746f 7263  work"] = "pytorc
+00025e40: 685f 6678 220a 0a20 2020 2020 2020 2023  h_fx"..        #
+00025e50: 2050 7954 6f72 6368 2031 2e31 3320 616e   PyTorch 1.13 an
+00025e60: 6420 6162 6f76 6520 7665 7273 696f 6e2c  d above version,
+00025e70: 206e 6565 6420 6578 616d 706c 655f 696e   need example_in
+00025e80: 7075 7473 2066 6f72 2066 7820 7472 6163  puts for fx trac
+00025e90: 652c 2062 7574 2069 7420 6e6f 7420 7265  e, but it not re
+00025ea0: 616c 7920 7573 6564 2c0a 2020 2020 2020  aly used,.      
+00025eb0: 2020 2320 736f 2073 6574 2069 7420 746f    # so set it to
+00025ec0: 204e 6f6e 652e 0a20 2020 2020 2020 2073   None..        s
+00025ed0: 656c 662e 6578 616d 706c 655f 696e 7075  elf.example_inpu
+00025ee0: 7473 203d 204e 6f6e 650a 2020 2020 2020  ts = None.      
+00025ef0: 2020 6966 2073 656c 662e 6465 6661 756c    if self.defaul
+00025f00: 745f 7163 6f6e 6669 6720 6973 206e 6f74  t_qconfig is not
+00025f10: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00025f20: 2020 2064 6566 6175 6c74 5f71 636f 6e66     default_qconf
+00025f30: 6967 203d 2063 6f70 792e 6465 6570 636f  ig = copy.deepco
+00025f40: 7079 2873 656c 662e 6465 6661 756c 745f  py(self.default_
+00025f50: 7163 6f6e 6669 6729 0a20 2020 2020 2020  qconfig).       
+00025f60: 2020 2020 2064 6566 6175 6c74 5f71 636f       default_qco
+00025f70: 6e66 6967 5b27 6163 7469 7661 7469 6f6e  nfig['activation
+00025f80: 275d 5b27 6474 7970 6527 5d20 3d20 5c0a  ']['dtype'] = \.
+00025f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00025fa0: 7365 6c66 2e64 6566 6175 6c74 5f71 636f  self.default_qco
+00025fb0: 6e66 6967 5b27 6163 7469 7661 7469 6f6e  nfig['activation
+00025fc0: 275d 5b27 6474 7970 6527 5d5b 305d 0a20  ']['dtype'][0]. 
+00025fd0: 2020 2020 2020 2020 2020 2064 6566 6175             defau
+00025fe0: 6c74 5f71 636f 6e66 6967 5b27 7765 6967  lt_qconfig['weig
+00025ff0: 6874 275d 5b27 6474 7970 6527 5d20 3d20  ht']['dtype'] = 
+00026000: 7365 6c66 2e64 6566 6175 6c74 5f71 636f  self.default_qco
+00026010: 6e66 6967 5b27 7765 6967 6874 275d 5b27  nfig['weight']['
+00026020: 6474 7970 6527 5d5b 305d 0a20 2020 2020  dtype'][0].     
+00026030: 2020 2020 2020 2073 656c 662e 7475 6e65         self.tune
+00026040: 5f63 6667 5b22 6f70 225d 5b28 2264 6566  _cfg["op"][("def
+00026050: 6175 6c74 5f71 636f 6e66 6967 222c 2022  ault_qconfig", "
+00026060: 2229 5d20 3d20 6465 6661 756c 745f 7163  ")] = default_qc
+00026070: 6f6e 6669 670a 2020 2020 2020 2020 6f70  onfig.        op
+00026080: 5f63 6667 7320 3d20 5f63 6667 5f74 6f5f  _cfgs = _cfg_to_
+00026090: 7163 6f6e 6669 6728 7365 6c66 2e74 756e  qconfig(self.tun
+000260a0: 655f 6366 672c 2073 656c 662e 6170 7072  e_cfg, self.appr
+000260b0: 6f61 6368 290a 2020 2020 2020 2020 7365  oach).        se
+000260c0: 6c66 2e74 756e 655f 6366 675b 2762 6631  lf.tune_cfg['bf1
+000260d0: 365f 6f70 735f 6c69 7374 275d 203d 206f  6_ops_list'] = o
+000260e0: 705f 6366 6773 5b27 6266 3136 5f6f 7073  p_cfgs['bf16_ops
+000260f0: 5f6c 6973 7427 5d0a 2020 2020 2020 2020  _list'].        
+00026100: 6465 6c20 6f70 5f63 6667 735b 2762 6631  del op_cfgs['bf1
+00026110: 365f 6f70 735f 6c69 7374 275d 0a20 2020  6_ops_list'].   
+00026120: 2020 2020 2067 632e 636f 6c6c 6563 7428       gc.collect(
+00026130: 290a 0a20 2020 2020 2020 2066 726f 6d20  )..        from 
+00026140: 746f 7263 682e 7175 616e 7469 7a61 7469  torch.quantizati
+00026150: 6f6e 2e71 7561 6e74 697a 655f 6678 2069  on.quantize_fx i
+00026160: 6d70 6f72 7420 7072 6570 6172 655f 6678  mport prepare_fx
+00026170: 2c20 636f 6e76 6572 745f 6678 2c20 7072  , convert_fx, pr
+00026180: 6570 6172 655f 7161 745f 6678 0a20 2020  epare_qat_fx.   
+00026190: 2020 2020 2069 6620 715f 6d6f 6465 6c2e       if q_model.
+000261a0: 6b77 6172 6773 2069 7320 6e6f 7420 4e6f  kwargs is not No
+000261b0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+000261c0: 7365 6c66 2e70 7265 7061 7265 5f63 7573  self.prepare_cus
+000261d0: 746f 6d5f 636f 6e66 6967 5f64 6963 7420  tom_config_dict 
+000261e0: 3d20 715f 6d6f 6465 6c2e 6b77 6172 6773  = q_model.kwargs
+000261f0: 2e67 6574 2827 7072 6570 6172 655f 6375  .get('prepare_cu
+00026200: 7374 6f6d 5f63 6f6e 6669 675f 6469 6374  stom_config_dict
+00026210: 272c 0a20 2020 2020 2020 2020 2020 2020  ',.             
+00026220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026250: 2020 2020 4e6f 6e65 290a 2020 2020 2020      None).      
+00026260: 2020 2020 2020 7365 6c66 2e63 6f6e 7665        self.conve
+00026270: 7274 5f63 7573 746f 6d5f 636f 6e66 6967  rt_custom_config
+00026280: 5f64 6963 7420 3d20 715f 6d6f 6465 6c2e  _dict = q_model.
+00026290: 6b77 6172 6773 2e67 6574 2827 636f 6e76  kwargs.get('conv
+000262a0: 6572 745f 6375 7374 6f6d 5f63 6f6e 6669  ert_custom_confi
+000262b0: 675f 6469 6374 272c 0a20 2020 2020 2020  g_dict',.       
+000262c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000262d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000262e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000262f0: 2020 2020 2020 2020 2020 4e6f 6e65 290a            None).
+00026300: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00026310: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
+00026320: 7265 7061 7265 5f63 7573 746f 6d5f 636f  repare_custom_co
+00026330: 6e66 6967 5f64 6963 742c 2073 656c 662e  nfig_dict, self.
+00026340: 636f 6e76 6572 745f 6375 7374 6f6d 5f63  convert_custom_c
+00026350: 6f6e 6669 675f 6469 6374 203d 204e 6f6e  onfig_dict = Non
+00026360: 652c 204e 6f6e 650a 2020 2020 2020 2020  e, None.        
+00026370: 7365 6c66 2e66 785f 6f70 5f63 6667 7320  self.fx_op_cfgs 
+00026380: 3d20 5f63 6667 735f 746f 5f66 785f 6366  = _cfgs_to_fx_cf
+00026390: 6773 286f 705f 6366 6773 2c20 7365 6c66  gs(op_cfgs, self
+000263a0: 2e61 7070 726f 6163 6829 0a20 2020 2020  .approach).     
+000263b0: 2020 2073 656c 662e 7475 6e65 5f63 6667     self.tune_cfg
+000263c0: 5b27 6678 5f73 7562 5f6d 6f64 756c 655f  ['fx_sub_module_
+000263d0: 6c69 7374 275d 203d 2073 656c 662e 7375  list'] = self.su
+000263e0: 625f 6d6f 6475 6c65 5f6c 6973 740a 2020  b_module_list.  
+000263f0: 2020 2020 2020 6966 2073 656c 662e 6170        if self.ap
+00026400: 7072 6f61 6368 203d 3d20 2771 7561 6e74  proach == 'quant
+00026410: 5f61 7761 7265 5f74 7261 696e 696e 6727  _aware_training'
+00026420: 3a0a 2020 2020 2020 2020 2020 2020 715f  :.            q_
+00026430: 6d6f 6465 6c2e 5f6d 6f64 656c 2e74 7261  model._model.tra
+00026440: 696e 2829 0a20 2020 2020 2020 2020 2020  in().           
+00026450: 2069 6620 7365 6c66 2e73 7562 5f6d 6f64   if self.sub_mod
+00026460: 756c 655f 6c69 7374 2069 7320 4e6f 6e65  ule_list is None
+00026470: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00026480: 2020 746d 705f 6d6f 6465 6c20 3d20 715f    tmp_model = q_
+00026490: 6d6f 6465 6c2e 5f6d 6f64 656c 0a20 2020  model._model.   
+000264a0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000264b0: 7365 6c66 2e76 6572 7369 6f6e 203e 2056  self.version > V
+000264c0: 6572 7369 6f6e 2822 312e 3132 2e31 2229  ersion("1.12.1")
+000264d0: 3a20 2023 2070 7261 676d 613a 206e 6f20  :  # pragma: no 
+000264e0: 636f 7665 720a 2020 2020 2020 2020 2020  cover.          
+000264f0: 2020 2020 2020 2020 2020 2320 7079 6c69            # pyli
+00026500: 6e74 3a20 6469 7361 626c 653d 4531 3132  nt: disable=E112
+00026510: 330a 2020 2020 2020 2020 2020 2020 2020  3.              
+00026520: 2020 2020 2020 715f 6d6f 6465 6c2e 5f6d        q_model._m
+00026530: 6f64 656c 203d 2070 7265 7061 7265 5f71  odel = prepare_q
+00026540: 6174 5f66 7828 0a20 2020 2020 2020 2020  at_fx(.         
+00026550: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+00026560: 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c 0a20  _model._model,. 
+00026570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026580: 2020 2020 2020 2073 656c 662e 6678 5f6f         self.fx_o
+00026590: 705f 6366 6773 2c0a 2020 2020 2020 2020  p_cfgs,.        
+000265a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000265b0: 6578 616d 706c 655f 696e 7075 7473 3d73  example_inputs=s
+000265c0: 656c 662e 6578 616d 706c 655f 696e 7075  elf.example_inpu
+000265d0: 7473 2c0a 2020 2020 2020 2020 2020 2020  ts,.            
+000265e0: 2020 2020 2020 2020 2020 2020 7072 6570              prep
+000265f0: 6172 655f 6375 7374 6f6d 5f63 6f6e 6669  are_custom_confi
+00026600: 673d 7365 6c66 2e70 7265 7061 7265 5f63  g=self.prepare_c
+00026610: 7573 746f 6d5f 636f 6e66 6967 5f64 6963  ustom_config_dic
+00026620: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
+00026630: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00026640: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00026650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026660: 2020 715f 6d6f 6465 6c2e 5f6d 6f64 656c    q_model._model
+00026670: 203d 2070 7265 7061 7265 5f71 6174 5f66   = prepare_qat_f
+00026680: 7828 0a20 2020 2020 2020 2020 2020 2020  x(.             
+00026690: 2020 2020 2020 2020 2020 2071 5f6d 6f64             q_mod
+000266a0: 656c 2e5f 6d6f 6465 6c2c 0a20 2020 2020  el._model,.     
+000266b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000266c0: 2020 2073 656c 662e 6678 5f6f 705f 6366     self.fx_op_cf
+000266d0: 6773 2c0a 2020 2020 2020 2020 2020 2020  gs,.            
+000266e0: 2020 2020 2020 2020 2020 2020 7072 6570              prep
+000266f0: 6172 655f 6375 7374 6f6d 5f63 6f6e 6669  are_custom_confi
+00026700: 675f 6469 6374 3d73 656c 662e 7072 6570  g_dict=self.prep
+00026710: 6172 655f 6375 7374 6f6d 5f63 6f6e 6669  are_custom_confi
+00026720: 675f 6469 6374 0a20 2020 2020 2020 2020  g_dict.         
+00026730: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00026740: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+00026750: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+00026760: 6f67 6765 722e 696e 666f 2827 4678 2074  ogger.info('Fx t
+00026770: 7261 6365 206f 6620 7468 6520 656e 7469  race of the enti
+00026780: 7265 206d 6f64 656c 2066 6169 6c65 642e  re model failed.
+00026790: 2027 202b 205c 0a20 2020 2020 2020 2020   ' + \.         
+000267a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000267b0: 2020 2027 5765 2077 696c 6c20 636f 6e64     'We will cond
+000267c0: 7563 7420 6175 746f 2071 7561 6e74 697a  uct auto quantiz
+000267d0: 6174 696f 6e27 290a 2020 2020 2020 2020  ation').        
+000267e0: 2020 2020 2020 2020 5079 546f 7263 685f          PyTorch_
+000267f0: 4658 4164 6170 746f 722e 7072 6570 6172  FXAdaptor.prepar
+00026800: 655f 7375 625f 6772 6170 6828 0a20 2020  e_sub_graph(.   
+00026810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026820: 2073 656c 662e 7375 625f 6d6f 6475 6c65   self.sub_module
+00026830: 5f6c 6973 742c 0a20 2020 2020 2020 2020  _list,.         
+00026840: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00026850: 6678 5f6f 705f 6366 6773 2c0a 2020 2020  fx_op_cfgs,.    
+00026860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026870: 715f 6d6f 6465 6c2e 5f6d 6f64 656c 2c0a  q_model._model,.
+00026880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026890: 2020 2020 7072 6566 6978 3d27 272c 0a20      prefix='',. 
+000268a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000268b0: 2020 2069 735f 7161 743d 5472 7565 2c0a     is_qat=True,.
+000268c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000268d0: 2020 2020 6578 616d 706c 655f 696e 7075      example_inpu
+000268e0: 7473 3d73 656c 662e 6578 616d 706c 655f  ts=self.example_
+000268f0: 696e 7075 7473 2c0a 2020 2020 2020 2020  inputs,.        
+00026900: 2020 2020 2020 2020 2020 2020 6375 7374              cust
+00026910: 6f6d 5f63 6f6e 6669 673d 7365 6c66 2e70  om_config=self.p
+00026920: 7265 7061 7265 5f63 7573 746f 6d5f 636f  repare_custom_co
+00026930: 6e66 6967 5f64 6963 740a 2020 2020 2020  nfig_dict.      
+00026940: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00026950: 2020 2020 2020 2020 2320 715f 6675 6e63          # q_func
+00026960: 2063 616e 2062 6520 6372 6561 7465 6420   can be created 
+00026970: 6279 206e 6575 7261 6c5f 636f 6d70 7265  by neural_compre
+00026980: 7373 6f72 2069 6e74 6572 6e61 6c20 6f72  ssor internal or
+00026990: 2070 6173 7365 6420 6279 2075 7365 722e   passed by user.
+000269a0: 2049 7427 7320 6372 6974 6963 616c 2074   It's critical t
+000269b0: 6f0a 2020 2020 2020 2020 2020 2020 2320  o.            # 
+000269c0: 6469 7374 696e 6775 6973 6820 686f 7720  distinguish how 
+000269d0: 715f 6675 6e63 2069 7320 7061 7373 6564  q_func is passed
+000269e0: 2073 696e 6365 206e 6575 7261 6c5f 636f   since neural_co
+000269f0: 6d70 7265 7373 6f72 2062 7569 6c74 2d69  mpressor built-i
+00026a00: 6e20 6675 6e63 7469 6f6e 7320 6163 6365  n functions acce
+00026a10: 7074 0a20 2020 2020 2020 2020 2020 2023  pt.            #
+00026a20: 206e 6575 7261 6c5f 636f 6d70 7265 7373   neural_compress
+00026a30: 6f72 206d 6f64 656c 2061 6e64 2075 7365  or model and use
+00026a40: 7220 6465 6669 6e65 6420 6675 6e63 2073  r defined func s
+00026a50: 686f 756c 6420 6163 6365 7074 2066 7261  hould accept fra
+00026a60: 6d65 776f 726b 206d 6f64 656c 2e0a 2020  mework model..  
+00026a70: 2020 2020 2020 2020 2020 2320 466f 7220            # For 
+00026a80: 6578 706f 7274 2041 5049 0a20 2020 2020  export API.     
+00026a90: 2020 2020 2020 2068 6f6f 6b5f 6c69 7374         hook_list
+00026aa0: 203d 2074 6f72 6368 5f75 7469 6c73 2e75   = torch_utils.u
+00026ab0: 7469 6c2e 5f73 6574 5f69 6e70 7574 5f73  til._set_input_s
+00026ac0: 6361 6c65 5f68 6f6f 6b28 715f 6d6f 6465  cale_hook(q_mode
+00026ad0: 6c2e 5f6d 6f64 656c 2c20 6f70 5f63 6667  l._model, op_cfg
+00026ae0: 7329 0a20 2020 2020 2020 2020 2020 2071  s).            q
+00026af0: 5f6d 6f64 656c 2e5f 6d6f 6465 6c20 3d20  _model._model = 
+00026b00: 715f 6675 6e63 280a 2020 2020 2020 2020  q_func(.        
+00026b10: 2020 2020 2020 2020 715f 6d6f 6465 6c20          q_model 
+00026b20: 6966 2067 6574 6174 7472 2871 5f66 756e  if getattr(q_fun
+00026b30: 632c 2027 6275 696c 7469 6e27 2c20 4e6f  c, 'builtin', No
+00026b40: 6e65 2920 656c 7365 2071 5f6d 6f64 656c  ne) else q_model
+00026b50: 2e5f 6d6f 6465 6c29 0a20 2020 2020 2020  ._model).       
+00026b60: 2020 2020 2061 7373 6572 7420 715f 6d6f       assert q_mo
+00026b70: 6465 6c2e 5f6d 6f64 656c 2069 7320 6e6f  del._model is no
+00026b80: 7420 4e6f 6e65 2c20 2250 6c65 6173 6520  t None, "Please 
+00026b90: 7265 7475 726e 2061 2074 7261 696e 6564  return a trained
+00026ba0: 206d 6f64 656c 2069 6e20 7472 6169 6e20   model in train 
+00026bb0: 6675 6e63 7469 6f6e 2122 0a20 2020 2020  function!".     
+00026bc0: 2020 2020 2020 2071 5f6d 6f64 656c 2e5f         q_model._
+00026bd0: 6d6f 6465 6c2e 6576 616c 2829 0a20 2020  model.eval().   
+00026be0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00026bf0: 2020 2020 2020 2069 6620 7365 6c66 2e73         if self.s
+00026c00: 7562 5f6d 6f64 756c 655f 6c69 7374 2069  ub_module_list i
+00026c10: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+00026c20: 2020 2020 2020 2020 746d 705f 6d6f 6465          tmp_mode
+00026c30: 6c20 3d20 715f 6d6f 6465 6c2e 5f6d 6f64  l = q_model._mod
+00026c40: 656c 0a20 2020 2020 2020 2020 2020 2020  el.             
+00026c50: 2020 2069 6620 7365 6c66 2e76 6572 7369     if self.versi
+00026c60: 6f6e 2e72 656c 6561 7365 203e 3d20 5665  on.release >= Ve
+00026c70: 7273 696f 6e28 2231 2e31 332e 3022 292e  rsion("1.13.0").
+00026c80: 7265 6c65 6173 653a 2020 2320 7072 6167  release:  # prag
+00026c90: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
+00026ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026cb0: 2023 2070 796c 696e 743a 2064 6973 6162   # pylint: disab
+00026cc0: 6c65 3d45 3131 3233 0a20 2020 2020 2020  le=E1123.       
+00026cd0: 2020 2020 2020 2020 2020 2020 2071 5f6d               q_m
+00026ce0: 6f64 656c 2e5f 6d6f 6465 6c20 3d20 7072  odel._model = pr
+00026cf0: 6570 6172 655f 6678 280a 2020 2020 2020  epare_fx(.      
+00026d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026d10: 2020 715f 6d6f 6465 6c2e 5f6d 6f64 656c    q_model._model
+00026d20: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00026d30: 2020 2020 2020 2020 2020 7365 6c66 2e66            self.f
+00026d40: 785f 6f70 5f63 6667 732c 0a20 2020 2020  x_op_cfgs,.     
+00026d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026d60: 2020 2065 7861 6d70 6c65 5f69 6e70 7574     example_input
+00026d70: 733d 7365 6c66 2e65 7861 6d70 6c65 5f69  s=self.example_i
+00026d80: 6e70 7574 732c 0a20 2020 2020 2020 2020  nputs,.         
+00026d90: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00026da0: 7265 7061 7265 5f63 7573 746f 6d5f 636f  repare_custom_co
+00026db0: 6e66 6967 3d73 656c 662e 7072 6570 6172  nfig=self.prepar
+00026dc0: 655f 6375 7374 6f6d 5f63 6f6e 6669 675f  e_custom_config_
+00026dd0: 6469 6374 0a20 2020 2020 2020 2020 2020  dict.           
+00026de0: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+00026df0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00026e00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00026e10: 2020 2020 2071 5f6d 6f64 656c 2e5f 6d6f       q_model._mo
+00026e20: 6465 6c20 3d20 7072 6570 6172 655f 6678  del = prepare_fx
+00026e30: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00026e40: 2020 2020 2020 2020 2020 715f 6d6f 6465            q_mode
+00026e50: 6c2e 5f6d 6f64 656c 2c0a 2020 2020 2020  l._model,.      
+00026e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026e70: 2020 7365 6c66 2e66 785f 6f70 5f63 6667    self.fx_op_cfg
+00026e80: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
+00026e90: 2020 2020 2020 2020 2020 2070 7265 7061             prepa
+00026ea0: 7265 5f63 7573 746f 6d5f 636f 6e66 6967  re_custom_config
+00026eb0: 5f64 6963 743d 7365 6c66 2e70 7265 7061  _dict=self.prepa
+00026ec0: 7265 5f63 7573 746f 6d5f 636f 6e66 6967  re_custom_config
+00026ed0: 5f64 6963 740a 2020 2020 2020 2020 2020  _dict.          
+00026ee0: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00026ef0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00026f00: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
+00026f10: 6767 6572 2e69 6e66 6f28 2746 7820 7472  gger.info('Fx tr
+00026f20: 6163 6520 6f66 2074 6865 2065 6e74 6972  ace of the entir
+00026f30: 6520 6d6f 6465 6c20 6661 696c 6564 2c20  e model failed, 
+00026f40: 2720 2b20 5c0a 2020 2020 2020 2020 2020  ' + \.          
+00026f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026f60: 2020 2757 6520 7769 6c6c 2063 6f6e 6475    'We will condu
+00026f70: 6374 2061 7574 6f20 7175 616e 7469 7a61  ct auto quantiza
+00026f80: 7469 6f6e 2729 0a20 2020 2020 2020 2020  tion').         
+00026f90: 2020 2020 2020 2050 7954 6f72 6368 5f46         PyTorch_F
+00026fa0: 5841 6461 7074 6f72 2e70 7265 7061 7265  XAdaptor.prepare
+00026fb0: 5f73 7562 5f67 7261 7068 280a 2020 2020  _sub_graph(.    
+00026fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026fd0: 7365 6c66 2e73 7562 5f6d 6f64 756c 655f  self.sub_module_
+00026fe0: 6c69 7374 2c0a 2020 2020 2020 2020 2020  list,.          
+00026ff0: 2020 2020 2020 2020 2020 7365 6c66 2e66            self.f
+00027000: 785f 6f70 5f63 6667 732c 0a20 2020 2020  x_op_cfgs,.     
+00027010: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+00027020: 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c 0a20  _model._model,. 
+00027030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027040: 2020 2070 7265 6669 783d 2727 2c0a 2020     prefix='',.  
+00027050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027060: 2020 6578 616d 706c 655f 696e 7075 7473    example_inputs
+00027070: 3d73 656c 662e 6578 616d 706c 655f 696e  =self.example_in
+00027080: 7075 7473 2c0a 2020 2020 2020 2020 2020  puts,.          
+00027090: 2020 2020 2020 2020 2020 6375 7374 6f6d            custom
+000270a0: 5f63 6f6e 6669 673d 7365 6c66 2e70 7265  _config=self.pre
+000270b0: 7061 7265 5f63 7573 746f 6d5f 636f 6e66  pare_custom_conf
+000270c0: 6967 5f64 6963 740a 2020 2020 2020 2020  ig_dict.        
+000270d0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+000270e0: 2020 2020 2020 6966 2073 656c 662e 6170        if self.ap
+000270f0: 7072 6f61 6368 2069 6e20 5b27 706f 7374  proach in ['post
+00027100: 5f74 7261 696e 696e 675f 7374 6174 6963  _training_static
+00027110: 5f71 7561 6e74 272c 2027 706f 7374 5f74  _quant', 'post_t
+00027120: 7261 696e 696e 675f 6175 746f 5f71 7561  raining_auto_qua
+00027130: 6e74 275d 3a0a 2020 2020 2020 2020 2020  nt']:.          
+00027140: 2020 2020 2020 2320 466f 7220 6578 706f        # For expo
+00027150: 7274 2041 5049 0a20 2020 2020 2020 2020  rt API.         
+00027160: 2020 2020 2020 2068 6f6f 6b5f 6c69 7374         hook_list
+00027170: 203d 2074 6f72 6368 5f75 7469 6c73 2e75   = torch_utils.u
+00027180: 7469 6c2e 5f73 6574 5f69 6e70 7574 5f73  til._set_input_s
+00027190: 6361 6c65 5f68 6f6f 6b28 715f 6d6f 6465  cale_hook(q_mode
+000271a0: 6c2e 5f6d 6f64 656c 2c20 6f70 5f63 6667  l._model, op_cfg
+000271b0: 7329 0a20 2020 2020 2020 2020 2020 2020  s).             
+000271c0: 2020 2069 7465 7261 7469 6f6e 7320 3d20     iterations = 
+000271d0: 7475 6e65 5f63 6667 2e67 6574 2827 6361  tune_cfg.get('ca
+000271e0: 6c69 625f 6974 6572 6174 696f 6e27 2c20  lib_iteration', 
+000271f0: 3129 0a20 2020 2020 2020 2020 2020 2020  1).             
+00027200: 2020 2069 6620 715f 6675 6e63 2069 7320     if q_func is 
+00027210: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00027220: 2020 2020 2020 2020 2020 2020 2020 715f                q_
+00027230: 6675 6e63 2871 5f6d 6f64 656c 2e5f 6d6f  func(q_model._mo
+00027240: 6465 6c29 0a20 2020 2020 2020 2020 2020  del).           
+00027250: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00027260: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00027270: 656c 662e 6d6f 6465 6c5f 6361 6c69 6272  elf.model_calibr
+00027280: 6174 696f 6e28 0a20 2020 2020 2020 2020  ation(.         
+00027290: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+000272a0: 5f6d 6f64 656c 2e5f 6d6f 6465 6c2c 0a20  _model._model,. 
+000272b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000272c0: 2020 2020 2020 2064 6174 616c 6f61 6465         dataloade
+000272d0: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
+000272e0: 2020 2020 2020 2020 2020 2069 7465 7261             itera
+000272f0: 7469 6f6e 732c 0a20 2020 2020 2020 2020  tions,.         
+00027300: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00027310: 616c 6962 5f73 616d 706c 696e 675f 7369  alib_sampling_si
+00027320: 7a65 3d74 756e 655f 6366 672e 6765 7428  ze=tune_cfg.get(
+00027330: 2763 616c 6962 5f73 616d 706c 696e 675f  'calib_sampling_
+00027340: 7369 7a65 272c 2031 290a 2020 2020 2020  size', 1).      
+00027350: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00027360: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00027370: 2e61 7070 726f 6163 6820 213d 2027 706f  .approach != 'po
+00027380: 7374 5f74 7261 696e 696e 675f 6479 6e61  st_training_dyna
+00027390: 6d69 635f 7175 616e 7427 3a0a 2020 2020  mic_quant':.    
+000273a0: 2020 2020 2020 2020 2320 466f 7220 6578          # For ex
+000273b0: 706f 7274 2041 5049 0a20 2020 2020 2020  port API.       
+000273c0: 2020 2020 2073 6361 6c65 5f69 6e66 6f20       scale_info 
+000273d0: 3d20 746f 7263 685f 7574 696c 732e 7574  = torch_utils.ut
+000273e0: 696c 2e5f 6765 745f 696e 7075 745f 7363  il._get_input_sc
+000273f0: 616c 6528 715f 6d6f 6465 6c2e 5f6d 6f64  ale(q_model._mod
+00027400: 656c 2c20 686f 6f6b 5f6c 6973 7429 0a0a  el, hook_list)..
+00027410: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00027420: 7375 625f 6d6f 6475 6c65 5f6c 6973 7420  sub_module_list 
+00027430: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+00027440: 2020 2020 2069 6620 7365 6c66 2e76 6572       if self.ver
+00027450: 7369 6f6e 2e72 656c 6561 7365 203e 3d20  sion.release >= 
+00027460: 5665 7273 696f 6e28 2231 2e31 332e 3022  Version("1.13.0"
+00027470: 292e 7265 6c65 6173 653a 2020 2320 7072  ).release:  # pr
+00027480: 6167 6d61 3a20 6e6f 2063 6f76 6572 0a20  agma: no cover. 
+00027490: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+000274a0: 2070 796c 696e 743a 2064 6973 6162 6c65   pylint: disable
+000274b0: 3d45 3131 3233 0a20 2020 2020 2020 2020  =E1123.         
+000274c0: 2020 2020 2020 2071 5f6d 6f64 656c 2e5f         q_model._
+000274d0: 6d6f 6465 6c20 3d20 636f 6e76 6572 745f  model = convert_
+000274e0: 6678 280a 2020 2020 2020 2020 2020 2020  fx(.            
+000274f0: 2020 2020 2020 2020 715f 6d6f 6465 6c2e          q_model.
+00027500: 5f6d 6f64 656c 2c0a 2020 2020 2020 2020  _model,.        
+00027510: 2020 2020 2020 2020 2020 2020 636f 6e76              conv
+00027520: 6572 745f 6375 7374 6f6d 5f63 6f6e 6669  ert_custom_confi
+00027530: 673d 7365 6c66 2e63 6f6e 7665 7274 5f63  g=self.convert_c
+00027540: 7573 746f 6d5f 636f 6e66 6967 5f64 6963  ustom_config_dic
+00027550: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
+00027560: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00027570: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00027580: 2020 2020 2020 715f 6d6f 6465 6c2e 5f6d        q_model._m
+00027590: 6f64 656c 203d 2063 6f6e 7665 7274 5f66  odel = convert_f
+000275a0: 7828 0a20 2020 2020 2020 2020 2020 2020  x(.             
+000275b0: 2020 2020 2020 2071 5f6d 6f64 656c 2e5f         q_model._
+000275c0: 6d6f 6465 6c2c 200a 2020 2020 2020 2020  model, .        
+000275d0: 2020 2020 2020 2020 2020 2020 636f 6e76              conv
+000275e0: 6572 745f 6375 7374 6f6d 5f63 6f6e 6669  ert_custom_confi
+000275f0: 675f 6469 6374 3d73 656c 662e 636f 6e76  g_dict=self.conv
+00027600: 6572 745f 6375 7374 6f6d 5f63 6f6e 6669  ert_custom_confi
+00027610: 675f 6469 6374 0a20 2020 2020 2020 2020  g_dict.         
+00027620: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00027630: 2020 2020 2074 6f72 6368 5f75 7469 6c73       torch_utils
+00027640: 2e75 7469 6c2e 6170 7065 6e64 5f61 7474  .util.append_att
+00027650: 7228 715f 6d6f 6465 6c2e 5f6d 6f64 656c  r(q_model._model
+00027660: 2c20 746d 705f 6d6f 6465 6c29 0a20 2020  , tmp_model).   
+00027670: 2020 2020 2020 2020 2064 656c 2074 6d70           del tmp
+00027680: 5f6d 6f64 656c 0a20 2020 2020 2020 2020  _model.         
+00027690: 2020 2067 632e 636f 6c6c 6563 7428 290a     gc.collect().
+000276a0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+000276b0: 2020 2020 2020 2020 2020 5079 546f 7263            PyTorc
+000276c0: 685f 4658 4164 6170 746f 722e 636f 6e76  h_FXAdaptor.conv
+000276d0: 6572 745f 7375 625f 6772 6170 6828 0a20  ert_sub_graph(. 
+000276e0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000276f0: 656c 662e 7375 625f 6d6f 6475 6c65 5f6c  elf.sub_module_l
+00027700: 6973 742c 0a20 2020 2020 2020 2020 2020  ist,.           
+00027710: 2020 2020 2071 5f6d 6f64 656c 2e5f 6d6f       q_model._mo
+00027720: 6465 6c2c 0a20 2020 2020 2020 2020 2020  del,.           
+00027730: 2020 2020 2070 7265 6669 783d 2727 2c0a       prefix='',.
+00027740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027750: 6375 7374 6f6d 5f63 6f6e 6669 673d 7365  custom_config=se
+00027760: 6c66 2e70 7265 7061 7265 5f63 7573 746f  lf.prepare_custo
+00027770: 6d5f 636f 6e66 6967 5f64 6963 740a 2020  m_config_dict.  
+00027780: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+00027790: 2020 2020 2069 6620 6c65 6e28 7365 6c66       if len(self
+000277a0: 2e74 756e 655f 6366 675b 2762 6631 365f  .tune_cfg['bf16_
+000277b0: 6f70 735f 6c69 7374 275d 2920 3e20 3020  ops_list']) > 0 
+000277c0: 616e 6420 5c0a 2020 2020 2020 2020 2020  and \.          
+000277d0: 2020 7365 6c66 2e76 6572 7369 6f6e 2e72    self.version.r
+000277e0: 656c 6561 7365 203e 3d20 5665 7273 696f  elease >= Versio
+000277f0: 6e28 2231 2e31 312e 3022 292e 7265 6c65  n("1.11.0").rele
+00027800: 6173 6520 616e 6420 7365 6c66 2e75 7365  ase and self.use
+00027810: 5f62 6631 3620 616e 6420 5c0a 2020 2020  _bf16 and \.    
+00027820: 2020 2020 2020 2020 2843 7075 496e 666f          (CpuInfo
+00027830: 2829 2e62 6631 3620 6f72 206f 732e 6765  ().bf16 or os.ge
+00027840: 7465 6e76 2827 464f 5243 455f 4246 3136  tenv('FORCE_BF16
+00027850: 2729 203d 3d20 2731 2729 3a20 2320 7072  ') == '1'): # pr
+00027860: 6167 6d61 3a20 6e6f 2063 6f76 6572 0a20  agma: no cover. 
+00027870: 2020 2020 2020 2020 2020 2071 5f6d 6f64             q_mod
+00027880: 656c 2e5f 6d6f 6465 6c20 3d20 746f 7263  el._model = torc
+00027890: 685f 7574 696c 732e 6266 3136 5f63 6f6e  h_utils.bf16_con
+000278a0: 7665 7274 2e43 6f6e 7665 7274 2871 5f6d  vert.Convert(q_m
+000278b0: 6f64 656c 2e5f 6d6f 6465 6c2c 2073 656c  odel._model, sel
+000278c0: 662e 7475 6e65 5f63 6667 290a 0a20 2020  f.tune_cfg)..   
+000278d0: 2020 2020 2071 5f6d 6f64 656c 2e71 5f63       q_model.q_c
+000278e0: 6f6e 6669 6720 3d20 636f 7079 2e64 6565  onfig = copy.dee
+000278f0: 7063 6f70 7928 7365 6c66 2e74 756e 655f  pcopy(self.tune_
+00027900: 6366 6729 0a20 2020 2020 2020 2069 6620  cfg).        if 
+00027910: 7365 6c66 2e61 7070 726f 6163 6820 213d  self.approach !=
+00027920: 2027 706f 7374 5f74 7261 696e 696e 675f   'post_training_
+00027930: 6479 6e61 6d69 635f 7175 616e 7427 3a0a  dynamic_quant':.
+00027940: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00027950: 2e5f 6765 745f 7363 616c 655f 7a65 726f  ._get_scale_zero
+00027960: 706f 696e 7428 715f 6d6f 6465 6c2e 5f6d  point(q_model._m
+00027970: 6f64 656c 2c20 715f 6d6f 6465 6c2e 715f  odel, q_model.q_
+00027980: 636f 6e66 6967 290a 2020 2020 2020 2020  config).        
+00027990: 2020 2020 715f 6d6f 6465 6c2e 715f 636f      q_model.q_co
+000279a0: 6e66 6967 5b27 7363 616c 655f 696e 666f  nfig['scale_info
+000279b0: 275d 203d 2073 6361 6c65 5f69 6e66 6f0a  '] = scale_info.
+000279c0: 0a20 2020 2020 2020 2073 656c 662e 5f64  .        self._d
+000279d0: 756d 705f 6d6f 6465 6c5f 6f70 5f73 7461  ump_model_op_sta
+000279e0: 7473 2871 5f6d 6f64 656c 2e5f 6d6f 6465  ts(q_model._mode
+000279f0: 6c2c 2071 5f6d 6f64 656c 2e71 5f63 6f6e  l, q_model.q_con
+00027a00: 6669 672c 2073 656c 662e 6170 7072 6f61  fig, self.approa
+00027a10: 6368 290a 2020 2020 2020 2020 746f 7263  ch).        torc
+00027a20: 685f 7574 696c 732e 7574 696c 2e67 6574  h_utils.util.get
+00027a30: 5f65 6d62 6564 6469 6e67 5f63 6f6e 7469  _embedding_conti
+00027a40: 6775 6f75 7328 715f 6d6f 6465 6c2e 5f6d  guous(q_model._m
+00027a50: 6f64 656c 290a 2020 2020 2020 2020 7265  odel).        re
+00027a60: 7475 726e 2071 5f6d 6f64 656c 0a0a 2020  turn q_model..  
+00027a70: 2020 6465 6620 6576 616c 7561 7465 2873    def evaluate(s
+00027a80: 656c 662c 0a20 2020 2020 2020 2020 2020  elf,.           
+00027a90: 2020 2020 2020 6d6f 6465 6c2c 0a20 2020        model,.   
+00027aa0: 2020 2020 2020 2020 2020 2020 2020 6461                da
+00027ab0: 7461 6c6f 6164 6572 2c0a 2020 2020 2020  taloader,.      
+00027ac0: 2020 2020 2020 2020 2020 2070 6f73 7470             postp
+00027ad0: 726f 6365 7373 3d4e 6f6e 652c 0a20 2020  rocess=None,.   
+00027ae0: 2020 2020 2020 2020 2020 2020 2020 6d65                me
+00027af0: 7472 6963 733d 4e6f 6e65 2c0a 2020 2020  trics=None,.    
+00027b00: 2020 2020 2020 2020 2020 2020 206d 6561               mea
+00027b10: 7375 7265 723d 4e6f 6e65 2c0a 2020 2020  surer=None,.    
+00027b20: 2020 2020 2020 2020 2020 2020 2069 7465               ite
+00027b30: 7261 7469 6f6e 3d2d 312c 0a20 2020 2020  ration=-1,.     
+00027b40: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
+00027b50: 6f72 626f 6172 643d 4661 6c73 652c 0a20  orboard=False,. 
+00027b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027b70: 6670 3332 5f62 6173 656c 696e 653d 4661  fp32_baseline=Fa
+00027b80: 6c73 6529 3a0a 2020 2020 2020 2020 2222  lse):.        ""
+00027b90: 2245 7865 6375 7465 2074 6865 2065 7661  "Execute the eva
+00027ba0: 6c75 6174 6520 7072 6f63 6573 7320 6f6e  luate process on
+00027bb0: 2074 6865 2073 7065 6369 6669 6564 206d   the specified m
+00027bc0: 6f64 656c 2e0a 0a20 2020 2020 2020 2041  odel...        A
+00027bd0: 7267 733a 0a20 2020 2020 2020 2020 2020  rgs:.           
+00027be0: 206d 6f64 656c 2028 6f62 6a65 6374 293a   model (object):
+00027bf0: 206d 6f64 656c 2074 6f20 7275 6e20 6576   model to run ev
+00027c00: 616c 7561 7469 6f6e 2e0a 2020 2020 2020  aluation..      
+00027c10: 2020 2020 2020 6461 7461 6c6f 6164 6572        dataloader
+00027c20: 2028 6f62 6a65 6374 293a 2065 7661 6c75   (object): evalu
+00027c30: 6174 696f 6e20 6461 7461 7365 742e 0a20  ation dataset.. 
+00027c40: 2020 2020 2020 2020 2020 2070 6f73 7470             postp
+00027c50: 726f 6365 7373 2028 6f62 6a65 6374 2c20  rocess (object, 
+00027c60: 6f70 7469 6f6e 616c 293a 2070 726f 6365  optional): proce
+00027c70: 7373 2066 756e 6374 696f 6e20 6166 7465  ss function afte
+00027c80: 7220 6576 616c 7561 7469 6f6e 2e0a 2020  r evaluation..  
+00027c90: 2020 2020 2020 2020 2020 6d65 7472 6963            metric
+00027ca0: 2028 6f62 6a65 6374 2c20 6f70 7469 6f6e   (object, option
+00027cb0: 616c 293a 206d 6574 7269 6320 6675 6e63  al): metric func
+00027cc0: 7469 6f6e 2e0a 2020 2020 2020 2020 2020  tion..          
+00027cd0: 2020 6d65 6173 7572 6572 2028 6f62 6a65    measurer (obje
+00027ce0: 6374 2c20 6f70 7469 6f6e 616c 293a 206d  ct, optional): m
+00027cf0: 6561 7375 7265 7220 6675 6e63 7469 6f6e  easurer function
+00027d00: 2e0a 2020 2020 2020 2020 2020 2020 6974  ..            it
+00027d10: 6572 6174 696f 6e20 2869 6e74 2c20 6f70  eration (int, op
+00027d20: 7469 6f6e 616c 293a 206e 756d 6265 7220  tional): number 
+00027d30: 6f66 2069 7465 7261 7469 6f6e 7320 746f  of iterations to
+00027d40: 2065 7661 6c75 6174 652e 0a20 2020 2020   evaluate..     
+00027d50: 2020 2020 2020 2074 656e 736f 7262 6f61         tensorboa
+00027d60: 7264 2028 626f 6f6c 2c20 6f70 7469 6f6e  rd (bool, option
+00027d70: 616c 293a 2064 756d 7020 6f75 7470 7574  al): dump output
+00027d80: 2074 656e 736f 7220 746f 2074 656e 736f   tensor to tenso
+00027d90: 7262 6f61 7264 2073 756d 6d61 7279 2066  rboard summary f
+00027da0: 696c 6573 2e0a 2020 2020 2020 2020 2020  iles..          
+00027db0: 2020 6670 3332 5f62 6173 656c 696e 6520    fp32_baseline 
+00027dc0: 2862 6f6f 6c65 6e2c 206f 7074 696f 6e61  (boolen, optiona
+00027dd0: 6c29 3a20 6f6e 6c79 2066 6f72 2063 6f6d  l): only for com
+00027de0: 7061 7265 5f6c 6162 656c 3d46 616c 7365  pare_label=False
+00027df0: 2070 6970 656c 696e 650a 0a20 2020 2020   pipeline..     
+00027e00: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
+00027e10: 2020 2020 2020 2020 286f 626a 6563 7429          (object)
+00027e20: 3a20 6163 6375 7261 6379 0a20 2020 2020  : accuracy.     
+00027e30: 2020 2022 2222 0a20 2020 2020 2020 2069     """.        i
+00027e40: 6620 7465 6e73 6f72 626f 6172 643a 2020  f tensorboard:  
+00027e50: 2320 7072 6167 6d61 3a20 6e6f 2063 6f76  # pragma: no cov
+00027e60: 6572 0a20 2020 2020 2020 2020 2020 2061  er.            a
+00027e70: 7373 6572 7420 4661 6c73 652c 2022 5079  ssert False, "Py
+00027e80: 546f 7263 6820 4658 206d 6f64 6520 6469  Torch FX mode di
+00027e90: 646e 2774 2073 7570 706f 7274 2074 656e  dn't support ten
+00027ea0: 736f 7262 6f61 7264 2066 6c61 6720 6e6f  sorboard flag no
+00027eb0: 7721 220a 2020 2020 2020 2020 7365 6c66  w!".        self
+00027ec0: 2e69 735f 6261 7365 6c69 6e65 203d 2066  .is_baseline = f
+00027ed0: 7033 325f 6261 7365 6c69 6e65 0a0a 2020  p32_baseline..  
+00027ee0: 2020 2020 2020 6d6f 6465 6c5f 203d 206d        model_ = m
+00027ef0: 6f64 656c 2e5f 6d6f 6465 6c0a 2020 2020  odel._model.    
+00027f00: 2020 2020 6173 7365 7274 2069 7369 6e73      assert isins
+00027f10: 7461 6e63 6528 0a20 2020 2020 2020 2020  tance(.         
+00027f20: 2020 206d 6f64 656c 5f2c 2074 6f72 6368     model_, torch
+00027f30: 2e6e 6e2e 4d6f 6475 6c65 292c 2022 5468  .nn.Module), "Th
+00027f40: 6520 6d6f 6465 6c20 7061 7373 6564 2069  e model passed i
+00027f50: 6e20 6973 206e 6f74 2074 6865 2069 6e73  n is not the ins
+00027f60: 7461 6e63 6520 6f66 2074 6f72 6368 2e6e  tance of torch.n
+00027f70: 6e2e 4d6f 6475 6c65 220a 2020 2020 2020  n.Module".      
+00027f80: 2020 6d6f 6465 6c5f 2e65 7661 6c28 290a    model_.eval().
+00027f90: 2020 2020 2020 2020 6d6f 6465 6c5f 2e74          model_.t
+00027fa0: 6f28 7365 6c66 2e64 6576 6963 6529 0a0a  o(self.device)..
+00027fb0: 2020 2020 2020 2020 6966 206d 6574 7269          if metri
+00027fc0: 6373 3a0a 2020 2020 2020 2020 2020 2020  cs:.            
+00027fd0: 7365 6c66 2e66 7033 325f 7072 6564 735f  self.fp32_preds_
+00027fe0: 6173 5f6c 6162 656c 203d 2061 6e79 285b  as_label = any([
+00027ff0: 6861 7361 7474 7228 6d65 7472 6963 2c20  hasattr(metric, 
+00028000: 2263 6f6d 7061 7265 5f6c 6162 656c 2229  "compare_label")
+00028010: 2061 6e64 205c 0a20 2020 2020 2020 2020   and \.         
+00028020: 2020 2020 2020 206e 6f74 206d 6574 7269         not metri
+00028030: 632e 636f 6d70 6172 655f 6c61 6265 6c20  c.compare_label 
+00028040: 666f 7220 6d65 7472 6963 2069 6e20 6d65  for metric in me
+00028050: 7472 6963 735d 290a 0a20 2020 2020 2020  trics])..       
+00028060: 2072 6574 7572 6e20 7365 6c66 2e6d 6f64   return self.mod
+00028070: 656c 5f65 7661 6c28 6d6f 6465 6c5f 2c20  el_eval(model_, 
+00028080: 6461 7461 6c6f 6164 6572 2c20 706f 7374  dataloader, post
+00028090: 7072 6f63 6573 732c 206d 6574 7269 6373  process, metrics
+000280a0: 2c20 6d65 6173 7572 6572 2c20 6974 6572  , measurer, iter
+000280b0: 6174 696f 6e29 0a0a 2020 2020 6465 6620  ation)..    def 
+000280c0: 5f70 7265 5f68 6f6f 6b5f 666f 725f 7161  _pre_hook_for_qa
+000280d0: 7428 7365 6c66 2c20 6461 7461 6c6f 6164  t(self, dataload
+000280e0: 6572 3d4e 6f6e 6529 3a0a 2020 2020 2020  er=None):.      
+000280f0: 2020 715f 6366 6773 203d 2074 6f72 6368    q_cfgs = torch
+00028100: 2e71 7561 6e74 697a 6174 696f 6e2e 5143  .quantization.QC
+00028110: 6f6e 6669 6728 0a20 2020 2020 2020 2020  onfig(.         
+00028120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028130: 2020 2061 6374 6976 6174 696f 6e3d 746f     activation=to
+00028140: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+00028150: 2e46 616b 6551 7561 6e74 697a 652e 7769  .FakeQuantize.wi
+00028160: 7468 5f61 7267 7328 0a20 2020 2020 2020  th_args(.       
+00028170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028180: 2020 2020 2020 2020 2020 2020 2064 7479               dty
+00028190: 7065 3d74 6f72 6368 2e71 7569 6e74 382c  pe=torch.quint8,
+000281a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000281b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000281c0: 2020 2020 2071 7363 6865 6d65 3d74 6f72       qscheme=tor
+000281d0: 6368 2e70 6572 5f74 656e 736f 725f 6166  ch.per_tensor_af
+000281e0: 6669 6e65 2c0a 2020 2020 2020 2020 2020  fine,.          
+000281f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028200: 2020 2020 2020 2020 2020 7265 6475 6365            reduce
+00028210: 5f72 616e 6765 3d52 4544 5543 455f 5241  _range=REDUCE_RA
+00028220: 4e47 452c 0a20 2020 2020 2020 2020 2020  NGE,.           
+00028230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028240: 2020 2020 2020 2020 206f 6273 6572 7665           observe
+00028250: 723d 746f 7263 682e 7175 616e 7469 7a61  r=torch.quantiza
+00028260: 7469 6f6e 2e4d 6f76 696e 6741 7665 7261  tion.MovingAvera
+00028270: 6765 4d69 6e4d 6178 4f62 7365 7276 6572  geMinMaxObserver
+00028280: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
+00028290: 2020 2020 2020 2020 2020 2020 2020 2077                 w
+000282a0: 6569 6768 743d 746f 7263 682e 7175 616e  eight=torch.quan
+000282b0: 7469 7a61 7469 6f6e 2e64 6566 6175 6c74  tization.default
+000282c0: 5f77 6569 6768 745f 6661 6b65 5f71 7561  _weight_fake_qua
+000282d0: 6e74 2920 5c0a 2020 2020 2020 2020 2020  nt) \.          
+000282e0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+000282f0: 2073 656c 662e 7665 7273 696f 6e2e 7265   self.version.re
+00028300: 6c65 6173 6520 3c20 5665 7273 696f 6e28  lease < Version(
+00028310: 2231 2e31 302e 3022 292e 7265 6c65 6173  "1.10.0").releas
+00028320: 6520 656c 7365 205c 0a20 2020 2020 2020  e else \.       
+00028330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028340: 2020 2074 6f72 6368 2e71 7561 6e74 697a     torch.quantiz
+00028350: 6174 696f 6e2e 5143 6f6e 6669 6728 0a20  ation.QConfig(. 
+00028360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028370: 2020 2020 2020 2020 2020 2061 6374 6976             activ
+00028380: 6174 696f 6e3d 746f 7263 682e 7175 616e  ation=torch.quan
+00028390: 7469 7a61 7469 6f6e 2e46 7573 6564 4d6f  tization.FusedMo
+000283a0: 7669 6e67 4176 674f 6273 4661 6b65 5175  vingAvgObsFakeQu
+000283b0: 616e 7469 7a65 2e77 6974 685f 6172 6773  antize.with_args
+000283c0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+000283d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000283e0: 2020 2020 2020 2020 2064 7479 7065 3d74           dtype=t
+000283f0: 6f72 6368 2e71 7569 6e74 382c 0a20 2020  orch.quint8,.   
+00028400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028420: 2020 2020 7173 6368 656d 653d 746f 7263      qscheme=torc
+00028430: 682e 7065 725f 7465 6e73 6f72 5f61 6666  h.per_tensor_aff
+00028440: 696e 652c 0a20 2020 2020 2020 2020 2020  ine,.           
+00028450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028460: 2020 2020 2020 2020 2020 2020 7265 6475              redu
+00028470: 6365 5f72 616e 6765 3d52 4544 5543 455f  ce_range=REDUCE_
+00028480: 5241 4e47 4529 2c0a 2020 2020 2020 2020  RANGE),.        
+00028490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000284a0: 2020 2020 7765 6967 6874 3d74 6f72 6368      weight=torch
+000284b0: 2e71 7561 6e74 697a 6174 696f 6e2e 6465  .quantization.de
+000284c0: 6661 756c 745f 6675 7365 645f 7065 725f  fault_fused_per_
+000284d0: 6368 616e 6e65 6c5f 7774 5f66 616b 655f  channel_wt_fake_
+000284e0: 7175 616e 7429 0a20 2020 2020 2020 2071  quant).        q
+000284f0: 7561 6e74 697a 6162 6c65 5f6f 7073 203d  uantizable_ops =
+00028500: 205b 5d0a 2020 2020 2020 2020 746d 705f   [].        tmp_
+00028510: 6d6f 6465 6c20 3d20 7365 6c66 2e66 7573  model = self.fus
+00028520: 655f 6678 5f6d 6f64 656c 2873 656c 662e  e_fx_model(self.
+00028530: 6d6f 6465 6c2c 2069 735f 7161 743d 5472  model, is_qat=Tr
+00028540: 7565 290a 2020 2020 2020 2020 7365 6c66  ue).        self
+00028550: 2e5f 6765 745f 7175 616e 7469 7a61 626c  ._get_quantizabl
+00028560: 655f 6f70 735f 7265 6375 7273 6976 656c  e_ops_recursivel
+00028570: 7928 746d 705f 6d6f 6465 6c2c 2027 272c  y(tmp_model, '',
+00028580: 2071 7561 6e74 697a 6162 6c65 5f6f 7073   quantizable_ops
+00028590: 290a 2020 2020 2020 2020 6266 3136 5f6f  ).        bf16_o
+000285a0: 7073 203d 205b 5d0a 2020 2020 2020 2020  ps = [].        
+000285b0: 6966 2073 656c 662e 7665 7273 696f 6e2e  if self.version.
+000285c0: 7265 6c65 6173 6520 3e3d 2056 6572 7369  release >= Versi
+000285d0: 6f6e 2822 312e 3131 2e30 2229 2e72 656c  on("1.11.0").rel
+000285e0: 6561 7365 2061 6e64 2073 656c 662e 7573  ease and self.us
+000285f0: 655f 6266 3136 2061 6e64 205c 0a20 2020  e_bf16 and \.   
+00028600: 2020 2020 2020 2020 2028 4370 7549 6e66           (CpuInf
+00028610: 6f28 292e 6266 3136 206f 7220 6f73 2e67  o().bf16 or os.g
+00028620: 6574 656e 7628 2746 4f52 4345 5f42 4631  etenv('FORCE_BF1
+00028630: 3627 2920 3d3d 2027 3127 293a 2023 2070  6') == '1'): # p
+00028640: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
+00028650: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00028660: 2e62 6631 365f 6f70 7320 3d20 7365 6c66  .bf16_ops = self
+00028670: 2e71 7565 7279 5f68 616e 646c 6572 2e67  .query_handler.g
+00028680: 6574 5f6f 705f 7479 7065 735f 6279 5f70  et_op_types_by_p
+00028690: 7265 6369 7369 6f6e 2822 6266 3136 2229  recision("bf16")
+000286a0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+000286b0: 662e 5f67 6574 5f62 6631 365f 6f70 735f  f._get_bf16_ops_
+000286c0: 7265 6375 7273 6976 656c 7928 746d 705f  recursively(tmp_
+000286d0: 6d6f 6465 6c2c 2027 272c 2062 6631 365f  model, '', bf16_
+000286e0: 6f70 7329 0a20 2020 2020 2020 2062 6631  ops).        bf1
+000286f0: 365f 6f70 735f 6c69 7374 203d 205b 286f  6_ops_list = [(o
+00028700: 7029 2066 6f72 206f 7020 696e 2062 6631  p) for op in bf1
+00028710: 365f 6f70 7320 6966 206f 7020 6e6f 7420  6_ops if op not 
+00028720: 696e 2071 7561 6e74 697a 6162 6c65 5f6f  in quantizable_o
+00028730: 7073 5d0a 2020 2020 2020 2020 7175 616e  ps].        quan
+00028740: 7469 7a65 645f 6f70 7320 3d20 4f72 6465  tized_ops = Orde
+00028750: 7265 6444 6963 7428 290a 2020 2020 2020  redDict().      
+00028760: 2020 666f 7220 6f70 2069 6e20 7175 616e    for op in quan
+00028770: 7469 7a61 626c 655f 6f70 733a 0a20 2020  tizable_ops:.   
+00028780: 2020 2020 2020 2020 2069 6620 6f70 5b31           if op[1
+00028790: 5d20 696e 205b 0a20 2020 2020 2020 2020  ] in [.         
+000287a0: 2020 2020 2020 2020 2020 2027 456d 6265             'Embe
+000287b0: 6464 696e 6727 2c20 2745 6d62 6564 6469  dding', 'Embeddi
+000287c0: 6e67 4261 6727 2c20 274c 5354 4d27 2c20  ngBag', 'LSTM', 
+000287d0: 2747 5255 272c 2027 4c53 544d 4365 6c6c  'GRU', 'LSTMCell
+000287e0: 272c 2027 4752 5543 656c 6c27 2c20 2752  ', 'GRUCell', 'R
+000287f0: 4e4e 4365 6c6c 270a 2020 2020 2020 2020  NNCell'.        
+00028800: 2020 2020 5d3a 0a20 2020 2020 2020 2020      ]:.         
+00028810: 2020 2020 2020 2071 7561 6e74 697a 6564         quantized
+00028820: 5f6f 7073 5b6f 705b 305d 5d20 3d20 746f  _ops[op[0]] = to
+00028830: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+00028840: 2e64 6566 6175 6c74 5f64 796e 616d 6963  .default_dynamic
+00028850: 5f71 636f 6e66 6967 0a20 2020 2020 2020  _qconfig.       
+00028860: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00028870: 2020 2020 2020 2020 2020 2071 7561 6e74             quant
+00028880: 697a 6564 5f6f 7073 5b6f 705b 305d 5d20  ized_ops[op[0]] 
+00028890: 3d20 715f 6366 6773 0a20 2020 2020 2020  = q_cfgs.       
+000288a0: 2023 2062 7569 6c64 206f 705f 636f 6e66   # build op_conf
+000288b0: 6967 5f64 6963 7420 746f 2073 6176 6520  ig_dict to save 
+000288c0: 6d6f 6475 6c65 2073 6361 6c65 2061 6e64  module scale and
+000288d0: 207a 6572 6f70 6f69 6e74 0a20 2020 2020   zeropoint.     
+000288e0: 2020 206f 705f 636f 6e66 6967 5f64 6963     op_config_dic
+000288f0: 7420 3d20 7b7d 0a20 2020 2020 2020 2066  t = {}.        f
+00028900: 6f72 206f 7020 696e 2071 7561 6e74 697a  or op in quantiz
+00028910: 6162 6c65 5f6f 7073 3a0a 2020 2020 2020  able_ops:.      
+00028920: 2020 2020 2020 6f70 5f63 6f6e 6669 675f        op_config_
+00028930: 6469 6374 5b6f 705d 203d 207b 2777 6569  dict[op] = {'wei
+00028940: 6768 7427 3a20 7b27 6474 7970 6527 3a20  ght': {'dtype': 
+00028950: 2769 6e74 3827 7d2c 2027 6163 7469 7661  'int8'}, 'activa
+00028960: 7469 6f6e 273a 207b 2764 7479 7065 273a  tion': {'dtype':
+00028970: 2027 7569 6e74 3827 7d7d 0a0a 2020 2020   'uint8'}}..    
+00028980: 2020 2020 6966 2073 656c 662e 7665 7273      if self.vers
+00028990: 696f 6e2e 7265 6c65 6173 6520 3c20 5665  ion.release < Ve
+000289a0: 7273 696f 6e28 2231 2e31 312e 3022 292e  rsion("1.11.0").
+000289b0: 7265 6c65 6173 653a 0a20 2020 2020 2020  release:.       
+000289c0: 2020 2020 2071 7561 6e74 697a 6564 5f6f       quantized_o
+000289d0: 7073 5b22 6465 6661 756c 745f 7163 6f6e  ps["default_qcon
+000289e0: 6669 6722 5d20 3d20 4e6f 6e65 0a20 2020  fig"] = None.   
+000289f0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00028a00: 2020 2020 2020 2066 726f 6d20 746f 7263         from torc
+00028a10: 682e 616f 2e71 7561 6e74 697a 6174 696f  h.ao.quantizatio
+00028a20: 6e20 696d 706f 7274 2064 6566 6175 6c74  n import default
+00028a30: 5f65 6d62 6564 6469 6e67 5f71 6174 5f71  _embedding_qat_q
+00028a40: 636f 6e66 6967 0a20 2020 2020 2020 2020  config.         
+00028a50: 2020 2066 6f72 206f 7020 696e 2071 7561     for op in qua
+00028a60: 6e74 697a 6162 6c65 5f6f 7073 3a0a 2020  ntizable_ops:.  
+00028a70: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00028a80: 206f 705b 315d 2069 6e20 5b27 456d 6265   op[1] in ['Embe
+00028a90: 6464 696e 6727 2c20 2745 6d62 6564 6469  dding', 'Embeddi
+00028aa0: 6e67 4261 6727 5d3a 0a20 2020 2020 2020  ngBag']:.       
+00028ab0: 2020 2020 2020 2020 2020 2020 2071 7561               qua
+00028ac0: 6e74 697a 6564 5f6f 7073 5b6f 705b 305d  ntized_ops[op[0]
+00028ad0: 5d20 3d20 6465 6661 756c 745f 656d 6265  ] = default_embe
+00028ae0: 6464 696e 675f 7161 745f 7163 6f6e 6669  dding_qat_qconfi
+00028af0: 670a 2020 2020 2020 2020 6672 6f6d 2074  g.        from t
+00028b00: 6f72 6368 2e71 7561 6e74 697a 6174 696f  orch.quantizatio
+00028b10: 6e2e 7175 616e 7469 7a65 5f66 7820 696d  n.quantize_fx im
+00028b20: 706f 7274 2070 7265 7061 7265 5f71 6174  port prepare_qat
+00028b30: 5f66 780a 2020 2020 2020 2020 6678 5f6f  _fx.        fx_o
+00028b40: 705f 6366 6773 203d 205f 6366 6773 5f74  p_cfgs = _cfgs_t
+00028b50: 6f5f 6678 5f63 6667 7328 7175 616e 7469  o_fx_cfgs(quanti
+00028b60: 7a65 645f 6f70 732c 2027 7175 616e 745f  zed_ops, 'quant_
+00028b70: 6177 6172 655f 7472 6169 6e69 6e67 2729  aware_training')
+00028b80: 0a20 2020 2020 2020 2073 656c 662e 6d6f  .        self.mo
+00028b90: 6465 6c2e 5f6d 6f64 656c 2e74 7261 696e  del._model.train
+00028ba0: 2829 0a0a 2020 2020 2020 2020 2320 5079  ()..        # Py
+00028bb0: 546f 7263 6820 312e 3133 2061 6e64 2061  Torch 1.13 and a
+00028bc0: 626f 7665 2076 6572 7369 6f6e 2c20 6e65  bove version, ne
+00028bd0: 6564 2065 7861 6d70 6c65 5f69 6e70 7574  ed example_input
+00028be0: 7320 666f 7220 6678 2074 7261 6365 2c20  s for fx trace, 
+00028bf0: 6275 7420 6974 206e 6f74 2072 6561 6c79  but it not realy
+00028c00: 2075 7365 642c 0a20 2020 2020 2020 2023   used,.        #
+00028c10: 2073 6f20 7365 7420 6974 2074 6f20 4e6f   so set it to No
+00028c20: 6e65 2e0a 2020 2020 2020 2020 7365 6c66  ne..        self
+00028c30: 2e65 7861 6d70 6c65 5f69 6e70 7574 7320  .example_inputs 
+00028c40: 3d20 4e6f 6e65 0a0a 2020 2020 2020 2020  = None..        
+00028c50: 2320 466f 7220 6578 706f 7274 2041 5049  # For export API
+00028c60: 2c20 6465 6570 636f 7079 2066 7033 325f  , deepcopy fp32_
+00028c70: 6d6f 6465 6c0a 2020 2020 2020 2020 7472  model.        tr
+00028c80: 793a 0a20 2020 2020 2020 2020 2020 2073  y:.            s
+00028c90: 656c 662e 6d6f 6465 6c2e 6670 3332 5f6d  elf.model.fp32_m
+00028ca0: 6f64 656c 203d 2063 6f70 792e 6465 6570  odel = copy.deep
+00028cb0: 636f 7079 2873 656c 662e 6d6f 6465 6c2e  copy(self.model.
+00028cc0: 6670 3332 5f6d 6f64 656c 290a 2020 2020  fp32_model).    
+00028cd0: 2020 2020 6578 6365 7074 2045 7863 6570      except Excep
+00028ce0: 7469 6f6e 2061 7320 653a 2020 2320 7072  tion as e:  # pr
+00028cf0: 6167 6d61 3a20 6e6f 2063 6f76 6572 0a20  agma: no cover. 
+00028d00: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
+00028d10: 722e 7761 726e 696e 6728 2246 6169 6c20  r.warning("Fail 
+00028d20: 746f 2064 6565 7020 636f 7079 2074 6865  to deep copy the
+00028d30: 206d 6f64 656c 2064 7565 2074 6f20 7b7d   model due to {}
+00028d40: 2c20 696e 706c 6163 6520 6973 2075 7365  , inplace is use
+00028d50: 6420 6e6f 772e 222e 666f 726d 6174 280a  d now.".format(.
+00028d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028d70: 7265 7072 2865 2929 290a 0a20 2020 2020  repr(e)))..     
+00028d80: 2020 2069 6620 7365 6c66 2e73 7562 5f6d     if self.sub_m
+00028d90: 6f64 756c 655f 6c69 7374 2069 7320 4e6f  odule_list is No
+00028da0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00028db0: 6966 2073 656c 662e 7665 7273 696f 6e2e  if self.version.
+00028dc0: 7265 6c65 6173 6520 3e3d 2056 6572 7369  release >= Versi
+00028dd0: 6f6e 2822 312e 3133 2e30 2229 2e72 656c  on("1.13.0").rel
+00028de0: 6561 7365 3a20 2023 2070 7261 676d 613a  ease:  # pragma:
+00028df0: 206e 6f20 636f 7665 720a 2020 2020 2020   no cover.      
+00028e00: 2020 2020 2020 2020 2020 2320 7079 6c69            # pyli
+00028e10: 6e74 3a20 6469 7361 626c 653d 4531 3132  nt: disable=E112
+00028e20: 330a 2020 2020 2020 2020 2020 2020 2020  3.              
+00028e30: 2020 7365 6c66 2e6d 6f64 656c 2e5f 6d6f    self.model._mo
+00028e40: 6465 6c20 3d20 7072 6570 6172 655f 7161  del = prepare_qa
+00028e50: 745f 6678 280a 2020 2020 2020 2020 2020  t_fx(.          
+00028e60: 2020 2020 2020 2020 2020 7365 6c66 2e6d            self.m
+00028e70: 6f64 656c 2e5f 6d6f 6465 6c2c 0a20 2020  odel._model,.   
+00028e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028e90: 2066 785f 6f70 5f63 6667 732c 0a20 2020   fx_op_cfgs,.   
+00028ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028eb0: 2065 7861 6d70 6c65 5f69 6e70 7574 733d   example_inputs=
+00028ec0: 7365 6c66 2e65 7861 6d70 6c65 5f69 6e70  self.example_inp
+00028ed0: 7574 732c 0a20 2020 2020 2020 2020 2020  uts,.           
+00028ee0: 2020 2020 2020 2020 2070 7265 7061 7265           prepare
+00028ef0: 5f63 7573 746f 6d5f 636f 6e66 6967 3d73  _custom_config=s
+00028f00: 656c 662e 6d6f 6465 6c2e 6b77 6172 6773  elf.model.kwargs
+00028f10: 2e67 6574 280a 2020 2020 2020 2020 2020  .get(.          
+00028f20: 2020 2020 2020 2020 2020 2020 2020 2770                'p
+00028f30: 7265 7061 7265 5f63 7573 746f 6d5f 636f  repare_custom_co
+00028f40: 6e66 6967 5f64 6963 7427 2c20 4e6f 6e65  nfig_dict', None
+00028f50: 2920 6966 2073 656c 662e 6d6f 6465 6c2e  ) if self.model.
+00028f60: 6b77 6172 6773 2069 7320 6e6f 7420 4e6f  kwargs is not No
+00028f70: 6e65 2065 6c73 6520 4e6f 6e65 290a 2020  ne else None).  
+00028f80: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+00028f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028fa0: 7365 6c66 2e6d 6f64 656c 2e5f 6d6f 6465  self.model._mode
+00028fb0: 6c20 3d20 7072 6570 6172 655f 7161 745f  l = prepare_qat_
+00028fc0: 6678 280a 2020 2020 2020 2020 2020 2020  fx(.            
+00028fd0: 2020 2020 2020 2020 7365 6c66 2e6d 6f64          self.mod
+00028fe0: 656c 2e5f 6d6f 6465 6c2c 0a20 2020 2020  el._model,.     
+00028ff0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00029000: 785f 6f70 5f63 6667 732c 0a20 2020 2020  x_op_cfgs,.     
+00029010: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00029020: 7265 7061 7265 5f63 7573 746f 6d5f 636f  repare_custom_co
+00029030: 6e66 6967 5f64 6963 743d 7365 6c66 2e6d  nfig_dict=self.m
+00029040: 6f64 656c 2e6b 7761 7267 732e 6765 7428  odel.kwargs.get(
+00029050: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00029060: 2020 2020 2020 2020 2027 7072 6570 6172           'prepar
+00029070: 655f 6375 7374 6f6d 5f63 6f6e 6669 675f  e_custom_config_
+00029080: 6469 6374 272c 204e 6f6e 6529 2069 6620  dict', None) if 
+00029090: 7365 6c66 2e6d 6f64 656c 2e6b 7761 7267  self.model.kwarg
+000290a0: 7320 6973 206e 6f74 204e 6f6e 6520 656c  s is not None el
+000290b0: 7365 204e 6f6e 6529 0a20 2020 2020 2020  se None).       
+000290c0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+000290d0: 2020 206c 6f67 6765 722e 696e 666f 2827     logger.info('
+000290e0: 4678 2074 7261 6365 206f 6620 7468 6520  Fx trace of the 
+000290f0: 656e 7469 7265 206d 6f64 656c 2066 6169  entire model fai
+00029100: 6c65 642e 2027 202b 205c 0a20 2020 2020  led. ' + \.     
+00029110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029120: 2020 2027 5765 2077 696c 6c20 636f 6e64     'We will cond
+00029130: 7563 7420 6175 746f 2071 7561 6e74 697a  uct auto quantiz
+00029140: 6174 696f 6e27 290a 2020 2020 2020 2020  ation').        
+00029150: 2020 2020 5079 546f 7263 685f 4658 4164      PyTorch_FXAd
+00029160: 6170 746f 722e 7072 6570 6172 655f 7375  aptor.prepare_su
+00029170: 625f 6772 6170 6828 7365 6c66 2e73 7562  b_graph(self.sub
+00029180: 5f6d 6f64 756c 655f 6c69 7374 2c0a 2020  _module_list,.  
+00029190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000291a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000291b0: 2020 2020 2020 2020 2020 2020 2020 6678                fx
+000291c0: 5f6f 705f 6366 6773 2c0a 2020 2020 2020  _op_cfgs,.      
+000291d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000291e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000291f0: 2020 2020 2020 2020 2020 7365 6c66 2e6d            self.m
+00029200: 6f64 656c 2e5f 6d6f 6465 6c2c 0a20 2020  odel._model,.   
+00029210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029230: 2020 2020 2020 2020 2020 2020 2070 7265               pre
+00029240: 6669 783d 2727 2c0a 2020 2020 2020 2020  fix='',.        
+00029250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029270: 2020 2020 2020 2020 6973 5f71 6174 3d54          is_qat=T
+00029280: 7275 652c 0a20 2020 2020 2020 2020 2020  rue,.           
+00029290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000292a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000292b0: 2020 2020 2065 7861 6d70 6c65 5f69 6e70       example_inp
+000292c0: 7574 733d 7365 6c66 2e65 7861 6d70 6c65  uts=self.example
+000292d0: 5f69 6e70 7574 7329 0a20 2020 2020 2020  _inputs).       
+000292e0: 2023 2054 6869 7320 6973 2061 2066 6c61   # This is a fla
+000292f0: 6720 666f 7220 7265 6c6f 6164 696e 670a  g for reloading.
+00029300: 2020 2020 2020 2020 7365 6c66 2e6d 6f64          self.mod
+00029310: 656c 2e71 5f63 6f6e 6669 6720 3d20 7b0a  el.q_config = {.
+00029320: 2020 2020 2020 2020 2020 2020 2763 616c              'cal
+00029330: 6962 5f73 616d 706c 696e 675f 7369 7a65  ib_sampling_size
+00029340: 273a 2031 3030 2c20 2320 746d 7020 6172  ': 100, # tmp ar
+00029350: 6720 666f 7220 6578 706f 7274 2041 5049  g for export API
+00029360: 0a20 2020 2020 2020 2020 2020 2027 6973  .            'is
+00029370: 5f6f 6e65 7368 6f74 273a 2054 7275 652c  _oneshot': True,
+00029380: 0a20 2020 2020 2020 2020 2020 2027 6672  .            'fr
+00029390: 616d 6577 6f72 6b27 3a20 2770 7974 6f72  amework': 'pytor
+000293a0: 6368 5f66 7827 2c0a 2020 2020 2020 2020  ch_fx',.        
+000293b0: 2020 2020 2772 6564 7563 655f 7261 6e67      'reduce_rang
+000293c0: 6527 3a20 5245 4455 4345 5f52 414e 4745  e': REDUCE_RANGE
+000293d0: 2c0a 2020 2020 2020 2020 2020 2020 2771  ,.            'q
+000293e0: 7561 6e74 697a 6162 6c65 5f6f 7073 273a  uantizable_ops':
+000293f0: 2071 7561 6e74 697a 6162 6c65 5f6f 7073   quantizable_ops
+00029400: 2c0a 2020 2020 2020 2020 2020 2020 2762  ,.            'b
+00029410: 6631 365f 6f70 735f 6c69 7374 273a 2062  f16_ops_list': b
+00029420: 6631 365f 6f70 735f 6c69 7374 2c0a 2020  f16_ops_list,.  
+00029430: 2020 2020 2020 2020 2020 276f 7027 3a20            'op': 
+00029440: 6f70 5f63 6f6e 6669 675f 6469 6374 2c0a  op_config_dict,.
+00029450: 2020 2020 2020 2020 2020 2020 2773 7562              'sub
+00029460: 5f6d 6f64 756c 655f 6c69 7374 273a 2073  _module_list': s
+00029470: 656c 662e 7375 625f 6d6f 6475 6c65 5f6c  elf.sub_module_l
+00029480: 6973 742c 0a20 2020 2020 2020 2020 2020  ist,.           
+00029490: 2027 6170 7072 6f61 6368 273a 2027 7175   'approach': 'qu
+000294a0: 616e 745f 6177 6172 655f 7472 6169 6e69  ant_aware_traini
+000294b0: 6e67 270a 2020 2020 2020 2020 7d0a 2020  ng'.        }.  
+000294c0: 2020 2020 2020 2320 466f 7220 6578 706f        # For expo
+000294d0: 7274 2041 5049 0a20 2020 2020 2020 2067  rt API.        g
+000294e0: 6c6f 6261 6c20 686f 6f6b 5f6c 6973 740a  lobal hook_list.
+000294f0: 2020 2020 2020 2020 686f 6f6b 5f6c 6973          hook_lis
+00029500: 7420 3d20 746f 7263 685f 7574 696c 732e  t = torch_utils.
+00029510: 7574 696c 2e5f 7365 745f 696e 7075 745f  util._set_input_
+00029520: 7363 616c 655f 686f 6f6b 2873 656c 662e  scale_hook(self.
+00029530: 6d6f 6465 6c2e 5f6d 6f64 656c 2c20 7175  model._model, qu
+00029540: 616e 7469 7a65 645f 6f70 7329 0a0a 2020  antized_ops)..  
+00029550: 2020 6465 6620 5f70 6f73 745f 686f 6f6b    def _post_hook
+00029560: 5f66 6f72 5f71 6174 2873 656c 6629 3a0a  _for_qat(self):.
+00029570: 2020 2020 2020 2020 2320 466f 7220 6578          # For ex
+00029580: 706f 7274 2041 5049 0a20 2020 2020 2020  port API.       
+00029590: 2073 6361 6c65 5f69 6e66 6f20 3d20 746f   scale_info = to
+000295a0: 7263 685f 7574 696c 732e 7574 696c 2e5f  rch_utils.util._
+000295b0: 6765 745f 696e 7075 745f 7363 616c 6528  get_input_scale(
+000295c0: 7365 6c66 2e6d 6f64 656c 2e5f 6d6f 6465  self.model._mode
+000295d0: 6c2c 2068 6f6f 6b5f 6c69 7374 290a 2020  l, hook_list).  
+000295e0: 2020 2020 2020 7365 6c66 2e6d 6f64 656c        self.model
+000295f0: 2e71 5f63 6f6e 6669 675b 2773 6361 6c65  .q_config['scale
+00029600: 5f69 6e66 6f27 5d20 3d20 7363 616c 655f  _info'] = scale_
+00029610: 696e 666f 0a20 2020 2020 2020 2066 726f  info.        fro
+00029620: 6d20 746f 7263 682e 7175 616e 7469 7a61  m torch.quantiza
+00029630: 7469 6f6e 2e71 7561 6e74 697a 655f 6678  tion.quantize_fx
+00029640: 2069 6d70 6f72 7420 636f 6e76 6572 745f   import convert_
+00029650: 6678 0a20 2020 2020 2020 2069 6620 7365  fx.        if se
+00029660: 6c66 2e73 7562 5f6d 6f64 756c 655f 6c69  lf.sub_module_li
+00029670: 7374 2069 7320 4e6f 6e65 3a0a 2020 2020  st is None:.    
+00029680: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00029690: 7665 7273 696f 6e20 3e20 5665 7273 696f  version > Versio
+000296a0: 6e28 2231 2e31 322e 3122 293a 2020 2320  n("1.12.1"):  # 
+000296b0: 7072 6167 6d61 3a20 6e6f 2063 6f76 6572  pragma: no cover
+000296c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000296d0: 2023 2070 796c 696e 743a 2064 6973 6162   # pylint: disab
+000296e0: 6c65 3d45 3131 3233 0a20 2020 2020 2020  le=E1123.       
+000296f0: 2020 2020 2020 2020 2073 656c 662e 6d6f           self.mo
+00029700: 6465 6c2e 5f6d 6f64 656c 203d 2063 6f6e  del._model = con
+00029710: 7665 7274 5f66 7828 0a20 2020 2020 2020  vert_fx(.       
+00029720: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+00029730: 662e 6d6f 6465 6c2e 5f6d 6f64 656c 2c0a  f.model._model,.
+00029740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029750: 2020 2020 636f 6e76 6572 745f 6375 7374      convert_cust
+00029760: 6f6d 5f63 6f6e 6669 673d 7365 6c66 2e6d  om_config=self.m
+00029770: 6f64 656c 2e6b 7761 7267 732e 6765 7428  odel.kwargs.get(
+00029780: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00029790: 2020 2020 2020 2020 2027 636f 6e76 6572           'conver
+000297a0: 745f 6375 7374 6f6d 5f63 6f6e 6669 675f  t_custom_config_
+000297b0: 6469 6374 272c 204e 6f6e 6529 2069 6620  dict', None) if 
+000297c0: 7365 6c66 2e6d 6f64 656c 2e6b 7761 7267  self.model.kwarg
+000297d0: 7320 6973 206e 6f74 204e 6f6e 6520 656c  s is not None el
+000297e0: 7365 204e 6f6e 6529 0a20 2020 2020 2020  se None).       
+000297f0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00029800: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00029810: 6d6f 6465 6c2e 5f6d 6f64 656c 203d 2063  model._model = c
+00029820: 6f6e 7665 7274 5f66 7828 0a20 2020 2020  onvert_fx(.     
+00029830: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00029840: 656c 662e 6d6f 6465 6c2e 5f6d 6f64 656c  elf.model._model
+00029850: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00029860: 2020 2020 2020 636f 6e76 6572 745f 6375        convert_cu
+00029870: 7374 6f6d 5f63 6f6e 6669 675f 6469 6374  stom_config_dict
+00029880: 3d73 656c 662e 6d6f 6465 6c2e 6b77 6172  =self.model.kwar
+00029890: 6773 2e67 6574 280a 2020 2020 2020 2020  gs.get(.        
+000298a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000298b0: 2763 6f6e 7665 7274 5f63 7573 746f 6d5f  'convert_custom_
+000298c0: 636f 6e66 6967 5f64 6963 7427 2c20 4e6f  config_dict', No
+000298d0: 6e65 2920 6966 2073 656c 662e 6d6f 6465  ne) if self.mode
+000298e0: 6c2e 6b77 6172 6773 2069 7320 6e6f 7420  l.kwargs is not 
+000298f0: 4e6f 6e65 2065 6c73 6520 4e6f 6e65 290a  None else None).
+00029900: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00029910: 2020 2020 2020 2020 2020 5079 546f 7263            PyTorc
+00029920: 685f 4658 4164 6170 746f 722e 636f 6e76  h_FXAdaptor.conv
+00029930: 6572 745f 7375 625f 6772 6170 6828 7365  ert_sub_graph(se
+00029940: 6c66 2e73 7562 5f6d 6f64 756c 655f 6c69  lf.sub_module_li
+00029950: 7374 2c20 5c0a 2020 2020 2020 2020 2020  st, \.          
+00029960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029980: 2020 2020 2020 7365 6c66 2e6d 6f64 656c        self.model
+00029990: 2e5f 6d6f 6465 6c2c 2070 7265 6669 783d  ._model, prefix=
+000299a0: 2727 290a 0a20 2020 2020 2020 2069 6620  '')..        if 
+000299b0: 7365 6c66 2e61 7070 726f 6163 6820 213d  self.approach !=
+000299c0: 2027 706f 7374 5f74 7261 696e 696e 675f   'post_training_
+000299d0: 6479 6e61 6d69 635f 7175 616e 7427 3a0a  dynamic_quant':.
+000299e0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+000299f0: 2e5f 6765 745f 7363 616c 655f 7a65 726f  ._get_scale_zero
+00029a00: 706f 696e 7428 7365 6c66 2e6d 6f64 656c  point(self.model
+00029a10: 2e5f 6d6f 6465 6c2c 2073 656c 662e 6d6f  ._model, self.mo
+00029a20: 6465 6c2e 715f 636f 6e66 6967 290a 2020  del.q_config).  
+00029a30: 2020 2020 2020 6966 206c 656e 2873 656c        if len(sel
+00029a40: 662e 6d6f 6465 6c2e 715f 636f 6e66 6967  f.model.q_config
+00029a50: 5b27 6266 3136 5f6f 7073 5f6c 6973 7427  ['bf16_ops_list'
+00029a60: 5d29 203e 2030 2061 6e64 205c 0a20 2020  ]) > 0 and \.   
+00029a70: 2020 2020 2020 2020 2073 656c 662e 7665           self.ve
+00029a80: 7273 696f 6e2e 7265 6c65 6173 6520 3e3d  rsion.release >=
+00029a90: 2056 6572 7369 6f6e 2822 312e 3131 2e30   Version("1.11.0
+00029aa0: 2229 2e72 656c 6561 7365 2061 6e64 2073  ").release and s
+00029ab0: 656c 662e 7573 655f 6266 3136 2061 6e64  elf.use_bf16 and
+00029ac0: 205c 0a20 2020 2020 2020 2020 2020 2028   \.            (
+00029ad0: 4370 7549 6e66 6f28 292e 6266 3136 206f  CpuInfo().bf16 o
+00029ae0: 7220 6f73 2e67 6574 656e 7628 2746 4f52  r os.getenv('FOR
+00029af0: 4345 5f42 4631 3627 2920 3d3d 2027 3127  CE_BF16') == '1'
+00029b00: 293a 2023 2070 7261 676d 613a 206e 6f20  ): # pragma: no 
+00029b10: 636f 7665 720a 2020 2020 2020 2020 2020  cover.          
+00029b20: 2020 7365 6c66 2e6d 6f64 656c 2e5f 6d6f    self.model._mo
+00029b30: 6465 6c20 3d20 746f 7263 685f 7574 696c  del = torch_util
+00029b40: 732e 6266 3136 5f63 6f6e 7665 7274 2e43  s.bf16_convert.C
+00029b50: 6f6e 7665 7274 2873 656c 662e 6d6f 6465  onvert(self.mode
+00029b60: 6c2e 5f6d 6f64 656c 2c20 7365 6c66 2e6d  l._model, self.m
+00029b70: 6f64 656c 2e71 5f63 6f6e 6669 6729 0a20  odel.q_config). 
+00029b80: 2020 2020 2020 2073 656c 662e 5f64 756d         self._dum
+00029b90: 705f 6d6f 6465 6c5f 6f70 5f73 7461 7473  p_model_op_stats
+00029ba0: 2873 656c 662e 6d6f 6465 6c2e 5f6d 6f64  (self.model._mod
+00029bb0: 656c 2c20 7365 6c66 2e6d 6f64 656c 2e71  el, self.model.q
+00029bc0: 5f63 6f6e 6669 672c 2073 656c 662e 6170  _config, self.ap
+00029bd0: 7072 6f61 6368 290a 2020 2020 2020 2020  proach).        
+00029be0: 746f 7263 685f 7574 696c 732e 7574 696c  torch_utils.util
+00029bf0: 2e67 6574 5f65 6d62 6564 6469 6e67 5f63  .get_embedding_c
+00029c00: 6f6e 7469 6775 6f75 7328 7365 6c66 2e6d  ontiguous(self.m
+00029c10: 6f64 656c 2e5f 6d6f 6465 6c29 0a0a 2020  odel._model)..  
+00029c20: 2020 6465 6620 7472 6169 6e28 7365 6c66    def train(self
+00029c30: 2c20 6d6f 6465 6c2c 2064 6174 616c 6f61  , model, dataloa
+00029c40: 6465 722c 206f 7074 696d 697a 6572 5f74  der, optimizer_t
+00029c50: 7570 6c65 2c20 6372 6974 6572 696f 6e5f  uple, criterion_
+00029c60: 7475 706c 652c 2068 6f6f 6b73 2c20 2a2a  tuple, hooks, **
+00029c70: 6b77 6172 6773 293a 0a20 2020 2020 2020  kwargs):.       
+00029c80: 2022 2222 4578 6563 7574 6520 7468 6520   """Execute the 
+00029c90: 7472 6169 6e20 7072 6f63 6573 7320 6f6e  train process on
+00029ca0: 2074 6865 2073 7065 6369 6669 6564 206d   the specified m
+00029cb0: 6f64 656c 2e0a 0a20 2020 2020 2020 2041  odel...        A
+00029cc0: 7267 733a 0a20 2020 2020 2020 2020 2020  rgs:.           
+00029cd0: 206d 6f64 656c 2028 6f62 6a65 6374 293a   model (object):
+00029ce0: 206d 6f64 656c 2074 6f20 7275 6e20 6576   model to run ev
+00029cf0: 616c 7561 7469 6f6e 2e0a 2020 2020 2020  aluation..      
+00029d00: 2020 2020 2020 6461 7461 6c6f 6164 6572        dataloader
+00029d10: 2028 6f62 6a65 6374 293a 2074 7261 696e   (object): train
+00029d20: 696e 6720 6461 7461 7365 742e 0a20 2020  ing dataset..   
+00029d30: 2020 2020 2020 2020 206f 7074 696d 697a           optimiz
+00029d40: 6572 2028 7475 706c 6529 3a20 4974 2069  er (tuple): It i
+00029d50: 7320 6120 7475 706c 6520 6f66 2028 636c  s a tuple of (cl
+00029d60: 732c 2070 6172 616d 6574 6572 7329 2066  s, parameters) f
+00029d70: 6f72 206f 7074 696d 697a 6572 2e0a 2020  or optimizer..  
+00029d80: 2020 2020 2020 2020 2020 6372 6974 6572            criter
+00029d90: 696f 6e20 2874 7570 6c65 293a 2049 7420  ion (tuple): It 
+00029da0: 6973 2061 2074 7570 6c65 206f 6620 2863  is a tuple of (c
+00029db0: 6c73 2c20 7061 7261 6d65 7465 7273 2920  ls, parameters) 
+00029dc0: 666f 7220 6372 6974 6572 696f 6e2e 0a20  for criterion.. 
+00029dd0: 2020 2020 2020 2020 2020 206b 7761 7267             kwarg
+00029de0: 7320 2864 6963 742c 206f 7074 696f 6e61  s (dict, optiona
+00029df0: 6c29 3a20 6f74 6865 7220 7061 7261 6d65  l): other parame
+00029e00: 7465 7273 2e0a 0a20 2020 2020 2020 2052  ters...        R
+00029e10: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
+00029e20: 2020 2020 4e6f 6e65 0a20 2020 2020 2020      None.       
+00029e30: 2022 2222 0a20 2020 2020 2020 2064 6576   """.        dev
+00029e40: 6963 6520 3d20 2263 7564 613a 3022 2069  ice = "cuda:0" i
+00029e50: 6620 7365 6c66 2e64 6576 6963 6520 213d  f self.device !=
+00029e60: 2022 4750 5522 2061 6e64 2074 6f72 6368   "GPU" and torch
+00029e70: 2e63 7564 612e 6973 5f61 7661 696c 6162  .cuda.is_availab
+00029e80: 6c65 2829 2065 6c73 6520 7365 6c66 2e64  le() else self.d
+00029e90: 6576 6963 650a 2020 2020 2020 2020 7365  evice.        se
+00029ea0: 6c66 2e6d 6f64 656c 203d 206d 6f64 656c  lf.model = model
+00029eb0: 0a20 2020 2020 2020 206f 7074 696d 697a  .        optimiz
+00029ec0: 6572 203d 206f 7074 696d 697a 6572 5f74  er = optimizer_t
+00029ed0: 7570 6c65 5b30 5d28 6d6f 6465 6c2e 5f6d  uple[0](model._m
+00029ee0: 6f64 656c 2e70 6172 616d 6574 6572 7328  odel.parameters(
+00029ef0: 292c 202a 2a6f 7074 696d 697a 6572 5f74  ), **optimizer_t
+00029f00: 7570 6c65 5b31 5d29 0a20 2020 2020 2020  uple[1]).       
+00029f10: 2063 7269 7465 7269 6f6e 203d 2063 7269   criterion = cri
+00029f20: 7465 7269 6f6e 5f74 7570 6c65 5b30 5d28  terion_tuple[0](
+00029f30: 2a2a 6372 6974 6572 696f 6e5f 7475 706c  **criterion_tupl
+00029f40: 655b 315d 290a 2020 2020 2020 2020 2320  e[1]).        # 
+00029f50: 7072 6570 6172 6520 686f 6f6b 7320 6669  prepare hooks fi
+00029f60: 7273 7420 746f 2065 6e73 7572 6520 6d6f  rst to ensure mo
+00029f70: 6465 6c20 7769 6c6c 2062 6520 636f 6e76  del will be conv
+00029f80: 6572 7465 6420 636f 7272 6563 746c 790a  erted correctly.
+00029f90: 2020 2020 2020 2020 6966 2068 6f6f 6b73          if hooks
+00029fa0: 2069 7320 6e6f 7420 4e6f 6e65 3a20 2023   is not None:  #
+00029fb0: 2070 7261 676d 613a 206e 6f20 636f 7665   pragma: no cove
+00029fc0: 720a 2020 2020 2020 2020 2020 2020 6f6e  r.            on
+00029fd0: 5f74 7261 696e 5f62 6567 696e 203d 2068  _train_begin = h
+00029fe0: 6f6f 6b73 5b27 6f6e 5f74 7261 696e 5f62  ooks['on_train_b
+00029ff0: 6567 696e 275d 0a20 2020 2020 2020 2020  egin'].         
+0002a000: 2020 206f 6e5f 7472 6169 6e5f 656e 6420     on_train_end 
+0002a010: 3d20 686f 6f6b 735b 276f 6e5f 7472 6169  = hooks['on_trai
+0002a020: 6e5f 656e 6427 5d0a 2020 2020 2020 2020  n_end'].        
+0002a030: 2020 2020 6f6e 5f65 706f 6368 5f62 6567      on_epoch_beg
+0002a040: 696e 203d 2068 6f6f 6b73 5b27 6f6e 5f65  in = hooks['on_e
+0002a050: 706f 6368 5f62 6567 696e 275d 0a20 2020  poch_begin'].   
+0002a060: 2020 2020 2020 2020 206f 6e5f 6570 6f63           on_epoc
+0002a070: 685f 656e 6420 3d20 686f 6f6b 735b 276f  h_end = hooks['o
+0002a080: 6e5f 6570 6f63 685f 656e 6427 5d0a 2020  n_epoch_end'].  
+0002a090: 2020 2020 2020 2020 2020 6f6e 5f73 7465            on_ste
+0002a0a0: 705f 6265 6769 6e20 3d20 686f 6f6b 735b  p_begin = hooks[
+0002a0b0: 276f 6e5f 7374 6570 5f62 6567 696e 275d  'on_step_begin']
+0002a0c0: 0a20 2020 2020 2020 2020 2020 206f 6e5f  .            on_
+0002a0d0: 7374 6570 5f65 6e64 203d 2068 6f6f 6b73  step_end = hooks
+0002a0e0: 5b27 6f6e 5f73 7465 705f 656e 6427 5d0a  ['on_step_end'].
+0002a0f0: 2020 2020 2020 2020 2020 2020 6f6e 5f61              on_a
+0002a100: 6674 6572 5f63 6f6d 7075 7465 5f6c 6f73  fter_compute_los
+0002a110: 7320 3d20 686f 6f6b 735b 276f 6e5f 6166  s = hooks['on_af
+0002a120: 7465 725f 636f 6d70 7574 655f 6c6f 7373  ter_compute_loss
+0002a130: 275d 0a20 2020 2020 2020 2020 2020 206f  '].            o
+0002a140: 6e5f 6265 666f 7265 5f6f 7074 696d 697a  n_before_optimiz
+0002a150: 6572 5f73 7465 7020 3d20 686f 6f6b 735b  er_step = hooks[
+0002a160: 276f 6e5f 6265 666f 7265 5f6f 7074 696d  'on_before_optim
+0002a170: 697a 6572 5f73 7465 7027 5d0a 2020 2020  izer_step'].    
+0002a180: 2020 2020 6d6f 6465 6c2e 5f6d 6f64 656c      model._model
+0002a190: 2e74 7261 696e 2829 0a20 2020 2020 2020  .train().       
+0002a1a0: 2069 6620 686f 6f6b 7320 6973 206e 6f74   if hooks is not
+0002a1b0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+0002a1c0: 2020 206f 6e5f 7472 6169 6e5f 6265 6769     on_train_begi
+0002a1d0: 6e28 6461 7461 6c6f 6164 6572 290a 2020  n(dataloader).  
+0002a1e0: 2020 2020 2020 7374 6172 745f 6570 6f63        start_epoc
+0002a1f0: 6873 203d 206b 7761 7267 735b 276b 7761  hs = kwargs['kwa
+0002a200: 7267 7327 5d5b 2773 7461 7274 5f65 706f  rgs']['start_epo
+0002a210: 6368 275d 0a20 2020 2020 2020 2065 6e64  ch'].        end
+0002a220: 5f65 706f 6368 7320 3d20 6b77 6172 6773  _epochs = kwargs
+0002a230: 5b27 6b77 6172 6773 275d 5b27 656e 645f  ['kwargs']['end_
+0002a240: 6570 6f63 6827 5d0a 2020 2020 2020 2020  epoch'].        
+0002a250: 6974 6572 7320 3d20 6b77 6172 6773 5b27  iters = kwargs['
+0002a260: 6b77 6172 6773 275d 5b27 6974 6572 6174  kwargs']['iterat
+0002a270: 696f 6e27 5d0a 2020 2020 2020 2020 6d6f  ion'].        mo
+0002a280: 6465 6c2e 5f6d 6f64 656c 2e74 6f28 6465  del._model.to(de
+0002a290: 7669 6365 290a 2020 2020 2020 2020 666f  vice).        fo
+0002a2a0: 7220 6e65 706f 6368 2069 6e20 7261 6e67  r nepoch in rang
+0002a2b0: 6528 7374 6172 745f 6570 6f63 6873 2c20  e(start_epochs, 
+0002a2c0: 656e 645f 6570 6f63 6873 293a 0a20 2020  end_epochs):.   
+0002a2d0: 2020 2020 2020 2020 2063 6e74 203d 2030           cnt = 0
+0002a2e0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0002a2f0: 686f 6f6b 7320 6973 206e 6f74 204e 6f6e  hooks is not Non
+0002a300: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+0002a310: 2020 206f 6e5f 6570 6f63 685f 6265 6769     on_epoch_begi
+0002a320: 6e28 6e65 706f 6368 290a 2020 2020 2020  n(nepoch).      
+0002a330: 2020 2020 2020 666f 7220 696e 7075 742c        for input,
+0002a340: 2074 6172 6765 7420 696e 2064 6174 616c   target in datal
+0002a350: 6f61 6465 723a 0a20 2020 2020 2020 2020  oader:.         
+0002a360: 2020 2020 2020 2074 6172 6765 7420 3d20         target = 
+0002a370: 7461 7267 6574 2e74 6f28 6465 7669 6365  target.to(device
+0002a380: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0002a390: 2020 6966 2068 6f6f 6b73 2069 7320 6e6f    if hooks is no
+0002a3a0: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+0002a3b0: 2020 2020 2020 2020 2020 2020 6f6e 5f73              on_s
+0002a3c0: 7465 705f 6265 6769 6e28 636e 7429 0a20  tep_begin(cnt). 
+0002a3d0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0002a3e0: 7269 6e74 2827 2e27 2c20 656e 643d 2727  rint('.', end=''
+0002a3f0: 2c20 666c 7573 683d 5472 7565 290a 2020  , flush=True).  
+0002a400: 2020 2020 2020 2020 2020 2020 2020 636e                cn
+0002a410: 7420 2b3d 2031 0a20 2020 2020 2020 2020  t += 1.         
+0002a420: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0002a430: 7079 746f 7263 685f 666f 7277 6172 645f  pytorch_forward_
+0002a440: 7772 6170 7065 7228 6d6f 6465 6c2e 5f6d  wrapper(model._m
+0002a450: 6f64 656c 2c20 696e 7075 742c 2064 6576  odel, input, dev
+0002a460: 6963 653d 6465 7669 6365 290a 2020 2020  ice=device).    
+0002a470: 2020 2020 2020 2020 2020 2020 6c6f 7373              loss
+0002a480: 203d 2063 7269 7465 7269 6f6e 286f 7574   = criterion(out
+0002a490: 7075 742c 2074 6172 6765 7429 0a20 2020  put, target).   
+0002a4a0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0002a4b0: 686f 6f6b 7320 6973 206e 6f74 204e 6f6e  hooks is not Non
+0002a4c0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+0002a4d0: 2020 2020 2020 206c 6f73 7320 3d20 6f6e         loss = on
+0002a4e0: 5f61 6674 6572 5f63 6f6d 7075 7465 5f6c  _after_compute_l
+0002a4f0: 6f73 7328 696e 7075 742c 206f 7574 7075  oss(input, outpu
+0002a500: 742c 206c 6f73 7329 0a20 2020 2020 2020  t, loss).       
+0002a510: 2020 2020 2020 2020 206f 7074 696d 697a           optimiz
+0002a520: 6572 2e7a 6572 6f5f 6772 6164 2829 0a20  er.zero_grad(). 
+0002a530: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+0002a540: 6f73 732e 6261 636b 7761 7264 2829 0a20  oss.backward(). 
+0002a550: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0002a560: 6620 686f 6f6b 7320 6973 206e 6f74 204e  f hooks is not N
+0002a570: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+0002a580: 2020 2020 2020 2020 206c 6f73 7320 3d20           loss = 
+0002a590: 6f6e 5f62 6566 6f72 655f 6f70 7469 6d69  on_before_optimi
+0002a5a0: 7a65 725f 7374 6570 2829 0a20 2020 2020  zer_step().     
+0002a5b0: 2020 2020 2020 2020 2020 206f 7074 696d             optim
+0002a5c0: 697a 6572 2e73 7465 7028 290a 2020 2020  izer.step().    
+0002a5d0: 2020 2020 2020 2020 2020 2020 6966 2068              if h
+0002a5e0: 6f6f 6b73 2069 7320 6e6f 7420 4e6f 6e65  ooks is not None
+0002a5f0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0002a600: 2020 2020 2020 6f6e 5f73 7465 705f 656e        on_step_en
+0002a610: 6428 290a 2020 2020 2020 2020 2020 2020  d().            
+0002a620: 2020 2020 6966 2063 6e74 203e 3d20 6974      if cnt >= it
+0002a630: 6572 733a 0a20 2020 2020 2020 2020 2020  ers:.           
+0002a640: 2020 2020 2020 2020 2062 7265 616b 0a20           break. 
+0002a650: 2020 2020 2020 2020 2020 2069 6620 686f             if ho
+0002a660: 6f6b 7320 6973 206e 6f74 204e 6f6e 653a  oks is not None:
+0002a670: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002a680: 206f 6e5f 6570 6f63 685f 656e 6428 290a   on_epoch_end().
+0002a690: 0a20 2020 2020 2020 2069 6620 6465 7669  .        if devi
+0002a6a0: 6365 2021 3d20 7365 6c66 2e64 6576 6963  ce != self.devic
+0002a6b0: 653a 2020 2320 7072 6167 6d61 3a20 6e6f  e:  # pragma: no
+0002a6c0: 2063 6f76 6572 0a20 2020 2020 2020 2020   cover.         
+0002a6d0: 2020 206d 6f64 656c 2e5f 6d6f 6465 6c2e     model._model.
+0002a6e0: 746f 2873 656c 662e 6465 7669 6365 290a  to(self.device).
+0002a6f0: 0a20 2020 2020 2020 2069 6620 686f 6f6b  .        if hook
+0002a700: 7320 6973 206e 6f74 204e 6f6e 653a 0a20  s is not None:. 
+0002a710: 2020 2020 2020 2020 2020 206f 6e5f 7472             on_tr
+0002a720: 6169 6e5f 656e 6428 290a 0a20 2020 2020  ain_end()..     
+0002a730: 2020 2072 6574 7572 6e20 6d6f 6465 6c2e     return model.
+0002a740: 5f6d 6f64 656c 0a0a 2020 2020 6465 6620  _model..    def 
+0002a750: 5f67 6574 5f6d 6f64 756c 655f 6f70 5f73  _get_module_op_s
+0002a760: 7461 7473 2873 656c 662c 206d 6f64 656c  tats(self, model
+0002a770: 2c20 7475 6e65 5f63 6667 2c20 6170 7072  , tune_cfg, appr
+0002a780: 6f61 6368 293a 0a20 2020 2020 2020 2022  oach):.        "
+0002a790: 2222 5468 6973 2069 7320 6120 6675 6e63  ""This is a func
+0002a7a0: 7469 6f6e 2074 6f20 6765 7420 7175 616e  tion to get quan
+0002a7b0: 7469 7a61 626c 6520 6f70 7320 6f66 206d  tizable ops of m
+0002a7c0: 6f64 656c 2074 6f20 7573 6572 2e0a 2020  odel to user..  
+0002a7d0: 2020 2020 2020 4172 6773 3a0a 2020 2020        Args:.    
+0002a7e0: 2020 2020 2020 2020 6d6f 6465 6c20 286f          model (o
+0002a7f0: 626a 6563 7429 3a20 696e 7075 7420 6d6f  bject): input mo
+0002a800: 6465 6c0a 2020 2020 2020 2020 2020 2020  del.            
+0002a810: 7475 6e65 5f63 6667 2028 6469 6374 293a  tune_cfg (dict):
+0002a820: 2071 7561 6e74 697a 6174 696f 6e20 636f   quantization co
+0002a830: 6e66 6967 0a20 2020 2020 2020 2020 2020  nfig.           
+0002a840: 2061 7070 726f 6163 6820 2873 7472 293a   approach (str):
+0002a850: 2071 7561 6e74 697a 6174 696f 6e20 6170   quantization ap
+0002a860: 7072 6f61 6368 0a20 2020 2020 2020 2052  proach.        R
+0002a870: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
+0002a880: 2020 2020 4e6f 6e65 0a20 2020 2020 2020      None.       
+0002a890: 2022 2222 0a20 2020 2020 2020 206d 6f64   """.        mod
+0002a8a0: 756c 6573 203d 2064 6963 7428 6d6f 6465  ules = dict(mode
+0002a8b0: 6c2e 6e61 6d65 645f 6d6f 6475 6c65 7328  l.named_modules(
+0002a8c0: 2929 0a20 2020 2020 2020 2072 6573 203d  )).        res =
+0002a8d0: 2064 6963 7428 290a 0a20 2020 2020 2020   dict()..       
+0002a8e0: 2069 6620 6170 7072 6f61 6368 203d 3d20   if approach == 
+0002a8f0: 2770 6f73 745f 7472 6169 6e69 6e67 5f64  'post_training_d
+0002a900: 796e 616d 6963 5f71 7561 6e74 273a 0a20  ynamic_quant':. 
+0002a910: 2020 2020 2020 2020 2020 2023 2066 6574             # fet
+0002a920: 6368 2069 6e74 3820 616e 6420 6670 3332  ch int8 and fp32
+0002a930: 206f 7073 2073 6574 2062 7920 4e65 7572   ops set by Neur
+0002a940: 616c 2043 6f6d 7072 6573 736f 7220 6672  al Compressor fr
+0002a950: 6f6d 2074 756e 655f 6366 670a 2020 2020  om tune_cfg.    
+0002a960: 2020 2020 2020 2020 666f 7220 6b65 7920          for key 
+0002a970: 696e 2074 756e 655f 6366 675b 276f 7027  in tune_cfg['op'
+0002a980: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
+0002a990: 2020 206f 705f 7479 7065 203d 206b 6579     op_type = key
+0002a9a0: 5b31 5d0a 2020 2020 2020 2020 2020 2020  [1].            
+0002a9b0: 2020 2020 2362 7569 6c64 2069 6e69 7469      #build initi
+0002a9c0: 616c 2064 6963 740a 2020 2020 2020 2020  al dict.        
+0002a9d0: 2020 2020 2020 2020 6966 206f 705f 7479          if op_ty
+0002a9e0: 7065 206e 6f74 2069 6e20 7265 732e 6b65  pe not in res.ke
+0002a9f0: 7973 2829 3a0a 2020 2020 2020 2020 2020  ys():.          
+0002aa00: 2020 2020 2020 2020 2020 7265 735b 6f70            res[op
+0002aa10: 5f74 7970 655d 203d 207b 2749 4e54 3827  _type] = {'INT8'
+0002aa20: 3a20 302c 2027 4246 3136 273a 2030 2c20  : 0, 'BF16': 0, 
+0002aa30: 2746 5033 3227 3a20 307d 0a20 2020 2020  'FP32': 0}.     
+0002aa40: 2020 2020 2020 2020 2020 2076 616c 7565             value
+0002aa50: 203d 2074 756e 655f 6366 675b 276f 7027   = tune_cfg['op'
+0002aa60: 5d5b 6b65 795d 0a20 2020 2020 2020 2020  ][key].         
+0002aa70: 2020 2020 2020 2023 2053 7065 6369 616c         # Special
+0002aa80: 2063 6173 6573 3a20 5175 616e 7453 7475   cases: QuantStu
+0002aa90: 622c 2045 6d62 6564 6469 6e67 0a20 2020  b, Embedding.   
+0002aaa0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0002aab0: 2827 7765 6967 6874 2720 696e 2076 616c  ('weight' in val
+0002aac0: 7565 2061 6e64 2076 616c 7565 5b27 7765  ue and value['we
+0002aad0: 6967 6874 275d 5b27 6474 7970 6527 5d20  ight']['dtype'] 
+0002aae0: 3d3d 2027 6670 3332 2729 206f 7220 5c0a  == 'fp32') or \.
+0002aaf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002ab00: 2020 2827 7765 6967 6874 2720 6e6f 7420    ('weight' not 
+0002ab10: 696e 2076 616c 7565 2061 6e64 2076 616c  in value and val
+0002ab20: 7565 5b27 6163 7469 7661 7469 6f6e 275d  ue['activation']
+0002ab30: 5b27 6474 7970 6527 5d20 3d3d 2027 6670  ['dtype'] == 'fp
+0002ab40: 3332 2729 3a0a 2020 2020 2020 2020 2020  32'):.          
+0002ab50: 2020 2020 2020 2020 2020 7265 735b 6f70            res[op
+0002ab60: 5f74 7970 655d 5b27 4650 3332 275d 202b  _type]['FP32'] +
+0002ab70: 3d20 310a 2020 2020 2020 2020 2020 2020  = 1.            
+0002ab80: 2020 2020 656c 6966 2076 616c 7565 5b27      elif value['
+0002ab90: 6163 7469 7661 7469 6f6e 275d 5b27 6474  activation']['dt
+0002aba0: 7970 6527 5d20 3d3d 2027 6266 3136 273a  ype'] == 'bf16':
+0002abb0: 2020 2320 7072 6167 6d61 3a20 6e6f 2063    # pragma: no c
+0002abc0: 6f76 6572 0a20 2020 2020 2020 2020 2020  over.           
+0002abd0: 2020 2020 2020 2020 2072 6573 5b6f 705f           res[op_
+0002abe0: 7479 7065 5d5b 2742 4631 3627 5d20 2b3d  type]['BF16'] +=
+0002abf0: 2031 0a20 2020 2020 2020 2020 2020 2020   1.             
+0002ac00: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0002ac10: 2020 2020 2020 2020 2020 2020 2072 6573               res
+0002ac20: 5b6f 705f 7479 7065 5d5b 2749 4e54 3827  [op_type]['INT8'
+0002ac30: 5d20 2b3d 2031 0a20 2020 2020 2020 2065  ] += 1.        e
+0002ac40: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0002ac50: 2071 7561 6e74 697a 6564 5f6d 6f64 6520   quantized_mode 
+0002ac60: 3d20 4661 6c73 650a 2020 2020 2020 2020  = False.        
+0002ac70: 2020 2020 666f 7220 6e6f 6465 2069 6e20      for node in 
+0002ac80: 6d6f 6465 6c2e 6772 6170 682e 6e6f 6465  model.graph.node
+0002ac90: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
+0002aca0: 2020 2069 6620 6e6f 6465 2e6f 7020 3d3d     if node.op ==
+0002acb0: 2027 6361 6c6c 5f6d 6f64 756c 6527 3a0a   'call_module':.
+0002acc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002acd0: 2020 2020 6966 206e 6f64 652e 7461 7267      if node.targ
+0002ace0: 6574 206e 6f74 2069 6e20 6d6f 6475 6c65  et not in module
+0002acf0: 733a 2020 2320 7072 6167 6d61 3a20 6e6f  s:  # pragma: no
+0002ad00: 2063 6f76 6572 0a20 2020 2020 2020 2020   cover.         
+0002ad10: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+0002ad20: 6f6e 7469 6e75 650a 2020 2020 2020 2020  ontinue.        
+0002ad30: 2020 2020 2020 2020 2020 2020 6f70 5f63              op_c
+0002ad40: 6c61 7373 203d 2074 7970 6528 6d6f 6475  lass = type(modu
+0002ad50: 6c65 735b 6e6f 6465 2e74 6172 6765 745d  les[node.target]
+0002ad60: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0002ad70: 2020 2020 2020 6f70 5f74 7970 6520 3d20        op_type = 
+0002ad80: 7374 7228 6f70 5f63 6c61 7373 2e5f 5f6e  str(op_class.__n
+0002ad90: 616d 655f 5f29 0a20 2020 2020 2020 2020  ame__).         
+0002ada0: 2020 2020 2020 2020 2020 2069 6620 2771             if 'q
+0002adb0: 7561 6e74 697a 6564 2720 696e 2073 7472  uantized' in str
+0002adc0: 286f 705f 636c 6173 7329 206f 7220 7175  (op_class) or qu
+0002add0: 616e 7469 7a65 645f 6d6f 6465 3a0a 2020  antized_mode:.  
+0002ade0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002adf0: 2020 2020 2020 6966 206f 705f 7479 7065        if op_type
+0002ae00: 206e 6f74 2069 6e20 7265 732e 6b65 7973   not in res.keys
+0002ae10: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+0002ae20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002ae30: 7265 735b 6f70 5f74 7970 655d 203d 207b  res[op_type] = {
+0002ae40: 2749 4e54 3827 3a20 302c 2027 4246 3136  'INT8': 0, 'BF16
+0002ae50: 273a 2030 2c20 2746 5033 3227 3a20 307d  ': 0, 'FP32': 0}
+0002ae60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002ae70: 2020 2020 2020 2020 2072 6573 5b6f 705f           res[op_
+0002ae80: 7479 7065 5d5b 2749 4e54 3827 5d20 2b3d  type]['INT8'] +=
+0002ae90: 2031 0a20 2020 2020 2020 2020 2020 2020   1.             
+0002aea0: 2020 2020 2020 2065 6c69 6620 6f70 5f63         elif op_c
+0002aeb0: 6c61 7373 2069 6e20 7365 6c66 2e77 6869  lass in self.whi
+0002aec0: 7465 5f6c 6973 743a 0a20 2020 2020 2020  te_list:.       
+0002aed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002aee0: 2069 6620 6f70 5f74 7970 6520 6e6f 7420   if op_type not 
+0002aef0: 696e 2072 6573 2e6b 6579 7328 293a 0a20  in res.keys():. 
+0002af00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002af10: 2020 2020 2020 2020 2020 2072 6573 5b6f             res[o
+0002af20: 705f 7479 7065 5d20 3d20 7b27 494e 5438  p_type] = {'INT8
+0002af30: 273a 2030 2c20 2742 4631 3627 3a20 302c  ': 0, 'BF16': 0,
+0002af40: 2027 4650 3332 273a 2030 7d0a 2020 2020   'FP32': 0}.    
+0002af50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002af60: 2020 2020 7265 735b 6f70 5f74 7970 655d      res[op_type]
+0002af70: 5b27 4650 3332 275d 202b 3d20 310a 2020  ['FP32'] += 1.  
+0002af80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002af90: 2020 636f 6e74 696e 7565 0a20 2020 2020    continue.     
+0002afa0: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+0002afb0: 6e6f 6465 2e6f 7020 3d3d 2027 6361 6c6c  node.op == 'call
+0002afc0: 5f66 756e 6374 696f 6e27 3a0a 2020 2020  _function':.    
+0002afd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002afe0: 6f70 5f74 7970 6520 3d20 7374 7228 6e6f  op_type = str(no
+0002aff0: 6465 2e74 6172 6765 742e 5f5f 6e61 6d65  de.target.__name
+0002b000: 5f5f 290a 2020 2020 2020 2020 2020 2020  __).            
+0002b010: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+0002b020: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+0002b030: 5f74 7970 6520 3d20 6e6f 6465 2e74 6172  _type = node.tar
+0002b040: 6765 740a 2020 2020 2020 2020 2020 2020  get.            
+0002b050: 2020 2020 2320 736b 6970 2069 6e70 7574      # skip input
+0002b060: 2061 6e64 206f 7574 7075 740a 2020 2020   and output.    
+0002b070: 2020 2020 2020 2020 2020 2020 6966 206e              if n
+0002b080: 6f74 2022 7175 616e 7469 7a65 5f70 6572  ot "quantize_per
+0002b090: 2220 696e 206f 705f 7479 7065 2061 6e64  " in op_type and
+0002b0a0: 206e 6f74 2071 7561 6e74 697a 6564 5f6d   not quantized_m
+0002b0b0: 6f64 653a 0a20 2020 2020 2020 2020 2020  ode:.           
+0002b0c0: 2020 2020 2020 2020 2063 6f6e 7469 6e75           continu
+0002b0d0: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+0002b0e0: 2020 2320 736b 6970 207a 6572 6f5f 7069    # skip zero_pi
+0002b0f0: 6f69 6e74 2061 6e64 2073 6361 6c65 0a20  oint and scale. 
+0002b100: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0002b110: 6620 227a 6572 6f5f 706f 696e 7422 2069  f "zero_point" i
+0002b120: 6e20 6f70 5f74 7970 6520 6f72 2022 7363  n op_type or "sc
+0002b130: 616c 6522 2069 6e20 6f70 5f74 7970 653a  ale" in op_type:
+0002b140: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002b150: 2020 2020 2063 6f6e 7469 6e75 650a 2020       continue.  
+0002b160: 2020 2020 2020 2020 2020 2020 2020 2362                #b
+0002b170: 7569 6c64 2069 6e69 7469 616c 2064 6963  uild initial dic
+0002b180: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
+0002b190: 2020 6966 206f 705f 7479 7065 206e 6f74    if op_type not
+0002b1a0: 2069 6e20 7265 732e 6b65 7973 2829 3a0a   in res.keys():.
+0002b1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002b1c0: 2020 2020 7265 735b 6f70 5f74 7970 655d      res[op_type]
+0002b1d0: 203d 207b 2749 4e54 3827 3a20 302c 2027   = {'INT8': 0, '
+0002b1e0: 4246 3136 273a 2030 2c20 2746 5033 3227  BF16': 0, 'FP32'
+0002b1f0: 3a20 307d 0a0a 2020 2020 2020 2020 2020  : 0}..          
+0002b200: 2020 2020 2020 6966 2022 7175 616e 7469        if "quanti
+0002b210: 7a65 5f70 6572 2220 696e 206f 705f 7479  ze_per" in op_ty
+0002b220: 7065 2061 6e64 206e 6f74 2071 7561 6e74  pe and not quant
+0002b230: 697a 6564 5f6d 6f64 653a 0a20 2020 2020  ized_mode:.     
+0002b240: 2020 2020 2020 2020 2020 2020 2020 2071                 q
+0002b250: 7561 6e74 697a 6564 5f6d 6f64 6520 3d20  uantized_mode = 
+0002b260: 5472 7565 0a20 2020 2020 2020 2020 2020  True.           
+0002b270: 2020 2020 2065 6c69 6620 2264 6571 7561       elif "dequa
+0002b280: 6e74 697a 6522 2069 6e20 6f70 5f74 7970  ntize" in op_typ
+0002b290: 6520 616e 6420 7175 616e 7469 7a65 645f  e and quantized_
+0002b2a0: 6d6f 6465 3a0a 2020 2020 2020 2020 2020  mode:.          
+0002b2b0: 2020 2020 2020 2020 2020 7175 616e 7469            quanti
+0002b2c0: 7a65 645f 6d6f 6465 203d 2046 616c 7365  zed_mode = False
+0002b2d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002b2e0: 2072 6573 5b6f 705f 7479 7065 5d5b 2749   res[op_type]['I
+0002b2f0: 4e54 3827 5d20 2b3d 2031 0a20 2020 2020  NT8'] += 1.     
+0002b300: 2020 2072 6574 7572 6e20 7265 730a 0a20     return res.. 
+0002b310: 2020 2064 6566 205f 6765 745f 7375 625f     def _get_sub_
+0002b320: 6d6f 6475 6c65 5f6f 705f 7374 6174 7328  module_op_stats(
+0002b330: 7365 6c66 2c20 6d6f 6465 6c2c 2074 756e  self, model, tun
+0002b340: 655f 6366 672c 2061 7070 726f 6163 682c  e_cfg, approach,
+0002b350: 2072 6573 2c20 7072 6566 6978 3d27 2729   res, prefix='')
+0002b360: 3a0a 2020 2020 2020 2020 2222 2254 6869  :.        """Thi
+0002b370: 7320 6973 2061 2066 756e 6374 696f 6e20  s is a function 
+0002b380: 746f 2067 6574 2071 7561 6e74 697a 6162  to get quantizab
+0002b390: 6c65 206f 7073 206f 6620 7375 6220 6d6f  le ops of sub mo
+0002b3a0: 6475 6c65 7320 746f 2075 7365 7220 7265  dules to user re
+0002b3b0: 6375 7273 6976 656c 792e 0a20 2020 2020  cursively..     
+0002b3c0: 2020 2041 7267 733a 0a20 2020 2020 2020     Args:.       
+0002b3d0: 2020 2020 206d 6f64 656c 2028 6f62 6a65       model (obje
+0002b3e0: 6374 293a 2069 6e70 7574 206d 6f64 656c  ct): input model
+0002b3f0: 0a20 2020 2020 2020 2020 2020 2074 756e  .            tun
+0002b400: 655f 6366 6720 2864 6963 7429 3a20 7175  e_cfg (dict): qu
+0002b410: 616e 7469 7a61 7469 6f6e 2063 6f6e 6669  antization confi
+0002b420: 670a 2020 2020 2020 2020 2020 2020 6170  g.            ap
+0002b430: 7072 6f61 6368 2028 7374 7229 3a20 7175  proach (str): qu
+0002b440: 616e 7469 7a61 7469 6f6e 2061 7070 726f  antization appro
+0002b450: 6163 680a 2020 2020 2020 2020 2020 2020  ach.            
+0002b460: 7265 7320 2864 6963 7429 203a 2063 6f6e  res (dict) : con
+0002b470: 7461 696e 7320 7265 7375 6c74 206f 6620  tains result of 
+0002b480: 7175 616e 7469 7a61 626c 6520 6f70 730a  quantizable ops.
+0002b490: 2020 2020 2020 2020 2020 2020 7072 6566              pref
+0002b4a0: 6978 2028 7374 7269 6e67 293a 2070 7265  ix (string): pre
+0002b4b0: 6669 7820 6f66 206f 7020 6e61 6d65 0a20  fix of op name. 
+0002b4c0: 2020 2020 2020 2052 6574 7572 6e73 3a0a         Returns:.
+0002b4d0: 2020 2020 2020 2020 2020 2020 4e6f 6e65              None
+0002b4e0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+0002b4f0: 2020 2020 2066 6f72 206e 616d 652c 206d       for name, m
+0002b500: 6f64 756c 6520 696e 206d 6f64 656c 2e6e  odule in model.n
+0002b510: 616d 6564 5f63 6869 6c64 7265 6e28 293a  amed_children():
+0002b520: 0a20 2020 2020 2020 2020 2020 206f 705f  .            op_
+0002b530: 6e61 6d65 203d 2070 7265 6669 7820 2b20  name = prefix + 
+0002b540: 272e 2720 2b20 6e61 6d65 2069 6620 7072  '.' + name if pr
+0002b550: 6566 6978 2021 3d20 2727 2065 6c73 6520  efix != '' else 
+0002b560: 6e61 6d65 0a20 2020 2020 2020 2020 2020  name.           
+0002b570: 2069 6620 6f70 5f6e 616d 6520 696e 2073   if op_name in s
+0002b580: 656c 662e 7375 625f 6d6f 6475 6c65 5f6c  elf.sub_module_l
+0002b590: 6973 743a 0a20 2020 2020 2020 2020 2020  ist:.           
+0002b5a0: 2020 2020 206d 6f64 756c 655f 7265 7320       module_res 
+0002b5b0: 3d20 7365 6c66 2e5f 6765 745f 6d6f 6475  = self._get_modu
+0002b5c0: 6c65 5f6f 705f 7374 6174 7328 6d6f 6475  le_op_stats(modu
+0002b5d0: 6c65 2c20 7475 6e65 5f63 6667 2c20 6170  le, tune_cfg, ap
+0002b5e0: 7072 6f61 6368 290a 2020 2020 2020 2020  proach).        
+0002b5f0: 2020 2020 2020 2020 666f 7220 6b65 792c          for key,
+0002b600: 2076 616c 7565 2069 6e20 6d6f 6475 6c65   value in module
+0002b610: 5f72 6573 2e69 7465 6d73 2829 3a0a 2020  _res.items():.  
+0002b620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002b630: 2020 6966 206b 6579 2069 6e20 7265 733a    if key in res:
+0002b640: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002b650: 2020 2020 2020 2020 2072 6573 5b6b 6579           res[key
+0002b660: 5d20 3d20 7b6b 3a20 7265 735b 6b65 795d  ] = {k: res[key]
+0002b670: 5b6b 5d20 2b20 7620 666f 7220 6b2c 2076  [k] + v for k, v
+0002b680: 2069 6e20 7661 6c75 652e 6974 656d 7328   in value.items(
+0002b690: 297d 0a20 2020 2020 2020 2020 2020 2020  )}.             
+0002b6a0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0002b6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002b6c0: 2020 2020 2072 6573 5b6b 6579 5d20 3d20       res[key] = 
+0002b6d0: 7661 6c75 650a 2020 2020 2020 2020 2020  value.          
+0002b6e0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0002b6f0: 2020 2020 2020 2020 7365 6c66 2e5f 6765          self._ge
+0002b700: 745f 7375 625f 6d6f 6475 6c65 5f6f 705f  t_sub_module_op_
+0002b710: 7374 6174 7328 6d6f 6475 6c65 2c20 7475  stats(module, tu
+0002b720: 6e65 5f63 6667 2c20 6170 7072 6f61 6368  ne_cfg, approach
+0002b730: 2c20 7265 732c 206f 705f 6e61 6d65 290a  , res, op_name).
+0002b740: 0a20 2020 2064 6566 205f 6475 6d70 5f6d  .    def _dump_m
+0002b750: 6f64 656c 5f6f 705f 7374 6174 7328 7365  odel_op_stats(se
+0002b760: 6c66 2c20 6d6f 6465 6c2c 2074 756e 655f  lf, model, tune_
+0002b770: 6366 672c 2061 7070 726f 6163 6829 3a0a  cfg, approach):.
+0002b780: 2020 2020 2020 2020 2222 2254 6869 7320          """This 
+0002b790: 6973 2061 2066 756e 6374 696f 6e20 746f  is a function to
+0002b7a0: 2064 756d 7020 7175 616e 7469 7a61 626c   dump quantizabl
+0002b7b0: 6520 6f70 7320 6f66 206d 6f64 656c 2074  e ops of model t
+0002b7c0: 6f20 7573 6572 2e0a 2020 2020 2020 2020  o user..        
+0002b7d0: 4172 6773 3a0a 2020 2020 2020 2020 2020  Args:.          
+0002b7e0: 2020 6d6f 6465 6c20 286f 626a 6563 7429    model (object)
+0002b7f0: 3a20 696e 7075 7420 6d6f 6465 6c0a 2020  : input model.  
+0002b800: 2020 2020 2020 2020 2020 7475 6e65 5f63            tune_c
+0002b810: 6667 2028 6469 6374 293a 2071 7561 6e74  fg (dict): quant
+0002b820: 697a 6174 696f 6e20 636f 6e66 6967 0a20  ization config. 
+0002b830: 2020 2020 2020 2020 2020 2061 7070 726f             appro
+0002b840: 6163 6820 2873 7472 293a 2071 7561 6e74  ach (str): quant
+0002b850: 697a 6174 696f 6e20 6170 7072 6f61 6368  ization approach
+0002b860: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
+0002b870: 3a0a 2020 2020 2020 2020 2020 2020 4e6f  :.            No
+0002b880: 6e65 0a20 2020 2020 2020 2022 2222 0a20  ne.        """. 
+0002b890: 2020 2020 2020 2069 6620 7365 6c66 2e73         if self.s
+0002b8a0: 7562 5f6d 6f64 756c 655f 6c69 7374 2069  ub_module_list i
+0002b8b0: 7320 4e6f 6e65 206f 7220 5c0a 2020 2020  s None or \.    
+0002b8c0: 2020 2020 2020 7365 6c66 2e61 7070 726f        self.appro
+0002b8d0: 6163 6820 3d3d 2027 706f 7374 5f74 7261  ach == 'post_tra
+0002b8e0: 696e 696e 675f 6479 6e61 6d69 635f 7175  ining_dynamic_qu
+0002b8f0: 616e 7427 3a0a 2020 2020 2020 2020 2020  ant':.          
+0002b900: 2020 7265 7320 3d20 7365 6c66 2e5f 6765    res = self._ge
+0002b910: 745f 6d6f 6475 6c65 5f6f 705f 7374 6174  t_module_op_stat
+0002b920: 7328 6d6f 6465 6c2c 2074 756e 655f 6366  s(model, tune_cf
+0002b930: 672c 2061 7070 726f 6163 6829 0a20 2020  g, approach).   
+0002b940: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0002b950: 2020 2020 2020 2072 6573 203d 2064 6963         res = dic
+0002b960: 7428 290a 2020 2020 2020 2020 2020 2020  t().            
+0002b970: 7365 6c66 2e5f 6765 745f 7375 625f 6d6f  self._get_sub_mo
+0002b980: 6475 6c65 5f6f 705f 7374 6174 7328 6d6f  dule_op_stats(mo
+0002b990: 6465 6c2c 2074 756e 655f 6366 672c 2061  del, tune_cfg, a
+0002b9a0: 7070 726f 6163 682c 2072 6573 290a 0a20  pproach, res).. 
+0002b9b0: 2020 2020 2020 2069 6620 7365 6c66 2e75         if self.u
+0002b9c0: 7365 5f62 6631 3620 616e 6420 2873 656c  se_bf16 and (sel
+0002b9d0: 662e 7665 7273 696f 6e2e 7265 6c65 6173  f.version.releas
+0002b9e0: 6520 3e3d 2056 6572 7369 6f6e 2822 312e  e >= Version("1.
+0002b9f0: 3131 2e30 2229 2e72 656c 6561 7365 2920  11.0").release) 
+0002ba00: 616e 6420 5c0a 2020 2020 2020 2020 2020  and \.          
+0002ba10: 2020 2843 7075 496e 666f 2829 2e62 6631    (CpuInfo().bf1
+0002ba20: 3620 6f72 206f 732e 6765 7465 6e76 2827  6 or os.getenv('
+0002ba30: 464f 5243 455f 4246 3136 2729 203d 3d20  FORCE_BF16') == 
+0002ba40: 2731 2729 3a20 2320 7072 6167 6d61 3a20  '1'): # pragma: 
+0002ba50: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
+0002ba60: 2020 2020 2062 6631 365f 6f70 735f 6c69       bf16_ops_li
+0002ba70: 7374 203d 2074 756e 655f 6366 675b 2762  st = tune_cfg['b
+0002ba80: 6631 365f 6f70 735f 6c69 7374 275d 0a20  f16_ops_list']. 
+0002ba90: 2020 2020 2020 2020 2020 2069 6620 6c65             if le
+0002baa0: 6e28 6266 3136 5f6f 7073 5f6c 6973 7429  n(bf16_ops_list)
+0002bab0: 203e 2030 3a0a 2020 2020 2020 2020 2020   > 0:.          
+0002bac0: 2020 2020 2020 666f 7220 6266 3136 5f6f        for bf16_o
+0002bad0: 7020 696e 2062 6631 365f 6f70 735f 6c69  p in bf16_ops_li
+0002bae0: 7374 3a0a 2020 2020 2020 2020 2020 2020  st:.            
+0002baf0: 2020 2020 2020 2020 6f70 5f74 7970 6520          op_type 
+0002bb00: 3d20 6266 3136 5f6f 705b 315d 0a20 2020  = bf16_op[1].   
 0002bb10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002bb20: 2320 7079 6c69 6e74 3a20 6469 7361 626c  # pylint: disabl
-0002bb30: 653d 4531 3132 342c 2045 3131 3233 0a20  e=E1124, E1123. 
-0002bb40: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0002bb50: 7573 6564 5f6d 6f64 656c 203d 205f 6675  used_model = _fu
-0002bb60: 7365 5f66 7828 6772 6170 685f 6d6f 6475  se_fx(graph_modu
-0002bb70: 6c65 2c0a 2020 2020 2020 2020 2020 2020  le,.            
-0002bb80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002bb90: 2020 2020 2020 2020 2020 2020 6973 5f71              is_q
-0002bba0: 6174 2c0a 2020 2020 2020 2020 2020 2020  at,.            
-0002bbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002bbc0: 2020 2020 2020 2020 2020 2020 6675 7365              fuse
-0002bbd0: 5f63 7573 746f 6d5f 636f 6e66 6967 3d70  _custom_config=p
-0002bbe0: 7265 7061 7265 5f63 7573 746f 6d5f 636f  repare_custom_co
-0002bbf0: 6e66 6967 5f64 6963 7429 0a20 2020 2020  nfig_dict).     
-0002bc00: 2020 2020 2020 2065 6c69 6620 7365 6c66         elif self
-0002bc10: 2e76 6572 7369 6f6e 2e72 656c 6561 7365  .version.release
-0002bc20: 203e 3d20 5665 7273 696f 6e28 2231 2e31   >= Version("1.1
-0002bc30: 312e 3022 292e 7265 6c65 6173 653a 2020  1.0").release:  
-0002bc40: 2320 7072 6167 6d61 3a20 6e6f 2063 6f76  # pragma: no cov
-0002bc50: 6572 0a20 2020 2020 2020 2020 2020 2020  er.             
-0002bc60: 2020 2023 2070 796c 696e 743a 2064 6973     # pylint: dis
-0002bc70: 6162 6c65 3d45 3131 3234 0a20 2020 2020  able=E1124.     
-0002bc80: 2020 2020 2020 2020 2020 2066 7573 6564             fused
-0002bc90: 5f6d 6f64 656c 203d 205f 6675 7365 5f66  _model = _fuse_f
-0002bca0: 7828 6772 6170 685f 6d6f 6475 6c65 2c0a  x(graph_module,.
-0002bcb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002bcc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002bcd0: 2020 2020 2020 2020 6973 5f71 6174 2c0a          is_qat,.
-0002bce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002bcf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002bd00: 2020 2020 2020 2020 6675 7365 5f63 7573          fuse_cus
-0002bd10: 746f 6d5f 636f 6e66 6967 5f64 6963 743d  tom_config_dict=
-0002bd20: 7072 6570 6172 655f 6375 7374 6f6d 5f63  prepare_custom_c
-0002bd30: 6f6e 6669 675f 6469 6374 290a 2020 2020  onfig_dict).    
-0002bd40: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0002bd50: 2020 2020 2020 2020 2020 2020 2020 6675                fu
-0002bd60: 7365 645f 6d6f 6465 6c20 3d20 5f66 7573  sed_model = _fus
-0002bd70: 655f 6678 2867 7261 7068 5f6d 6f64 756c  e_fx(graph_modul
-0002bd80: 652c 2070 7265 7061 7265 5f63 7573 746f  e, prepare_custo
-0002bd90: 6d5f 636f 6e66 6967 5f64 6963 7429 0a20  m_config_dict). 
-0002bda0: 2020 2020 2020 2065 7863 6570 743a 0a20         except:. 
-0002bdb0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0002bdc0: 7375 625f 6d6f 6475 6c65 5f6c 6973 7420  sub_module_list 
-0002bdd0: 3d20 5b5d 0a20 2020 2020 2020 2020 2020  = [].           
-0002bde0: 206d 6f64 756c 655f 6469 6374 203d 2064   module_dict = d
-0002bdf0: 6963 7428 746d 705f 6d6f 6465 6c2e 6e61  ict(tmp_model.na
-0002be00: 6d65 645f 6d6f 6475 6c65 7328 2929 0a20  med_modules()). 
-0002be10: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0002be20: 5f66 7573 655f 7375 625f 6772 6170 6828  _fuse_sub_graph(
-0002be30: 746d 705f 6d6f 6465 6c2c 206d 6f64 756c  tmp_model, modul
-0002be40: 655f 6469 6374 2c20 7072 6566 6978 3d27  e_dict, prefix='
-0002be50: 272c 2069 735f 7161 743d 6973 5f71 6174  ', is_qat=is_qat
-0002be60: 290a 2020 2020 2020 2020 2020 2020 6675  ).            fu
-0002be70: 7365 645f 6d6f 6465 6c20 3d20 746d 705f  sed_model = tmp_
-0002be80: 6d6f 6465 6c0a 2020 2020 2020 2020 7265  model.        re
-0002be90: 7475 726e 2066 7573 6564 5f6d 6f64 656c  turn fused_model
-0002bea0: 0a0a 2020 2020 6465 6620 5f66 7573 655f  ..    def _fuse_
-0002beb0: 7375 625f 6772 6170 6828 7365 6c66 2c20  sub_graph(self, 
-0002bec0: 6d6f 6465 6c2c 206d 6f64 756c 655f 6469  model, module_di
-0002bed0: 6374 2c20 7072 6566 6978 2c20 6973 5f71  ct, prefix, is_q
-0002bee0: 6174 293a 0a20 2020 2020 2020 2022 2222  at):.        """
-0002bef0: 5468 6973 2069 7320 6120 6865 6c70 6572  This is a helper
-0002bf00: 2066 756e 6374 696f 6e20 746f 2067 6574   function to get
-0002bf10: 2066 7573 6564 2066 7820 7375 6220 6d6f   fused fx sub mo
-0002bf20: 6475 6c65 7320 7265 6375 7273 6976 656c  dules recursivel
-0002bf30: 7920 666f 7220 5079 546f 7263 685f 4658  y for PyTorch_FX
-0002bf40: 4164 6170 746f 722e 0a0a 2020 2020 2020  Adaptor...      
-0002bf50: 2020 4172 6773 3a0a 2020 2020 2020 2020    Args:.        
-0002bf60: 2020 2020 6d6f 6465 6c20 286f 626a 6563      model (objec
-0002bf70: 7429 3a20 696e 7075 7420 6d6f 6465 6c20  t): input model 
-0002bf80: 7768 6963 6820 6973 2050 7954 6f72 6368  which is PyTorch
-0002bf90: 206d 6f64 656c 2e0a 2020 2020 2020 2020   model..        
-0002bfa0: 2020 2020 6d6f 6475 6c65 5f64 6963 7420      module_dict 
-0002bfb0: 2864 6963 7429 3a20 6d6f 6475 6c65 2064  (dict): module d
-0002bfc0: 6963 7420 6f66 2069 6e70 7574 206d 6f64  ict of input mod
-0002bfd0: 656c 2e0a 2020 2020 2020 2020 2020 2020  el..            
-0002bfe0: 7072 6566 6978 2028 7374 7269 6e67 293a  prefix (string):
-0002bff0: 2070 7265 6669 7820 6f66 206f 7020 6e61   prefix of op na
-0002c000: 6d65 2e0a 2020 2020 2020 2020 2020 2020  me..            
-0002c010: 6973 5f71 6174 2028 626f 6f6c 293a 2063  is_qat (bool): c
-0002c020: 6865 636b 2071 7561 6e74 697a 6174 696f  heck quantizatio
-0002c030: 6e20 6170 7072 6f61 6368 2069 7320 7161  n approach is qa
-0002c040: 7420 6f72 206e 6f74 2e0a 0a20 2020 2020  t or not...     
-0002c050: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
-0002c060: 2020 2020 2020 2020 6675 7365 645f 6d6f          fused_mo
-0002c070: 6465 6c20 2847 7261 7068 4d6f 6475 6c65  del (GraphModule
-0002c080: 293a 2066 7573 6564 2047 7261 7068 4d6f  ): fused GraphMo
-0002c090: 6475 6c65 206d 6f64 656c 2066 726f 6d20  dule model from 
-0002c0a0: 746f 7263 682e 6678 2e0a 2020 2020 2020  torch.fx..      
-0002c0b0: 2020 2222 220a 2020 2020 2020 2020 6672    """.        fr
-0002c0c0: 6f6d 2074 6f72 6368 2e71 7561 6e74 697a  om torch.quantiz
-0002c0d0: 6174 696f 6e2e 7175 616e 7469 7a65 5f66  ation.quantize_f
-0002c0e0: 7820 696d 706f 7274 205f 6675 7365 5f66  x import _fuse_f
-0002c0f0: 780a 2020 2020 2020 2020 696d 706f 7274  x.        import
-0002c100: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
-0002c110: 696f 6e2e 7175 616e 7469 7a61 7469 6f6e  ion.quantization
-0002c120: 5f6d 6170 7069 6e67 7320 6173 2074 7171  _mappings as tqq
-0002c130: 6d0a 2020 2020 2020 2020 6678 5f77 6869  m.        fx_whi
-0002c140: 7465 5f6c 6973 7420 3d20 7471 716d 2e67  te_list = tqqm.g
-0002c150: 6574 5f64 6566 6175 6c74 5f71 636f 6e66  et_default_qconf
-0002c160: 6967 5f70 726f 7061 6761 7469 6f6e 5f6c  ig_propagation_l
-0002c170: 6973 7428 290a 2020 2020 2020 2020 666f  ist().        fo
-0002c180: 7220 6e61 6d65 2c20 6d6f 6475 6c65 2069  r name, module i
-0002c190: 6e20 6d6f 6465 6c2e 6e61 6d65 645f 6368  n model.named_ch
-0002c1a0: 696c 6472 656e 2829 3a0a 2020 2020 2020  ildren():.      
-0002c1b0: 2020 2020 2020 2320 4658 2051 4154 2063        # FX QAT c
-0002c1c0: 616e 6e6f 7420 6661 6c6c 6261 636b 206e  annot fallback n
-0002c1d0: 6e2e 4472 6f70 6f75 7420 6672 6f6d 2074  n.Dropout from t
-0002c1e0: 7261 696e 206d 6f64 6520 746f 2065 7661  rain mode to eva
-0002c1f0: 6c0a 2020 2020 2020 2020 2020 2020 6966  l.            if
-0002c200: 2074 7970 6528 6d6f 6475 6c65 2920 3d3d   type(module) ==
-0002c210: 2074 6f72 6368 2e6e 6e2e 4472 6f70 6f75   torch.nn.Dropou
-0002c220: 743a 2020 2320 7072 6167 6d61 3a20 6e6f  t:  # pragma: no
-0002c230: 2063 6f76 6572 0a20 2020 2020 2020 2020   cover.         
-0002c240: 2020 2020 2020 2063 6f6e 7469 6e75 650a         continue.
-0002c250: 2020 2020 2020 2020 2020 2020 6f70 5f6e              op_n
-0002c260: 616d 6520 3d20 7072 6566 6978 202b 2027  ame = prefix + '
-0002c270: 2e27 202b 206e 616d 6520 6966 2070 7265  .' + name if pre
-0002c280: 6669 7820 213d 2027 2720 656c 7365 206e  fix != '' else n
-0002c290: 616d 650a 2020 2020 2020 2020 2020 2020  ame.            
-0002c2a0: 6966 206f 705f 6e61 6d65 206e 6f74 2069  if op_name not i
-0002c2b0: 6e20 6d6f 6475 6c65 5f64 6963 743a 0a20  n module_dict:. 
-0002c2c0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-0002c2d0: 6f6e 7469 6e75 650a 2020 2020 2020 2020  ontinue.        
-0002c2e0: 2020 2020 6966 2074 7970 6528 6d6f 6475      if type(modu
-0002c2f0: 6c65 2920 696e 2066 785f 7768 6974 655f  le) in fx_white_
-0002c300: 6c69 7374 205c 0a20 2020 2020 2020 2020  list \.         
-0002c310: 2020 2020 2061 6e64 2074 7970 6528 6d6f       and type(mo
-0002c320: 6475 6c65 2920 213d 2074 6f72 6368 2e6e  dule) != torch.n
-0002c330: 6e2e 5365 7175 656e 7469 616c 3a0a 2020  n.Sequential:.  
-0002c340: 2020 2020 2020 2020 2020 2020 2020 6d6f                mo
-0002c350: 6475 6c65 203d 2074 6f72 6368 2e71 7561  dule = torch.qua
-0002c360: 6e74 697a 6174 696f 6e2e 5175 616e 7457  ntization.QuantW
-0002c370: 7261 7070 6572 286d 6f64 756c 6529 0a20  rapper(module). 
-0002c380: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-0002c390: 6c66 2e5f 6368 6563 6b5f 6479 6e61 6d69  lf._check_dynami
-0002c3a0: 635f 636f 6e74 726f 6c28 6d6f 6475 6c65  c_control(module
-0002c3b0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0002c3c0: 2020 2073 656c 662e 5f66 7573 655f 7375     self._fuse_su
-0002c3d0: 625f 6772 6170 6828 6d6f 6475 6c65 2c20  b_graph(module, 
-0002c3e0: 6d6f 6475 6c65 5f64 6963 742c 206f 705f  module_dict, op_
-0002c3f0: 6e61 6d65 2c20 6973 5f71 6174 3d69 735f  name, is_qat=is_
-0002c400: 7161 7429 0a20 2020 2020 2020 2020 2020  qat).           
-0002c410: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-0002c420: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0002c430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002c440: 6772 6170 685f 6d6f 6475 6c65 203d 2074  graph_module = t
-0002c450: 6f72 6368 2e66 782e 7379 6d62 6f6c 6963  orch.fx.symbolic
-0002c460: 5f74 7261 6365 286d 6f64 756c 6529 0a20  _trace(module). 
-0002c470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002c480: 2020 2069 6620 7365 6c66 2e76 6572 7369     if self.versi
-0002c490: 6f6e 2e72 656c 6561 7365 203e 3d20 5665  on.release >= Ve
-0002c4a0: 7273 696f 6e28 2231 2e31 312e 3022 292e  rsion("1.11.0").
-0002c4b0: 7265 6c65 6173 653a 2020 2320 7072 6167  release:  # prag
-0002c4c0: 6d61 3a20 6e6f 2063 6f76 6572 0a20 2020  ma: no cover.   
-0002c4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002c4e0: 2020 2020 2066 7573 6564 5f6d 6f64 656c       fused_model
-0002c4f0: 203d 205f 6675 7365 5f66 7828 6772 6170   = _fuse_fx(grap
-0002c500: 685f 6d6f 6475 6c65 2c20 6973 5f71 6174  h_module, is_qat
-0002c510: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-0002c520: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-0002c530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002c540: 2020 2020 6675 7365 645f 6d6f 6465 6c20      fused_model 
-0002c550: 3d20 5f66 7573 655f 6678 2867 7261 7068  = _fuse_fx(graph
-0002c560: 5f6d 6f64 756c 6529 2020 2320 7079 6c69  _module)  # pyli
-0002c570: 6e74 3a20 6469 7361 626c 653d 4531 3132  nt: disable=E112
-0002c580: 300a 2020 2020 2020 2020 2020 2020 2020  0.              
-0002c590: 2020 2020 2020 7365 7461 7474 7228 6d6f        setattr(mo
-0002c5a0: 6465 6c2c 206e 616d 652c 2066 7573 6564  del, name, fused
-0002c5b0: 5f6d 6f64 656c 290a 2020 2020 2020 2020  _model).        
-0002c5c0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0002c5d0: 2e73 7562 5f6d 6f64 756c 655f 6c69 7374  .sub_module_list
-0002c5e0: 2e61 7070 656e 6428 6f70 5f6e 616d 6529  .append(op_name)
-0002c5f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0002c600: 2065 7863 6570 743a 0a20 2020 2020 2020   except:.       
-0002c610: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-0002c620: 662e 5f66 7573 655f 7375 625f 6772 6170  f._fuse_sub_grap
-0002c630: 6828 6d6f 6475 6c65 2c20 6d6f 6475 6c65  h(module, module
-0002c640: 5f64 6963 742c 206f 705f 6e61 6d65 2c20  _dict, op_name, 
-0002c650: 6973 5f71 6174 290a 0a20 2020 2040 7374  is_qat)..    @st
-0002c660: 6174 6963 6d65 7468 6f64 0a20 2020 2064  aticmethod.    d
-0002c670: 6566 205f 6368 6563 6b5f 6479 6e61 6d69  ef _check_dynami
-0002c680: 635f 636f 6e74 726f 6c28 6d6f 6475 6c65  c_control(module
-0002c690: 293a 0a20 2020 2020 2020 2022 2222 5468  ):.        """Th
-0002c6a0: 6973 2069 7320 6120 6865 6c70 6572 2066  is is a helper f
-0002c6b0: 756e 6374 696f 6e20 746f 2063 6865 636b  unction to check
-0002c6c0: 2064 796e 616d 6963 2063 6f6e 7472 6f6c   dynamic control
-0002c6d0: 2069 6e20 666f 7277 6172 6420 6675 6e63   in forward func
-0002c6e0: 7469 6f6e 206f 6620 6d6f 6475 6c65 2e0a  tion of module..
-0002c6f0: 0a20 2020 2020 2020 2041 7267 733a 0a20  .        Args:. 
-0002c700: 2020 2020 2020 2020 2020 206d 6f64 756c             modul
-0002c710: 6520 286f 626a 6563 7429 3a20 696e 7075  e (object): inpu
-0002c720: 7420 6d6f 6475 6c65 2077 6869 6368 2069  t module which i
-0002c730: 7320 5079 546f 7263 6820 4d6f 6475 6c65  s PyTorch Module
-0002c740: 2e0a 0a20 2020 2020 2020 2052 6574 7572  ...        Retur
-0002c750: 6e73 3a0a 2020 2020 2020 2020 2020 2020  ns:.            
-0002c760: 6675 7365 645f 6d6f 6465 6c20 2847 7261  fused_model (Gra
-0002c770: 7068 4d6f 6475 6c65 293a 2066 7573 6564  phModule): fused
-0002c780: 2047 7261 7068 4d6f 6475 6c65 206d 6f64   GraphModule mod
-0002c790: 656c 2066 726f 6d20 746f 7263 682e 6678  el from torch.fx
-0002c7a0: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
-0002c7b0: 2020 2020 2020 696d 706f 7274 2069 6e73        import ins
-0002c7c0: 7065 6374 0a20 2020 2020 2020 2069 6d70  pect.        imp
-0002c7d0: 6f72 7420 7265 0a20 2020 2020 2020 2074  ort re.        t
-0002c7e0: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
-0002c7f0: 6c69 6e65 7320 3d20 696e 7370 6563 742e  lines = inspect.
-0002c800: 6765 7473 6f75 7263 6528 6d6f 6475 6c65  getsource(module
-0002c810: 2e66 6f72 7761 7264 290a 2020 2020 2020  .forward).      
-0002c820: 2020 2020 2020 2320 5072 6f78 7920 6f62        # Proxy ob
-0002c830: 6a2e 2077 696c 6c20 616c 7761 7973 2062  j. will always b
-0002c840: 6520 6465 7465 6374 6420 6173 2060 6e6f  e detectd as `no
-0002c850: 7420 4e6f 6e65 602e 0a20 2020 2020 2020  t None`..       
-0002c860: 2020 2020 2023 204f 7468 6572 2073 6974       # Other sit
-0002c870: 7561 7469 6f6e 7320 636f 756c 6420 6265  uations could be
-0002c880: 2064 6574 6563 7465 6420 6279 2070 7265   detected by pre
-0002c890: 7061 7265 5f66 7820 6675 6e63 7469 6f6e  pare_fx function
-0002c8a0: 2e0a 2020 2020 2020 2020 2020 2020 7061  ..            pa
-0002c8b0: 7474 6572 6e20 3d20 2269 7328 206e 6f74  ttern = "is( not
-0002c8c0: 293f 204e 6f6e 6522 0a20 2020 2020 2020  )? None".       
-0002c8d0: 2020 2020 2061 6e77 7320 3d20 7265 2e73       anws = re.s
-0002c8e0: 6561 7263 6828 7061 7474 6572 6e2c 206c  earch(pattern, l
-0002c8f0: 696e 6573 290a 2020 2020 2020 2020 2020  ines).          
-0002c900: 2020 6966 2061 6e77 733a 0a20 2020 2020    if anws:.     
-0002c910: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0002c920: 6e20 5472 7565 0a20 2020 2020 2020 2065  n True.        e
-0002c930: 7863 6570 743a 2020 2320 7072 6167 6d61  xcept:  # pragma
-0002c940: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
-0002c950: 2020 2020 2020 206c 6f67 6765 722e 696e         logger.in
-0002c960: 666f 2827 4d6f 6475 6c65 2068 6173 206e  fo('Module has n
-0002c970: 6f20 666f 7277 6172 6420 6675 6e63 7469  o forward functi
-0002c980: 6f6e 2729 0a20 2020 2020 2020 2072 6574  on').        ret
-0002c990: 7572 6e20 4661 6c73 650a 0a20 2020 2064  urn False..    d
-0002c9a0: 6566 2067 6574 5f6f 7574 7075 745f 6f70  ef get_output_op
-0002c9b0: 5f6e 616d 6573 2873 656c 662c 202a 6172  _names(self, *ar
-0002c9c0: 6773 2c20 2a2a 6b77 6172 6773 293a 0a20  gs, **kwargs):. 
-0002c9d0: 2020 2020 2020 2072 6574 7572 6e20 4e6f         return No
-0002c9e0: 6e65 0a0a 2020 2020 6465 6620 6361 6c63  ne..    def calc
-0002c9f0: 756c 6174 655f 6f70 5f73 656e 7369 7469  ulate_op_sensiti
-0002ca00: 7669 7479 2873 656c 662c 206d 6f64 656c  vity(self, model
-0002ca10: 2c20 6461 7461 6c6f 6164 6572 2c20 7475  , dataloader, tu
-0002ca20: 6e65 5f63 6667 2c20 6f75 7470 7574 5f6f  ne_cfg, output_o
-0002ca30: 705f 6e61 6d65 732c 0a20 2020 2020 2020  p_names,.       
-0002ca40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002ca50: 2020 2020 2020 2020 2020 636f 6e66 6964            confid
-0002ca60: 656e 6365 5f62 6174 6368 6573 2c20 6661  ence_batches, fa
-0002ca70: 6c6c 6261 636b 3d54 7275 652c 2072 6571  llback=True, req
-0002ca80: 7561 6e74 697a 655f 6366 6773 3d4e 6f6e  uantize_cfgs=Non
-0002ca90: 6529 3a0a 2020 2020 2020 2020 2222 2254  e):.        """T
-0002caa0: 6869 7320 6973 2061 2068 656c 7065 7220  his is a helper 
-0002cab0: 6675 6e63 7469 6f6e 2066 6f72 2060 7175  function for `qu
-0002cac0: 6572 795f 6677 5f63 6170 6162 696c 6974  ery_fw_capabilit
-0002cad0: 7960 2c0a 2020 2020 2020 2020 2020 2061  y`,.           a
-0002cae0: 6e64 2069 7420 7769 6c6c 2067 6574 2061  nd it will get a
-0002caf0: 6c6c 2071 7561 6e74 697a 6162 6c65 206f  ll quantizable o
-0002cb00: 7073 2066 726f 6d20 6d6f 6465 6c2e 0a0a  ps from model...
-0002cb10: 2020 2020 2020 2020 4172 6773 3a0a 2020          Args:.  
-0002cb20: 2020 2020 2020 2020 2020 6d6f 6465 6c20            model 
-0002cb30: 286f 626a 6563 7429 3a20 494e 4320 6d6f  (object): INC mo
-0002cb40: 6465 6c20 636f 6e74 6169 6e69 6e67 2066  del containing f
-0002cb50: 7033 3220 6d6f 6465 6c0a 2020 2020 2020  p32 model.      
-0002cb60: 2020 2020 2020 6461 7461 6c6f 6164 6572        dataloader
-0002cb70: 2028 7374 7269 6e67 293a 2064 6174 616c   (string): datal
-0002cb80: 6f61 6465 7220 636f 6e74 6169 6e73 2072  oader contains r
-0002cb90: 6561 6c20 6461 7461 2e0a 2020 2020 2020  eal data..      
-0002cba0: 2020 2020 2020 7475 6e65 5f63 6667 2028        tune_cfg (
-0002cbb0: 6469 6374 293a 2064 6963 7469 6f6e 6172  dict): dictionar
-0002cbc0: 7920 6f66 2074 756e 6520 636f 6e66 6967  y of tune config
-0002cbd0: 7572 6520 666f 7220 6561 6368 206f 702e  ure for each op.
-0002cbe0: 0a20 2020 2020 2020 2020 2020 2066 616c  .            fal
-0002cbf0: 6c62 6163 6b20 2862 6f6f 6c29 3a20 7377  lback (bool): sw
-0002cc00: 6974 6368 206d 6574 686f 6420 696e 2066  itch method in f
-0002cc10: 616c 6c62 6163 6b20 7374 6167 6520 616e  allback stage an
-0002cc20: 6420 7265 2d71 7561 6e74 697a 6520 7374  d re-quantize st
-0002cc30: 6167 650a 0a20 2020 2020 2020 2052 6574  age..        Ret
-0002cc40: 7572 6e73 3a0a 2020 2020 2020 2020 2020  urns:.          
-0002cc50: 2020 6f70 735f 6c73 7420 286c 6973 7429    ops_lst (list)
-0002cc60: 3a20 736f 7274 6564 206f 7020 6c69 7374  : sorted op list
-0002cc70: 2062 7920 7365 6e73 6974 6976 6974 790a   by sensitivity.
-0002cc80: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-0002cc90: 2020 2020 6672 6f6d 202e 746f 7263 685f      from .torch_
-0002cca0: 7574 696c 732e 7574 696c 2069 6d70 6f72  utils.util impor
-0002ccb0: 7420 6765 745f 6661 6c6c 6261 636b 5f6f  t get_fallback_o
-0002ccc0: 7264 6572 0a20 2020 2020 2020 206f 7264  rder.        ord
-0002ccd0: 6572 6564 5f6f 7073 203d 2067 6574 5f66  ered_ops = get_f
-0002cce0: 616c 6c62 6163 6b5f 6f72 6465 7228 7365  allback_order(se
-0002ccf0: 6c66 2c20 6d6f 6465 6c2e 6d6f 6465 6c2c  lf, model.model,
-0002cd00: 2064 6174 616c 6f61 6465 722c 2074 756e   dataloader, tun
-0002cd10: 655f 6366 672c 0a20 2020 2020 2020 2020  e_cfg,.         
-0002cd20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002cd30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002cd40: 636f 6e66 6964 656e 6365 5f62 6174 6368  confidence_batch
-0002cd50: 6573 2c20 6661 6c6c 6261 636b 2c20 7265  es, fallback, re
-0002cd60: 7175 616e 7469 7a65 5f63 6667 7329 0a20  quantize_cfgs). 
-0002cd70: 2020 2020 2020 2072 6574 7572 6e20 6f72         return or
-0002cd80: 6465 7265 645f 6f70 730a 0a0a 636c 6173  dered_ops...clas
-0002cd90: 7320 5079 546f 7263 6851 7565 7279 2851  s PyTorchQuery(Q
-0002cda0: 7565 7279 4261 636b 656e 6443 6170 6162  ueryBackendCapab
-0002cdb0: 696c 6974 7929 3a0a 2020 2020 6465 6620  ility):.    def 
-0002cdc0: 5f5f 696e 6974 5f5f 2873 656c 662c 206c  __init__(self, l
-0002cdd0: 6f63 616c 5f63 6f6e 6669 675f 6669 6c65  ocal_config_file
-0002cde0: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
-0002cdf0: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
-0002ce00: 2829 0a20 2020 2020 2020 2073 656c 662e  ().        self.
-0002ce10: 7665 7273 696f 6e20 3d20 6765 745f 746f  version = get_to
-0002ce20: 7263 685f 7665 7273 696f 6e28 290a 2020  rch_version().  
-0002ce30: 2020 2020 2020 7365 6c66 2e63 6667 203d        self.cfg =
-0002ce40: 206c 6f63 616c 5f63 6f6e 6669 675f 6669   local_config_fi
-0002ce50: 6c65 0a20 2020 2020 2020 2073 656c 662e  le.        self.
-0002ce60: 6375 725f 636f 6e66 6967 203d 204e 6f6e  cur_config = Non
-0002ce70: 650a 2020 2020 2020 2020 7365 6c66 2e5f  e.        self._
-0002ce80: 6f6e 655f 7368 6f74 5f71 7565 7279 2829  one_shot_query()
-0002ce90: 0a0a 2020 2020 6465 6620 5f67 6574 5f73  ..    def _get_s
-0002cea0: 7065 6369 6669 6564 5f76 6572 7369 6f6e  pecified_version
-0002ceb0: 5f63 6667 2873 656c 662c 2064 6174 6129  _cfg(self, data)
-0002cec0: 3a0a 2020 2020 2020 2020 2222 2247 6574  :.        """Get
-0002ced0: 2074 6865 2063 6f6e 6669 6775 7261 7469   the configurati
-0002cee0: 6f6e 2066 6f72 2074 6865 2063 7572 7265  on for the curre
-0002cef0: 6e74 2072 756e 7469 6d65 2e0a 2020 2020  nt runtime..    
-0002cf00: 2020 2020 4966 2074 6865 7265 2773 206e      If there's n
-0002cf10: 6f20 6d61 7463 6865 6420 636f 6e66 6967  o matched config
-0002cf20: 7572 6174 696f 6e20 696e 2074 6865 2069  uration in the i
-0002cf30: 6e70 7574 2079 616d 6c2c 2077 6527 6c6c  nput yaml, we'll
-0002cf40: 0a20 2020 2020 2020 2075 7365 2074 6865  .        use the
-0002cf50: 2060 6465 6661 756c 7460 2066 6965 6c64   `default` field
-0002cf60: 206f 6620 7961 6d6c 2e0a 0a20 2020 2020   of yaml...     
-0002cf70: 2020 2041 7267 733a 0a20 2020 2020 2020     Args:.       
-0002cf80: 2020 2020 2064 6174 6120 2859 616d 6c20       data (Yaml 
-0002cf90: 636f 6e74 656e 7429 3a20 696e 7075 7420  content): input 
-0002cfa0: 7961 6d6c 2066 696c 652e 0a0a 2020 2020  yaml file...    
-0002cfb0: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
-0002cfc0: 2020 2020 2020 2020 205b 6469 6374 696f           [dictio
-0002cfd0: 6e61 7279 5d3a 2074 6865 2063 6f6e 7465  nary]: the conte
-0002cfe0: 6e74 2066 6f72 2073 7065 6369 6669 6320  nt for specific 
-0002cff0: 7665 7273 696f 6e2e 0a20 2020 2020 2020  version..       
-0002d000: 2022 2222 0a20 2020 2020 2020 2023 2064   """.        # d
-0002d010: 6566 6175 6c74 5f63 6f6e 6669 6720 3d20  efault_config = 
-0002d020: 4e6f 6e65 0a20 2020 2020 2020 2066 6f72  None.        for
-0002d030: 2073 7562 5f64 6174 6120 696e 2064 6174   sub_data in dat
-0002d040: 613a 0a20 2020 2020 2020 2020 2020 2069  a:.            i
-0002d050: 6620 7375 625f 6461 7461 5b27 7665 7273  f sub_data['vers
-0002d060: 696f 6e27 5d5b 276e 616d 6527 5d20 3d3d  ion']['name'] ==
-0002d070: 2027 6465 6661 756c 7427 3a0a 2020 2020   'default':.    
-0002d080: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0002d090: 726e 2073 7562 5f64 6174 610a 2020 2020  rn sub_data.    
-0002d0a0: 2020 2020 2020 2020 7375 625f 6461 7461          sub_data
-0002d0b0: 5f76 6572 7369 6f6e 203d 2056 6572 7369  _version = Versi
-0002d0c0: 6f6e 2873 7562 5f64 6174 615b 2776 6572  on(sub_data['ver
-0002d0d0: 7369 6f6e 275d 5b27 6e61 6d65 275d 290a  sion']['name']).
-0002d0e0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-0002d0f0: 656c 662e 7665 7273 696f 6e20 3e3d 2073  elf.version >= s
-0002d100: 7562 5f64 6174 615f 7665 7273 696f 6e3a  ub_data_version:
-0002d110: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0002d120: 2072 6574 7572 6e20 7375 625f 6461 7461   return sub_data
-0002d130: 0a0a 2020 2020 6465 6620 5f6f 6e65 5f73  ..    def _one_s
-0002d140: 686f 745f 7175 6572 7928 7365 6c66 293a  hot_query(self):
-0002d150: 0a20 2020 2020 2020 2077 6974 6820 6f70  .        with op
-0002d160: 656e 2873 656c 662e 6366 6729 2061 7320  en(self.cfg) as 
-0002d170: 663a 0a20 2020 2020 2020 2020 2020 2063  f:.            c
-0002d180: 6f6e 7465 6e74 203d 2079 616d 6c2e 7361  ontent = yaml.sa
-0002d190: 6665 5f6c 6f61 6428 6629 0a20 2020 2020  fe_load(f).     
-0002d1a0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0002d1b0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0002d1c0: 2e63 7572 5f63 6f6e 6669 6720 3d20 7365  .cur_config = se
-0002d1d0: 6c66 2e5f 6765 745f 7370 6563 6966 6965  lf._get_specifie
-0002d1e0: 645f 7665 7273 696f 6e5f 6366 6728 636f  d_version_cfg(co
-0002d1f0: 6e74 656e 7429 0a20 2020 2020 2020 2020  ntent).         
-0002d200: 2020 2065 7863 6570 7420 4578 6365 7074     except Except
-0002d210: 696f 6e20 6173 2065 3a20 2023 2070 7261  ion as e:  # pra
-0002d220: 676d 613a 206e 6f20 636f 7665 720a 2020  gma: no cover.  
-0002d230: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-0002d240: 6767 6572 2e69 6e66 6f28 2246 6169 6c20  gger.info("Fail 
-0002d250: 746f 2070 6172 7365 207b 7d20 6475 6520  to parse {} due 
-0002d260: 746f 207b 7d22 2e66 6f72 6d61 7428 7365  to {}".format(se
-0002d270: 6c66 2e63 6667 2c20 7374 7228 6529 2929  lf.cfg, str(e)))
-0002d280: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0002d290: 2073 656c 662e 6375 725f 636f 6e66 6967   self.cur_config
-0002d2a0: 203d 204e 6f6e 650a 2020 2020 2020 2020   = None.        
-0002d2b0: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
-0002d2c0: 6c75 6545 7272 6f72 2822 506c 6561 7365  lueError("Please
-0002d2d0: 2063 6865 636b 2069 6620 7468 6520 666f   check if the fo
-0002d2e0: 726d 6174 206f 6620 7b7d 2066 6f6c 6c6f  rmat of {} follo
-0002d2f0: 7773 2022 0a20 2020 2020 2020 2020 2020  ws ".           
-0002d300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002d310: 2020 2020 2020 224e 6575 7261 6c20 436f        "Neural Co
-0002d320: 6d70 7265 7373 6f72 2079 616d 6c20 7363  mpressor yaml sc
-0002d330: 6865 6d65 2e22 2e66 6f72 6d61 7428 7365  heme.".format(se
-0002d340: 6c66 2e63 6667 2929 0a20 2020 2020 2020  lf.cfg)).       
-0002d350: 2073 656c 662e 5f75 7064 6174 655f 6366   self._update_cf
-0002d360: 675f 7769 7468 5f75 7372 5f64 6566 696e  g_with_usr_defin
-0002d370: 6974 696f 6e28 290a 0a20 2020 2064 6566  ition()..    def
-0002d380: 205f 7570 6461 7465 5f63 6667 5f77 6974   _update_cfg_wit
-0002d390: 685f 7573 725f 6465 6669 6e69 7469 6f6e  h_usr_definition
-0002d3a0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-0002d3b0: 6672 6f6d 206e 6575 7261 6c5f 636f 6d70  from neural_comp
-0002d3c0: 7265 7373 6f72 2e63 6f6e 662e 7079 7468  ressor.conf.pyth
-0002d3d0: 6f6e 6963 5f63 6f6e 6669 6720 696d 706f  onic_config impo
-0002d3e0: 7274 2070 7974 6f72 6368 5f63 6f6e 6669  rt pytorch_confi
-0002d3f0: 670a 2020 2020 2020 2020 6966 2070 7974  g.        if pyt
-0002d400: 6f72 6368 5f63 6f6e 6669 672e 7072 6563  orch_config.prec
-0002d410: 6973 696f 6e73 2069 7320 6e6f 7420 4e6f  isions is not No
-0002d420: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-0002d430: 7365 6c66 2e63 7572 5f63 6f6e 6669 675b  self.cur_config[
-0002d440: 2770 7265 6369 7369 6f6e 7327 5d5b 276e  'precisions']['n
-0002d450: 616d 6573 275d 203d 2027 2c27 2e6a 6f69  ames'] = ','.joi
-0002d460: 6e28 7079 746f 7263 685f 636f 6e66 6967  n(pytorch_config
-0002d470: 2e70 7265 6369 7369 6f6e 7329 0a0a 2020  .precisions)..  
-0002d480: 2020 6465 6620 6765 745f 7175 616e 7469    def get_quanti
-0002d490: 7a61 7469 6f6e 5f63 6170 6162 696c 6974  zation_capabilit
-0002d4a0: 7928 7365 6c66 293a 0a20 2020 2020 2020  y(self):.       
-0002d4b0: 2022 2222 4765 7420 7468 6520 7375 7070   """Get the supp
-0002d4c0: 6f72 7465 6420 6f70 2074 7970 6573 2720  orted op types' 
-0002d4d0: 7175 616e 7469 7a61 7469 6f6e 2063 6170  quantization cap
-0002d4e0: 6162 696c 6974 792e 0a0a 2020 2020 2020  ability...      
-0002d4f0: 2020 5265 7475 726e 733a 0a20 2020 2020    Returns:.     
-0002d500: 2020 2020 2020 205b 6469 6374 696f 6e61         [dictiona
-0002d510: 7279 206c 6973 745d 3a20 4120 6c69 7374  ry list]: A list
-0002d520: 2063 6f6d 706f 7365 6420 6f66 2064 6963   composed of dic
-0002d530: 7469 6f6e 6172 7920 7768 6963 6820 6b65  tionary which ke
-0002d540: 7920 6973 2070 7265 6369 7369 6f6e 0a20  y is precision. 
-0002d550: 2020 2020 2020 2020 2020 2061 6e64 2076             and v
-0002d560: 616c 7565 2069 7320 6120 6469 6374 2074  alue is a dict t
-0002d570: 6861 7420 6465 7363 7269 6265 7320 616c  hat describes al
-0002d580: 6c20 6f70 2074 7970 6573 2720 7175 616e  l op types' quan
-0002d590: 7469 7a61 7469 6f6e 2063 6170 6162 696c  tization capabil
-0002d5a0: 6974 792e 0a20 2020 2020 2020 2022 2222  ity..        """
-0002d5b0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0002d5c0: 7365 6c66 2e63 7572 5f63 6f6e 6669 675b  self.cur_config[
-0002d5d0: 2769 6e74 3827 5d0a 0a20 2020 2064 6566  'int8']..    def
-0002d5e0: 2067 6574 5f6f 705f 7479 7065 7328 7365   get_op_types(se
-0002d5f0: 6c66 293a 0a20 2020 2020 2020 2022 2222  lf):.        """
-0002d600: 4765 7420 7468 6520 7375 7070 6f72 7465  Get the supporte
-0002d610: 6420 6f70 2074 7970 6573 2062 7920 616c  d op types by al
-0002d620: 6c20 7072 6563 6973 696f 6e73 2e0a 2020  l precisions..  
-0002d630: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
-0002d640: 2020 2020 2020 2020 2020 205b 6469 6374             [dict
-0002d650: 696f 6e61 7279 206c 6973 745d 3a20 4120  ionary list]: A 
-0002d660: 6c69 7374 2063 6f6d 706f 7365 6420 6f66  list composed of
-0002d670: 2064 6963 7469 6f6e 6172 7920 7768 6963   dictionary whic
-0002d680: 6820 6b65 7920 6973 2070 7265 6369 7369  h key is precisi
-0002d690: 6f6e 0a20 2020 2020 2020 2020 2020 2061  on.            a
-0002d6a0: 6e64 2076 616c 7565 2069 7320 7468 6520  nd value is the 
-0002d6b0: 6f70 2074 7970 6573 2e0a 2020 2020 2020  op types..      
-0002d6c0: 2020 2222 220a 2020 2020 2020 2020 7265    """.        re
-0002d6d0: 7475 726e 2073 656c 662e 6375 725f 636f  turn self.cur_co
-0002d6e0: 6e66 6967 0a0a 2020 2020 6465 6620 6765  nfig..    def ge
-0002d6f0: 745f 6f70 5f74 7970 6573 5f62 795f 7072  t_op_types_by_pr
-0002d700: 6563 6973 696f 6e28 7365 6c66 2c20 7072  ecision(self, pr
-0002d710: 6563 6973 696f 6e29 3a0a 2020 2020 2020  ecision):.      
-0002d720: 2020 2222 2247 6574 206f 7020 7479 7065    """Get op type
-0002d730: 7320 7065 7220 7072 6563 6973 696f 6e0a  s per precision.
-0002d740: 2020 2020 2020 2020 4172 6773 3a0a 2020          Args:.  
-0002d750: 2020 2020 2020 2020 2020 7072 6563 6973            precis
-0002d760: 696f 6e20 2873 7472 696e 6729 3a20 7072  ion (string): pr
-0002d770: 6563 6973 696f 6e20 6e61 6d65 0a20 2020  ecision name.   
-0002d780: 2020 2020 2052 6574 7572 6e73 3a0a 2020       Returns:.  
-0002d790: 2020 2020 2020 2020 2020 5b73 7472 696e            [strin
-0002d7a0: 6720 6c69 7374 5d3a 2041 206c 6973 7420  g list]: A list 
-0002d7b0: 636f 6d70 6f73 6564 206f 6620 6f70 2074  composed of op t
-0002d7c0: 7970 652e 0a20 2020 2020 2020 2022 2222  ype..        """
-0002d7d0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0002d7e0: 7365 6c66 2e63 7572 5f63 6f6e 6669 675b  self.cur_config[
-0002d7f0: 7072 6563 6973 696f 6e5d 0a              precision].
+0002bb20: 2069 6620 6f70 5f74 7970 6520 696e 2072   if op_type in r
+0002bb30: 6573 2e6b 6579 7328 293a 0a20 2020 2020  es.keys():.     
+0002bb40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002bb50: 2020 2072 6573 5b6f 705f 7479 7065 5d5b     res[op_type][
+0002bb60: 2742 4631 3627 5d20 2b3d 2031 0a20 2020  'BF16'] += 1.   
+0002bb70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002bb80: 2020 2020 2069 6620 7265 735b 6f70 5f74       if res[op_t
+0002bb90: 7970 655d 5b27 4650 3332 275d 203e 2030  ype]['FP32'] > 0
+0002bba0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0002bbb0: 2020 2020 2020 2020 2020 2020 2020 7265                re
+0002bbc0: 735b 6f70 5f74 7970 655d 5b27 4650 3332  s[op_type]['FP32
+0002bbd0: 275d 202d 3d20 310a 2020 2020 2020 2020  '] -= 1.        
+0002bbe0: 2020 2020 2020 2020 2020 2020 656c 7365              else
+0002bbf0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0002bc00: 2020 2020 2020 2020 2020 7265 735b 6f70            res[op
+0002bc10: 5f74 7970 655d 203d 207b 2749 4e54 3827  _type] = {'INT8'
+0002bc20: 3a20 302c 2027 4246 3136 273a 2031 2c20  : 0, 'BF16': 1, 
+0002bc30: 2746 5033 3227 3a20 307d 0a0a 0a20 2020  'FP32': 0}...   
+0002bc40: 2020 2020 206f 7574 7075 745f 6461 7461       output_data
+0002bc50: 203d 205b 5b0a 2020 2020 2020 2020 2020   = [[.          
+0002bc60: 2020 6f70 5f74 7970 652c 0a20 2020 2020    op_type,.     
+0002bc70: 2020 2020 2020 2073 756d 2872 6573 5b6f         sum(res[o
+0002bc80: 705f 7479 7065 5d2e 7661 6c75 6573 2829  p_type].values()
+0002bc90: 292c 2072 6573 5b6f 705f 7479 7065 5d5b  ), res[op_type][
+0002bca0: 2749 4e54 3827 5d2c 2072 6573 5b6f 705f  'INT8'], res[op_
+0002bcb0: 7479 7065 5d5b 2742 4631 3627 5d2c 0a20  type]['BF16'],. 
+0002bcc0: 2020 2020 2020 2020 2020 2072 6573 5b6f             res[o
+0002bcd0: 705f 7479 7065 5d5b 2746 5033 3227 5d0a  p_type]['FP32'].
+0002bce0: 2020 2020 2020 2020 5d20 666f 7220 6f70          ] for op
+0002bcf0: 5f74 7970 6520 696e 2072 6573 2e6b 6579  _type in res.key
+0002bd00: 7328 295d 0a0a 2020 2020 2020 2020 5374  s()]..        St
+0002bd10: 6174 6973 7469 6373 286f 7574 7075 745f  atistics(output_
+0002bd20: 6461 7461 2c0a 2020 2020 2020 2020 2020  data,.          
+0002bd30: 2020 2020 2020 2020 2068 6561 6465 723d           header=
+0002bd40: 274d 6978 6564 2050 7265 6369 7369 6f6e  'Mixed Precision
+0002bd50: 2053 7461 7469 7374 6963 7327 2c0a 2020   Statistics',.  
+0002bd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002bd70: 2066 6965 6c64 5f6e 616d 6573 3d5b 224f   field_names=["O
+0002bd80: 7020 5479 7065 222c 2022 546f 7461 6c22  p Type", "Total"
+0002bd90: 2c20 2249 4e54 3822 2c20 2242 4631 3622  , "INT8", "BF16"
+0002bda0: 2c20 2246 5033 3222 5d29 2e70 7269 6e74  , "FP32"]).print
+0002bdb0: 5f73 7461 7428 290a 0a20 2020 2064 6566  _stat()..    def
+0002bdc0: 205f 6765 745f 7175 616e 7469 7a61 626c   _get_quantizabl
+0002bdd0: 655f 6f70 735f 7265 6375 7273 6976 656c  e_ops_recursivel
+0002bde0: 7928 7365 6c66 2c20 6d6f 6465 6c2c 2070  y(self, model, p
+0002bdf0: 7265 6669 782c 2071 7561 6e74 697a 6162  refix, quantizab
+0002be00: 6c65 5f6f 7073 293a 0a20 2020 2020 2020  le_ops):.       
+0002be10: 2022 2222 5468 6973 2069 7320 6120 6865   """This is a he
+0002be20: 6c70 6572 2066 756e 6374 696f 6e20 666f  lper function fo
+0002be30: 7220 6071 7565 7279 5f66 775f 6361 7061  r `query_fw_capa
+0002be40: 6269 6c69 7479 602c 0a20 2020 2020 2020  bility`,.       
+0002be50: 2020 2020 616e 6420 6974 2077 696c 6c20      and it will 
+0002be60: 6765 7420 616c 6c20 7175 616e 7469 7a61  get all quantiza
+0002be70: 626c 6520 6f70 7320 6672 6f6d 206d 6f64  ble ops from mod
+0002be80: 656c 2e0a 0a20 2020 2020 2020 2041 7267  el...        Arg
+0002be90: 733a 0a20 2020 2020 2020 2020 2020 206d  s:.            m
+0002bea0: 6f64 656c 2028 6f62 6a65 6374 293a 2069  odel (object): i
+0002beb0: 6e70 7574 206d 6f64 656c 0a20 2020 2020  nput model.     
+0002bec0: 2020 2020 2020 2070 7265 6669 7820 2873         prefix (s
+0002bed0: 7472 696e 6729 3a20 7072 6566 6978 206f  tring): prefix o
+0002bee0: 6620 6f70 206e 616d 650a 2020 2020 2020  f op name.      
+0002bef0: 2020 2020 2020 7175 616e 7469 7a61 626c        quantizabl
+0002bf00: 655f 6f70 7320 286c 6973 7429 3a20 6c69  e_ops (list): li
+0002bf10: 7374 206f 6620 7175 616e 7469 7a61 626c  st of quantizabl
+0002bf20: 6520 6f70 7320 6672 6f6d 206d 6f64 656c  e ops from model
+0002bf30: 2069 6e63 6c75 6465 206f 7020 6e61 6d65   include op name
+0002bf40: 2061 6e64 2074 7970 652e 0a0a 2020 2020   and type...    
+0002bf50: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
+0002bf60: 2020 2020 2020 2020 204e 6f6e 650a 2020           None.  
+0002bf70: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0002bf80: 2020 6d6f 6475 6c65 5f64 6963 7420 3d20    module_dict = 
+0002bf90: 6469 6374 286d 6f64 656c 2e6e 616d 6564  dict(model.named
+0002bfa0: 5f6d 6f64 756c 6573 2829 290a 2020 2020  _modules()).    
+0002bfb0: 2020 2020 666f 7220 6f70 5f6e 616d 652c      for op_name,
+0002bfc0: 2063 6869 6c64 2069 6e20 6d6f 6465 6c2e   child in model.
+0002bfd0: 6e61 6d65 645f 6d6f 6475 6c65 7328 293a  named_modules():
+0002bfe0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0002bff0: 7365 6c66 2e69 735f 6675 7365 645f 6d6f  self.is_fused_mo
+0002c000: 6475 6c65 2863 6869 6c64 293a 0a20 2020  dule(child):.   
+0002c010: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+0002c020: 206e 616d 652c 205f 2069 6e20 6368 696c   name, _ in chil
+0002c030: 642e 6e61 6d65 645f 6368 696c 6472 656e  d.named_children
+0002c040: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+0002c050: 2020 2020 2020 2020 6d6f 6475 6c65 5f70          module_p
+0002c060: 7265 6669 7820 3d20 6f70 5f6e 616d 6520  refix = op_name 
+0002c070: 2b20 272e 2720 2b20 6e61 6d65 0a20 2020  + '.' + name.   
+0002c080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c090: 2069 6620 6d6f 6475 6c65 5f70 7265 6669   if module_prefi
+0002c0a0: 7820 696e 206d 6f64 756c 655f 6469 6374  x in module_dict
+0002c0b0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0002c0c0: 2020 2020 2020 2020 2020 6d6f 6475 6c65            module
+0002c0d0: 5f64 6963 742e 706f 7028 6d6f 6475 6c65  _dict.pop(module
+0002c0e0: 5f70 7265 6669 7829 2020 2320 7265 6d6f  _prefix)  # remo
+0002c0f0: 7665 2073 7562 2d6d 6f64 756c 6573 206f  ve sub-modules o
+0002c100: 6620 6675 7365 6420 6d6f 6475 6c65 730a  f fused modules.
+0002c110: 0a20 2020 2020 2020 2066 6f72 206f 705f  .        for op_
+0002c120: 6e61 6d65 2c20 6368 696c 6420 696e 206d  name, child in m
+0002c130: 6f64 756c 655f 6469 6374 2e69 7465 6d73  odule_dict.items
+0002c140: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+0002c150: 6966 2074 7970 6528 6368 696c 6429 2069  if type(child) i
+0002c160: 6e20 7365 6c66 2e77 6869 7465 5f6c 6973  n self.white_lis
+0002c170: 7420 5c0a 2020 2020 2020 2020 2020 2020  t \.            
+0002c180: 2020 2061 6e64 2074 7970 6528 6368 696c     and type(chil
+0002c190: 6429 2021 3d20 746f 7263 682e 6e6e 2e53  d) != torch.nn.S
+0002c1a0: 6571 7565 6e74 6961 6c20 5c0a 2020 2020  equential \.    
+0002c1b0: 2020 2020 2020 2020 2020 2061 6e64 2074             and t
+0002c1c0: 7970 6528 6368 696c 6429 2021 3d20 746f  ype(child) != to
+0002c1d0: 7263 682e 7175 616e 7469 7a61 7469 6f6e  rch.quantization
+0002c1e0: 2e73 7475 6273 2e44 6551 7561 6e74 5374  .stubs.DeQuantSt
+0002c1f0: 7562 3a0a 2020 2020 2020 2020 2020 2020  ub:.            
+0002c200: 2020 2020 7175 616e 7469 7a61 626c 655f      quantizable_
+0002c210: 6f70 732e 6170 7065 6e64 280a 2020 2020  ops.append(.    
+0002c220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c230: 286f 705f 6e61 6d65 2c20 756e 6966 795f  (op_name, unify_
+0002c240: 6f70 5f74 7970 655f 6d61 7070 696e 675b  op_type_mapping[
+0002c250: 7374 7228 6368 696c 642e 5f5f 636c 6173  str(child.__clas
+0002c260: 735f 5f2e 5f5f 6e61 6d65 5f5f 295d 0a20  s__.__name__)]. 
+0002c270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c280: 2020 2020 6966 2073 7472 2863 6869 6c64      if str(child
+0002c290: 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e 616d  .__class__.__nam
+0002c2a0: 655f 5f29 2069 6e20 756e 6966 795f 6f70  e__) in unify_op
+0002c2b0: 5f74 7970 655f 6d61 7070 696e 6720 656c  _type_mapping el
+0002c2c0: 7365 2073 7472 280a 2020 2020 2020 2020  se str(.        
+0002c2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c2e0: 2063 6869 6c64 2e5f 5f63 6c61 7373 5f5f   child.__class__
+0002c2f0: 2e5f 5f6e 616d 655f 5f29 2929 0a0a 2020  .__name__)))..  
+0002c300: 2020 6465 6620 5f67 6574 5f6d 6f64 756c    def _get_modul
+0002c310: 655f 7363 616c 655f 7a65 726f 706f 696e  e_scale_zeropoin
+0002c320: 7428 7365 6c66 2c20 6d6f 6465 6c2c 2074  t(self, model, t
+0002c330: 756e 655f 6366 672c 2070 7265 6669 783d  une_cfg, prefix=
+0002c340: 2727 293a 0a20 2020 2020 2020 2022 2222  ''):.        """
+0002c350: 6765 7420 6163 7469 7661 7469 6f6e 2073  get activation s
+0002c360: 6361 6c65 2061 6e64 207a 6572 6f5f 706f  cale and zero_po
+0002c370: 696e 7420 666f 7220 636f 6e76 6572 7465  int for converte
+0002c380: 6420 6d6f 6475 6c65 2e0a 0a20 2020 2020  d module...     
+0002c390: 2020 2041 7267 733a 0a20 2020 2020 2020     Args:.       
+0002c3a0: 2020 2020 206d 6f64 656c 2028 6469 7229       model (dir)
+0002c3b0: 3a20 496e 7438 206d 6f64 656c 2063 6f6e  : Int8 model con
+0002c3c0: 7665 7274 6564 2066 726f 6d20 6670 3332  verted from fp32
+0002c3d0: 206d 6f64 656c 2e0a 2020 2020 2020 2020   model..        
+0002c3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c3f0: 2073 6361 6c65 2061 6e64 207a 6572 6f5f   scale and zero_
+0002c400: 706f 696e 7420 6973 2073 6574 2077 6974  point is set wit
+0002c410: 6820 6361 6c69 6272 6174 696f 6e20 666f  h calibration fo
+0002c420: 7220 6561 6368 206d 6f64 756c 650a 2020  r each module.  
+0002c430: 2020 2020 2020 2020 2020 7475 6e65 5f63            tune_c
+0002c440: 6667 2028 6f62 6a65 6374 293a 2054 6869  fg (object): Thi
+0002c450: 7320 6669 6c65 2073 6176 6573 2073 6361  s file saves sca
+0002c460: 6c65 2061 6e64 207a 6572 6f5f 706f 696e  le and zero_poin
+0002c470: 7420 6f66 200a 2020 2020 2020 2020 2020  t of .          
+0002c480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c490: 2020 2020 206f 7574 7075 7420 6163 7469       output acti
+0002c4a0: 7661 7469 6f6e 206f 6620 6561 6368 2071  vation of each q
+0002c4b0: 7561 6e74 697a 6564 206d 6f64 756c 652e  uantized module.
+0002c4c0: 0a20 2020 2020 2020 2020 2020 2070 7265  .            pre
+0002c4d0: 6669 7820 2873 7472 696e 6729 3a20 7072  fix (string): pr
+0002c4e0: 6566 6978 206f 6620 6f70 206e 616d 650a  efix of op name.
+0002c4f0: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
+0002c500: 3a0a 2020 2020 2020 2020 2020 2020 4e6f  :.            No
+0002c510: 6e65 0a20 2020 2020 2020 2022 2222 0a20  ne.        """. 
+0002c520: 2020 2020 2020 2023 2067 6574 2073 6361         # get sca
+0002c530: 6c65 2061 6e64 207a 6572 6f5f 706f 696e  le and zero_poin
+0002c540: 7420 6f66 206d 6f64 756c 6573 2e0a 2020  t of modules..  
+0002c550: 2020 2020 2020 6d6f 6475 6c65 7320 3d20        modules = 
+0002c560: 6469 6374 286d 6f64 656c 2e6e 616d 6564  dict(model.named
+0002c570: 5f6d 6f64 756c 6573 2829 290a 2020 2020  _modules()).    
+0002c580: 2020 2020 666f 7220 6b65 7920 696e 2074      for key in t
+0002c590: 756e 655f 6366 675b 276f 7027 5d3a 0a20  une_cfg['op']:. 
+0002c5a0: 2020 2020 2020 2020 2020 2069 6620 7072             if pr
+0002c5b0: 6566 6978 3a0a 2020 2020 2020 2020 2020  efix:.          
+0002c5c0: 2020 2020 2020 7375 625f 6e61 6d65 203d        sub_name =
+0002c5d0: 206b 6579 5b30 5d2e 7265 706c 6163 6528   key[0].replace(
+0002c5e0: 7072 6566 6978 202b 2027 2e27 2c20 2727  prefix + '.', ''
+0002c5f0: 2c20 3129 0a20 2020 2020 2020 2020 2020  , 1).           
+0002c600: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0002c610: 2020 2020 2020 2073 7562 5f6e 616d 6520         sub_name 
+0002c620: 3d20 6b65 795b 305d 0a20 2020 2020 2020  = key[0].       
+0002c630: 2020 2020 2069 6620 7375 625f 6e61 6d65       if sub_name
+0002c640: 2069 6e20 6d6f 6475 6c65 733a 0a20 2020   in modules:.   
+0002c650: 2020 2020 2020 2020 2020 2020 2076 616c               val
+0002c660: 7565 203d 2074 756e 655f 6366 675b 276f  ue = tune_cfg['o
+0002c670: 7027 5d5b 6b65 795d 0a20 2020 2020 2020  p'][key].       
+0002c680: 2020 2020 2020 2020 2061 7373 6572 7420           assert 
+0002c690: 6973 696e 7374 616e 6365 2876 616c 7565  isinstance(value
+0002c6a0: 2c20 6469 6374 290a 2020 2020 2020 2020  , dict).        
+0002c6b0: 2020 2020 2020 2020 6966 2068 6173 6174          if hasat
+0002c6c0: 7472 286d 6f64 756c 6573 5b73 7562 5f6e  tr(modules[sub_n
+0002c6d0: 616d 655d 2c20 2773 6361 6c65 2729 3a0a  ame], 'scale'):.
+0002c6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c6f0: 2020 2020 7661 6c75 655b 2761 6374 6976      value['activ
+0002c700: 6174 696f 6e27 5d5b 2773 6361 6c65 275d  ation']['scale']
+0002c710: 203d 2066 6c6f 6174 286d 6f64 756c 6573   = float(modules
+0002c720: 5b73 7562 5f6e 616d 655d 2e73 6361 6c65  [sub_name].scale
+0002c730: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0002c740: 2020 6966 2068 6173 6174 7472 286d 6f64    if hasattr(mod
+0002c750: 756c 6573 5b73 7562 5f6e 616d 655d 2c20  ules[sub_name], 
+0002c760: 277a 6572 6f5f 706f 696e 7427 293a 0a20  'zero_point'):. 
+0002c770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c780: 2020 2076 616c 7565 5b27 6163 7469 7661     value['activa
+0002c790: 7469 6f6e 275d 5b27 7a65 726f 5f70 6f69  tion']['zero_poi
+0002c7a0: 6e74 275d 203d 2069 6e74 286d 6f64 756c  nt'] = int(modul
+0002c7b0: 6573 5b73 7562 5f6e 616d 655d 2e7a 6572  es[sub_name].zer
+0002c7c0: 6f5f 706f 696e 7429 0a20 2020 2020 2020  o_point).       
+0002c7d0: 2023 2067 6574 2073 6361 6c65 2061 6e64   # get scale and
+0002c7e0: 207a 6572 6f5f 706f 696e 7420 6f66 2067   zero_point of g
+0002c7f0: 6574 6174 7472 206f 7073 2028 6c69 6b65  etattr ops (like
+0002c800: 2071 7561 6e74 697a 6520 6f70 7329 2e0a   quantize ops)..
+0002c810: 2020 2020 2020 2020 666f 7220 6e6f 6465          for node
+0002c820: 2069 6e20 6d6f 6465 6c2e 6772 6170 682e   in model.graph.
+0002c830: 6e6f 6465 733a 0a20 2020 2020 2020 2020  nodes:.         
+0002c840: 2020 2069 6620 6e6f 6465 2e6f 7020 3d3d     if node.op ==
+0002c850: 2027 6765 745f 6174 7472 273a 0a20 2020   'get_attr':.   
+0002c860: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0002c870: 7072 6566 6978 3a0a 2020 2020 2020 2020  prefix:.        
+0002c880: 2020 2020 2020 2020 2020 2020 7375 625f              sub_
+0002c890: 6e61 6d65 203d 2070 7265 6669 7820 2b20  name = prefix + 
+0002c8a0: 272d 2d27 202b 206e 6f64 652e 7461 7267  '--' + node.targ
+0002c8b0: 6574 0a20 2020 2020 2020 2020 2020 2020  et.             
+0002c8c0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0002c8d0: 2020 2020 2020 2020 2020 2020 2073 7562               sub
+0002c8e0: 5f6e 616d 6520 3d20 6e6f 6465 2e74 6172  _name = node.tar
+0002c8f0: 6765 740a 2020 2020 2020 2020 2020 2020  get.            
+0002c900: 2020 2020 6966 206e 6f74 2068 6173 6174      if not hasat
+0002c910: 7472 286d 6f64 656c 2c20 6e6f 6465 2e74  tr(model, node.t
+0002c920: 6172 6765 7429 3a0a 2020 2020 2020 2020  arget):.        
+0002c930: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+0002c940: 696e 7565 0a20 2020 2020 2020 2020 2020  inue.           
+0002c950: 2020 2020 2069 6620 2773 6361 6c65 2720       if 'scale' 
+0002c960: 696e 206e 6f64 652e 7461 7267 6574 3a0a  in node.target:.
+0002c970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c980: 2020 2020 7475 6e65 5f63 6667 5b27 6765      tune_cfg['ge
+0002c990: 745f 6174 7472 275d 5b73 7562 5f6e 616d  t_attr'][sub_nam
+0002c9a0: 655d 203d 2066 6c6f 6174 2867 6574 6174  e] = float(getat
+0002c9b0: 7472 286d 6f64 656c 2c20 6e6f 6465 2e74  tr(model, node.t
+0002c9c0: 6172 6765 7429 290a 2020 2020 2020 2020  arget)).        
+0002c9d0: 2020 2020 2020 2020 656c 6966 2027 7a65          elif 'ze
+0002c9e0: 726f 5f70 6f69 6e74 2720 696e 206e 6f64  ro_point' in nod
+0002c9f0: 652e 7461 7267 6574 3a0a 2020 2020 2020  e.target:.      
+0002ca00: 2020 2020 2020 2020 2020 2020 2020 7475                tu
+0002ca10: 6e65 5f63 6667 5b27 6765 745f 6174 7472  ne_cfg['get_attr
+0002ca20: 275d 5b73 7562 5f6e 616d 655d 203d 2069  '][sub_name] = i
+0002ca30: 6e74 2867 6574 6174 7472 286d 6f64 656c  nt(getattr(model
+0002ca40: 2c20 6e6f 6465 2e74 6172 6765 7429 290a  , node.target)).
+0002ca50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002ca60: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+0002ca70: 2020 2020 2020 2020 2020 7061 7373 0a0a            pass..
+0002ca80: 2020 2020 6465 6620 5f67 6574 5f73 7562      def _get_sub
+0002ca90: 5f6d 6f64 756c 655f 7363 616c 655f 7a65  _module_scale_ze
+0002caa0: 726f 706f 696e 7428 7365 6c66 2c20 6d6f  ropoint(self, mo
+0002cab0: 6465 6c2c 2074 756e 655f 6366 672c 2070  del, tune_cfg, p
+0002cac0: 7265 6669 783d 2727 293a 0a20 2020 2020  refix=''):.     
+0002cad0: 2020 2022 2222 6765 7420 6163 7469 7661     """get activa
+0002cae0: 7469 6f6e 2073 6361 6c65 2061 6e64 207a  tion scale and z
+0002caf0: 6572 6f5f 706f 696e 7420 666f 7220 636f  ero_point for co
+0002cb00: 6e76 6572 7465 6420 7375 6220 6d6f 6475  nverted sub modu
+0002cb10: 6c65 7320 7265 6375 7273 6976 656c 792e  les recursively.
+0002cb20: 0a0a 2020 2020 2020 2020 4172 6773 3a0a  ..        Args:.
+0002cb30: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
+0002cb40: 6c20 2864 6972 293a 2049 6e74 3820 6d6f  l (dir): Int8 mo
+0002cb50: 6465 6c20 636f 6e76 6572 7465 6420 6672  del converted fr
+0002cb60: 6f6d 2066 7033 3220 6d6f 6465 6c2e 0a20  om fp32 model.. 
+0002cb70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002cb80: 2020 2020 2020 2073 6361 6c65 2061 6e64         scale and
+0002cb90: 207a 6572 6f5f 706f 696e 7420 6973 2073   zero_point is s
+0002cba0: 6574 2077 6974 6820 6361 6c69 6272 6174  et with calibrat
+0002cbb0: 696f 6e20 666f 7220 6561 6368 206d 6f64  ion for each mod
+0002cbc0: 756c 650a 2020 2020 2020 2020 2020 2020  ule.            
+0002cbd0: 7475 6e65 5f63 6667 2028 6f62 6a65 6374  tune_cfg (object
+0002cbe0: 293a 2054 6869 7320 6669 6c65 2073 6176  ): This file sav
+0002cbf0: 6573 2073 6361 6c65 2061 6e64 207a 6572  es scale and zer
+0002cc00: 6f5f 706f 696e 7420 6f66 205c 0a20 2020  o_point of \.   
+0002cc10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002cc20: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+0002cc30: 6163 7469 7661 7469 6f6e 206f 6620 6561  activation of ea
+0002cc40: 6368 2071 7561 6e74 697a 6564 206d 6f64  ch quantized mod
+0002cc50: 756c 652e 0a20 2020 2020 2020 2020 2020  ule..           
+0002cc60: 2070 7265 6669 7820 2873 7472 696e 6729   prefix (string)
+0002cc70: 3a20 7072 6566 6978 206f 6620 6f70 206e  : prefix of op n
+0002cc80: 616d 650a 0a20 2020 2020 2020 2052 6574  ame..        Ret
+0002cc90: 7572 6e73 3a0a 2020 2020 2020 2020 2020  urns:.          
+0002cca0: 2020 4e6f 6e65 0a20 2020 2020 2020 2022    None.        "
+0002ccb0: 2222 0a20 2020 2020 2020 2066 6f72 206e  "".        for n
+0002ccc0: 616d 652c 206d 6f64 756c 6520 696e 206d  ame, module in m
+0002ccd0: 6f64 656c 2e6e 616d 6564 5f63 6869 6c64  odel.named_child
+0002cce0: 7265 6e28 293a 0a20 2020 2020 2020 2020  ren():.         
+0002ccf0: 2020 206f 705f 6e61 6d65 203d 2070 7265     op_name = pre
+0002cd00: 6669 7820 2b20 272e 2720 2b20 6e61 6d65  fix + '.' + name
+0002cd10: 2069 6620 7072 6566 6978 2021 3d20 2727   if prefix != ''
+0002cd20: 2065 6c73 6520 6e61 6d65 0a20 2020 2020   else name.     
+0002cd30: 2020 2020 2020 2069 6620 6f70 5f6e 616d         if op_nam
+0002cd40: 6520 696e 2073 656c 662e 7375 625f 6d6f  e in self.sub_mo
+0002cd50: 6475 6c65 5f6c 6973 743a 0a20 2020 2020  dule_list:.     
+0002cd60: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0002cd70: 5f67 6574 5f6d 6f64 756c 655f 7363 616c  _get_module_scal
+0002cd80: 655f 7a65 726f 706f 696e 7428 6d6f 6475  e_zeropoint(modu
+0002cd90: 6c65 2c20 7475 6e65 5f63 6667 2c20 6f70  le, tune_cfg, op
+0002cda0: 5f6e 616d 6529 0a20 2020 2020 2020 2020  _name).         
+0002cdb0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0002cdc0: 2020 2020 2020 2020 2073 656c 662e 5f67           self._g
+0002cdd0: 6574 5f73 7562 5f6d 6f64 756c 655f 7363  et_sub_module_sc
+0002cde0: 616c 655f 7a65 726f 706f 696e 7428 6d6f  ale_zeropoint(mo
+0002cdf0: 6475 6c65 2c20 7475 6e65 5f63 6667 2c20  dule, tune_cfg, 
+0002ce00: 6f70 5f6e 616d 6529 0a0a 2020 2020 6465  op_name)..    de
+0002ce10: 6620 5f67 6574 5f73 6361 6c65 5f7a 6572  f _get_scale_zer
+0002ce20: 6f70 6f69 6e74 2873 656c 662c 206d 6f64  opoint(self, mod
+0002ce30: 656c 2c20 7475 6e65 5f63 6667 293a 0a20  el, tune_cfg):. 
+0002ce40: 2020 2020 2020 2022 2222 6765 7420 6163         """get ac
+0002ce50: 7469 7661 7469 6f6e 2073 6361 6c65 2061  tivation scale a
+0002ce60: 6e64 207a 6572 6f5f 706f 696e 7420 666f  nd zero_point fo
+0002ce70: 7220 636f 6e76 6572 7465 6420 6d6f 6465  r converted mode
+0002ce80: 6c2e 0a0a 2020 2020 2020 2020 4172 6773  l...        Args
+0002ce90: 3a0a 2020 2020 2020 2020 2020 2020 6d6f  :.            mo
+0002cea0: 6465 6c20 2864 6972 293a 2049 6e74 3820  del (dir): Int8 
+0002ceb0: 6d6f 6465 6c20 636f 6e76 6572 7465 6420  model converted 
+0002cec0: 6672 6f6d 2066 7033 3220 6d6f 6465 6c2e  from fp32 model.
+0002ced0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002cee0: 2020 2020 2020 2020 2073 6361 6c65 2061           scale a
+0002cef0: 6e64 207a 6572 6f5f 706f 696e 7420 6973  nd zero_point is
+0002cf00: 2073 6574 2077 6974 6820 6361 6c69 6272   set with calibr
+0002cf10: 6174 696f 6e20 666f 7220 6561 6368 206d  ation for each m
+0002cf20: 6f64 756c 650a 2020 2020 2020 2020 2020  odule.          
+0002cf30: 2020 7475 6e65 5f63 6667 2028 6f62 6a65    tune_cfg (obje
+0002cf40: 6374 293a 2054 6869 7320 6669 6c65 2073  ct): This file s
+0002cf50: 6176 6573 2073 6361 6c65 2061 6e64 207a  aves scale and z
+0002cf60: 6572 6f5f 706f 696e 7420 6f66 205c 0a20  ero_point of \. 
+0002cf70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002cf80: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+0002cf90: 7420 6163 7469 7661 7469 6f6e 206f 6620  t activation of 
+0002cfa0: 6561 6368 2071 7561 6e74 697a 6564 206d  each quantized m
+0002cfb0: 6f64 756c 652e 0a0a 2020 2020 2020 2020  odule...        
+0002cfc0: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
+0002cfd0: 2020 2020 204e 6f6e 650a 2020 2020 2020       None.      
+0002cfe0: 2020 2222 220a 2020 2020 2020 2020 7475    """.        tu
+0002cff0: 6e65 5f63 6667 5b27 6765 745f 6174 7472  ne_cfg['get_attr
+0002d000: 275d 203d 207b 7d0a 2020 2020 2020 2020  '] = {}.        
+0002d010: 6966 2073 656c 662e 7375 625f 6d6f 6475  if self.sub_modu
+0002d020: 6c65 5f6c 6973 7420 6973 204e 6f6e 653a  le_list is None:
+0002d030: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+0002d040: 662e 5f67 6574 5f6d 6f64 756c 655f 7363  f._get_module_sc
+0002d050: 616c 655f 7a65 726f 706f 696e 7428 6d6f  ale_zeropoint(mo
+0002d060: 6465 6c2c 2074 756e 655f 6366 6729 0a20  del, tune_cfg). 
+0002d070: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0002d080: 2020 2020 2020 2020 2073 656c 662e 5f67           self._g
+0002d090: 6574 5f73 7562 5f6d 6f64 756c 655f 7363  et_sub_module_sc
+0002d0a0: 616c 655f 7a65 726f 706f 696e 7428 6d6f  ale_zeropoint(mo
+0002d0b0: 6465 6c2c 2074 756e 655f 6366 6729 0a0a  del, tune_cfg)..
+0002d0c0: 2020 2020 4073 7461 7469 636d 6574 686f      @staticmetho
+0002d0d0: 640a 2020 2020 6465 6620 7072 6570 6172  d.    def prepar
+0002d0e0: 655f 7375 625f 6772 6170 6828 7375 625f  e_sub_graph(sub_
+0002d0f0: 6d6f 6475 6c65 5f6c 6973 742c 0a20 2020  module_list,.   
+0002d100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002d110: 2020 2020 2020 2066 785f 6f70 5f63 6667         fx_op_cfg
+0002d120: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
+0002d130: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
+0002d140: 656c 2c0a 2020 2020 2020 2020 2020 2020  el,.            
+0002d150: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+0002d160: 6566 6978 2c0a 2020 2020 2020 2020 2020  efix,.          
+0002d170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002d180: 6973 5f71 6174 3d46 616c 7365 2c0a 2020  is_qat=False,.  
+0002d190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002d1a0: 2020 2020 2020 2020 6578 616d 706c 655f          example_
+0002d1b0: 696e 7075 7473 3d4e 6f6e 652c 0a20 2020  inputs=None,.   
+0002d1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002d1d0: 2020 2020 2020 2063 7573 746f 6d5f 636f         custom_co
+0002d1e0: 6e66 6967 3d4e 6f6e 6529 3a0a 2020 2020  nfig=None):.    
+0002d1f0: 2020 2020 2222 2253 7461 7469 6320 6d65      """Static me
+0002d200: 7468 6f64 2074 6f20 7072 6570 6172 6520  thod to prepare 
+0002d210: 7375 6220 6d6f 6475 6c65 7320 7265 6375  sub modules recu
+0002d220: 7273 6976 656c 792e 0a0a 2020 2020 2020  rsively...      
+0002d230: 2020 4172 6773 3a0a 2020 2020 2020 2020    Args:.        
+0002d240: 2020 2020 7375 625f 6d6f 6475 6c65 5f6c      sub_module_l
+0002d250: 6973 7420 286c 6973 7429 3a20 636f 6e74  ist (list): cont
+0002d260: 6169 6e73 2074 6865 206e 616d 6520 6f66  ains the name of
+0002d270: 2074 7261 6365 6162 6c65 2073 7562 206d   traceable sub m
+0002d280: 6f64 756c 6573 0a20 2020 2020 2020 2020  odules.         
+0002d290: 2020 2066 785f 6f70 5f63 6667 7320 2864     fx_op_cfgs (d
+0002d2a0: 6963 742c 2051 436f 6e66 6967 4d61 7070  ict, QConfigMapp
+0002d2b0: 696e 6729 3a20 7468 6520 636f 6e66 6967  ing): the config
+0002d2c0: 7572 6174 696f 6e20 666f 7220 7072 6570  uration for prep
+0002d2d0: 6172 655f 6678 2071 7561 6e74 697a 6174  are_fx quantizat
+0002d2e0: 696f 6e2e 0a20 2020 2020 2020 2020 2020  ion..           
+0002d2f0: 206d 6f64 656c 2028 6469 7229 3a20 696e   model (dir): in
+0002d300: 7075 7420 6d6f 6465 6c20 7768 6963 6820  put model which 
+0002d310: 6973 2050 7954 6f72 6368 206d 6f64 656c  is PyTorch model
+0002d320: 2e0a 2020 2020 2020 2020 2020 2020 7072  ..            pr
+0002d330: 6566 6978 2028 7374 7269 6e67 293a 2070  efix (string): p
+0002d340: 7265 6669 7820 6f66 206f 7020 6e61 6d65  refix of op name
+0002d350: 0a20 2020 2020 2020 2020 2020 2069 735f  .            is_
+0002d360: 7161 7420 2862 6f6f 6c29 3a20 7768 6574  qat (bool): whet
+0002d370: 6865 7220 6974 2069 7320 6120 7161 7420  her it is a qat 
+0002d380: 7175 616e 7469 7a61 7469 6f6e 0a20 2020  quantization.   
+0002d390: 2020 2020 2020 2020 2065 7861 6d70 6c65           example
+0002d3a0: 5f69 6e70 7574 7320 2874 656e 736f 7220  _inputs (tensor 
+0002d3b0: 2f20 7475 7065 206f 6620 7465 6e73 6f72  / tupe of tensor
+0002d3c0: 293a 2065 7861 6d70 6c65 2069 6e70 7574  ): example input
+0002d3d0: 730a 2020 2020 2020 2020 2020 2020 6375  s.            cu
+0002d3e0: 7374 6f6d 5f63 6f6e 6669 6720 2864 6963  stom_config (dic
+0002d3f0: 7429 3a20 6375 7374 6f6d 206e 6f6e 2074  t): custom non t
+0002d400: 7261 6365 6162 6c65 206d 6f64 756c 6520  raceable module 
+0002d410: 6469 6374 0a0a 2020 2020 2020 2020 5265  dict..        Re
+0002d420: 7475 726e 733a 0a20 2020 2020 2020 2020  turns:.         
+0002d430: 2020 206d 6f64 656c 2028 6469 7229 3a20     model (dir): 
+0002d440: 6f75 7470 7574 206d 6f64 656c 2077 6869  output model whi
+0002d450: 6368 2069 7320 6120 7072 6570 6172 6564  ch is a prepared
+0002d460: 2050 7954 6f72 6368 206d 6f64 656c 2e0a   PyTorch model..
+0002d470: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+0002d480: 2020 2020 6672 6f6d 2074 6f72 6368 2e71      from torch.q
+0002d490: 7561 6e74 697a 6174 696f 6e2e 7175 616e  uantization.quan
+0002d4a0: 7469 7a65 5f66 7820 696d 706f 7274 2070  tize_fx import p
+0002d4b0: 7265 7061 7265 5f66 782c 2070 7265 7061  repare_fx, prepa
+0002d4c0: 7265 5f71 6174 5f66 780a 2020 2020 2020  re_qat_fx.      
+0002d4d0: 2020 696d 706f 7274 2074 6f72 6368 2e71    import torch.q
+0002d4e0: 7561 6e74 697a 6174 696f 6e2e 7175 616e  uantization.quan
+0002d4f0: 7469 7a61 7469 6f6e 5f6d 6170 7069 6e67  tization_mapping
+0002d500: 7320 6173 2074 7171 6d0a 2020 2020 2020  s as tqqm.      
+0002d510: 2020 7665 7273 696f 6e20 3d20 6765 745f    version = get_
+0002d520: 746f 7263 685f 7665 7273 696f 6e28 290a  torch_version().
+0002d530: 2020 2020 2020 2020 6678 5f77 6869 7465          fx_white
+0002d540: 5f6c 6973 7420 3d20 7471 716d 2e67 6574  _list = tqqm.get
+0002d550: 5f64 6566 6175 6c74 5f71 636f 6e66 6967  _default_qconfig
+0002d560: 5f70 726f 7061 6761 7469 6f6e 5f6c 6973  _propagation_lis
+0002d570: 7428 290a 2020 2020 2020 2020 666f 7220  t().        for 
+0002d580: 6e61 6d65 2c20 6d6f 6475 6c65 2069 6e20  name, module in 
+0002d590: 6d6f 6465 6c2e 6e61 6d65 645f 6368 696c  model.named_chil
+0002d5a0: 6472 656e 2829 3a0a 2020 2020 2020 2020  dren():.        
+0002d5b0: 2020 2020 6f70 5f6e 616d 6520 3d20 7072      op_name = pr
+0002d5c0: 6566 6978 202b 2027 2e27 202b 206e 616d  efix + '.' + nam
+0002d5d0: 6520 6966 2070 7265 6669 7820 213d 2027  e if prefix != '
+0002d5e0: 2720 656c 7365 206e 616d 650a 2020 2020  ' else name.    
+0002d5f0: 2020 2020 2020 2020 2320 736b 6970 2063          # skip c
+0002d600: 7573 746f 6d20 6e6f 6e20 7472 6163 6561  ustom non tracea
+0002d610: 626c 6520 6d6f 6475 6c65 2069 6e20 6669  ble module in fi
+0002d620: 6e65 2d67 7261 696e 6564 2046 580a 2020  ne-grained FX.  
+0002d630: 2020 2020 2020 2020 2020 6966 2063 7573            if cus
+0002d640: 746f 6d5f 636f 6e66 6967 3a0a 2020 2020  tom_config:.    
+0002d650: 2020 2020 2020 2020 2020 2020 6966 2028              if (
+0002d660: 276e 6f6e 5f74 7261 6365 6162 6c65 5f6d  'non_traceable_m
+0002d670: 6f64 756c 655f 6e61 6d65 2720 696e 2063  odule_name' in c
+0002d680: 7573 746f 6d5f 636f 6e66 6967 205c 0a20  ustom_config \. 
+0002d690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002d6a0: 2061 6e64 206f 705f 6e61 6d65 2069 6e20   and op_name in 
+0002d6b0: 6375 7374 6f6d 5f63 6f6e 6669 675b 276e  custom_config['n
+0002d6c0: 6f6e 5f74 7261 6365 6162 6c65 5f6d 6f64  on_traceable_mod
+0002d6d0: 756c 655f 6e61 6d65 275d 2920 5c0a 2020  ule_name']) \.  
+0002d6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002d6f0: 6f72 2028 276e 6f6e 5f74 7261 6365 6162  or ('non_traceab
+0002d700: 6c65 5f6d 6f64 756c 655f 636c 6173 7327  le_module_class'
+0002d710: 2069 6e20 6375 7374 6f6d 5f63 6f6e 6669   in custom_confi
+0002d720: 6720 5c0a 2020 2020 2020 2020 2020 2020  g \.            
+0002d730: 2020 2020 2020 616e 6420 6973 696e 7374        and isinst
+0002d740: 616e 6365 286d 6f64 756c 652c 2074 7570  ance(module, tup
+0002d750: 6c65 2863 7573 746f 6d5f 636f 6e66 6967  le(custom_config
+0002d760: 5b27 6e6f 6e5f 7472 6163 6561 626c 655f  ['non_traceable_
+0002d770: 6d6f 6475 6c65 5f63 6c61 7373 275d 2929  module_class']))
+0002d780: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+0002d790: 2020 2020 2020 2063 6f6e 7469 6e75 650a         continue.
+0002d7a0: 2020 2020 2020 2020 2020 2020 6966 206f              if o
+0002d7b0: 705f 6e61 6d65 2069 6e20 7375 625f 6d6f  p_name in sub_mo
+0002d7c0: 6475 6c65 5f6c 6973 743a 0a20 2020 2020  dule_list:.     
+0002d7d0: 2020 2020 2020 2020 2020 2023 2072 656d             # rem
+0002d7e0: 6f76 6520 7072 6566 6978 2069 6e20 6678  ove prefix in fx
+0002d7f0: 5f6f 705f 6366 6773 0a20 2020 2020 2020  _op_cfgs.       
+0002d800: 2020 2020 2020 2020 2076 6572 7369 6f6e           version
+0002d810: 203d 2067 6574 5f74 6f72 6368 5f76 6572   = get_torch_ver
+0002d820: 7369 6f6e 2829 0a20 2020 2020 2020 2020  sion().         
+0002d830: 2020 2020 2020 2069 6620 7665 7273 696f         if versio
+0002d840: 6e20 3e20 5665 7273 696f 6e28 2231 2e31  n > Version("1.1
+0002d850: 322e 3122 293a 2020 2320 7072 6167 6d61  2.1"):  # pragma
+0002d860: 3a20 6e6f 2063 6f76 6572 0a20 2020 2020  : no cover.     
+0002d870: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0002d880: 726f 6d20 746f 7263 682e 616f 2e71 7561  rom torch.ao.qua
+0002d890: 6e74 697a 6174 696f 6e20 696d 706f 7274  ntization import
+0002d8a0: 2051 436f 6e66 6967 4d61 7070 696e 670a   QConfigMapping.
+0002d8b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002d8c0: 2020 2020 6678 5f73 7562 5f6f 705f 6366      fx_sub_op_cf
+0002d8d0: 6773 203d 2051 436f 6e66 6967 4d61 7070  gs = QConfigMapp
+0002d8e0: 696e 6728 290a 2020 2020 2020 2020 2020  ing().          
+0002d8f0: 2020 2020 2020 2020 2020 6678 5f73 7562            fx_sub
+0002d900: 5f6f 705f 6366 6773 2e73 6574 5f67 6c6f  _op_cfgs.set_glo
+0002d910: 6261 6c28 4e6f 6e65 290a 2020 2020 2020  bal(None).      
+0002d920: 2020 2020 2020 2020 2020 2020 2020 6678                fx
+0002d930: 5f6f 705f 6366 6773 5f64 6963 7420 3d20  _op_cfgs_dict = 
+0002d940: 6678 5f6f 705f 6366 6773 2e74 6f5f 6469  fx_op_cfgs.to_di
+0002d950: 6374 2829 0a20 2020 2020 2020 2020 2020  ct().           
+0002d960: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0002d970: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0002d980: 785f 7375 625f 6f70 5f63 6667 7320 3d20  x_sub_op_cfgs = 
+0002d990: 6469 6374 2829 0a20 2020 2020 2020 2020  dict().         
+0002d9a0: 2020 2020 2020 2020 2020 2066 785f 7375             fx_su
+0002d9b0: 625f 6f70 5f63 6667 735b 2727 5d20 3d20  b_op_cfgs[''] = 
+0002d9c0: 4e6f 6e65 0a20 2020 2020 2020 2020 2020  None.           
+0002d9d0: 2020 2020 2020 2020 2066 785f 7375 625f           fx_sub_
+0002d9e0: 6f70 5f63 6667 735b 276d 6f64 756c 655f  op_cfgs['module_
+0002d9f0: 6e61 6d65 275d 203d 205b 5d0a 2020 2020  name'] = [].    
+0002da00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002da10: 6678 5f6f 705f 6366 6773 5f64 6963 7420  fx_op_cfgs_dict 
+0002da20: 3d20 6678 5f6f 705f 6366 6773 0a0a 2020  = fx_op_cfgs..  
+0002da30: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+0002da40: 7220 6b2c 2076 2069 6e20 6678 5f6f 705f  r k, v in fx_op_
+0002da50: 6366 6773 5f64 6963 745b 276d 6f64 756c  cfgs_dict['modul
+0002da60: 655f 6e61 6d65 275d 3a0a 2020 2020 2020  e_name']:.      
+0002da70: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0002da80: 206f 705f 6e61 6d65 2069 6e20 6b3a 0a20   op_name in k:. 
+0002da90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002daa0: 2020 2020 2020 2073 7562 5f6e 616d 6520         sub_name 
+0002dab0: 3d20 6b2e 7265 706c 6163 6528 6f70 5f6e  = k.replace(op_n
+0002dac0: 616d 6520 2b20 272e 272c 2027 272c 2031  ame + '.', '', 1
+0002dad0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0002dae0: 2020 2020 2020 2020 2020 6966 2076 6572            if ver
+0002daf0: 7369 6f6e 203e 2056 6572 7369 6f6e 2822  sion > Version("
+0002db00: 312e 3132 2e31 2229 3a20 2023 2070 7261  1.12.1"):  # pra
+0002db10: 676d 613a 206e 6f20 636f 7665 720a 2020  gma: no cover.  
+0002db20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002db30: 2020 2020 2020 2020 2020 2320 7079 6c69            # pyli
+0002db40: 6e74 3a20 6469 7361 626c 653d 6e6f 2d6d  nt: disable=no-m
+0002db50: 656d 6265 720a 2020 2020 2020 2020 2020  ember.          
+0002db60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002db70: 2020 6678 5f73 7562 5f6f 705f 6366 6773    fx_sub_op_cfgs
+0002db80: 2e73 6574 5f6d 6f64 756c 655f 6e61 6d65  .set_module_name
+0002db90: 2873 7562 5f6e 616d 652c 2076 290a 2020  (sub_name, v).  
+0002dba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002dbb0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+0002dbc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002dbd0: 2020 2020 2020 2020 6678 5f73 7562 5f6f          fx_sub_o
+0002dbe0: 705f 6366 6773 5b27 6d6f 6475 6c65 5f6e  p_cfgs['module_n
+0002dbf0: 616d 6527 5d2e 6170 7065 6e64 2828 7375  ame'].append((su
+0002dc00: 625f 6e61 6d65 2c20 7629 290a 0a20 2020  b_name, v))..   
+0002dc10: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0002dc20: 7479 7065 286d 6f64 756c 6529 2069 6e20  type(module) in 
+0002dc30: 6678 5f77 6869 7465 5f6c 6973 7420 616e  fx_white_list an
+0002dc40: 6420 7479 7065 286d 6f64 756c 6529 2021  d type(module) !
+0002dc50: 3d20 746f 7263 682e 6e6e 2e53 6571 7565  = torch.nn.Seque
+0002dc60: 6e74 6961 6c3a 0a20 2020 2020 2020 2020  ntial:.         
+0002dc70: 2020 2020 2020 2020 2020 2023 2044 6f6e             # Don
+0002dc80: 2774 2072 6561 6c6c 7920 6e65 6564 2061  't really need a
+0002dc90: 2071 7561 6e74 2f64 6571 7561 6e74 2c20   quant/dequant, 
+0002dca0: 6a75 7374 206d 6f76 6520 6e6e 2e45 6d62  just move nn.Emb
+0002dcb0: 6564 6469 6e67 205c 0a20 2020 2020 2020  edding \.       
+0002dcc0: 2020 2020 2020 2020 2020 2020 2023 2074               # t
+0002dcd0: 6f20 6c6f 7765 7220 6c65 7665 6c20 666f  o lower level fo
+0002dce0: 7220 6678 2064 6574 6563 7469 6f6e 2e0a  r fx detection..
+0002dcf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002dd00: 2020 2020 746d 705f 6d6f 6475 6c65 203d      tmp_module =
+0002dd10: 2074 6f72 6368 2e71 7561 6e74 697a 6174   torch.quantizat
+0002dd20: 696f 6e2e 5175 616e 7457 7261 7070 6572  ion.QuantWrapper
+0002dd30: 286d 6f64 756c 6529 0a20 2020 2020 2020  (module).       
+0002dd40: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+0002dd50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002dd60: 2020 2074 6d70 5f6d 6f64 756c 6520 3d20     tmp_module = 
+0002dd70: 6d6f 6475 6c65 0a20 2020 2020 2020 2020  module.         
+0002dd80: 2020 2020 2020 2023 2070 796c 696e 743a         # pylint:
+0002dd90: 2064 6973 6162 6c65 3d45 3131 3233 0a20   disable=E1123. 
+0002dda0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0002ddb0: 2070 7261 676d 613a 206e 6f20 636f 7665   pragma: no cove
+0002ddc0: 720a 2020 2020 2020 2020 2020 2020 2020  r.              
+0002ddd0: 2020 6966 2069 735f 7161 743a 0a20 2020    if is_qat:.   
+0002dde0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002ddf0: 206d 6f64 756c 655f 7072 6520 3d20 7072   module_pre = pr
+0002de00: 6570 6172 655f 7161 745f 6678 280a 2020  epare_qat_fx(.  
+0002de10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002de20: 2020 2020 2020 746d 705f 6d6f 6475 6c65        tmp_module
+0002de30: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0002de40: 2020 2020 2020 2020 2020 6678 5f73 7562            fx_sub
+0002de50: 5f6f 705f 6366 6773 2920 6966 2076 6572  _op_cfgs) if ver
+0002de60: 7369 6f6e 203c 3d20 5665 7273 696f 6e28  sion <= Version(
+0002de70: 2231 2e31 322e 3122 2920 656c 7365 2070  "1.12.1") else p
+0002de80: 7265 7061 7265 5f71 6174 5f66 7828 0a20  repare_qat_fx(. 
+0002de90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002dea0: 2020 2020 2020 2020 2020 2074 6d70 5f6d             tmp_m
+0002deb0: 6f64 756c 652c 2066 785f 7375 625f 6f70  odule, fx_sub_op
+0002dec0: 5f63 6667 732c 2065 7861 6d70 6c65 5f69  _cfgs, example_i
+0002ded0: 6e70 7574 733d 6578 616d 706c 655f 696e  nputs=example_in
+0002dee0: 7075 7473 290a 2020 2020 2020 2020 2020  puts).          
+0002def0: 2020 2020 2020 2320 7079 6c69 6e74 3a20        # pylint: 
+0002df00: 6469 7361 626c 653d 4531 3132 330a 2020  disable=E1123.  
+0002df10: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+0002df20: 7072 6167 6d61 3a20 6e6f 2063 6f76 6572  pragma: no cover
+0002df30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002df40: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0002df50: 2020 2020 2020 2020 2020 206d 6f64 756c             modul
+0002df60: 655f 7072 6520 3d20 7072 6570 6172 655f  e_pre = prepare_
+0002df70: 6678 280a 2020 2020 2020 2020 2020 2020  fx(.            
+0002df80: 2020 2020 2020 2020 2020 2020 746d 705f              tmp_
+0002df90: 6d6f 6475 6c65 2c0a 2020 2020 2020 2020  module,.        
+0002dfa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002dfb0: 6678 5f73 7562 5f6f 705f 6366 6773 2920  fx_sub_op_cfgs) 
+0002dfc0: 6966 2076 6572 7369 6f6e 203c 3d20 5665  if version <= Ve
+0002dfd0: 7273 696f 6e28 2231 2e31 322e 3122 2920  rsion("1.12.1") 
+0002dfe0: 656c 7365 2070 7265 7061 7265 5f66 7828  else prepare_fx(
+0002dff0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002e000: 2020 2020 2020 2020 2020 2020 2074 6d70               tmp
+0002e010: 5f6d 6f64 756c 652c 2066 785f 7375 625f  _module, fx_sub_
+0002e020: 6f70 5f63 6667 732c 2065 7861 6d70 6c65  op_cfgs, example
+0002e030: 5f69 6e70 7574 733d 6578 616d 706c 655f  _inputs=example_
+0002e040: 696e 7075 7473 290a 2020 2020 2020 2020  inputs).        
+0002e050: 2020 2020 2020 2020 746f 7263 685f 7574          torch_ut
+0002e060: 696c 732e 7574 696c 2e61 7070 656e 645f  ils.util.append_
+0002e070: 6174 7472 286d 6f64 756c 655f 7072 652c  attr(module_pre,
+0002e080: 206d 6f64 756c 652c 2066 785f 7768 6974   module, fx_whit
+0002e090: 655f 6c69 7374 290a 2020 2020 2020 2020  e_list).        
+0002e0a0: 2020 2020 2020 2020 7365 7461 7474 7228          setattr(
+0002e0b0: 6d6f 6465 6c2c 206e 616d 652c 206d 6f64  model, name, mod
+0002e0c0: 756c 655f 7072 6529 0a20 2020 2020 2020  ule_pre).       
+0002e0d0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0002e0e0: 2020 2020 2020 2020 2020 2050 7954 6f72             PyTor
+0002e0f0: 6368 5f46 5841 6461 7074 6f72 2e70 7265  ch_FXAdaptor.pre
+0002e100: 7061 7265 5f73 7562 5f67 7261 7068 2873  pare_sub_graph(s
+0002e110: 7562 5f6d 6f64 756c 655f 6c69 7374 2c0a  ub_module_list,.
+0002e120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e150: 2020 2020 6678 5f6f 705f 6366 6773 2c0a      fx_op_cfgs,.
+0002e160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e190: 2020 2020 6d6f 6475 6c65 2c0a 2020 2020      module,.    
+0002e1a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e1d0: 6f70 5f6e 616d 652c 0a20 2020 2020 2020  op_name,.       
+0002e1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e200: 2020 2020 2020 2020 2020 2020 2069 735f               is_
+0002e210: 7161 742c 0a20 2020 2020 2020 2020 2020  qat,.           
+0002e220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e240: 2020 2020 2020 2020 2065 7861 6d70 6c65           example
+0002e250: 5f69 6e70 7574 733d 6578 616d 706c 655f  _inputs=example_
+0002e260: 696e 7075 7473 290a 0a20 2020 2040 7374  inputs)..    @st
+0002e270: 6174 6963 6d65 7468 6f64 0a20 2020 2064  aticmethod.    d
+0002e280: 6566 2063 6f6e 7665 7274 5f73 7562 5f67  ef convert_sub_g
+0002e290: 7261 7068 2873 7562 5f6d 6f64 756c 655f  raph(sub_module_
+0002e2a0: 6c69 7374 2c20 6d6f 6465 6c2c 2070 7265  list, model, pre
+0002e2b0: 6669 782c 2063 7573 746f 6d5f 636f 6e66  fix, custom_conf
+0002e2c0: 6967 3d4e 6f6e 6529 3a0a 2020 2020 2020  ig=None):.      
+0002e2d0: 2020 2222 2253 7461 7469 6320 6d65 7468    """Static meth
+0002e2e0: 6f64 2074 6f20 636f 6e76 6572 7420 7375  od to convert su
+0002e2f0: 6220 6d6f 6475 6c65 7320 7265 6375 7273  b modules recurs
+0002e300: 6976 656c 792e 0a0a 2020 2020 2020 2020  ively...        
+0002e310: 4172 6773 3a0a 2020 2020 2020 2020 2020  Args:.          
+0002e320: 2020 7375 625f 6d6f 6475 6c65 5f6c 6973    sub_module_lis
+0002e330: 7420 286c 6973 7429 3a20 636f 6e74 6169  t (list): contai
+0002e340: 6e73 2074 6865 206e 616d 6520 6f66 2074  ns the name of t
+0002e350: 7261 6365 6162 6c65 2073 7562 206d 6f64  raceable sub mod
+0002e360: 756c 6573 0a20 2020 2020 2020 2020 2020  ules.           
+0002e370: 206d 6f64 656c 2028 6469 7229 3a20 696e   model (dir): in
+0002e380: 7075 7420 6d6f 6465 6c20 7768 6963 6820  put model which 
+0002e390: 6973 2070 7265 7061 7265 6420 5079 546f  is prepared PyTo
+0002e3a0: 7263 6820 6d6f 6465 6c2e 0a20 2020 2020  rch model..     
+0002e3b0: 2020 2020 2020 2070 7265 6669 7820 2873         prefix (s
+0002e3c0: 7472 696e 6729 3a20 7072 6566 6978 206f  tring): prefix o
+0002e3d0: 6620 6f70 206e 616d 650a 2020 2020 2020  f op name.      
+0002e3e0: 2020 2020 2020 6375 7374 6f6d 5f63 6f6e        custom_con
+0002e3f0: 6669 6720 2864 6963 7429 3a20 6375 7374  fig (dict): cust
+0002e400: 6f6d 206e 6f6e 2074 7261 6365 6162 6c65  om non traceable
+0002e410: 206d 6f64 756c 6520 6469 6374 0a0a 2020   module dict..  
+0002e420: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
+0002e430: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+0002e440: 2028 6469 7229 3a20 6f75 7470 7574 206d   (dir): output m
+0002e450: 6f64 656c 2077 6869 6368 2069 7320 6120  odel which is a 
+0002e460: 636f 6e76 6572 7465 6420 5079 546f 7263  converted PyTorc
+0002e470: 6820 696e 7438 206d 6f64 656c 2e0a 2020  h int8 model..  
+0002e480: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0002e490: 2020 6672 6f6d 2074 6f72 6368 2e71 7561    from torch.qua
+0002e4a0: 6e74 697a 6174 696f 6e2e 7175 616e 7469  ntization.quanti
+0002e4b0: 7a65 5f66 7820 696d 706f 7274 2063 6f6e  ze_fx import con
+0002e4c0: 7665 7274 5f66 780a 2020 2020 2020 2020  vert_fx.        
+0002e4d0: 666f 7220 6e61 6d65 2c20 6d6f 6475 6c65  for name, module
+0002e4e0: 2069 6e20 6d6f 6465 6c2e 6e61 6d65 645f   in model.named_
+0002e4f0: 6368 696c 6472 656e 2829 3a0a 2020 2020  children():.    
+0002e500: 2020 2020 2020 2020 6f70 5f6e 616d 6520          op_name 
+0002e510: 3d20 7072 6566 6978 202b 2027 2e27 202b  = prefix + '.' +
+0002e520: 206e 616d 6520 6966 2070 7265 6669 7820   name if prefix 
+0002e530: 213d 2027 2720 656c 7365 206e 616d 650a  != '' else name.
+0002e540: 2020 2020 2020 2020 2020 2020 2320 736b              # sk
+0002e550: 6970 2063 7573 746f 6d20 6e6f 6e20 7472  ip custom non tr
+0002e560: 6163 6561 626c 6520 6d6f 6475 6c65 2069  aceable module i
+0002e570: 6e20 6669 6e65 2d67 7261 696e 6564 2046  n fine-grained F
+0002e580: 580a 2020 2020 2020 2020 2020 2020 6966  X.            if
+0002e590: 2063 7573 746f 6d5f 636f 6e66 6967 3a0a   custom_config:.
+0002e5a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e5b0: 6966 2028 276e 6f6e 5f74 7261 6365 6162  if ('non_traceab
+0002e5c0: 6c65 5f6d 6f64 756c 655f 6e61 6d65 2720  le_module_name' 
+0002e5d0: 696e 2063 7573 746f 6d5f 636f 6e66 6967  in custom_config
+0002e5e0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0002e5f0: 2020 2020 2061 6e64 206f 705f 6e61 6d65       and op_name
+0002e600: 2069 6e20 6375 7374 6f6d 5f63 6f6e 6669   in custom_confi
+0002e610: 675b 276e 6f6e 5f74 7261 6365 6162 6c65  g['non_traceable
+0002e620: 5f6d 6f64 756c 655f 6e61 6d65 275d 2920  _module_name']) 
+0002e630: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+0002e640: 2020 2020 6f72 2028 276e 6f6e 5f74 7261      or ('non_tra
+0002e650: 6365 6162 6c65 5f6d 6f64 756c 655f 636c  ceable_module_cl
+0002e660: 6173 7327 2069 6e20 6375 7374 6f6d 5f63  ass' in custom_c
+0002e670: 6f6e 6669 6720 5c0a 2020 2020 2020 2020  onfig \.        
+0002e680: 2020 2020 2020 2020 2020 616e 6420 6973            and is
+0002e690: 696e 7374 616e 6365 286d 6f64 756c 652c  instance(module,
+0002e6a0: 2074 7570 6c65 2863 7573 746f 6d5f 636f   tuple(custom_co
+0002e6b0: 6e66 6967 5b27 6e6f 6e5f 7472 6163 6561  nfig['non_tracea
+0002e6c0: 626c 655f 6d6f 6475 6c65 5f63 6c61 7373  ble_module_class
+0002e6d0: 275d 2929 293a 0a20 2020 2020 2020 2020  ']))):.         
+0002e6e0: 2020 2020 2020 2020 2020 2063 6f6e 7469             conti
+0002e6f0: 6e75 650a 2020 2020 2020 2020 2020 2020  nue.            
+0002e700: 6966 206f 705f 6e61 6d65 2069 6e20 7375  if op_name in su
+0002e710: 625f 6d6f 6475 6c65 5f6c 6973 743a 0a20  b_module_list:. 
+0002e720: 2020 2020 2020 2020 2020 2020 2020 206d                 m
+0002e730: 6f64 756c 655f 636f 6e20 3d20 636f 6e76  odule_con = conv
+0002e740: 6572 745f 6678 286d 6f64 756c 6529 0a20  ert_fx(module). 
+0002e750: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+0002e760: 6f72 6368 5f75 7469 6c73 2e75 7469 6c2e  orch_utils.util.
+0002e770: 6170 7065 6e64 5f61 7474 7228 6d6f 6475  append_attr(modu
+0002e780: 6c65 5f63 6f6e 2c20 6d6f 6475 6c65 290a  le_con, module).
+0002e790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e7a0: 7365 7461 7474 7228 6d6f 6465 6c2c 206e  setattr(model, n
+0002e7b0: 616d 652c 206d 6f64 756c 655f 636f 6e29  ame, module_con)
+0002e7c0: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
+0002e7d0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+0002e7e0: 2020 2050 7954 6f72 6368 5f46 5841 6461     PyTorch_FXAda
+0002e7f0: 7074 6f72 2e63 6f6e 7665 7274 5f73 7562  ptor.convert_sub
+0002e800: 5f67 7261 7068 2873 7562 5f6d 6f64 756c  _graph(sub_modul
+0002e810: 655f 6c69 7374 2c20 5c0a 2020 2020 2020  e_list, \.      
+0002e820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e830: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002e840: 2020 2020 2020 2020 2020 2020 2020 6d6f                mo
+0002e850: 6475 6c65 2c20 6f70 5f6e 616d 6529 0a0a  dule, op_name)..
+0002e860: 2020 2020 4064 756d 705f 656c 6170 7365      @dump_elapse
+0002e870: 645f 7469 6d65 2822 5061 7373 2071 7565  d_time("Pass que
+0002e880: 7279 2066 7261 6d65 776f 726b 2063 6170  ry framework cap
+0002e890: 6162 696c 6974 7922 290a 2020 2020 6465  ability").    de
+0002e8a0: 6620 7175 6572 795f 6677 5f63 6170 6162  f query_fw_capab
+0002e8b0: 696c 6974 7928 7365 6c66 2c20 6d6f 6465  ility(self, mode
+0002e8c0: 6c29 3a0a 2020 2020 2020 2020 2222 2254  l):.        """T
+0002e8d0: 6869 7320 6973 2061 2068 656c 7065 7220  his is a helper 
+0002e8e0: 6675 6e63 7469 6f6e 2074 6f20 6765 7420  function to get 
+0002e8f0: 616c 6c20 7175 616e 7469 7a61 626c 6520  all quantizable 
+0002e900: 6f70 7320 6672 6f6d 206d 6f64 656c 2e0a  ops from model..
+0002e910: 0a20 2020 2020 2020 2041 7267 733a 0a20  .        Args:. 
+0002e920: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+0002e930: 2028 6f62 6a65 6374 293a 2069 6e70 7574   (object): input
+0002e940: 206d 6f64 656c 2077 6869 6368 2069 7320   model which is 
+0002e950: 4e65 7572 616c 2043 6f6d 7072 6573 736f  Neural Compresso
+0002e960: 7220 6d6f 6465 6c0a 0a20 2020 2020 2020  r model..       
+0002e970: 2052 6574 7572 6e73 3a0a 2020 2020 2020   Returns:.      
+0002e980: 2020 2020 2020 715f 6361 7061 6269 6c69        q_capabili
+0002e990: 7479 2028 6469 6374 696f 6e61 7279 293a  ty (dictionary):
+0002e9a0: 2074 756e 696e 6720 6361 7061 6269 6c69   tuning capabili
+0002e9b0: 7479 2066 6f72 2065 6163 6820 6f70 2066  ty for each op f
+0002e9c0: 726f 6d20 6d6f 6465 6c2e 0a20 2020 2020  rom model..     
+0002e9d0: 2020 2022 2222 0a20 2020 2020 2020 2073     """.        s
+0002e9e0: 656c 662e 7072 655f 6f70 7469 6d69 7a65  elf.pre_optimize
+0002e9f0: 645f 6d6f 6465 6c20 3d20 6d6f 6465 6c0a  d_model = model.
+0002ea00: 2020 2020 2020 2020 746d 705f 6d6f 6465          tmp_mode
+0002ea10: 6c20 3d20 6d6f 6465 6c2e 5f6d 6f64 656c  l = model._model
+0002ea20: 0a20 2020 2020 2020 2074 6d70 5f6d 6f64  .        tmp_mod
+0002ea30: 656c 203d 2073 656c 662e 6675 7365 5f66  el = self.fuse_f
+0002ea40: 785f 6d6f 6465 6c28 6d6f 6465 6c2c 2069  x_model(model, i
+0002ea50: 735f 7161 743d 2873 656c 662e 6170 7072  s_qat=(self.appr
+0002ea60: 6f61 6368 203d 3d20 2271 7561 6e74 5f61  oach == "quant_a
+0002ea70: 7761 7265 5f74 7261 696e 696e 6722 2929  ware_training"))
+0002ea80: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0002ea90: 7365 6c66 2e5f 6765 745f 7175 616e 7469  self._get_quanti
+0002eaa0: 7a61 626c 655f 6f70 7328 746d 705f 6d6f  zable_ops(tmp_mo
+0002eab0: 6465 6c29 0a0a 2020 2020 6465 6620 6675  del)..    def fu
+0002eac0: 7365 5f66 785f 6d6f 6465 6c28 7365 6c66  se_fx_model(self
+0002ead0: 2c20 6d6f 6465 6c2c 2069 735f 7161 7429  , model, is_qat)
+0002eae0: 3a0a 2020 2020 2020 2020 2222 2254 6869  :.        """Thi
+0002eaf0: 7320 6973 2061 2068 656c 7065 7220 6675  s is a helper fu
+0002eb00: 6e63 7469 6f6e 2074 6f20 6765 7420 6675  nction to get fu
+0002eb10: 7365 6420 6678 206d 6f64 656c 2066 6f72  sed fx model for
+0002eb20: 2050 7954 6f72 6368 5f46 5841 6461 7074   PyTorch_FXAdapt
+0002eb30: 6f72 2e0a 0a20 2020 2020 2020 2041 7267  or...        Arg
+0002eb40: 733a 0a20 2020 2020 2020 2020 2020 206d  s:.            m
+0002eb50: 6f64 656c 2028 6f62 6a65 6374 293a 2069  odel (object): i
+0002eb60: 6e70 7574 206d 6f64 656c 2077 6869 6368  nput model which
+0002eb70: 2069 7320 4e65 7572 616c 2043 6f6d 7072   is Neural Compr
+0002eb80: 6573 736f 7220 6d6f 6465 6c2e 0a20 2020  essor model..   
+0002eb90: 2020 2020 2020 2020 2069 735f 7161 7420           is_qat 
+0002eba0: 2862 6f6f 6c29 3a20 6368 6563 6b20 7175  (bool): check qu
+0002ebb0: 616e 7469 7a61 7469 6f6e 2061 7070 726f  antization appro
+0002ebc0: 6163 6820 6973 2071 6174 206f 7220 6e6f  ach is qat or no
+0002ebd0: 742e 0a0a 2020 2020 2020 2020 5265 7475  t...        Retu
+0002ebe0: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
+0002ebf0: 2066 7573 6564 5f6d 6f64 656c 2028 4772   fused_model (Gr
+0002ec00: 6170 684d 6f64 756c 6529 3a20 6675 7365  aphModule): fuse
+0002ec10: 6420 4772 6170 684d 6f64 756c 6520 6d6f  d GraphModule mo
+0002ec20: 6465 6c20 6672 6f6d 2074 6f72 6368 2e66  del from torch.f
+0002ec30: 782e 0a20 2020 2020 2020 2022 2222 0a20  x..        """. 
+0002ec40: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
+0002ec50: 2020 2020 2020 2020 746d 705f 6d6f 6465          tmp_mode
+0002ec60: 6c20 3d20 636f 7079 2e64 6565 7063 6f70  l = copy.deepcop
+0002ec70: 7928 6d6f 6465 6c2e 5f6d 6f64 656c 290a  y(model._model).
+0002ec80: 2020 2020 2020 2020 6578 6365 7074 2045          except E
+0002ec90: 7863 6570 7469 6f6e 2061 7320 653a 0a20  xception as e:. 
+0002eca0: 2020 2020 2020 2020 2020 2074 6d70 5f6d             tmp_m
+0002ecb0: 6f64 656c 203d 206d 6f64 656c 2e5f 6d6f  odel = model._mo
+0002ecc0: 6465 6c0a 2020 2020 2020 2020 2020 2020  del.            
+0002ecd0: 6c6f 6767 6572 2e77 6172 6e69 6e67 2822  logger.warning("
+0002ece0: 4465 6570 636f 7079 2066 6169 6c65 643a  Deepcopy failed:
+0002ecf0: 207b 7d2c 2069 6e70 6c61 6365 3d54 7275   {}, inplace=Tru
+0002ed00: 6520 6e6f 7721 222e 666f 726d 6174 2872  e now!".format(r
+0002ed10: 6570 7228 6529 2929 0a0a 2020 2020 2020  epr(e)))..      
+0002ed20: 2020 746d 705f 6d6f 6465 6c2e 7472 6169    tmp_model.trai
+0002ed30: 6e28 2920 6966 2069 735f 7161 7420 656c  n() if is_qat el
+0002ed40: 7365 2074 6d70 5f6d 6f64 656c 2e65 7661  se tmp_model.eva
+0002ed50: 6c28 290a 2020 2020 2020 2020 6672 6f6d  l().        from
+0002ed60: 2074 6f72 6368 2e66 7820 696d 706f 7274   torch.fx import
+0002ed70: 2047 7261 7068 4d6f 6475 6c65 0a20 2020   GraphModule.   
+0002ed80: 2020 2020 2066 726f 6d20 746f 7263 682e       from torch.
+0002ed90: 7175 616e 7469 7a61 7469 6f6e 2e71 7561  quantization.qua
+0002eda0: 6e74 697a 655f 6678 2069 6d70 6f72 7420  ntize_fx import 
+0002edb0: 5f66 7573 655f 6678 2c20 5175 616e 7469  _fuse_fx, Quanti
+0002edc0: 7a61 7469 6f6e 5472 6163 6572 0a20 2020  zationTracer.   
+0002edd0: 2020 2020 2069 6620 6d6f 6465 6c2e 6b77       if model.kw
+0002ede0: 6172 6773 2069 7320 6e6f 7420 4e6f 6e65  args is not None
+0002edf0: 3a0a 2020 2020 2020 2020 2020 2020 7072  :.            pr
+0002ee00: 6570 6172 655f 6375 7374 6f6d 5f63 6f6e  epare_custom_con
+0002ee10: 6669 675f 6469 6374 203d 206d 6f64 656c  fig_dict = model
+0002ee20: 2e6b 7761 7267 732e 6765 7428 2770 7265  .kwargs.get('pre
+0002ee30: 7061 7265 5f63 7573 746f 6d5f 636f 6e66  pare_custom_conf
+0002ee40: 6967 5f64 6963 7427 2c20 7b7d 290a 2020  ig_dict', {}).  
+0002ee50: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+0002ee60: 2020 2020 2020 2020 7072 6570 6172 655f          prepare_
+0002ee70: 6375 7374 6f6d 5f63 6f6e 6669 675f 6469  custom_config_di
+0002ee80: 6374 203d 207b 7d0a 2020 2020 2020 2020  ct = {}.        
+0002ee90: 736b 6970 7065 645f 6d6f 6475 6c65 5f6e  skipped_module_n
+0002eea0: 616d 6573 203d 2070 7265 7061 7265 5f63  ames = prepare_c
+0002eeb0: 7573 746f 6d5f 636f 6e66 6967 5f64 6963  ustom_config_dic
+0002eec0: 742e 6765 7428 5c0a 2020 2020 2020 2020  t.get(\.        
+0002eed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002eee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002eef0: 2020 2020 276e 6f6e 5f74 7261 6365 6162      'non_traceab
+0002ef00: 6c65 5f6d 6f64 756c 655f 6e61 6d65 272c  le_module_name',
+0002ef10: 205b 5d29 0a20 2020 2020 2020 2073 6b69   []).        ski
+0002ef20: 7070 6564 5f6d 6f64 756c 655f 636c 6173  pped_module_clas
+0002ef30: 7365 7320 3d20 7072 6570 6172 655f 6375  ses = prepare_cu
+0002ef40: 7374 6f6d 5f63 6f6e 6669 675f 6469 6374  stom_config_dict
+0002ef50: 2e67 6574 285c 0a20 2020 2020 2020 2020  .get(\.         
+0002ef60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002ef70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002ef80: 2020 2027 6e6f 6e5f 7472 6163 6561 626c     'non_traceabl
+0002ef90: 655f 6d6f 6475 6c65 5f63 6c61 7373 272c  e_module_class',
+0002efa0: 205b 5d29 0a20 2020 2020 2020 2074 7279   []).        try
+0002efb0: 3a0a 2020 2020 2020 2020 2020 2020 7472  :.            tr
+0002efc0: 6163 6572 203d 2051 7561 6e74 697a 6174  acer = Quantizat
+0002efd0: 696f 6e54 7261 6365 7228 736b 6970 7065  ionTracer(skippe
+0002efe0: 645f 6d6f 6475 6c65 5f6e 616d 6573 2c20  d_module_names, 
+0002eff0: 736b 6970 7065 645f 6d6f 6475 6c65 5f63  skipped_module_c
+0002f000: 6c61 7373 6573 290a 2020 2020 2020 2020  lasses).        
+0002f010: 2020 2020 6772 6170 685f 6d6f 6475 6c65      graph_module
+0002f020: 203d 2047 7261 7068 4d6f 6475 6c65 2874   = GraphModule(t
+0002f030: 6d70 5f6d 6f64 656c 2c20 7472 6163 6572  mp_model, tracer
+0002f040: 2e74 7261 6365 2874 6d70 5f6d 6f64 656c  .trace(tmp_model
+0002f050: 2929 0a20 2020 2020 2020 2020 2020 2069  )).            i
+0002f060: 6620 7365 6c66 2e76 6572 7369 6f6e 2e72  f self.version.r
+0002f070: 656c 6561 7365 203e 3d20 5665 7273 696f  elease >= Versio
+0002f080: 6e28 2231 2e31 332e 3022 292e 7265 6c65  n("1.13.0").rele
+0002f090: 6173 653a 2020 2320 7072 6167 6d61 3a20  ase:  # pragma: 
+0002f0a0: 6e6f 2063 6f76 6572 0a20 2020 2020 2020  no cover.       
+0002f0b0: 2020 2020 2020 2020 2023 2070 796c 696e           # pylin
+0002f0c0: 743a 2064 6973 6162 6c65 3d45 3131 3234  t: disable=E1124
+0002f0d0: 2c20 4531 3132 330a 2020 2020 2020 2020  , E1123.        
+0002f0e0: 2020 2020 2020 2020 6675 7365 645f 6d6f          fused_mo
+0002f0f0: 6465 6c20 3d20 5f66 7573 655f 6678 2867  del = _fuse_fx(g
+0002f100: 7261 7068 5f6d 6f64 756c 652c 0a20 2020  raph_module,.   
+0002f110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f130: 2020 2020 2069 735f 7161 742c 0a20 2020       is_qat,.   
+0002f140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f160: 2020 2020 2066 7573 655f 6375 7374 6f6d       fuse_custom
+0002f170: 5f63 6f6e 6669 673d 7072 6570 6172 655f  _config=prepare_
+0002f180: 6375 7374 6f6d 5f63 6f6e 6669 675f 6469  custom_config_di
+0002f190: 6374 290a 2020 2020 2020 2020 2020 2020  ct).            
+0002f1a0: 656c 6966 2073 656c 662e 7665 7273 696f  elif self.versio
+0002f1b0: 6e2e 7265 6c65 6173 6520 3e3d 2056 6572  n.release >= Ver
+0002f1c0: 7369 6f6e 2822 312e 3131 2e30 2229 2e72  sion("1.11.0").r
+0002f1d0: 656c 6561 7365 3a20 2023 2070 7261 676d  elease:  # pragm
+0002f1e0: 613a 206e 6f20 636f 7665 720a 2020 2020  a: no cover.    
+0002f1f0: 2020 2020 2020 2020 2020 2020 2320 7079              # py
+0002f200: 6c69 6e74 3a20 6469 7361 626c 653d 4531  lint: disable=E1
+0002f210: 3132 340a 2020 2020 2020 2020 2020 2020  124.            
+0002f220: 2020 2020 6675 7365 645f 6d6f 6465 6c20      fused_model 
+0002f230: 3d20 5f66 7573 655f 6678 2867 7261 7068  = _fuse_fx(graph
+0002f240: 5f6d 6f64 756c 652c 0a20 2020 2020 2020  _module,.       
+0002f250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f270: 2069 735f 7161 742c 0a20 2020 2020 2020   is_qat,.       
+0002f280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f2a0: 2066 7573 655f 6375 7374 6f6d 5f63 6f6e   fuse_custom_con
+0002f2b0: 6669 675f 6469 6374 3d70 7265 7061 7265  fig_dict=prepare
+0002f2c0: 5f63 7573 746f 6d5f 636f 6e66 6967 5f64  _custom_config_d
+0002f2d0: 6963 7429 0a20 2020 2020 2020 2020 2020  ict).           
+0002f2e0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0002f2f0: 2020 2020 2020 2066 7573 6564 5f6d 6f64         fused_mod
+0002f300: 656c 203d 205f 6675 7365 5f66 7828 6772  el = _fuse_fx(gr
+0002f310: 6170 685f 6d6f 6475 6c65 2c20 7072 6570  aph_module, prep
+0002f320: 6172 655f 6375 7374 6f6d 5f63 6f6e 6669  are_custom_confi
+0002f330: 675f 6469 6374 290a 2020 2020 2020 2020  g_dict).        
+0002f340: 6578 6365 7074 3a0a 2020 2020 2020 2020  except:.        
+0002f350: 2020 2020 7365 6c66 2e73 7562 5f6d 6f64      self.sub_mod
+0002f360: 756c 655f 6c69 7374 203d 205b 5d0a 2020  ule_list = [].  
+0002f370: 2020 2020 2020 2020 2020 6d6f 6475 6c65            module
+0002f380: 5f64 6963 7420 3d20 6469 6374 2874 6d70  _dict = dict(tmp
+0002f390: 5f6d 6f64 656c 2e6e 616d 6564 5f6d 6f64  _model.named_mod
+0002f3a0: 756c 6573 2829 290a 2020 2020 2020 2020  ules()).        
+0002f3b0: 2020 2020 7365 6c66 2e5f 6675 7365 5f73      self._fuse_s
+0002f3c0: 7562 5f67 7261 7068 2874 6d70 5f6d 6f64  ub_graph(tmp_mod
+0002f3d0: 656c 2c20 6d6f 6475 6c65 5f64 6963 742c  el, module_dict,
+0002f3e0: 2070 7265 6669 783d 2727 2c20 6973 5f71   prefix='', is_q
+0002f3f0: 6174 3d69 735f 7161 7429 0a20 2020 2020  at=is_qat).     
+0002f400: 2020 2020 2020 2066 7573 6564 5f6d 6f64         fused_mod
+0002f410: 656c 203d 2074 6d70 5f6d 6f64 656c 0a20  el = tmp_model. 
+0002f420: 2020 2020 2020 2072 6574 7572 6e20 6675         return fu
+0002f430: 7365 645f 6d6f 6465 6c0a 0a20 2020 2064  sed_model..    d
+0002f440: 6566 205f 6675 7365 5f73 7562 5f67 7261  ef _fuse_sub_gra
+0002f450: 7068 2873 656c 662c 206d 6f64 656c 2c20  ph(self, model, 
+0002f460: 6d6f 6475 6c65 5f64 6963 742c 2070 7265  module_dict, pre
+0002f470: 6669 782c 2069 735f 7161 7429 3a0a 2020  fix, is_qat):.  
+0002f480: 2020 2020 2020 2222 2254 6869 7320 6973        """This is
+0002f490: 2061 2068 656c 7065 7220 6675 6e63 7469   a helper functi
+0002f4a0: 6f6e 2074 6f20 6765 7420 6675 7365 6420  on to get fused 
+0002f4b0: 6678 2073 7562 206d 6f64 756c 6573 2072  fx sub modules r
+0002f4c0: 6563 7572 7369 7665 6c79 2066 6f72 2050  ecursively for P
+0002f4d0: 7954 6f72 6368 5f46 5841 6461 7074 6f72  yTorch_FXAdaptor
+0002f4e0: 2e0a 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
+0002f4f0: 0a20 2020 2020 2020 2020 2020 206d 6f64  .            mod
+0002f500: 656c 2028 6f62 6a65 6374 293a 2069 6e70  el (object): inp
+0002f510: 7574 206d 6f64 656c 2077 6869 6368 2069  ut model which i
+0002f520: 7320 5079 546f 7263 6820 6d6f 6465 6c2e  s PyTorch model.
+0002f530: 0a20 2020 2020 2020 2020 2020 206d 6f64  .            mod
+0002f540: 756c 655f 6469 6374 2028 6469 6374 293a  ule_dict (dict):
+0002f550: 206d 6f64 756c 6520 6469 6374 206f 6620   module dict of 
+0002f560: 696e 7075 7420 6d6f 6465 6c2e 0a20 2020  input model..   
+0002f570: 2020 2020 2020 2020 2070 7265 6669 7820           prefix 
+0002f580: 2873 7472 696e 6729 3a20 7072 6566 6978  (string): prefix
+0002f590: 206f 6620 6f70 206e 616d 652e 0a20 2020   of op name..   
+0002f5a0: 2020 2020 2020 2020 2069 735f 7161 7420           is_qat 
+0002f5b0: 2862 6f6f 6c29 3a20 6368 6563 6b20 7175  (bool): check qu
+0002f5c0: 616e 7469 7a61 7469 6f6e 2061 7070 726f  antization appro
+0002f5d0: 6163 6820 6973 2071 6174 206f 7220 6e6f  ach is qat or no
+0002f5e0: 742e 0a0a 2020 2020 2020 2020 5265 7475  t...        Retu
+0002f5f0: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
+0002f600: 2066 7573 6564 5f6d 6f64 656c 2028 4772   fused_model (Gr
+0002f610: 6170 684d 6f64 756c 6529 3a20 6675 7365  aphModule): fuse
+0002f620: 6420 4772 6170 684d 6f64 756c 6520 6d6f  d GraphModule mo
+0002f630: 6465 6c20 6672 6f6d 2074 6f72 6368 2e66  del from torch.f
+0002f640: 782e 0a20 2020 2020 2020 2022 2222 0a20  x..        """. 
+0002f650: 2020 2020 2020 2066 726f 6d20 746f 7263         from torc
+0002f660: 682e 7175 616e 7469 7a61 7469 6f6e 2e71  h.quantization.q
+0002f670: 7561 6e74 697a 655f 6678 2069 6d70 6f72  uantize_fx impor
+0002f680: 7420 5f66 7573 655f 6678 0a20 2020 2020  t _fuse_fx.     
+0002f690: 2020 2069 6d70 6f72 7420 746f 7263 682e     import torch.
+0002f6a0: 7175 616e 7469 7a61 7469 6f6e 2e71 7561  quantization.qua
+0002f6b0: 6e74 697a 6174 696f 6e5f 6d61 7070 696e  ntization_mappin
+0002f6c0: 6773 2061 7320 7471 716d 0a20 2020 2020  gs as tqqm.     
+0002f6d0: 2020 2066 785f 7768 6974 655f 6c69 7374     fx_white_list
+0002f6e0: 203d 2074 7171 6d2e 6765 745f 6465 6661   = tqqm.get_defa
+0002f6f0: 756c 745f 7163 6f6e 6669 675f 7072 6f70  ult_qconfig_prop
+0002f700: 6167 6174 696f 6e5f 6c69 7374 2829 0a20  agation_list(). 
+0002f710: 2020 2020 2020 2066 6f72 206e 616d 652c         for name,
+0002f720: 206d 6f64 756c 6520 696e 206d 6f64 656c   module in model
+0002f730: 2e6e 616d 6564 5f63 6869 6c64 7265 6e28  .named_children(
+0002f740: 293a 0a20 2020 2020 2020 2020 2020 2023  ):.            #
+0002f750: 2046 5820 5141 5420 6361 6e6e 6f74 2066   FX QAT cannot f
+0002f760: 616c 6c62 6163 6b20 6e6e 2e44 726f 706f  allback nn.Dropo
+0002f770: 7574 2066 726f 6d20 7472 6169 6e20 6d6f  ut from train mo
+0002f780: 6465 2074 6f20 6576 616c 0a20 2020 2020  de to eval.     
+0002f790: 2020 2020 2020 2069 6620 7479 7065 286d         if type(m
+0002f7a0: 6f64 756c 6529 203d 3d20 746f 7263 682e  odule) == torch.
+0002f7b0: 6e6e 2e44 726f 706f 7574 3a20 2023 2070  nn.Dropout:  # p
+0002f7c0: 7261 676d 613a 206e 6f20 636f 7665 720a  ragma: no cover.
+0002f7d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f7e0: 636f 6e74 696e 7565 0a20 2020 2020 2020  continue.       
+0002f7f0: 2020 2020 206f 705f 6e61 6d65 203d 2070       op_name = p
+0002f800: 7265 6669 7820 2b20 272e 2720 2b20 6e61  refix + '.' + na
+0002f810: 6d65 2069 6620 7072 6566 6978 2021 3d20  me if prefix != 
+0002f820: 2727 2065 6c73 6520 6e61 6d65 0a20 2020  '' else name.   
+0002f830: 2020 2020 2020 2020 2069 6620 6f70 5f6e           if op_n
+0002f840: 616d 6520 6e6f 7420 696e 206d 6f64 756c  ame not in modul
+0002f850: 655f 6469 6374 3a0a 2020 2020 2020 2020  e_dict:.        
+0002f860: 2020 2020 2020 2020 636f 6e74 696e 7565          continue
+0002f870: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0002f880: 7479 7065 286d 6f64 756c 6529 2069 6e20  type(module) in 
+0002f890: 6678 5f77 6869 7465 5f6c 6973 7420 5c0a  fx_white_list \.
+0002f8a0: 2020 2020 2020 2020 2020 2020 2020 616e                an
+0002f8b0: 6420 7479 7065 286d 6f64 756c 6529 2021  d type(module) !
+0002f8c0: 3d20 746f 7263 682e 6e6e 2e53 6571 7565  = torch.nn.Seque
+0002f8d0: 6e74 6961 6c3a 0a20 2020 2020 2020 2020  ntial:.         
+0002f8e0: 2020 2020 2020 206d 6f64 756c 6520 3d20         module = 
+0002f8f0: 746f 7263 682e 7175 616e 7469 7a61 7469  torch.quantizati
+0002f900: 6f6e 2e51 7561 6e74 5772 6170 7065 7228  on.QuantWrapper(
+0002f910: 6d6f 6475 6c65 290a 2020 2020 2020 2020  module).        
+0002f920: 2020 2020 6966 2073 656c 662e 5f63 6865      if self._che
+0002f930: 636b 5f64 796e 616d 6963 5f63 6f6e 7472  ck_dynamic_contr
+0002f940: 6f6c 286d 6f64 756c 6529 3a0a 2020 2020  ol(module):.    
+0002f950: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0002f960: 2e5f 6675 7365 5f73 7562 5f67 7261 7068  ._fuse_sub_graph
+0002f970: 286d 6f64 756c 652c 206d 6f64 756c 655f  (module, module_
+0002f980: 6469 6374 2c20 6f70 5f6e 616d 652c 2069  dict, op_name, i
+0002f990: 735f 7161 743d 6973 5f71 6174 290a 2020  s_qat=is_qat).  
+0002f9a0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+0002f9b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002f9c0: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
+0002f9d0: 2020 2020 2020 2020 2067 7261 7068 5f6d           graph_m
+0002f9e0: 6f64 756c 6520 3d20 746f 7263 682e 6678  odule = torch.fx
+0002f9f0: 2e73 796d 626f 6c69 635f 7472 6163 6528  .symbolic_trace(
+0002fa00: 6d6f 6475 6c65 290a 2020 2020 2020 2020  module).        
+0002fa10: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+0002fa20: 656c 662e 7665 7273 696f 6e2e 7265 6c65  elf.version.rele
+0002fa30: 6173 6520 3e3d 2056 6572 7369 6f6e 2822  ase >= Version("
+0002fa40: 312e 3131 2e30 2229 2e72 656c 6561 7365  1.11.0").release
+0002fa50: 3a20 2023 2070 7261 676d 613a 206e 6f20  :  # pragma: no 
+0002fa60: 636f 7665 720a 2020 2020 2020 2020 2020  cover.          
+0002fa70: 2020 2020 2020 2020 2020 2020 2020 6675                fu
+0002fa80: 7365 645f 6d6f 6465 6c20 3d20 5f66 7573  sed_model = _fus
+0002fa90: 655f 6678 2867 7261 7068 5f6d 6f64 756c  e_fx(graph_modul
+0002faa0: 652c 2069 735f 7161 7429 0a20 2020 2020  e, is_qat).     
+0002fab0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0002fac0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0002fad0: 2020 2020 2020 2020 2020 2020 2066 7573               fus
+0002fae0: 6564 5f6d 6f64 656c 203d 205f 6675 7365  ed_model = _fuse
+0002faf0: 5f66 7828 6772 6170 685f 6d6f 6475 6c65  _fx(graph_module
+0002fb00: 2920 2023 2070 796c 696e 743a 2064 6973  )  # pylint: dis
+0002fb10: 6162 6c65 3d45 3131 3230 0a20 2020 2020  able=E1120.     
+0002fb20: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0002fb30: 6574 6174 7472 286d 6f64 656c 2c20 6e61  etattr(model, na
+0002fb40: 6d65 2c20 6675 7365 645f 6d6f 6465 6c29  me, fused_model)
+0002fb50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002fb60: 2020 2020 2073 656c 662e 7375 625f 6d6f       self.sub_mo
+0002fb70: 6475 6c65 5f6c 6973 742e 6170 7065 6e64  dule_list.append
+0002fb80: 286f 705f 6e61 6d65 290a 2020 2020 2020  (op_name).      
+0002fb90: 2020 2020 2020 2020 2020 6578 6365 7074            except
+0002fba0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0002fbb0: 2020 2020 2020 7365 6c66 2e5f 6675 7365        self._fuse
+0002fbc0: 5f73 7562 5f67 7261 7068 286d 6f64 756c  _sub_graph(modul
+0002fbd0: 652c 206d 6f64 756c 655f 6469 6374 2c20  e, module_dict, 
+0002fbe0: 6f70 5f6e 616d 652c 2069 735f 7161 7429  op_name, is_qat)
+0002fbf0: 0a0a 2020 2020 4073 7461 7469 636d 6574  ..    @staticmet
+0002fc00: 686f 640a 2020 2020 6465 6620 5f63 6865  hod.    def _che
+0002fc10: 636b 5f64 796e 616d 6963 5f63 6f6e 7472  ck_dynamic_contr
+0002fc20: 6f6c 286d 6f64 756c 6529 3a0a 2020 2020  ol(module):.    
+0002fc30: 2020 2020 2222 2254 6869 7320 6973 2061      """This is a
+0002fc40: 2068 656c 7065 7220 6675 6e63 7469 6f6e   helper function
+0002fc50: 2074 6f20 6368 6563 6b20 6479 6e61 6d69   to check dynami
+0002fc60: 6320 636f 6e74 726f 6c20 696e 2066 6f72  c control in for
+0002fc70: 7761 7264 2066 756e 6374 696f 6e20 6f66  ward function of
+0002fc80: 206d 6f64 756c 652e 0a0a 2020 2020 2020   module...      
+0002fc90: 2020 4172 6773 3a0a 2020 2020 2020 2020    Args:.        
+0002fca0: 2020 2020 6d6f 6475 6c65 2028 6f62 6a65      module (obje
+0002fcb0: 6374 293a 2069 6e70 7574 206d 6f64 756c  ct): input modul
+0002fcc0: 6520 7768 6963 6820 6973 2050 7954 6f72  e which is PyTor
+0002fcd0: 6368 204d 6f64 756c 652e 0a0a 2020 2020  ch Module...    
+0002fce0: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
+0002fcf0: 2020 2020 2020 2020 2066 7573 6564 5f6d           fused_m
+0002fd00: 6f64 656c 2028 4772 6170 684d 6f64 756c  odel (GraphModul
+0002fd10: 6529 3a20 6675 7365 6420 4772 6170 684d  e): fused GraphM
+0002fd20: 6f64 756c 6520 6d6f 6465 6c20 6672 6f6d  odule model from
+0002fd30: 2074 6f72 6368 2e66 782e 0a20 2020 2020   torch.fx..     
+0002fd40: 2020 2022 2222 0a20 2020 2020 2020 2069     """.        i
+0002fd50: 6d70 6f72 7420 696e 7370 6563 740a 2020  mport inspect.  
+0002fd60: 2020 2020 2020 696d 706f 7274 2072 650a        import re.
+0002fd70: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+0002fd80: 2020 2020 2020 2020 206c 696e 6573 203d           lines =
+0002fd90: 2069 6e73 7065 6374 2e67 6574 736f 7572   inspect.getsour
+0002fda0: 6365 286d 6f64 756c 652e 666f 7277 6172  ce(module.forwar
+0002fdb0: 6429 0a20 2020 2020 2020 2020 2020 2023  d).            #
+0002fdc0: 2050 726f 7879 206f 626a 2e20 7769 6c6c   Proxy obj. will
+0002fdd0: 2061 6c77 6179 7320 6265 2064 6574 6563   always be detec
+0002fde0: 7464 2061 7320 606e 6f74 204e 6f6e 6560  td as `not None`
+0002fdf0: 2e0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+0002fe00: 4f74 6865 7220 7369 7475 6174 696f 6e73  Other situations
+0002fe10: 2063 6f75 6c64 2062 6520 6465 7465 6374   could be detect
+0002fe20: 6564 2062 7920 7072 6570 6172 655f 6678  ed by prepare_fx
+0002fe30: 2066 756e 6374 696f 6e2e 0a20 2020 2020   function..     
+0002fe40: 2020 2020 2020 2070 6174 7465 726e 203d         pattern =
+0002fe50: 2022 6973 2820 6e6f 7429 3f20 4e6f 6e65   "is( not)? None
+0002fe60: 220a 2020 2020 2020 2020 2020 2020 616e  ".            an
+0002fe70: 7773 203d 2072 652e 7365 6172 6368 2870  ws = re.search(p
+0002fe80: 6174 7465 726e 2c20 6c69 6e65 7329 0a20  attern, lines). 
+0002fe90: 2020 2020 2020 2020 2020 2069 6620 616e             if an
+0002fea0: 7773 3a0a 2020 2020 2020 2020 2020 2020  ws:.            
+0002feb0: 2020 2020 7265 7475 726e 2054 7275 650a      return True.
+0002fec0: 2020 2020 2020 2020 6578 6365 7074 3a20          except: 
+0002fed0: 2023 2070 7261 676d 613a 206e 6f20 636f   # pragma: no co
+0002fee0: 7665 720a 2020 2020 2020 2020 2020 2020  ver.            
+0002fef0: 6c6f 6767 6572 2e69 6e66 6f28 274d 6f64  logger.info('Mod
+0002ff00: 756c 6520 6861 7320 6e6f 2066 6f72 7761  ule has no forwa
+0002ff10: 7264 2066 756e 6374 696f 6e27 290a 2020  rd function').  
+0002ff20: 2020 2020 2020 7265 7475 726e 2046 616c        return Fal
+0002ff30: 7365 0a0a 2020 2020 6465 6620 6765 745f  se..    def get_
+0002ff40: 6f75 7470 7574 5f6f 705f 6e61 6d65 7328  output_op_names(
+0002ff50: 7365 6c66 2c20 2a61 7267 732c 202a 2a6b  self, *args, **k
+0002ff60: 7761 7267 7329 3a0a 2020 2020 2020 2020  wargs):.        
+0002ff70: 7265 7475 726e 204e 6f6e 650a 0a20 2020  return None..   
+0002ff80: 2064 6566 2063 616c 6375 6c61 7465 5f6f   def calculate_o
+0002ff90: 705f 7365 6e73 6974 6976 6974 7928 7365  p_sensitivity(se
+0002ffa0: 6c66 2c20 6d6f 6465 6c2c 2064 6174 616c  lf, model, datal
+0002ffb0: 6f61 6465 722c 2074 756e 655f 6366 672c  oader, tune_cfg,
+0002ffc0: 206f 7574 7075 745f 6f70 5f6e 616d 6573   output_op_names
+0002ffd0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0002ffe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002fff0: 2020 2063 6f6e 6669 6465 6e63 655f 6261     confidence_ba
+00030000: 7463 6865 732c 2066 616c 6c62 6163 6b3d  tches, fallback=
+00030010: 5472 7565 2c20 7265 7175 616e 7469 7a65  True, requantize
+00030020: 5f63 6667 733d 4e6f 6e65 293a 0a20 2020  _cfgs=None):.   
+00030030: 2020 2020 2022 2222 5468 6973 2069 7320       """This is 
+00030040: 6120 6865 6c70 6572 2066 756e 6374 696f  a helper functio
+00030050: 6e20 666f 7220 6071 7565 7279 5f66 775f  n for `query_fw_
+00030060: 6361 7061 6269 6c69 7479 602c 0a20 2020  capability`,.   
+00030070: 2020 2020 2020 2020 616e 6420 6974 2077          and it w
+00030080: 696c 6c20 6765 7420 616c 6c20 7175 616e  ill get all quan
+00030090: 7469 7a61 626c 6520 6f70 7320 6672 6f6d  tizable ops from
+000300a0: 206d 6f64 656c 2e0a 0a20 2020 2020 2020   model...       
+000300b0: 2041 7267 733a 0a20 2020 2020 2020 2020   Args:.         
+000300c0: 2020 206d 6f64 656c 2028 6f62 6a65 6374     model (object
+000300d0: 293a 2049 4e43 206d 6f64 656c 2063 6f6e  ): INC model con
+000300e0: 7461 696e 696e 6720 6670 3332 206d 6f64  taining fp32 mod
+000300f0: 656c 0a20 2020 2020 2020 2020 2020 2064  el.            d
+00030100: 6174 616c 6f61 6465 7220 2873 7472 696e  ataloader (strin
+00030110: 6729 3a20 6461 7461 6c6f 6164 6572 2063  g): dataloader c
+00030120: 6f6e 7461 696e 7320 7265 616c 2064 6174  ontains real dat
+00030130: 612e 0a20 2020 2020 2020 2020 2020 2074  a..            t
+00030140: 756e 655f 6366 6720 2864 6963 7429 3a20  une_cfg (dict): 
+00030150: 6469 6374 696f 6e61 7279 206f 6620 7475  dictionary of tu
+00030160: 6e65 2063 6f6e 6669 6775 7265 2066 6f72  ne configure for
+00030170: 2065 6163 6820 6f70 2e0a 2020 2020 2020   each op..      
+00030180: 2020 2020 2020 6661 6c6c 6261 636b 2028        fallback (
+00030190: 626f 6f6c 293a 2073 7769 7463 6820 6d65  bool): switch me
+000301a0: 7468 6f64 2069 6e20 6661 6c6c 6261 636b  thod in fallback
+000301b0: 2073 7461 6765 2061 6e64 2072 652d 7175   stage and re-qu
+000301c0: 616e 7469 7a65 2073 7461 6765 0a0a 2020  antize stage..  
+000301d0: 2020 2020 2020 5265 7475 726e 733a 0a20        Returns:. 
+000301e0: 2020 2020 2020 2020 2020 206f 7073 5f6c             ops_l
+000301f0: 7374 2028 6c69 7374 293a 2073 6f72 7465  st (list): sorte
+00030200: 6420 6f70 206c 6973 7420 6279 2073 656e  d op list by sen
+00030210: 7369 7469 7669 7479 0a20 2020 2020 2020  sitivity.       
+00030220: 2022 2222 0a20 2020 2020 2020 2066 726f   """.        fro
+00030230: 6d20 2e74 6f72 6368 5f75 7469 6c73 2e75  m .torch_utils.u
+00030240: 7469 6c20 696d 706f 7274 2067 6574 5f66  til import get_f
+00030250: 616c 6c62 6163 6b5f 6f72 6465 720a 2020  allback_order.  
+00030260: 2020 2020 2020 6f72 6465 7265 645f 6f70        ordered_op
+00030270: 7320 3d20 6765 745f 6661 6c6c 6261 636b  s = get_fallback
+00030280: 5f6f 7264 6572 2873 656c 662c 206d 6f64  _order(self, mod
+00030290: 656c 2e6d 6f64 656c 2c20 6461 7461 6c6f  el.model, datalo
+000302a0: 6164 6572 2c20 7475 6e65 5f63 6667 2c0a  ader, tune_cfg,.
+000302b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000302c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000302d0: 2020 2020 2020 2020 2063 6f6e 6669 6465           confide
+000302e0: 6e63 655f 6261 7463 6865 732c 2066 616c  nce_batches, fal
+000302f0: 6c62 6163 6b2c 2072 6571 7561 6e74 697a  lback, requantiz
+00030300: 655f 6366 6773 290a 2020 2020 2020 2020  e_cfgs).        
+00030310: 7265 7475 726e 206f 7264 6572 6564 5f6f  return ordered_o
+00030320: 7073 0a0a 0a63 6c61 7373 2050 7954 6f72  ps...class PyTor
+00030330: 6368 5175 6572 7928 5175 6572 7942 6163  chQuery(QueryBac
+00030340: 6b65 6e64 4361 7061 6269 6c69 7479 293a  kendCapability):
+00030350: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+00030360: 5f28 7365 6c66 2c20 6c6f 6361 6c5f 636f  _(self, local_co
+00030370: 6e66 6967 5f66 696c 653d 4e6f 6e65 293a  nfig_file=None):
+00030380: 0a20 2020 2020 2020 2073 7570 6572 2829  .        super()
+00030390: 2e5f 5f69 6e69 745f 5f28 290a 2020 2020  .__init__().    
+000303a0: 2020 2020 7365 6c66 2e76 6572 7369 6f6e      self.version
+000303b0: 203d 2067 6574 5f74 6f72 6368 5f76 6572   = get_torch_ver
+000303c0: 7369 6f6e 2829 0a20 2020 2020 2020 2073  sion().        s
+000303d0: 656c 662e 6366 6720 3d20 6c6f 6361 6c5f  elf.cfg = local_
+000303e0: 636f 6e66 6967 5f66 696c 650a 2020 2020  config_file.    
+000303f0: 2020 2020 7365 6c66 2e63 7572 5f63 6f6e      self.cur_con
+00030400: 6669 6720 3d20 4e6f 6e65 0a20 2020 2020  fig = None.     
+00030410: 2020 2073 656c 662e 5f6f 6e65 5f73 686f     self._one_sho
+00030420: 745f 7175 6572 7928 290a 0a20 2020 2064  t_query()..    d
+00030430: 6566 205f 6765 745f 7370 6563 6966 6965  ef _get_specifie
+00030440: 645f 7665 7273 696f 6e5f 6366 6728 7365  d_version_cfg(se
+00030450: 6c66 2c20 6461 7461 293a 0a20 2020 2020  lf, data):.     
+00030460: 2020 2022 2222 4765 7420 7468 6520 636f     """Get the co
+00030470: 6e66 6967 7572 6174 696f 6e20 666f 7220  nfiguration for 
+00030480: 7468 6520 6375 7272 656e 7420 7275 6e74  the current runt
+00030490: 696d 652e 0a20 2020 2020 2020 2049 6620  ime..        If 
+000304a0: 7468 6572 6527 7320 6e6f 206d 6174 6368  there's no match
+000304b0: 6564 2063 6f6e 6669 6775 7261 7469 6f6e  ed configuration
+000304c0: 2069 6e20 7468 6520 696e 7075 7420 7961   in the input ya
+000304d0: 6d6c 2c20 7765 276c 6c0a 2020 2020 2020  ml, we'll.      
+000304e0: 2020 7573 6520 7468 6520 6064 6566 6175    use the `defau
+000304f0: 6c74 6020 6669 656c 6420 6f66 2079 616d  lt` field of yam
+00030500: 6c2e 0a0a 2020 2020 2020 2020 4172 6773  l...        Args
+00030510: 3a0a 2020 2020 2020 2020 2020 2020 6461  :.            da
+00030520: 7461 2028 5961 6d6c 2063 6f6e 7465 6e74  ta (Yaml content
+00030530: 293a 2069 6e70 7574 2079 616d 6c20 6669  ): input yaml fi
+00030540: 6c65 2e0a 0a20 2020 2020 2020 2052 6574  le...        Ret
+00030550: 7572 6e73 3a0a 2020 2020 2020 2020 2020  urns:.          
+00030560: 2020 5b64 6963 7469 6f6e 6172 795d 3a20    [dictionary]: 
+00030570: 7468 6520 636f 6e74 656e 7420 666f 7220  the content for 
+00030580: 7370 6563 6966 6963 2076 6572 7369 6f6e  specific version
+00030590: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
+000305a0: 2020 2020 2020 2320 6465 6661 756c 745f        # default_
+000305b0: 636f 6e66 6967 203d 204e 6f6e 650a 2020  config = None.  
+000305c0: 2020 2020 2020 666f 7220 7375 625f 6461        for sub_da
+000305d0: 7461 2069 6e20 6461 7461 3a0a 2020 2020  ta in data:.    
+000305e0: 2020 2020 2020 2020 6966 2073 7562 5f64          if sub_d
+000305f0: 6174 615b 2776 6572 7369 6f6e 275d 5b27  ata['version']['
+00030600: 6e61 6d65 275d 203d 3d20 2764 6566 6175  name'] == 'defau
+00030610: 6c74 273a 0a20 2020 2020 2020 2020 2020  lt':.           
+00030620: 2020 2020 2072 6574 7572 6e20 7375 625f       return sub_
+00030630: 6461 7461 0a20 2020 2020 2020 2020 2020  data.           
+00030640: 2073 7562 5f64 6174 615f 7665 7273 696f   sub_data_versio
+00030650: 6e20 3d20 5665 7273 696f 6e28 7375 625f  n = Version(sub_
+00030660: 6461 7461 5b27 7665 7273 696f 6e27 5d5b  data['version'][
+00030670: 276e 616d 6527 5d29 0a20 2020 2020 2020  'name']).       
+00030680: 2020 2020 2069 6620 7365 6c66 2e76 6572       if self.ver
+00030690: 7369 6f6e 203e 3d20 7375 625f 6461 7461  sion >= sub_data
+000306a0: 5f76 6572 7369 6f6e 3a0a 2020 2020 2020  _version:.      
+000306b0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+000306c0: 2073 7562 5f64 6174 610a 0a20 2020 2064   sub_data..    d
+000306d0: 6566 205f 6f6e 655f 7368 6f74 5f71 7565  ef _one_shot_que
+000306e0: 7279 2873 656c 6629 3a0a 2020 2020 2020  ry(self):.      
+000306f0: 2020 7769 7468 206f 7065 6e28 7365 6c66    with open(self
+00030700: 2e63 6667 2920 6173 2066 3a0a 2020 2020  .cfg) as f:.    
+00030710: 2020 2020 2020 2020 636f 6e74 656e 7420          content 
+00030720: 3d20 7961 6d6c 2e73 6166 655f 6c6f 6164  = yaml.safe_load
+00030730: 2866 290a 2020 2020 2020 2020 2020 2020  (f).            
+00030740: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
+00030750: 2020 2020 2073 656c 662e 6375 725f 636f       self.cur_co
+00030760: 6e66 6967 203d 2073 656c 662e 5f67 6574  nfig = self._get
+00030770: 5f73 7065 6369 6669 6564 5f76 6572 7369  _specified_versi
+00030780: 6f6e 5f63 6667 2863 6f6e 7465 6e74 290a  on_cfg(content).
+00030790: 2020 2020 2020 2020 2020 2020 6578 6365              exce
+000307a0: 7074 2045 7863 6570 7469 6f6e 2061 7320  pt Exception as 
+000307b0: 653a 2020 2320 7072 6167 6d61 3a20 6e6f  e:  # pragma: no
+000307c0: 2063 6f76 6572 0a20 2020 2020 2020 2020   cover.         
+000307d0: 2020 2020 2020 206c 6f67 6765 722e 696e         logger.in
+000307e0: 666f 2822 4661 696c 2074 6f20 7061 7273  fo("Fail to pars
+000307f0: 6520 7b7d 2064 7565 2074 6f20 7b7d 222e  e {} due to {}".
+00030800: 666f 726d 6174 2873 656c 662e 6366 672c  format(self.cfg,
+00030810: 2073 7472 2865 2929 290a 2020 2020 2020   str(e))).      
+00030820: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
+00030830: 7572 5f63 6f6e 6669 6720 3d20 4e6f 6e65  ur_config = None
+00030840: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00030850: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00030860: 7228 2250 6c65 6173 6520 6368 6563 6b20  r("Please check 
+00030870: 6966 2074 6865 2066 6f72 6d61 7420 6f66  if the format of
+00030880: 207b 7d20 666f 6c6c 6f77 7320 220a 2020   {} follows ".  
+00030890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000308a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000308b0: 4e65 7572 616c 2043 6f6d 7072 6573 736f  Neural Compresso
+000308c0: 7220 7961 6d6c 2073 6368 656d 652e 222e  r yaml scheme.".
+000308d0: 666f 726d 6174 2873 656c 662e 6366 6729  format(self.cfg)
+000308e0: 290a 2020 2020 2020 2020 7365 6c66 2e5f  ).        self._
+000308f0: 7570 6461 7465 5f63 6667 5f77 6974 685f  update_cfg_with_
+00030900: 7573 725f 6465 6669 6e69 7469 6f6e 2829  usr_definition()
+00030910: 0a0a 2020 2020 6465 6620 5f75 7064 6174  ..    def _updat
+00030920: 655f 6366 675f 7769 7468 5f75 7372 5f64  e_cfg_with_usr_d
+00030930: 6566 696e 6974 696f 6e28 7365 6c66 293a  efinition(self):
+00030940: 0a20 2020 2020 2020 2066 726f 6d20 6e65  .        from ne
+00030950: 7572 616c 5f63 6f6d 7072 6573 736f 722e  ural_compressor.
+00030960: 636f 6e66 2e70 7974 686f 6e69 635f 636f  conf.pythonic_co
+00030970: 6e66 6967 2069 6d70 6f72 7420 7079 746f  nfig import pyto
+00030980: 7263 685f 636f 6e66 6967 0a20 2020 2020  rch_config.     
+00030990: 2020 2069 6620 7079 746f 7263 685f 636f     if pytorch_co
+000309a0: 6e66 6967 2e70 7265 6369 7369 6f6e 7320  nfig.precisions 
+000309b0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+000309c0: 2020 2020 2020 2020 2073 656c 662e 6375           self.cu
+000309d0: 725f 636f 6e66 6967 5b27 7072 6563 6973  r_config['precis
+000309e0: 696f 6e73 275d 5b27 6e61 6d65 7327 5d20  ions']['names'] 
+000309f0: 3d20 272c 272e 6a6f 696e 2870 7974 6f72  = ','.join(pytor
+00030a00: 6368 5f63 6f6e 6669 672e 7072 6563 6973  ch_config.precis
+00030a10: 696f 6e73 290a 0a20 2020 2064 6566 2067  ions)..    def g
+00030a20: 6574 5f71 7561 6e74 697a 6174 696f 6e5f  et_quantization_
+00030a30: 6361 7061 6269 6c69 7479 2873 656c 662c  capability(self,
+00030a40: 2064 6174 6174 7970 653d 2769 6e74 3827   datatype='int8'
+00030a50: 293a 0a20 2020 2020 2020 2022 2222 4765  ):.        """Ge
+00030a60: 7420 7468 6520 7375 7070 6f72 7465 6420  t the supported 
+00030a70: 6f70 2074 7970 6573 2720 7175 616e 7469  op types' quanti
+00030a80: 7a61 7469 6f6e 2063 6170 6162 696c 6974  zation capabilit
+00030a90: 792e 0a0a 2020 2020 2020 2020 4172 6773  y...        Args
+00030aa0: 3a0a 2020 2020 2020 2020 2020 2020 6461  :.            da
+00030ab0: 7461 7479 7065 3a20 7468 6520 6461 7461  tatype: the data
+00030ac0: 2074 7970 652e 2044 6566 6175 6c74 7320   type. Defaults 
+00030ad0: 746f 2027 696e 7438 272e 0a0a 2020 2020  to 'int8'...    
+00030ae0: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
+00030af0: 2020 2020 2020 2020 205b 6469 6374 696f           [dictio
+00030b00: 6e61 7279 206c 6973 745d 3a20 4120 6c69  nary list]: A li
+00030b10: 7374 2063 6f6d 706f 7365 6420 6f66 2064  st composed of d
+00030b20: 6963 7469 6f6e 6172 7920 7768 6963 6820  ictionary which 
+00030b30: 6b65 7920 6973 2070 7265 6369 7369 6f6e  key is precision
+00030b40: 0a20 2020 2020 2020 2020 2020 2061 6e64  .            and
+00030b50: 2076 616c 7565 2069 7320 6120 6469 6374   value is a dict
+00030b60: 2074 6861 7420 6465 7363 7269 6265 7320   that describes 
+00030b70: 616c 6c20 6f70 2074 7970 6573 2720 7175  all op types' qu
+00030b80: 616e 7469 7a61 7469 6f6e 2063 6170 6162  antization capab
+00030b90: 696c 6974 792e 0a20 2020 2020 2020 2022  ility..        "
+00030ba0: 2222 0a20 2020 2020 2020 2061 7373 6572  "".        asser
+00030bb0: 7420 6461 7461 7479 7065 2069 6e20 7365  t datatype in se
+00030bc0: 6c66 2e67 6574 5f71 7561 6e74 5f64 6174  lf.get_quant_dat
+00030bd0: 6174 7970 6573 2829 2c20 5c0a 2020 2020  atypes(), \.    
+00030be0: 2020 2020 2020 2020 6622 5468 6520 7461          f"The ta
+00030bf0: 7267 6574 2064 6174 6120 7479 7065 2073  rget data type s
+00030c00: 686f 756c 6420 6265 206f 6e65 206f 6620  hould be one of 
+00030c10: 7b73 656c 662e 6765 745f 7175 616e 745f  {self.get_quant_
+00030c20: 6461 7461 7479 7065 7328 297d 220a 2020  datatypes()}".  
+00030c30: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+00030c40: 662e 6375 725f 636f 6e66 6967 5b64 6174  f.cur_config[dat
+00030c50: 6174 7970 655d 0a0a 2020 2020 6465 6620  atype]..    def 
+00030c60: 6765 745f 7175 616e 745f 6461 7461 7479  get_quant_dataty
+00030c70: 7065 7328 7365 6c66 293a 0a20 2020 2020  pes(self):.     
+00030c80: 2020 2022 2222 476f 7420 6c6f 772d 7072     """Got low-pr
+00030c90: 6563 6973 696f 6e20 6461 7461 2074 7970  ecision data typ
+00030ca0: 6573 2066 6f72 2071 7561 6e74 697a 6174  es for quantizat
+00030cb0: 696f 6e2e 0a20 2020 2020 2020 200a 2020  ion..        .  
+00030cc0: 2020 2020 2020 436f 6c6c 6563 7473 2061        Collects a
+00030cd0: 6c6c 2064 6174 6120 7479 7065 7320 666f  ll data types fo
+00030ce0: 7220 7175 616e 7469 7a61 7469 6f6e 2c20  r quantization, 
+00030cf0: 7375 6368 2061 7320 696e 7438 2c20 696e  such as int8, in
+00030d00: 7434 2e0a 2020 2020 2020 2020 2222 220a  t4..        """.
+00030d10: 2020 2020 2020 2020 2320 544f 444f 2074          # TODO t
+00030d20: 6f20 6861 6e64 6c65 206f 7468 6572 2064  o handle other d
+00030d30: 6174 6120 7479 7065 7320 7375 6368 2046  ata types such F
+00030d40: 5038 2c20 4650 3845 344d 330a 2020 2020  P8, FP8E4M3.    
+00030d50: 2020 2020 6461 7461 7479 7065 5f6c 7374      datatype_lst
+00030d60: 203d 205b 5d0a 2020 2020 2020 2020 666f   = [].        fo
+00030d70: 7220 6b65 7920 696e 2073 656c 662e 6375  r key in self.cu
+00030d80: 725f 636f 6e66 6967 3a0a 2020 2020 2020  r_config:.      
+00030d90: 2020 2020 2020 6966 206b 6579 2e73 7461        if key.sta
+00030da0: 7274 7377 6974 6828 2769 6e74 2729 3a0a  rtswith('int'):.
+00030db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00030dc0: 6461 7461 7479 7065 5f6c 7374 2e61 7070  datatype_lst.app
+00030dd0: 656e 6428 6b65 7929 0a20 2020 2020 2020  end(key).       
+00030de0: 2072 6574 7572 6e20 6461 7461 7479 7065   return datatype
+00030df0: 5f6c 7374 0a0a 2020 2020 6465 6620 6765  _lst..    def ge
+00030e00: 745f 6f70 5f74 7970 6573 2873 656c 6629  t_op_types(self)
+00030e10: 3a0a 2020 2020 2020 2020 2222 2247 6574  :.        """Get
+00030e20: 2074 6865 2073 7570 706f 7274 6564 206f   the supported o
+00030e30: 7020 7479 7065 7320 6279 2061 6c6c 2070  p types by all p
+00030e40: 7265 6369 7369 6f6e 732e 0a20 2020 2020  recisions..     
+00030e50: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
+00030e60: 2020 2020 2020 2020 5b64 6963 7469 6f6e          [diction
+00030e70: 6172 7920 6c69 7374 5d3a 2041 206c 6973  ary list]: A lis
+00030e80: 7420 636f 6d70 6f73 6564 206f 6620 6469  t composed of di
+00030e90: 6374 696f 6e61 7279 2077 6869 6368 206b  ctionary which k
+00030ea0: 6579 2069 7320 7072 6563 6973 696f 6e0a  ey is precision.
+00030eb0: 2020 2020 2020 2020 2020 2020 616e 6420              and 
+00030ec0: 7661 6c75 6520 6973 2074 6865 206f 7020  value is the op 
+00030ed0: 7479 7065 732e 0a20 2020 2020 2020 2022  types..        "
+00030ee0: 2222 0a20 2020 2020 2020 2072 6574 7572  "".        retur
+00030ef0: 6e20 7365 6c66 2e63 7572 5f63 6f6e 6669  n self.cur_confi
+00030f00: 670a 0a20 2020 2064 6566 2067 6574 5f6f  g..    def get_o
+00030f10: 705f 7479 7065 735f 6279 5f70 7265 6369  p_types_by_preci
+00030f20: 7369 6f6e 2873 656c 662c 2070 7265 6369  sion(self, preci
+00030f30: 7369 6f6e 293a 0a20 2020 2020 2020 2022  sion):.        "
+00030f40: 2222 4765 7420 6f70 2074 7970 6573 2070  ""Get op types p
+00030f50: 6572 2070 7265 6369 7369 6f6e 0a20 2020  er precision.   
+00030f60: 2020 2020 2041 7267 733a 0a20 2020 2020       Args:.     
+00030f70: 2020 2020 2020 2070 7265 6369 7369 6f6e         precision
+00030f80: 2028 7374 7269 6e67 293a 2070 7265 6369   (string): preci
+00030f90: 7369 6f6e 206e 616d 650a 2020 2020 2020  sion name.      
+00030fa0: 2020 5265 7475 726e 733a 0a20 2020 2020    Returns:.     
+00030fb0: 2020 2020 2020 205b 7374 7269 6e67 206c         [string l
+00030fc0: 6973 745d 3a20 4120 6c69 7374 2063 6f6d  ist]: A list com
+00030fd0: 706f 7365 6420 6f66 206f 7020 7479 7065  posed of op type
+00030fe0: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
+00030ff0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+00031000: 662e 6375 725f 636f 6e66 6967 5b70 7265  f.cur_config[pre
+00031010: 6369 7369 6f6e 5d0a                      cision].
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/pytorch_cpu.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/pytorch_cpu.yaml`

 * *Files 0% similar despite different names*

```diff
@@ -254,15 +254,14 @@
                         'scheme': ['sym'],
                         'granularity': ['per_channel'],
                         'algorithm': ['minmax']
                         },
                      },
           },
     }
-  uint8: *cap_s8_1_11
 
 
 -
   version:
     name: '1.10'
 
   bf16: []
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/pytorch_gpu.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/pytorch_gpu.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/pytorch_ipex.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/pytorch_ipex.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/query.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/query.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tensorflow.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tensorflow.py`

 * *Files 0% similar despite different names*

```diff
@@ -2161,14 +2161,17 @@
         import tensorflow as tf
         if tf.version.VERSION in spr_base_verions or self.itex_mode:
             patterns['int8'] = spr_int8_pattern_list
             patterns['uint8'] = spr_uint8_pattern_list
         elif version1_gte_version2(tf.version.VERSION, '2.1.0'):
             patterns['int8'] = tf_int8_pattern_list
             patterns['uint8'] = tf_uint8_pattern_list
+            if self.itex_mode:
+                patterns['int8'].append("FusedBatchNormV3 + Relu")
+                patterns['int8'].append("FusedBatchNormV3 + LeakyRelu")
         elif version1_eq_version2(tf.version.VERSION, '1.15.0-up3'):
             patterns['int8'] = tf1_15_up3_int8_pattern_list
             patterns['uint8'] = tf1_15_up3_uint8_pattern_list
         else:
             patterns['int8'] = old_tf_int8_pattern_list
             patterns['uint8'] = old_tf_uint8_pattern_list
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tensorflow.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tensorflow.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tensorflow_itex.yaml` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tensorflow_itex.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_converter.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_converter.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_converter_without_calib.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_converter_without_calib.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/bf16_convert.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/bf16_convert.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_add_to_biasadd.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_add_to_biasadd.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_layout.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_layout.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_leakyrelu.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_leakyrelu.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_nan_to_random.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_nan_to_random.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_placeholder_to_const.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_placeholder_to_const.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dequantize_cast_optimizer.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dequantize_cast_optimizer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dilated_contraction.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dilated_contraction.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dummy_biasadd.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dummy_biasadd.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/expanddims_optimizer.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/expanddims_optimizer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fetch_weight_from_reshape.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fetch_weight_from_reshape.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_batch_norm.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_batch_norm.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_constant.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_constant.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_biasadd_add.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_biasadd_add.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_column_wise_mul.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_column_wise_mul.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_conv_with_math.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_conv_with_math.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_bn.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_bn.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_in.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_in.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_gelu.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_gelu.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_layer_norm.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_layer_norm.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_conv.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_conv.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_fp32_conv.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_fp32_conv.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_reshape_transpose.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_reshape_transpose.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/graph_cse_optimizer.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/graph_cse_optimizer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/grappler_pass.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/grappler_pass.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/insert_print_node.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/insert_print_node.py`

 * *Files 0% similar despite different names*

```diff
@@ -165,18 +165,16 @@
                     attr_value_pb2.AttrValue.ListValue(type=attr_u))
                 post_node_names = graph_info[Helper.node_name_from_input(each_node_name)].outputs
                 if post_node_names:
                     for post_node_name in post_node_names:
                         post_node = graph_info[post_node_name].node
                         if each_node_name not in post_node.input:
                             continue
-                        if post_node.op == 'FusedBatchNormV3':
-                            if "_print_identity" in \
-                               graph_info[Helper.node_name_from_input(post_node.name)].node.input[0]:
-                                continue
+                        if post_node.op == 'FusedBatchNormV3' and "_print_identity" not in \
+                           graph_info[Helper.node_name_from_input(post_node.name)].node.input[0]:
                             identity_node = Helper.create_node("Identity", post_node.name+'_print_identity',
                                 [graph_info[Helper.node_name_from_input(post_node.name)].node.input[0]])
                             identity_node.attr["T"].CopyFrom(src_dt)
                             cur_graph.add_node(identity_node,
                                             graph_info[Helper.node_name_from_input(post_node.name)].node.input[0],
                                             [post_node.name])
                             identity_node.input.append("^" + min_print_node.name)
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/move_squeeze_after_relu.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/move_squeeze_after_relu.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/pre_optimize.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/pre_optimize.py`

 * *Files 0% similar despite different names*

```diff
@@ -212,24 +212,27 @@
             self._tmp_graph_def).do_transformation()
 
         self._tmp_graph_def = ExpandDimsOptimizer(
             self._tmp_graph_def).do_transformation()
 
         self._tmp_graph_def = FetchWeightFromReshapeOptimizer(
             self._tmp_graph_def).do_transformation()
+
+        self._tmp_graph_def = MoveSqueezeAfterReluOptimizer(
+            self._tmp_graph_def).do_transformation()
+
         if not self.new_api and not itex_mode:
             #TODO we need to remove below optimizer once the TF enabled the single
             # matmul op quantization
             self._tmp_graph_def = InjectDummyBiasAddOptimizer(
                 self._tmp_graph_def, output_node_names).do_transformation()
+                
         self._tmp_graph_def = FuseBiasAddAndAddOptimizer(
             self._tmp_graph_def).do_transformation()
 
-        self._tmp_graph_def = MoveSqueezeAfterReluOptimizer(
-            self._tmp_graph_def).do_transformation()
 
         self._tmp_graph_def = ConvertNanToRandom(
             self._tmp_graph_def).do_transformation()
 
         self._tmp_graph_def = StripEquivalentNodesOptimizer(
             self._tmp_graph_def, output_node_names).do_transformation()
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/remove_training_nodes.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/remove_training_nodes.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/rename_batch_norm.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/rename_batch_norm.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/split_shared_input.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/split_shared_input.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_equivalent_nodes.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_equivalent_nodes.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_unused_nodes.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_unused_nodes.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/switch_optimizer.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/switch_optimizer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/graph_base.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/graph_base.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_fake_quant.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_fake_quant.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value.py`

 * *Files 3% similar despite different names*

```diff
@@ -238,14 +238,19 @@
             in_node_name = node_name.replace('eightbit_requant_range', 'eightbit_quantized_in')
             if not self.graph_info.get(bn_node_name) or \
                 not bn_node_name.endswith('_eightbit_quantized_bn'):
                 bn_node_name = None
             if not self.graph_info.get(in_node_name) or \
                 not in_node_name.endswith('_eightbit_quantized_in'):
                 in_node_name = None
+
+            if self.itex_mode and ('FusedBatchNormV3_eightbit_requant_range' in node_name or \
+                'FusedBatchNorm_eightbit_requant_range' in node_name):
+                bn_node_name = node_name[:-len("_eightbit_requant_range")]
+
             if node_name not in self.graph_info \
                 and bn_node_name not in self.graph_info \
                     and in_node_name not in self.graph_info:
                 continue
 
             min_node = node_def_pb2.NodeDef()
             min_node.op = "Const"
@@ -276,24 +281,36 @@
                 attr_value_pb2.AttrValue(type=dtypes.float32.as_datatype_enum))
             max_node.attr["value"].CopyFrom(
                 attr_value_pb2.AttrValue(
                     tensor=tensor_util.make_tensor_proto(float(value[1]),
                     dtypes.float32, [])))
 
             if bn_node_name:
-                self.cur_graph.replace_const_node(
-                    min_node,
-                    [Helper.node_name_from_input(bn_node_name)],
-                    bn_node_name + '_input7_output_min'
-                )
-                self.cur_graph.replace_const_node(
-                    max_node,
-                    [Helper.node_name_from_input(bn_node_name)],
-                    bn_node_name + '_input8_output_max'
-                )
+                if self.itex_mode:
+                    self.cur_graph.replace_const_node(
+                        min_node,
+                        [Helper.node_name_from_input(bn_node_name+'_eightbit_quantize_bn')],
+                        bn_node_name + '_eightbit_input7_output_min'
+                    )
+                    self.cur_graph.replace_const_node(
+                        max_node,
+                        [Helper.node_name_from_input(bn_node_name+'_eightbit_quantize_bn')],
+                        bn_node_name + '_eightbit_input8_output_max'
+                    )
+                else:
+                    self.cur_graph.replace_const_node(
+                        min_node,
+                        [Helper.node_name_from_input(bn_node_name)],
+                        bn_node_name + '_input7_output_min'
+                    )
+                    self.cur_graph.replace_const_node(
+                        max_node,
+                        [Helper.node_name_from_input(bn_node_name)],
+                        bn_node_name + '_input8_output_max'
+                    )
             elif in_node_name:
                 self.cur_graph.replace_const_node(
                     min_node,
                     [Helper.node_name_from_input(in_node_name)],
                     in_node_name + '_input7_output_min'
                 )
                 self.cur_graph.replace_const_node(
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value_without_calib.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value_without_calib.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_redundant_dequantize.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_redundant_dequantize.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_requantize.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_requantize.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_requantize.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_requantize.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/meta_op_optimizer.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/meta_op_optimizer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_hostconst_converter.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_hostconst_converter.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_quantized_op_cse.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_quantized_op_cse.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/rnn_convert.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/rnn_convert.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/scale_propagation.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/scale_propagation.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_graph.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_graph.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_node.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_node.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_schema.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_schema.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/tf2onnx_utils.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/tf2onnx_utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/insert_qdq_pattern.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/insert_qdq_pattern.py`

 * *Files 1% similar despite different names*

```diff
@@ -354,17 +354,22 @@
             self.graph_info[op_name].node.input[input_index] = dequantize_node.name
         else:
             reshape_dims_node = Helper.create_constant_node(
                 reshape_dims_name, -1, dtypes.int32, [1])
             reduction_dims_node = Helper.create_constant_node(
                 reduction_dims_name, 0, dtypes.int32, [1])
             reshape_input_name = namespace_prefix + "_reshape_" + unique_input_name
-            min_input_name = namespace_prefix + "_min_" + unique_input_name
-            max_input_name = namespace_prefix + "_max_" + unique_input_name
-            quantize_input_name = namespace_prefix + "_quantize_" + unique_input_name
+            if self.itex_mode and self.graph_info[op_name].node.op == 'FusedBatchNormV3':
+                min_input_name = namespace_prefix + "_input7_output_min"
+                max_input_name = namespace_prefix + "_input8_output_max"
+                quantize_input_name = namespace_prefix + "_quantize_bn"
+            else:
+                min_input_name = namespace_prefix + "_min_" + unique_input_name
+                max_input_name = namespace_prefix + "_max_" + unique_input_name
+                quantize_input_name = namespace_prefix + "_quantize_" + unique_input_name
 
             reshape_input_node = Helper.create_node(
                 "Reshape", reshape_input_name,
                 [input_name, reshape_dims_name])
             Helper.set_attr_dtype(reshape_input_node, "T", dtypes.float32)
 
             min_input_node = Helper.create_node(
@@ -645,14 +650,14 @@
             return True
 
         #TODO Remove below two lines once the TF enabled the QuantizedMatMul while
         # transpose_a could be set to True.
         if not self.itex_mode and self.graph_info[matched_node_name].node.op == "MatMul": 
             if self.graph_info[matched_node_name].node.attr["transpose_a"].b == True:
                 return True
-        if "FusedBatchNorm" in self.graph_info[matched_node_name].node.op:
+        if "FusedBatchNorm" in self.graph_info[matched_node_name].node.op and not self.itex_mode:
             return True
-        if "_MklFusedInstanceNorm" == self.graph_info[matched_node_name].node.op:
+        if "_MklFusedInstanceNorm" == self.graph_info[matched_node_name].node.op and not self.itex_mode:
             return True
         return False
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/merge_duplicated_qdq.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/merge_duplicated_qdq.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/share_qdq_y_pattern.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/share_qdq_y_pattern.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/graph_util.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/graph_util.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/fake_quantize.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/fake_quantize.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_config.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_config.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_helper.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_helper.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/optimize_layer.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/optimize_layer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_add.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_add.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_base.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_base.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_bn.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_bn.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_wrapper.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_wrapper.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_bn.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_bn.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_concatv2.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_concatv2.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_conv.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_conv.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_deconv.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_deconv.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_in.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_in.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_matmul.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_matmul.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_pooling.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_pooling.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/optimize_qdq.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/optimize_qdq.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_base.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_base.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_bn.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_bn.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_concatv2.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_concatv2.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_conv.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_conv.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_for_intel_cpu.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_for_intel_cpu.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_matmul.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_matmul.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_pooling.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_pooling.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/quantize_graph_common.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/quantize_graph_common.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/tf2onnx_converter.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/tf2onnx_converter.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/bias_correction.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/bias_correction.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/insert_logging.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/insert_logging.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/tf_utils/util.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/tf_utils/util.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/bf16_convert.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/bf16_convert.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/hawq_metric.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/hawq_metric.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/smooth_quant.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/smooth_quant.py`

 * *Files 12% similar despite different names*

```diff
@@ -12,51 +12,76 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from neural_compressor.utils.utility import LazyImport
+import json
 
 torch = LazyImport('torch')
 from ...utils import logger
+from collections import UserDict
 
 
-def model_forward(model, dataloader, iters):
+def forward_wrapper(model, input, device='cpu'):
+    if isinstance(input, dict) or isinstance(input, UserDict):
+        if device == 'cpu':
+            output = model(**input)
+        else:  # pragma: no cover
+            for inp in input.keys():
+                input[inp] = input[inp].to(device) \
+                    if isinstance(input[inp], torch.Tensor) else input[inp]
+            output = model(**input)
+    elif isinstance(input, list) or isinstance(input, tuple):
+        if device == 'cpu':
+            output = model(*input)
+        else:  # pragma: no cover
+            input = [inp.to(device) \
+                    if isinstance(inp, torch.Tensor) else inp
+                    for inp in input] # pylint: disable=E1133
+            output = model(*input)
+    else:
+        if device == 'cpu' or not isinstance(input, torch.Tensor):
+            output = model(input)
+        else:  # pragma: no cover
+            input = input.to(device)  # pylint: disable=no-member
+            output = model(input)
+    return output
+
+
+def model_forward(model, dataloader, iters, device):
     try:
         cnt = 0
         for idx, (input, label) in enumerate(dataloader):
-            output = model(input)
+            output = forward_wrapper(model, input, device)
             cnt += 1
             if cnt >= iters:
                 break
     except Exception as e:
         cnt = 0
         for idx, input in enumerate(dataloader):
-            if isinstance(input, dict):
-                out = model(**input)
-            elif isinstance(input, list) or isinstance(input, tuple):
-                out = model(*input)
-            else:
-                out = model(input)
+            output = forward_wrapper(model, input, device)
             cnt += 1
             if cnt >= iters:
                 break
 
 
-def quant_dequant_w(m, num_bits=8, scheme='asym'):##TODO take sym as default
+def quant_dequant_w(m, num_bits=8, scheme='asym'):  ##TODO take sym as default
+    eps = torch.finfo(torch.float32).eps
     if isinstance(m, torch.nn.Linear):
         x = m.weight
         if scheme == 'sym':
             q_min, q_max = -2. ** (num_bits - 1), 2. ** (num_bits - 1) - 1.
-            scale = torch.abs(torch.max(x, dim=1).values) / (2 ** (num_bits - 1) - 1)
+            scale = torch.max(torch.abs(x), dim=1).values / (float(q_max - q_min) / 2)
         else:
             q_min, q_max = 0, 2. ** num_bits - 1.
             scale = (torch.max(x, dim=1).values - torch.min(x, dim=1).values) / (2 ** num_bits - 1)
-        scale = torch.clip(scale, min=1e-5)
+
+        scale = torch.clip(scale, min=eps)
 
         if scheme == 'sym':
             bias = 0
         else:
             bias = torch.round(0 - (torch.min(x, dim=1).values) / scale)
             bias = bias.unsqueeze(dim=-1)
         scale = scale.unsqueeze(dim=-1)
@@ -65,19 +90,19 @@
         return (q_x - bias) * scale
     elif isinstance(m, torch.nn.Conv2d):
         x = m.weight
         x = torch.permute(x, (0, 2, 3, 1))
         x = x.reshape(-1, x.shape[-1])
         if scheme == 'sym':
             q_min, q_max = -2. ** (num_bits - 1), 2. ** (num_bits - 1) - 1.
-            scale = torch.abs(torch.max(x, dim=0).values) / (2 ** (num_bits - 1) - 1)
+            scale = torch.max(torch.abs(x), dim=0).values / (2 ** (num_bits - 1) - 1)
         else:
             q_min, q_max = 0, 2. ** num_bits - 1.
             scale = (torch.max(x, dim=0).values - torch.min(x, dim=0).values) / (2 ** num_bits - 1)
-        scale = torch.clip(scale, min=1e-5)
+        scale = torch.clip(scale, min=eps)
         if scheme == 'sym':
             bias = 0
         else:
             bias = torch.round(0 - (torch.min(x, dim=0).values) / scale)
             bias = bias.unsqueeze(dim=0)
         scale = scale.unsqueeze(dim=0)
 
@@ -88,32 +113,70 @@
         q_dq_x = torch.permute(q_dq_x, (0, 3, 1, 2))
         return q_dq_x
     else:
         logger.warning("unsupported layer type, please have a check")
 
 
 def quant_dequant_x(x, num_bits=8):
+    eps = torch.finfo(torch.float32).eps
     q_min, q_max = 0, 2. ** num_bits - 1.
     scale = (torch.max(x) - torch.min(x)) / (2 ** num_bits - 1)
-    scale = torch.clip(scale, min=1e-5)
+    scale = torch.clip(scale, min=eps)
     bias = torch.round(0 - (torch.min(x)) / scale)
     q_x = x / scale + bias
     q_x.clamp_(q_min, q_max).round_()
     return scale * (q_x - bias)
 
 
+def get_module(model, key):
+    """Get module from model by key name
+
+    Args:
+        model (torch.nn.Module): original model
+        key (str): module name to be replaced
+    """
+    attrs = key.split('.')
+    module = model
+    for attr in attrs:
+        try:
+            attr = int(attr)
+            module = module[attr]
+        except:
+            module = getattr(module, attr)
+    return module
+
+
+def set_module(model, key, new_module):
+    """Set new module into model by key name
+
+    Args:
+        model (torch.nn.Module): original model
+        key (str): module name to be replaced
+        new_module (torch.nn.Module): new module to be inserted
+    """
+    attrs = key.split('.')
+    module = model
+    for attr in attrs[:-1]:
+        try:
+            attr = int(attr)
+            module = module[attr]
+        except:
+            module = getattr(module, attr)
+    setattr(module, attrs[-1], new_module)
+
+
 class TorchSmoothQuant:
     """
     Fake input channel quantization, for more details please refer to
     [1] SmoothQuant: Accurate and Efficient
     Post-Training Quantization for Large Language Models
     [2] SPIQ: Data-Free Per-Channel Static Input Quantization
     Currently, we only handle the layers whose smooth scale could be absorbed, we will support other layers later.
-    We only support inplace mode which means the model weights will be changed, you can call recover function only
-    once to recover the weights if needed
+    We only support inplace mode which means the model weights will be changed, you can call recover function
+    to recover the weights if needed
     """
 
     def __init__(self, model, dataloader, traced_model=None):
         """
         :param model: Torch model :param dataloader: Calibration dataloader :param traced_model: A specific model
         shares the same architecture as the model and could be traced by torch.jit. If not supplied, we use model
         instead.
@@ -124,63 +187,56 @@
         self.model.eval()
         self.device = device
         self.dtype = dtype
         self.dataloader = dataloader
         self.input_values = {}
         self.output_values = {}
         self.input_maxes = {}
+        self.input_mins = {}
+        self.input_abs_maxes = {}
         self.hook_layer_names = []
         self.hook_values_handles = []
         self.traced_model = traced_model
         if self.traced_model == None:
             self.traced_model = self.model
         self.weight_scale_info = {}
         self.absorb_scales_info = {}
+        self.insert_mul = True
+        self.allow_absorb = False
+        self.self_absorb_layers = {}
+        self.absorb_to_layer = {}
 
     def _get_device(self):
         """
         Get the model device
         :return:Model device
         """
         for _, p in self.model.named_parameters():
             return p.data.device, p.data.dtype
 
-    def _get_module(self, key):
-        """
-        Get the module by the name parsed by jit
-        :param key: the module name with the jit format
-        :return: the module in original model
-        """
-        attrs = key.split('.')
-        module = self.model
-        for attr in attrs:
-            try:
-                attr = int(attr)
-                module = module[attr]
-            except:
-                module = getattr(module, attr)
-        return module
-
     def _save_input_pc_hook(self, name):
         """
         A forward hook to save input max of a module
         :param name: the module name
         :return: A hook function
         """
 
         def save_input_hook(module, inputs, outputs):
             if name not in self.input_maxes.keys():
                 self.input_maxes[name] = []
+                self.input_mins[name] = []
             input = inputs[0]
             ##TODO check input channel is correct
-            if len(module.weight.shape) == 4:  ##conv3d or conv1d not suppoted now, need better way
+            if len(module.weight.shape) == 4:  ##conv3d or conv1d not supported now, need better way
                 input = input.permute(0, 2, 3, 1)
             input = input.reshape(-1, input.shape[-1])
             max_tensor = torch.max(input, dim=0)[0]
+            min_tensor = torch.min(input, dim=0)[0]
             self.input_maxes[name].append(max_tensor)
+            self.input_mins[name].append(min_tensor)
             # self.input_values[name] = input
             # self.output_values[name] = outputs
 
         return save_input_hook
 
     def _save_input_output_hook(self, name):
         """
@@ -191,16 +247,16 @@
 
         def save_input_output_hook(module, inputs, outputs):
             input = inputs[0]
             # if name in self.input_values:
             #     self.input_values[name].append(input)
             #     self.output_values[name].append(outputs)
             # else:
-            self.input_values[name] = [input]##TODO save more,like 8
-            self.output_values[name] = [outputs]##TODO do not save output
+            self.input_values[name] = [input]  ##TODO save more,like 8
+            self.output_values[name] = [outputs]  ##TODO do not save output
 
         return save_input_output_hook
 
     def _add_observer(self, modules, input_output_modules=None):
         """
         :param modules: the modules which the observer will insert to
         :return:
@@ -223,282 +279,331 @@
         """
         for hook_handle in self.hook_handles:
             hook_handle.remove()
         if self.hook_values_handles:
             for hook_handle in self.hook_values_handles:
                 hook_handle.remove()
 
-    # ##https://gist.github.com/sailfish009/28b54c8aa6398148a6358b8f03c0b611
-    # def percentile(t: torch.tensor, q: float):
-    #     """
-    #     Return the ``q``-th percentile of the flattened input tensor's data.
-    #
-    #     CAUTION:
-    #      * Needs PyTorch >= 1.1.0, as ``torch.kthvalue()`` is used.
-    #      * Values are not interpolated, which corresponds to
-    #        ``numpy.percentile(..., interpolation="nearest")``.
-    #
-    #     :param t: Input tensor.
-    #     :param q: Percentile to compute, which must be between 0 and 100 inclusive.
-    #     :return: Resulting value (scalar).
-    #     """
-    #     # Note that ``kthvalue()`` works one-based, i.e. the first sorted value
-    #     # indeed corresponds to k=1, not k=0! Use float(q) instead of q directly,
-    #     # so that ``round()`` returns an integer, even if q is a np.float32.
-    #     k = 1 + round(.01 * float(q) * (t.numel() - 1))
-    #     result = t.view(-1).kthvalue(k).values.item()
-    #     return result
-
     def _calibrate(self, absorb_to_layer, calib_iter, save_input_output=False):
         """
         :param absorb_to_layer: A dict,key is the absorb layer, val is a list of the to be smoothed layer
         :param calib_iter: Data size for calibration
         :return: A dict that saved the layer name and the channe-wised max value info
         """
         layer_to_absorb = {}
         for key in absorb_to_layer:
             for layer_name in absorb_to_layer[key]:
                 layer_to_absorb[layer_name] = key
         hook_module_names_tmp = [absorb_to_layer[key][0] for key in absorb_to_layer.keys()]
         hook_modules = {}
 
         for index, name in enumerate(hook_module_names_tmp):
-            module = self._get_module(name)
+            module = get_module(self.model, name)
             if isinstance(module, torch.nn.Linear) or isinstance(module,
                                                                  torch.nn.Conv2d):
                 if isinstance(module, torch.nn.Conv2d):
-                    if module.groups > 1 and module.in_channels == module.out_channels and \
-                            module.groups == module.in_channels:
-                        continue
-                    else:
+                    if self._check_dw_conv(module):
                         pass
+                    elif module.groups > 1:
+                        continue
 
                 hook_modules[name] = module
         if len(hook_modules) == 0:
             return {}
         hook_modules_input_output = {}
         for name in self.hook_layer_names:
-            hook_modules_input_output[name] = self._get_module(name)
+            hook_modules_input_output[name] = get_module(self.model, name)
         self._add_observer(hook_modules, hook_modules_input_output)
         self._dump_min_max(calib_iter=calib_iter)
         self._remove_observer()
-        return self.input_maxes
+        return self.input_abs_maxes
 
     def _dump_min_max(self, calibration_method="min_max", calib_iter=100):
         """
         Dump min max per channel information, the min max value will be saved in input_maxes attribute
         :param calibration_method: only support min_max currently
         :param calib_iter: Sample size for calibration
         :return:
         """
-        model_forward(self.model, self.dataloader, calib_iter)
+        model_forward(self.model, self.dataloader, calib_iter, self.device)
         ##stack
         for key in self.input_maxes.keys():
-            val = self.input_maxes[key]
-            val = torch.stack(val, dim=0)
-            val = torch.max(torch.abs(val), dim=0)[0]  ##FIXME should add abs
-            self.input_maxes[key] = val
+            max_val = self.input_maxes[key]
+            max_val = torch.stack(max_val, dim=0)
+            min_val = self.input_mins[key]
+            min_val = torch.stack(min_val, dim=0)
+            self.input_maxes[key] = torch.max(max_val, dim=0)[0]
+            self.input_mins[key] = torch.min(min_val, dim=0)[0]
+            abs_max_val = torch.max(torch.abs(self.input_mins[key]), torch.abs(self.input_maxes[key]))
+            self.input_abs_maxes[key] = abs_max_val
         for key in self.input_values.keys():
             self.input_values[key] = torch.cat(self.input_values[key], dim=0)  ##this may introduce memory issue
             self.output_values[key] = torch.cat(self.output_values[key], dim=0)
 
     def _reshape_in_channel_to_last(self, layer_name):
         """
         Move the input channel to the last dim
         :param layer_name: Layer name
         :return: The reshaped weight
         """
-        weight = self._get_module(layer_name).weight  ##TODO oc*ic, support transposed conv
+        weight = get_module(self.model, layer_name).weight  ##TODO oc*ic, support transposed conv
         if len(weight.shape) == 4:
             weight = weight.permute(0, 2, 3, 1)
             weight = weight.reshape(-1, weight.shape[-1])
         return weight
 
-    def _scale_layer_weight(self, layer_name, scale):  ##input channel
+    def _reshape_scale_for_weight(self, layer, scale):
         """
-        Scale the layer weights at input channel
-        :param layer_name: The layer name
-        :param scale: The scale to be multiplied
+        reshape the scale for weight input channel, depthwise output channel
+        :param layer:  torch module
+        :param scale: orig scale
+        :return: reshaped scale
+        """
+        if isinstance(layer, torch.nn.Conv2d) and layer.groups > 1:  ##only depthwise conv could hit here
+            scale = scale.view(scale.shape[0], 1, 1, 1)  ##mount on output channel
+
+        elif isinstance(layer, torch.nn.Conv2d):
+            scale = scale.view(1, scale.shape[0], 1, 1)
+
+        elif isinstance(layer, torch.nn.Linear):
+            scale = scale.view(1, scale.shape[0])
+
+        return scale
+
+    def _reshape_scale_for_input(self, layer, scale):
+        """
+        reshape the scale for input feature in channel
+        :param layer:
+        :param scale:
         :return:
         """
-        layer = self._get_module(layer_name)
-        if isinstance(layer, torch.nn.Conv2d) or isinstance(layer, torch.nn.ConvTranspose2d):
+        if isinstance(layer, torch.nn.Conv2d):
             scale = scale.view(1, scale.shape[0], 1, 1)
-            layer.weight *= scale
+
         elif isinstance(layer, torch.nn.Linear):
             scale = scale.view(1, scale.shape[0])
-            layer.weight *= scale
-        else:
-            logger.warning(f"found unsupported layer {type(layer)}, try to multiply scale directly ")
-            layer.weight *= scale
+
+        return scale
+
+    def _scale_layer_weight(self, layer_name, scale):  ##input channel
+        """
+        Scale the layer weights at input channel, depthwise conv output channel
+        :param layer_name: The layer name
+        :param scale: The scale to be multiplied
+        :return:
+        """
+        layer = get_module(self.model, layer_name)
+        from .model_wrapper import SQLinearWrapper
+        if isinstance(layer, SQLinearWrapper):
+            layer = layer.sq_linear
+        scale = self._reshape_scale_for_weight(layer, scale)
+        layer.weight *= scale
+        return scale
 
     def _absorb_scales(self, layer_name, scale):  ##output channel
         """
         Absorb the scale to the layer at output channel
         :param layer_name: The module name
         :param scale: The scale to be absorbed
         :return:
         """
-        layer = self._get_module(layer_name)
-        if isinstance(layer, torch.nn.BatchNorm2d) or isinstance(layer, torch.nn.GroupNorm) or \
-                isinstance(layer, torch.nn.InstanceNorm2d):
-            if layer.affine:
-                layer.weight *= scale
-                layer.bias *= scale
+        from .model_wrapper import SQLinearWrapper
+        layer = get_module(self.model, layer_name)
+        if self.insert_mul:
+            if isinstance(layer, SQLinearWrapper):
+                set_module(self.model, layer_name, layer.sq_linear)  ##recover
             else:
-                layer.affine = True
-                weight = torch.ones(layer.num_features, device=self.device, dtype=self.dtype) * scale
-                layer.weight = torch.nn.Parameter(
-                    weight, requires_grad=False)
-                bias = torch.zeros(layer.num_features, device=self.device, dtype=self.dtype)
-                layer.bias = torch.nn.Parameter(bias, requires_grad=False
-                                                )
-        elif isinstance(layer, torch.nn.LayerNorm):
-            if layer.elementwise_affine:
+                input_minmax = [self.input_mins[layer_name], self.input_maxes[layer_name]]
+                new_module = SQLinearWrapper(layer, scale, input_minmax)
+                set_module(self.model, layer_name, new_module)
+
+        elif self.allow_absorb:
+            if isinstance(layer, torch.nn.BatchNorm2d) or isinstance(layer, torch.nn.GroupNorm) or \
+                    isinstance(layer, torch.nn.InstanceNorm2d):
+                if layer.affine:
+                    layer.weight *= scale
+                    layer.bias *= scale
+                else:
+                    layer.affine = True
+                    weight = torch.ones(layer.num_features, device=self.device, dtype=self.dtype) * scale
+                    layer.weight = torch.nn.Parameter(
+                        weight, requires_grad=False)
+                    bias = torch.zeros(layer.num_features, device=self.device, dtype=self.dtype)
+                    layer.bias = torch.nn.Parameter(bias, requires_grad=False
+                                                    )
+            elif isinstance(layer, torch.nn.LayerNorm):
+                if layer.elementwise_affine:
+                    layer.weight *= scale
+                    layer.bias *= scale
+                else:
+                    layer.elementwise_affine = True
+                    weight = torch.ones(layer.num_features, device=self.device, dtype=self.dtype) * scale
+                    layer.weight = torch.nn.Parameter(
+                        torch.ones(weight, requires_grad=False))
+                    bias = torch.zeros(layer.num_features, device=self.device, dtype=self.dtype)
+                    layer.bias = torch.nn.Parameter(
+                        bias, requires_grad=False)
+
+            elif isinstance(layer, torch.nn.Conv2d):
+                ##the order could not be changed
+                if hasattr(layer, "bias") and (layer.bias != None):
+                    layer.bias *= scale
+                scale = scale.view(scale.shape[0], 1, 1, 1)
                 layer.weight *= scale
-                layer.bias *= scale
-            else:
-                layer.elementwise_affine = True
-                weight = torch.ones(layer.num_features, device=self.device, dtype=self.dtype) * scale
-                layer.weight = torch.nn.Parameter(
-                    torch.ones(weight, requires_grad=False))
-                bias = torch.zeros(layer.num_features, device=self.device, dtype=self.dtype)
-                layer.bias = torch.nn.Parameter(
-                    bias, requires_grad=False)
-
-        elif isinstance(layer, torch.nn.Conv2d):
-            ##the order could not be changed
-            if hasattr(layer, "bias") and (layer.bias != None):
-                layer.bias *= scale
-            scale = scale.view(scale.shape[0], 1, 1, 1)
-            layer.weight *= scale
-
-        elif isinstance(layer, torch.nn.Linear):
-            if hasattr(layer, "bias") and (layer.bias != None):
-                layer.bias *= scale
-            scale = scale.view(scale.shape[0], 1)
-            layer.weight *= scale
-
-        elif layer.__class__.__name__ == "LlamaRMSNorm" or layer.__class__.__name__ == "T5LayerNorm":  ##quite tricky
-            layer.weight *= scale
 
+            elif isinstance(layer, torch.nn.Linear):
+                if hasattr(layer, "bias") and (layer.bias != None):
+                    layer.bias *= scale
+                scale = scale.view(scale.shape[0], 1)
+                layer.weight *= scale
 
-        else:
-            logger.warning(f"found unsupported layer {type(layer)}, try to multiply scale to weight and bias directly, "
-                           f"this may introduce accuracy issue, please have a check ")
-            if hasattr(layer, "weight") and layer.weight != None:
+            elif layer.__class__.__name__ == "LlamaRMSNorm" \
+              or layer.__class__.__name__ == "T5LayerNorm":  ##quite tricky
                 layer.weight *= scale
-            if hasattr(layer, "bias") and layer.bias != None:
-                layer.bias *= scale
+
+            else:
+                logger.warning(f"found unsupported layer {type(layer)}, try to multiply scale to "
+                  f"weight and bias directly, this may introduce accuracy issue, please have a check ")
+                if hasattr(layer, "weight") and layer.weight != None:
+                    layer.weight *= scale
+                if hasattr(layer, "bias") and layer.bias != None:
+                    layer.bias *= scale
 
     def _adjust_parameters(self, absorb_to_layer, input_maxes, alpha=0.5):
         """
         adjust the weights and biases
         :param absorb_to_layer: A dict mapping absorb layer to smooth quantized layer
         :param input_maxes: The channel-wise input max info for layers
-        :param alpha: Alpha value to balance the quantization difficulty of activation and weight
+        :param alpha: Alpha value to balance the quantization difficulty of activation and weight, a float of a dict
         :return:
         """
         absorb_to_input_maxes = {}
         for key in absorb_to_layer.keys():
             layer_name = absorb_to_layer[key][0]
             absorb_to_input_maxes[key] = input_maxes[layer_name]
 
         weight_scales_info = {}
         absorb_scales_info = {}
         for index, key in enumerate(absorb_to_layer.keys()):
+            if isinstance(alpha, float):
+                alpha_key = alpha
+            elif isinstance(alpha, dict):
+                alpha_key = alpha[key]
             input_max = absorb_to_input_maxes[key]
             layers = absorb_to_layer[key]
             weights = []
             for layer in layers:
                 weight = self._reshape_in_channel_to_last(layer)
                 weights.append(weight)
 
             weights = torch.cat(weights, dim=0)
 
             weight_max_per_channel = torch.max(torch.abs(weights), dim=0)[0]
-            input_power = torch.pow(input_max, alpha)
-            logger.debug(f"{max(input_max)}, {min(input_power)}")
-            weight_power = torch.pow(weight_max_per_channel, 1 - alpha)
+            input_power = torch.pow(input_max, alpha_key)
+            logger.debug(f"{max(input_max)}, {min(input_max)}")
+            weight_power = torch.pow(weight_max_per_channel, 1 - alpha_key)
             # logger.info(f"{absorb_to_layer[key][0]} layer sparsity is
             # {1.0-torch.count_nonzero(input_power)/input_power.numel()}")
 
             scale = torch.clip(input_power / weight_power, min=1e-5)
             scale[input_power == 0] = 1.0
 
             self._absorb_scales(key, 1.0 / scale)
             absorb_scales_info[key] = 1.0 / scale
             layer_names = absorb_to_layer[key]
             for layer_name in layer_names:
                 self._scale_layer_weight(layer_name, scale)
                 weight_scales_info[layer_name] = scale
         return weight_scales_info, absorb_scales_info
 
-    def _check_same_hyperparameters(self, percentile, op_types,
-                                    scales_per_op, calib_iter):
+    def _check_need_calibration(self, alpha, percentile, op_types,
+                                scales_per_op, calib_iter):
         """
-        :param percentile:
-        :param op_types:
-        :param scales_per_op:
-        :param calib_iter:
+        check need calibration or not
+        :param alpha: current alpha
+        :param percentile: current percentile
+        :param op_types: current op_types
+        :param scales_per_op: current scales_per_op
+        :param calib_iter:: current scales_per_op
         :return:
         """
-        if len(self.input_maxes) == 0:
-            self.percentile = percentile
-            self.op_types = op_types
-            self.scales_per_op = scales_per_op
-            self.calib_iter = calib_iter
-            return False
-        if self.percentile != percentile or self.op_types != op_types \
-                or self.scales_per_op != scales_per_op or self.calib_iter != calib_iter:
+        need_calib = True
+        if len(self.input_maxes) == 0:  ## the first time
+            need_calib = True
+            self.alpha = alpha
             self.percentile = percentile
             self.op_types = op_types
             self.scales_per_op = scales_per_op
             self.calib_iter = calib_iter
+            return need_calib
+
+        if self.percentile == percentile and self.op_types == op_types \
+                and self.scales_per_op == scales_per_op and self.calib_iter != calib_iter:
+            if isinstance(alpha, float):
+                need_calib = False
+            elif self.alpha == "auto":
+                need_calib = False
+
+        self.alpha = alpha
+        self.percentile = percentile
+        self.op_types = op_types
+        self.scales_per_op = scales_per_op
+        self.calib_iter = calib_iter
+        return need_calib
+
+    def _check_dw_conv(self, module):
+        if not isinstance(module, torch.nn.Conv2d):
             return False
-        else:
-            return True
 
-    def auto_tune_alpha(self, input_maxes, alpha_min=0.3, alpha_max=0.7, alpha_step=0.05, attn_method='min'):
+        return module.groups > 1 and module.in_channels == module.out_channels and \
+               module.groups == module.in_channels
+
+    def _auto_tune_alpha(self, input_maxes, alpha_min=0.3, alpha_max=0.7, alpha_step=0.05, attn_method='min'):
         """
         Perform alpha-tuning to obtain layer-wise optimal alpha values and adjust parameters accordingly.
         input_maxes:
         alpha_min: min value of alpha search space.
         alpha_max: max value of alpha search space.
         alpha_step: step size of alpha search space.
         attn_method: criterion method used on attention ops; currently min, max and mean are supported.
         """
-        logger.info("enter auto")
+        logger.info("auto tuning alpha")
         import copy
+        from .model_wrapper import SQLinearWrapper
         alpha_scale = 100
-        alpha_values = list(range(round(alpha_min * alpha_scale), round((alpha_max + alpha_step) * alpha_scale),
-                                  round(alpha_step * alpha_scale)))
+        alpha_space = list(range(round(alpha_min * alpha_scale), round((alpha_max + alpha_step) * alpha_scale),
+                                 round(alpha_step * alpha_scale)))
+        alpha_space = [alpha / alpha_scale for alpha in alpha_space]
+
         ans_layer2absorb, self.layer_to_absorb, ans = {}, {}, {}
         ## Searching optimal alphas
         for idx, key in enumerate(self.absorb_to_layer):
             absorb_to_layer_sample, input_max_op = {}, {}
             absorb_key = key
             absorb_to_layer_sample[absorb_key] = self.absorb_to_layer[absorb_key]
             loss_all_layers = {}
             for layer_key in self.absorb_to_layer[absorb_key]:
+                # if self._check_dw_conv(get_module(self.model,layer_key)):
+
                 if layer_key not in self.layer_to_absorb.values():
                     if layer_key in input_maxes:
                         self.layer_to_absorb[absorb_key] = layer_key
                 layer_key_ = self.layer_to_absorb[absorb_key]
                 input_max_op[layer_key] = input_maxes[layer_key_]
                 loss_alpha = {}
-                for alpha in alpha_values:
-                    alpha = alpha / alpha_scale
+                for alpha in alpha_space:
                     self.weight_scale_info, self.absorb_scales_info = self._adjust_parameters(absorb_to_layer_sample,
                                                                                               input_max_op, alpha)
                     input_of_op, output_of_op = self.input_values[layer_key], self.output_values[layer_key]
-                    # if output_of_op.ndim == 3:
-                    #     output_of_op = output_of_op[0]
-                    input_of_op_q = quant_dequant_x(input_of_op * self.absorb_scales_info[absorb_key])
-                    layer = self._get_module(layer_key)
+                    input_scale = self._reshape_scale_for_input(get_module(self.model, layer_key),
+                                                                self.absorb_scales_info[absorb_key])
+                    input_of_op_q = quant_dequant_x(input_of_op * input_scale)
+                    layer = get_module(self.model, layer_key)
+                    if isinstance(layer, SQLinearWrapper):
+                        layer = layer.sq_linear
                     weight_qdq = quant_dequant_w(layer)
                     layer_cp = copy.deepcopy(layer)
                     layer_cp.weight.data = weight_qdq
                     output_of_op_q = layer_cp(input_of_op_q)
                     self.recover()
                     loss = torch.sum(torch.abs(output_of_op - output_of_op_q) ** 2)
                     loss_alpha[alpha] = loss
@@ -514,95 +619,128 @@
                         ans_layer2absorb[absorb_key] = max(ans_layer2absorb[absorb_key], ans[layer_key])
                     elif attn_method == 'min':
                         ans_layer2absorb[absorb_key] = min(ans_layer2absorb[absorb_key], ans[layer_key])
                     elif attn_method == 'mean':
                         pass
             if attn_method == 'mean':
                 mean_loss = {}
-                for alpha in alpha_values:
-                    alpha = alpha / alpha_scale
+                for alpha in alpha_space:
                     mean_loss[alpha] = 0
                     for key in loss_all_layers.keys():
                         mean_loss[alpha] += loss_all_layers[key][alpha]
                 min_alpha = min(mean_loss, key=mean_loss.get)
                 if len(loss_all_layers) > 1:
                     ans_layer2absorb[absorb_key] = min_alpha
+        logger.info("auto tuning alpha done")
+        return ans_layer2absorb
 
-        for idx, key in enumerate(self.absorb_to_layer):  # Adjust parameters according to optimal alphas.
-            absorb_to_layer_sample, input_max_op = {}, {}
-            absorb_key = key
-            absorb_to_layer_sample[absorb_key] = self.absorb_to_layer[absorb_key]
-            layer_key_ = self.layer_to_absorb[absorb_key]
-            input_max_op[layer_key_] = input_maxes[layer_key_]
-            if key in ans_layer2absorb:
-                op_weight_scale, op_absorb_scale = self._adjust_parameters(absorb_to_layer_sample, input_max_op,
-                                                                           alpha=ans_layer2absorb[key])
-            else:
-                op_weight_scale, op_absorb_scale = self._adjust_parameters(absorb_to_layer_sample, input_max_op)
-            self.weight_scale_info.update(op_weight_scale)
-            self.absorb_scales_info.update(op_absorb_scale)
-        self.input_values, self.output_values = {}, {}
-
-    def transform(self, alpha=0.5, percentile=99.999, op_types=['Linear', 'Conv2d'],
-                  scales_per_op=False, calib_iter=100):
+    def transform(self, alpha=0.5, folding=False, percentile=99.999, op_types=['Linear', 'Conv2d'],
+                  scales_per_op=False, calib_iter=100,
+                  auto_alpha_args={'alpha_min': 0.3, 'alpha_max': 0.7, 'alpha_step': 0.05, 'attn_method': 'min'}):
         """
         The main entry of smooth quant
         :param alpha: Alpha value to balance the quantization difficulty of activation and weight, please refer
         to the paper for more details
+        :param folding: whether insert mul(False) or just allow foldable layers(True) for SmoothQuant
         :param percentile: Not supported now
         :param op_types: The op typed to be smooth quantized
         :param scales_per_op: Not supported now
         :param calib_iter: Data size for calibration
         :return: A FP32 model with the same architecture as the orig model but with different weight which will be
         benefit to quantization
         """
+        if folding:
+            self.insert_mul, self.allow_absorb = False, True
+        else:
+            self.insert_mul, self.allow_absorb = True, False
+        if isinstance(alpha, float) and (alpha < 0 or alpha > 1):
+            logger.warning("alpha should be a float value in [0, 1] or 'auto' ")
+            if alpha < 0:
+                alpha = 0
+                logger.warning("reset alpha to 0 ")
+            if alpha > 1.0:
+                alpha = 1.0
+                logger.warning("reset alpha to 1.0 ")
+
         if not isinstance(self.model, torch.nn.Module):
             logger.warning("smooth quant is ignored since the model is not a torch module")
             return self.model
-        matched = self._check_same_hyperparameters(percentile, op_types, scales_per_op, calib_iter)
+        self.recover()
+        need_calibration = self._check_need_calibration(alpha, percentile, op_types, scales_per_op, calib_iter)
         with torch.no_grad():
             input_maxes = self.input_maxes
-            if matched == False:  ##avoid multiple calibaration during tuning if the only difference is alpha
-                self.recover()
-                self.absorb_to_layer, no_absorb_layers = self._trace(
-                    op_types)  ##TODO we need to insert mul layer for no_absorb_layers later
+            if need_calibration:  ##avoid multiple calibaration during tuning if the only difference is alpha
+                if self.insert_mul:
+                    self.self_absorb_layers = self._get_all_layer_names()   # TODO: only support linear now.
+                if self.allow_absorb:
+                    self.absorb_to_layer, no_absorb_layers = self._trace(
+                        op_types)  ##TODO we need to insert mul layer for no_absorb_layers later
+                    if self.absorb_to_layer == None and no_absorb_layers == None:
+                        logger.warning("sorry, could not trace the model, smooth quant is ignored")
+                        logger.warning("if you are using huggingface model,"
+                                    "you could set torchscript to True "
+                                    "when loading the model or set the return_dict to False")
+                        return self.model
+
+                # remove self.self_absorb_layers if it exists in self.absorb_to_layer
+                for k, v in self.absorb_to_layer.items():
+                    for i in v:
+                        if i in self.self_absorb_layers:
+                            self.self_absorb_layers.pop(i)
+                self.absorb_to_layer.update(self.self_absorb_layers)
                 for key in self.absorb_to_layer:
                     self.hook_layer_names += self.absorb_to_layer[key]
+
                 if self.absorb_to_layer == None and no_absorb_layers == None:
                     logger.warning("sorry, could not trace the model, smooth quant is ignored")
                     logger.warning("if you are using huggingface model,"
-                                   "you could set torchscript to True "
-                                   "when loading the model or set the return_dict to False")
+                                   "you could set torchscript to True ")
                     return self.model
                 save_input_output = False
                 if alpha == "auto":
                     save_input_output = True
 
                 input_maxes = self._calibrate(self.absorb_to_layer, calib_iter, save_input_output)
+                if alpha == 'auto':
+                    self.alpha_per_layer = self._auto_tune_alpha(input_maxes, **auto_alpha_args)  ##save the alpha
 
-            self.recover()
             if alpha == 'auto':
-                self.auto_tune_alpha(input_maxes)
-            else:
-                self.weight_scale_info, self.absorb_scales_info = self._adjust_parameters(self.absorb_to_layer,
-                                                                                          input_maxes, alpha)
+                alpha = self.alpha_per_layer
+
+            self.weight_scale_info, self.absorb_scales_info = self._adjust_parameters(self.absorb_to_layer,
+                                                                                      input_maxes, alpha)
+            self.input_values, self.output_values = {}, {}
             return self.model
 
     def recover(self):
         """
         recover the model weights
         :return:
         """
         with torch.no_grad():
             for key in self.weight_scale_info:
                 self._scale_layer_weight(key, 1.0 / self.weight_scale_info[key])
             for key in self.absorb_scales_info:
                 self._absorb_scales(key, 1.0 / self.absorb_scales_info[key])
             self.weight_scale_info = {}  ##clear the data
             self.absorb_scales_info = {}
+ 
+    def _get_all_layer_names(self, op_types=['Linear']):
+        """
+        Try the model to find the layers which can be smooth quantized.
+        :param op_types: The op types to be smooth quantized
+        :return:
+        self_absorb_layer: A dict, absorb layer name (itself): layers to be smooth quantized
+        """
+        self_absorb_layer = {}
+        for name, module in self.model.named_modules():
+            for op_type in op_types:
+                if op_type == str(module.__class__.__name__):
+                    self_absorb_layer[name] = [name]
+        return self_absorb_layer
 
     def _trace(self, op_types):
         """
         Try the model to find the layers which can be smooth quantized.
         :param op_types: The op types to be smooth quantized
         :return:
         absorb_to_layer: A dict, absorb layer name:layers to be smooth quantized
@@ -618,26 +756,14 @@
 
 def get_parent(node):
     if node.inputs() == None:
         return None
     return list(node.inputs())[0].node()
 
 
-def get_module(model, key):
-    attrs = key.split('.')
-    module = model
-    for attr in attrs:
-        try:
-            attr = int(attr)
-            module = module[attr]
-        except:
-            module = getattr(module, attr)
-    return module
-
-
 class GraphTrace:
     """
     """
 
     def __init__(self):
         self.supported_torch_module_to_aten = {
             "Linear": "aten::linear",
@@ -759,7 +885,43 @@
                 layer_type = layer.__class__.__name__
                 if layer_type not in self.supported_torch_module_to_aten.keys():
                     supported = False
                     break
             if supported:
                 res[key] = absorb_to_layer[key]
         return res
+
+def update_sq_scale(ipex_config_path, smoothquant_scale_info):
+    """update ipex_config.json with smoothquant scale info generated by our algorithm.
+
+    Args:
+        ipex_config_path (str): a path to temporary ipex_config.json file.
+        smoothquant_scale_info (dict): a dict contains smoothquant scale info.
+    """
+    with open(ipex_config_path, 'r') as f:
+        ipex_config = json.load(f)
+        for module_name, v in ipex_config.items():
+            if 'q_op_infos' in v and v['q_op_infos']:
+                for op_num, v1 in v['q_op_infos'].items():
+                    if 'weight_tensor_infos' in v1 and v1['weight_tensor_infos']:
+                        op_name = v1['fqn']
+                        if op_name in smoothquant_scale_info:
+                            input_scale_for_mul = \
+                                    smoothquant_scale_info[op_name]['input_scale_for_mul'].tolist()
+                            input_scale_after_mul = \
+                                    smoothquant_scale_info[op_name]['input_scale_after_mul'].tolist()
+                            input_zero_point_after_mul = \
+                                    smoothquant_scale_info[op_name]['input_zero_point_after_mul'].tolist()
+                            weight_scale_for_mul = \
+                                    (1 / smoothquant_scale_info[op_name]['input_scale_for_mul']).tolist()
+                            weight_scale_after_mul = \
+                                    smoothquant_scale_info[op_name]['weight_scale_after_mul'].tolist()
+                            v1['input_tensor_infos'][0]['smooth_quant_scaling_factor'] = input_scale_for_mul
+                            v1['input_tensor_infos'][0]['scale'] = input_scale_after_mul
+                            v1['input_tensor_infos'][0]['zero_point'] = input_zero_point_after_mul
+                            v1['weight_tensor_infos'][0]['smooth_quant_scaling_factor'] = weight_scale_for_mul
+                            v1['weight_tensor_infos'][0]['scale'] = weight_scale_after_mul
+        f.close()
+    # overwrite ipex_config_path
+    with open(ipex_config_path, 'w') as f1:
+        json.dump(ipex_config, f1, indent = 4)
+        f1.close()
```

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/symbolic_trace.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/symbolic_trace.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/adaptor/torch_utils/util.py` & `neural_compressor_full-2.1.1/neural_compressor/adaptor/torch_utils/util.py`

 * *Files 2% similar despite different names*

```diff
@@ -731,19 +731,22 @@
     output_fp32 = simple_inference(model, example_inp)
     inner_output_fp32 = inner_output
 
     fx_op_cfgs = {}
     fallback_order = {}
     logger.info('Evaluate the sensitivity for each int8 operation')
     for op_name, qconfig in tqdm(op_cfgs.items()):
+        if op_name == "bf16_ops_list":
+            continue
         global op_cfg_mapping
         if op_name not in op_cfg_mapping:
             op_cfg_mapping[op_name] = qconfig
         tmp_model = copy.deepcopy(model)
         if not qconfig:
+            logger.debug(f"No qconfig for {op_name}, next op.")
             continue
         op_cfgs[op_name] = None
         fx_op_cfgs = _cfgs_to_fx_cfgs(op_cfgs, tune_cfg["approach"])
         op_cfgs[op_name] = qconfig
         from torch.quantization.quantize_fx import prepare_fx,convert_fx
         # do quantization
         if adaptor.sub_module_list is None:
@@ -766,29 +769,32 @@
         module.register_forward_hook(output_hook)
         output_qdq = simple_inference(tmp_model, example_inp)
         inner_output_int8 = inner_output.dequantize() if \
           inner_output.dtype == torch.quint8 else inner_output
         mse_val = (inner_output_fp32 - inner_output_int8).pow(2).sum()
         fallback_order[(op_name, op_type_dict[op_name])] = mse_val
 
-    ordered_ops = sorted(fallback_order.keys(), key=lambda key: fallback_order[key], \
-                                    reverse=False)
+    logger.debug(f"fallback order: {fallback_order}")
+    ordered_ops = sorted(fallback_order.keys(), key=lambda key: fallback_order[key], reverse=False)
+    if not ordered_ops:
+        return ordered_ops
     min_mse, max_mse = fallback_order[ordered_ops[0]], fallback_order[ordered_ops[-1]]
 
     if min_mse < 0.8 * max_mse:
+        logger.debug("Return the sorted ops early.")
         return ordered_ops
 
-
     double_check_list = []
     for op_name in ordered_ops:
         if min_mse <= fallback_order[op_name] <= (max_mse - min_mse) * 0.1 + min_mse:
             double_check_list.append(op_name)
-
-    check_num = min(len(ordered_ops)//10, 5)
+    
+    check_num = min(len(ordered_ops)//10 + 1, 5)
     double_check_list = ordered_ops[:check_num]
+    logger.debug(f"double check list: {double_check_list}")
     worst_op_name = ordered_ops[-1]
     op_cfgs[worst_op_name[0]] = None # fallback worst module first
     new_fallback_order = {}
 
     logger.info('Evaluate the sensitivity gradient for selected operations')
     for op_name, op_type in tqdm(double_check_list):
         tmp_model = copy.deepcopy(model)
@@ -913,7 +919,36 @@
     from packaging.version import Version
     try:
         torch_version = torch.__version__.split('+')[0]
     except ValueError as e:  # pragma: no cover
         assert False, 'Got an unknown version of torch: {}'.format(e)
     version = Version(torch_version)
     return version
+
+
+def match_datatype_pattern(datatype, pattern=None):
+    """Check the datatype pattern."""
+    import re
+    if not pattern:
+        pattern = r"(uint|int)([1-8])"
+    match = re.match(pattern, datatype)
+    return match
+    
+def _get_signed_and_bits(datatype):
+    """Parse sign and bits from datatype."""
+    unsigned = datatype[0] == 'u'
+    if unsigned:
+        num_bits = int(datatype[4:])
+    else:
+        num_bits = int(datatype[3:])
+    return unsigned, num_bits
+
+def calculate_quant_min_max(unsigned, num_bits):
+    """Calculate the qmin and qmax according to the datatype."""
+    # TODO handle reduce range
+    quant_min, quant_max = None, None
+    if unsigned:
+        quant_min, quant_max =0.0 , 2.0**(num_bits) - 1.0
+    else:
+        quant_min, quant_max = -1 * 2.0**(num_bits - 1), 2.0**(num_bits - 1) - 1
+    return quant_min, quant_max
+
```

### Comparing `neural_compressor_full-2.1/neural_compressor/algorithm/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/algorithm/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/algorithm/algorithm.py` & `neural_compressor_full-2.1.1/neural_compressor/algorithm/algorithm.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/algorithm/fast_bias_correction.py` & `neural_compressor_full-2.1.1/neural_compressor/algorithm/fast_bias_correction.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/algorithm/smooth_quant.py` & `neural_compressor_full-2.1.1/neural_compressor/algorithm/smooth_quant.py`

 * *Files 4% similar despite different names*

```diff
@@ -37,19 +37,21 @@
     def __init__(self, alpha=0.5):
         """Initialize SmoothQuant class.
 
         Args:
             alpha:Alpha value to balance the quantization difficulty of activation and weight,
                 please refer to the paper for more details
         """
-        # percentile:Percentile of calibration to remove outliers,float(0->100)
+        # folding: whether insert mul(False) or just allow foldable layers(True) for SmoothQuant
+        # percentile: Percentile of calibration to remove outliers,float(0->100)
         # op_types: The op types whose input tensor will be dumped,['Conv', 'Linear']
         # scales_per_op: True, each op will have an individual scale, mainly for accuracy
         #                False, ops with the same input will share a scale, mainly for performance
         self.alpha = alpha
+        self.folding = False
         self.percentile = None
         self.op_types = None
         self.scales_per_op = None
         self.tune_cfg = None
 
     def __call__(self, origin_model, q_model, adaptor, dataloader, calib_iter):
         """Return the processed model via SmoothQuant algorithm.
@@ -65,17 +67,24 @@
             adaptor: adaptor
             dataloader: dataloader
             calib_iter: calib_iter
 
         Returns:
             model: A modified onnx model
         """
-        args = {}  ##different backends may have different default values
+        kwargs = {}  ##different backends may have different default values
         if self.op_types != None:
-            args["op_types"] = self.op_types
+            kwargs["op_types"] = self.op_types
         if self.percentile != None:
-            args['percentile'] = self.percentile
+            kwargs['percentile'] = self.percentile
         if self.scales_per_op != None:
-            args['scales_per_op'] = self.scales_per_op
-        q_model = adaptor.smooth_quant(origin_model, dataloader, calib_iter, self.tune_cfg, self.alpha,
-                                       **args)
+            kwargs['scales_per_op'] = self.scales_per_op
+        q_model = adaptor.smooth_quant(
+            origin_model,
+            dataloader,
+            calib_iter,
+            self.tune_cfg,
+            alpha=self.alpha,
+            folding=self.folding,
+            **kwargs,
+        )
         return q_model
```

### Comparing `neural_compressor_full-2.1/neural_compressor/algorithm/weight_correction.py` & `neural_compressor_full-2.1.1/neural_compressor/algorithm/weight_correction.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/benchmark.py` & `neural_compressor_full-2.1.1/neural_compressor/benchmark.py`

 * *Files 1% similar despite different names*

```diff
@@ -205,15 +205,15 @@
                         throughput = re.search(r"[T,t]hroughput:\s+(\d+(\.\d+)?)", line)
                         throughput_l.append(float(throughput.group(1))) if throughput and throughput.group(1) else None
             if throughput_l and latency_l:
                 assert len(latency_l)==len(throughput_l)==num_of_instance, \
                     "Multiple instance benchmark failed with some instance!"
 
                 output_data = [
-                    ["Latency average [second/sample]", "{:.3f}".format(sum(latency_l)/len(latency_l))],
+                    ["Latency average [second/sample]", "{:.6f}".format((sum(latency_l)/len(latency_l))/1000)],
                     ["Throughput sum [samples/second]", "{:.3f}".format(sum(throughput_l))]
                 ]
                 logger.info("********************************************")
                 Statistics(
                     output_data,
                     header='Multiple Instance Benchmark Summary',
                     field_names=["Items", "Result"]).print_stat()
```

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/callbacks.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/callbacks.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/distillation/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/distillation/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/distillation/criterions.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/distillation/criterions.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/pruner/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/pruner/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/pruner/criteria.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/pruner/criteria.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/pruner/patterns.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/pruner/patterns.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/pruner/pruners.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/pruner/pruners.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/pruner/regs.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/pruner/regs.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/pruner/schedulers.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/pruner/schedulers.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/compression/pruner/utils.py` & `neural_compressor_full-2.1.1/neural_compressor/compression/pruner/utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/conf/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/conf/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/conf/config.py` & `neural_compressor_full-2.1.1/neural_compressor/conf/config.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/conf/dotdict.py` & `neural_compressor_full-2.1.1/neural_compressor/conf/dotdict.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/conf/pythonic_config.py` & `neural_compressor_full-2.1.1/neural_compressor/conf/pythonic_config.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/config.py` & `neural_compressor_full-2.1.1/neural_compressor/config.py`

 * *Files 0% similar despite different names*

```diff
@@ -1619,15 +1619,15 @@
 
     Args:
         dtype (str, optional): The data type of the exported model, select from ["fp32", "int8"]. 
                                Defaults to "int8".
         opset_version (int, optional): The ONNX opset version used for export. Defaults to 14.
         quant_format (str, optional): The quantization format of the exported int8 onnx model, 
                                       select from ["QDQ", "QLinear"]. Defaults to "QDQ".
-        example_inputs (optional): Example inputs used for tracing model. Defaults to None.
+        example_inputs (tensor|list|tuple|dict, optional): Example inputs used for tracing model. Defaults to None.
         input_names (list, optional): A list of model input names. Defaults to None.
         output_names (list, optional): A list of model output names. Defaults to None.
         dynamic_axes (dict, optional): A dictionary of dynamic axes information. Defaults to None.
     """
     def __init__(
         self,
         dtype="int8",
@@ -1738,15 +1738,15 @@
 
     Args:
         dtype (str, optional): The data type of the exported model, select from ["fp32", "int8"]. 
                                Defaults to "int8".
         opset_version (int, optional): The ONNX opset version used for export. Defaults to 14.
         quant_format (str, optional): The quantization format of the exported int8 onnx model, 
                                       select from ["QDQ", "QLinear"]. Defaults to "QDQ".
-        example_inputs (required): Example inputs used for tracing model. Defaults to None.
+        example_inputs (tensor|list|tuple|dict, required): Example inputs used for tracing model. Defaults to None.
         input_names (list, optional): A list of model input names. Defaults to None.
         output_names (list, optional): A list of model output names. Defaults to None.
         dynamic_axes (dict, optional): A dictionary of dynamic axes information. Defaults to None.
         recipe (str, optional): A string to select recipes used for Linear -> Matmul + Add, select from 
                                 ["QDQ_OP_FP32_BIAS", "QDQ_OP_INT32_BIAS", "QDQ_OP_FP32_BIAS_QDQ"]. 
                                 Defaults to 'QDQ_OP_FP32_BIAS'.
```

### Comparing `neural_compressor_full-2.1/neural_compressor/contrib/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/contrib/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/contrib/strategy/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/contrib/strategy/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/contrib/strategy/sigopt.py` & `neural_compressor_full-2.1.1/neural_compressor/contrib/strategy/sigopt.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/contrib/strategy/tpe.py` & `neural_compressor_full-2.1.1/neural_compressor/contrib/strategy/tpe.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/data/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/base_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/base_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/default_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/default_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/fetcher.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/fetcher.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/mxnet_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/mxnet_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/onnxrt_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/onnxrt_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/pytorch_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/pytorch_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/sampler.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/sampler.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/dataloaders/tensorflow_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/data/dataloaders/tensorflow_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/datasets/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/data/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/datasets/bert_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/data/datasets/bert_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/datasets/coco_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/data/datasets/coco_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/datasets/dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/data/datasets/dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/datasets/dummy_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/data/datasets/dummy_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/datasets/dummy_dataset_v2.py` & `neural_compressor_full-2.1.1/neural_compressor/data/datasets/dummy_dataset_v2.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/datasets/imagenet_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/data/datasets/imagenet_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/datasets/style_transfer_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/data/datasets/style_transfer_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/filters/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/data/filters/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/filters/coco_filter.py` & `neural_compressor_full-2.1.1/neural_compressor/data/filters/coco_filter.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/filters/filter.py` & `neural_compressor_full-2.1.1/neural_compressor/data/filters/filter.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/transforms/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/data/transforms/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/transforms/coco_transform.py` & `neural_compressor_full-2.1.1/neural_compressor/data/transforms/coco_transform.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/transforms/imagenet_transform.py` & `neural_compressor_full-2.1.1/neural_compressor/data/transforms/imagenet_transform.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/transforms/postprocess.py` & `neural_compressor_full-2.1.1/neural_compressor/data/transforms/postprocess.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/transforms/tokenization.py` & `neural_compressor_full-2.1.1/neural_compressor/data/transforms/tokenization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/data/transforms/transform.py` & `neural_compressor_full-2.1.1/neural_compressor/data/transforms/transform.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/benchmark.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/benchmark.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/common/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/common/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/common/criterion.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/common/criterion.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/common/dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/common/dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/common/metric.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/common/metric.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/common/model.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/common/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/common/optimizer.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/common/optimizer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/common/postprocess.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/common/postprocess.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/common/torch_utils.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/common/torch_utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/component.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/component.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/compression/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/compression/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/compression/pruning.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/compression/pruning.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/base_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/base_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/default_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/default_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/fetcher.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/fetcher.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/mxnet_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/mxnet_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/onnxrt_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/onnxrt_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/pytorch_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/pytorch_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/sampler.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/sampler.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/dataloaders/tensorflow_dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/dataloaders/tensorflow_dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/bert_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/bert_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/coco_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/coco_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/dummy_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/dummy_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/dummy_dataset_v2.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/dummy_dataset_v2.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/imagenet_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/imagenet_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/datasets/style_transfer_dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/datasets/style_transfer_dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/filters/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/filters/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/filters/coco_filter.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/filters/coco_filter.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/filters/filter.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/filters/filter.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/imagenet_transform.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/imagenet_transform.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/tokenization.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/tokenization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/data/transforms/transform.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/data/transforms/transform.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/distillation.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/distillation.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/export/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/export/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/export/qlinear2qdq.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/export/qlinear2qdq.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/export/tf2onnx.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/export/tf2onnx.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/export/torch2onnx.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/export/torch2onnx.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/export/utils.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/export/utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/graph_optimization.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/graph_optimization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/metric/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/metric/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/metric/bleu.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/metric/bleu.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/metric/bleu_util.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/metric/bleu_util.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/metric/coco_label_map.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/metric/coco_label_map.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/metric/coco_tools.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/metric/coco_tools.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/metric/evaluate_squad.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/metric/evaluate_squad.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/metric/f1.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/metric/f1.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/metric/metric.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/metric/metric.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/mixed_precision.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/mixed_precision.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/model_conversion.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/model_conversion.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/nas/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/nas/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/nas/basic_nas.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/nas/basic_nas.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/nas/dynas.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/nas/dynas.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/nas/nas.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/nas/nas.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/nas/nas_utils.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/nas/nas_utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/nas/search_algorithms.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/nas/search_algorithms.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/gradient_sensitivity.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/gradient_sensitivity.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/group_lasso.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/group_lasso.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/magnitude.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/magnitude.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/pattern_lock.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/pattern_lock.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruner_legacy/pruner.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruner_legacy/pruner.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruning.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruning.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/patterns/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/patterns/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/patterns/pattern.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/patterns/pattern.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pruning_v2.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pruning_v2.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/logger.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/logger.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/patterns.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/patterns.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/prune_utils.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/prune_utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/pruner.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/pruner.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/pruning.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/pruning.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/pytorch_pruner/scheduler.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/pytorch_pruner/scheduler.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/quantization.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/quantization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/experimental/scheduler.py` & `neural_compressor_full-2.1.1/neural_compressor/experimental/scheduler.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/metric/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/metric/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/metric/bleu.py` & `neural_compressor_full-2.1.1/neural_compressor/metric/bleu.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/metric/bleu_util.py` & `neural_compressor_full-2.1.1/neural_compressor/metric/bleu_util.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/metric/coco_label_map.py` & `neural_compressor_full-2.1.1/neural_compressor/metric/coco_label_map.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/metric/coco_tools.py` & `neural_compressor_full-2.1.1/neural_compressor/metric/coco_tools.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/metric/evaluate_squad.py` & `neural_compressor_full-2.1.1/neural_compressor/metric/evaluate_squad.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/metric/f1.py` & `neural_compressor_full-2.1.1/neural_compressor/metric/f1.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/metric/metric.py` & `neural_compressor_full-2.1.1/neural_compressor/metric/metric.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/mix_precision.py` & `neural_compressor_full-2.1.1/neural_compressor/mix_precision.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/model/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/model/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/model/base_model.py` & `neural_compressor_full-2.1.1/neural_compressor/model/base_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/model/keras_model.py` & `neural_compressor_full-2.1.1/neural_compressor/model/keras_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/model/model.py` & `neural_compressor_full-2.1.1/neural_compressor/model/model.py`

 * *Files 2% similar despite different names*

```diff
@@ -168,21 +168,21 @@
             if backend_tmp == "pytorch":
                 backend = "pytorch_fx"
             else:
                 backend = backend_tmp
         elif backend == "ipex":
             backend = "pytorch_ipex"
 
-        if 'tensorflow' in backend:
+        if 'tensorflow' in backend or backend == 'keras':
             if kwargs.get("approach", None) == "quant_aware_training":
                 return TensorflowQATModel(root, **kwargs)
 
             if 'modelType' in kwargs:
                 model_type = kwargs['modelType']
             else:
                 model_type = get_model_type(root)
-            if model_type == 'keras':
+            if backend == 'keras' and model_type == 'keras':
                 return MODELS['keras'](root, **kwargs)
             model = MODELS['tensorflow'](model_type, root, **kwargs)
         else:
             model = MODELS[backend](root, **kwargs)
         return model
```

### Comparing `neural_compressor_full-2.1/neural_compressor/model/mxnet_model.py` & `neural_compressor_full-2.1.1/neural_compressor/model/mxnet_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/model/nets_factory.py` & `neural_compressor_full-2.1.1/neural_compressor/model/nets_factory.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/model/onnx_model.py` & `neural_compressor_full-2.1.1/neural_compressor/model/onnx_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/model/tensorflow_model.py` & `neural_compressor_full-2.1.1/neural_compressor/model/tensorflow_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/model/torch_model.py` & `neural_compressor_full-2.1.1/neural_compressor/model/torch_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/objective.py` & `neural_compressor_full-2.1.1/neural_compressor/objective.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/quantization.py` & `neural_compressor_full-2.1.1/neural_compressor/quantization.py`

 * *Files 6% similar despite different names*

```diff
@@ -403,17 +403,15 @@
         model (torch.nn.Module):              For Tensorflow model, it could be a path
                                               to frozen pb,loaded graph_def object or
                                               a path to ckpt/savedmodel folder.
                                               For PyTorch model, it's torch.nn.model
                                               instance.
                                               For MXNet model, it's mxnet.symbol.Symbol
                                               or gluon.HybirdBlock instance.
-        conf (QuantizationAwareTrainingConfig or PostTrainingQuantConfig):
-                                              The class of QuantizationAwareTrainingConfig
-                                              and PostTrainingQuantConfig containing accuracy goal,
+        conf (PostTrainingQuantConfig):       The class of PostTrainingQuantConfig containing accuracy goal,
                                               tuning objective and preferred calibration &
                                               quantization tuning space etc.
         calib_dataloader (generator):         Data loader for calibration, mandatory for
                                               post-training quantization. It is iterable
                                               and should yield a tuple (input, label) for
                                               calibration dataset containing label,
                                               or yield (input, _) for label-free calibration
@@ -433,15 +431,18 @@
                                               and outputs a higher-is-better accuracy scalar
                                               value.
                                               The pseudo code should be something like:
                                               def eval_func(model):
                                                    input, label = dataloader()
                                                    output = model(input)
                                                    accuracy = metric(output, label)
-                                                   return accuracy
+                                                   return accuracy.
+                                              The user only needs to set eval_func or
+                                              eval_dataloader and eval_metric which is an alternative option
+                                              to tune the model accuracy.
         eval_dataloader (generator, optional): Data loader for evaluation. It is iterable
                                               and should yield a tuple of (input, label).
                                               The input could be a object, list, tuple or
                                               dict, depending on user implementation,
                                               as well as it can be taken as model input.
                                               The label should be able to take as input of
                                               supported metrics. If this parameter is
@@ -453,25 +454,28 @@
                                               process.
         eval_metric (dict or obj):             Set metric class or a dict of built-in metric configures,
                                               and neural_compressor will initialize this class when evaluation.
 
     Example::
 
         # Quantization code for PTQ
-        from neural_compressor import PostTrainingQuantConfig, set_workspace
+        from neural_compressor import PostTrainingQuantConfig
         from neural_compressor import quantization
-        conf = PostTrainingQuantConfig()
-
-        # saved intermediate files in ./saved folder
-        set_workspace("./saved")
+        def eval_func(model):
+            for input, label in dataloader:
+                output = model(input)
+                metric.update(output, label)
+            accuracy = metric.result()
+            return accuracy
 
+        conf = PostTrainingQuantConfig()
         q_model = quantization.fit(model_origin,
                                    conf,
                                    calib_dataloader=dataloader,
-                                   calib_func=eval_func)
+                                   eval_func=eval_func)
 
         # Saved quantized model in ./saved folder
         q_model.save("./saved")
     """
     quantizer = _PostTrainingQuant(conf)
     quantizer.model = model
     if eval_func is not None:
```

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/auto.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/auto.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/auto_mixed_precision.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/auto_mixed_precision.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/basic.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/basic.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/bayesian.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/bayesian.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/conservative.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/conservative.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/exhaustive.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/exhaustive.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/hawq_v2.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/hawq_v2.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/mse.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/mse.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/mse_v2.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/mse_v2.py`

 * *Files 9% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 from typing import Dict, Any, List
 from .strategy import strategy_registry, TuneStrategy
 from ..utils import logger
 from time import time 
 
 from .utils.tuning_sampler import OpTypeWiseTuningSampler
 from .utils.tuning_structs import OpTuningConfig
-
+from .utils.constant import PRECISION_LIST
 @strategy_registry
 class MSE_V2TuneStrategy(TuneStrategy):
     """The `mse_v2` tuning strategy.
     
     MSE_v2 is a strategy with a two stages fallback and revert fallback. 
     Note that, only tensorflow framework and pytorch FX backend is currently supported for mse_v2
     tuning strategy.
@@ -78,14 +78,16 @@
                 for item in items_lst:
                     op_item_dtype_dict[item.name] = target_quant_mode
 
             op_item_dtype_dict = OrderedDict()
             for quant_mode, quant_mode_items in quant_mode_wise_items.items():
                 initial_op_quant_mode(quant_mode_items, quant_mode, op_item_dtype_dict)
 
+            quant_ops = quant_mode_wise_items.get('static', [])
+            quant_ops += quant_mode_wise_items.get('dynamic', [])
             # Optype-wise tuning 
             early_stop_tuning = True
             stage1_cnt = 0
             stage1_max = 2  # TODO set a more appropriate value
             op_wise_tuning_sampler = OpTypeWiseTuningSampler(tuning_space, [], [], 
                                                              op_item_dtype_dict, initial_op_tuning_cfg)
             for op_tuning_cfg in op_wise_tuning_sampler:
@@ -129,38 +131,51 @@
                                        if self.cfg.tuning.strategy.confidence_batches != None else 2)
             tune_cfg_backup = deepcopy(tune_cfg)
             quant_ops_in_tune_cfg = self._collect_ops_by_quant_mode(tune_cfg, 'dynamic') + \
                                     self._collect_ops_by_quant_mode(tune_cfg, 'static')
             op_quant_cfgs = {op_info: tune_cfg_backup[op_info] for op_info in quant_ops_in_tune_cfg}
             fallback_records = []
             self.re_quant = True
-            while not self.objectives.compare(self.last_tune_result, self.baseline):
-                # Record the time of calcutating the sensitivity
-                start = time()
-                ops_lst = self.adaptor.calculate_op_sensitivity(self.model, 
-                                                                self.calib_dataloader, 
-                                                                deepcopy(self._tune_cfg_converter(tune_cfg)), 
-                                                                self.output_op_names,
-                                                                self.confidence_batches,
-                                                                fallback=True)
-                logger.debug(f"*** The op sensitivity analysis took {time() - start:.2f}s.")
-                select_op_info = ops_lst[0]
-                logger.info(f"*** The op {select_op_info} have the highest sensitivity in the current state, \
-                    fallback it to fp32.")
-                tune_cfg[select_op_info] = OpTuningConfig(select_op_info[0], 
-                                                            select_op_info[1], 
-                                                            'fp32', 
-                                                            self.tuning_space)
-                # Record the fallback history
-                if not fallback_records: 
-                    fallback_records = [[select_op_info]]
+            for target_dtype in PRECISION_LIST:
+                tune_cfg = deepcopy(tune_cfg_backup)
+                target_type_op_lst = set(tuning_space.query_items_by_quant_mode(target_dtype))
+                fallback_items_lst = [item for item in quant_ops if item in target_type_op_lst]
+                if fallback_items_lst:
+                    logger.info(f"Start to fallback op to {target_dtype}.")
                 else:
-                    fallback_records.append(fallback_records[-1] + [select_op_info])
-                logger.debug(f"*** The fallback ops record: \n{self._tuning_record_msg(fallback_records)}")
-                yield tune_cfg
+                    logger.info(f"No op support {target_dtype}.")
+                    continue
+                while not self.objectives.compare(self.last_tune_result, self.baseline):
+                    # Record the time of calculating the sensitivity
+                    start = time()
+                    ops_lst = self.adaptor.calculate_op_sensitivity(self.model, 
+                                                                    self.calib_dataloader, 
+                                                                    deepcopy(self._tune_cfg_converter(tune_cfg)), 
+                                                                    self.output_op_names,
+                                                                    self.confidence_batches,
+                                                                    fallback=True)
+                    if not ops_lst:
+                        logger.debug(f" Try to fallback to next data type.")
+                        break
+                    logger.debug(f"*** The op sensitivity analysis took {time() - start:.2f}s.")
+                    select_op_info = ops_lst[0]
+                    logger.debug(f"*** ops_lst({len(ops_lst)}): {ops_lst} ")
+                    logger.info(f"*** The op {select_op_info} have the highest sensitivity in the current state, \
+                        fallback it to {target_dtype}.")
+                    tune_cfg[select_op_info] = OpTuningConfig(select_op_info[0],
+                                                                select_op_info[1],
+                                                                target_dtype, 
+                                                                self.tuning_space)
+                    # Record the fallback history
+                    if not fallback_records: 
+                        fallback_records = [[select_op_info]]
+                    else:
+                        fallback_records.append(fallback_records[-1] + [select_op_info])
+                    logger.debug(f"*** The fallback ops record: \n{self._tuning_record_msg(fallback_records)}")
+                    yield tune_cfg
 
             logger.info(f"*** The accuracy meeting the accuracy requirements, stop fallback ops.")
             while self.objectives.compare(self.last_tune_result, self.baseline):
                 if len(fallback_records) == 0 or len(fallback_records[-1]) <= 1:
                     logger.info(f"*** Stop re-quant due to no int8 op or only 1 int8 op left.")
                     break
                 logger.info(f"*** Start to re-quant the fallback op in the previous stage.")
```

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/random.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/random.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/strategy.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/strategy.py`

 * *Files 1% similar despite different names*

```diff
@@ -547,14 +547,21 @@
         algo_scheduler.reset_exec_algorithms()
         if recipe_cfgs and recipe_cfgs.get('smooth_quant', False):
             # skip assign alpha to sq first.
             # set the alpha to 0.5 by default
             smooth_quant_args = recipe_cfgs.get('smooth_quant_args', {'alpha': 0.5})
             sq_algo = ALGORITHMS()['smooth_quant']
             sq_algo.alpha = smooth_quant_args['alpha']
+            if 'folding' not in smooth_quant_args:
+                smooth_quant_args['folding'] = True if self.framework in ['pytorch', 'pytorch_fx'] \
+                  else False
+                logger.info("SmoothQuant args 'folding' is not set, it's {} now.".format(smooth_quant_args['folding']))
+                if self.framework == 'pytorch_ipex':
+                    smooth_quant_args['folding'] = None # will reset it to True if IPEX version < 2.1.
+            sq_algo.folding = smooth_quant_args['folding']
             #logger.debug(f"Set smooth quant with alpha {smooth_quant_args['alpha']} as the pre-quantization algo.")
             algo_scheduler.append_algorithm('pre_quantization', sq_algo)
             
             
     def set_param_for_post_quantization_algos(self, algo_scheduler, tune_cfg, pre_optimized_model, q_model) -> None:
         """Set the parameter for post-quantization algos, such as bias correction, weight correction.
 
@@ -704,15 +711,15 @@
             logger.info("Force setting 'tuning.exit_policy.performance_only = True'.")
             
         if not self.cfg.tuning.exit_policy.performance_only:
             # get fp32 model baseline
             if self.baseline is None:
                 logger.info("Get FP32 model baseline.")
                 self._fp32_model = self.model
-                self.baseline = self._evaluate(self.model)       
+                self.baseline = self._evaluate(self.model)
                 self.objectives.baseline = self.baseline
                 # record the FP32 baseline
                 self._add_tuning_history()
             self.show_baseline_info()
 
     def _recover_best_qmodel_from_tuning_cfg(self):
         """Recover the best quantized model from tuning config."""
@@ -1055,14 +1062,15 @@
                 self.cfg.model.framework = 'pytorch_ipex'
                 framework = 'pytorch_ipex'
             elif self.cfg.model.backend == 'default':
                 self.cfg.model.framework = 'pytorch_fx'
                 framework = 'pytorch_fx'
             if self.mixed_precision_mode:
                 framework_specific_info.update({"approach": "post_training_dynamic_quant"})
+            framework_specific_info.update({'recipes': self.cfg.quantization.get('recipes', {})})
             framework_specific_info.update({"q_dataloader": q_dataloader})
             framework_specific_info.update({"use_bf16": self.cfg.use_bf16 \
                             if self.cfg.use_bf16 is not None else True})
             framework_specific_info.update(
                 {"workspace_path": os.path.dirname(self.deploy_path)})
             if self.cfg['quantization']['op_wise'] is not None \
                and 'default_qconfig' in self.cfg['quantization']['op_wise']:
```

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/utils/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/utils/constant.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/utils/constant.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Strategy constant."""
 
-PRECISION_SET = {'bf16', 'fp16' , 'fp32',}
+PRECISION_LIST = ['bf16', 'fp16' , 'fp32']
 QUANT_MODE_SET = {'static', 'dynamic'}
 QUNAT_BIT_SET = {'int8', 'uint8', 'int4', 'uint4'}
 
 TUNING_ITEMS_LST = [('activation','scheme'), ('activation','algorithm'), ('activation','granularity'),
                     ('weight','scheme'), ('weight','algorithm'), ('weight','granularity'), 'sampling_size']
 
 PRECISION_SET_V2_0 = {'fp32', 'bf16'}
```

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/utils/tuning_sampler.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/utils/tuning_sampler.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/utils/tuning_space.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/utils/tuning_space.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/utils/tuning_structs.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/utils/tuning_structs.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tuning structure."""
 
 from typing import Dict
-from .constant import QUANT_MODE_SET, TUNING_ITEMS_LST, PRECISION_SET
+from .constant import QUANT_MODE_SET, TUNING_ITEMS_LST, PRECISION_LIST
 from ...utils import logger
 
 class OpTuningConfig:
     """Op tuning config."""
     
     def __init__(self, op_name, op_type, op_quant_mode, tuning_space, kwargs={}):
         """Create the tuning config.
@@ -42,15 +42,15 @@
         self.act_dtype = None
         self.weight_dtype = None
         self.has_weight = self.op_name_type in tuning_space.ops_attr['weight']
         self._set_dtype()
         
     def _set_dtype(self):
         """Set the date type."""
-        if self.op_quant_mode in PRECISION_SET:
+        if self.op_quant_mode in PRECISION_LIST:
             self.act_dtype, self.weight_dtype = self.op_quant_mode, self.op_quant_mode
         else:
             self.act_dtype = self.kwargs.get('activation_dtype', None)
             self.weight_dtype = self.kwargs.get('weight_dtype', None)
         assert self.act_dtype and isinstance(self.act_dtype, str),\
             (f"Didn't assign the activation data type for {self.op_name, self.op_type}", \
                 f"with quant_mode {self.op_quant_mode}")
```

### Comparing `neural_compressor_full-2.1/neural_compressor/strategy/utils/utility.py` & `neural_compressor_full-2.1.1/neural_compressor/strategy/utils/utility.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/template/api_doc_example.py` & `neural_compressor_full-2.1.1/neural_compressor/template/api_doc_example.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/template/graph_optimization.yaml` & `neural_compressor_full-2.1.1/neural_compressor/template/graph_optimization.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/template/pruning.yaml` & `neural_compressor_full-2.1.1/neural_compressor/template/pruning.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/template/ptq.yaml` & `neural_compressor_full-2.1.1/neural_compressor/template/ptq.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/template/qat.yaml` & `neural_compressor_full-2.1.1/neural_compressor/template/qat.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/training.py` & `neural_compressor_full-2.1.1/neural_compressor/training.py`

 * *Files 1% similar despite different names*

```diff
@@ -263,28 +263,27 @@
 
 
 def prepare_compression(model: Callable, confs: Union[Callable, List], **kwargs):
     """Summary.
 
     Args:
         model (Callable, optional):    The model to optimize.
-        confs (Union[Callable, List]): Config of Distillation, Quantization, Pruning,
-                                       or list of config for orchestration optimization.
-                                       The config class is QuantizationAwareTrainingConfig,
-                                       PruningConfig, distillationConfig.
+        confs (Union[Callable, List]): The instance of QuantizationAwareTrainingConfig,
+                                       PruningConfig and distillationConfig, or a list of
+                                       config for orchestration optimization.
         options (Options, optional):   The configure for random_seed, workspace,
                                        resume path and tensorboard flag.
 
     Returns:
-        CompressionManager
+        An object of CompressionManager.
 
     Examples::
 
         import neural_compressor.training.prepare_compression
-        
+
         compression_manager = prepare_compression(conf, model)
         train_loop:
             compression_manager.on_train_begin()
             for epoch in range(epochs):
                 compression_manager.on_epoch_begin(epoch)
                 for i, batch in enumerate(dataloader):
                     compression_manager.on_step_begin(i)
```

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/collect_layer_histogram.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/collect_layer_histogram.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/constant.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/constant.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/create_obj_from_config.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/create_obj_from_config.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/kl_divergence.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/kl_divergence.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/load_huggingface.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/load_huggingface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/logger.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/logger.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/options.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/options.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/pytorch.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/pytorch.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/utils/utility.py` & `neural_compressor_full-2.1.1/neural_compressor/utils/utility.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/bin/inc_bench` & `neural_compressor_full-2.1.1/neural_compressor/ux/bin/inc_bench`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/benchmark.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/benchmark.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/benchmark_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/benchmark_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/benchmark/execute_benchmark.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/benchmark/execute_benchmark.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/benchmark_config_generator.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/benchmark_config_generator.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/config_generator.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/config_generator.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/graph_optimization_config_generator.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/graph_optimization_config_generator.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/mixed_precision_config_generator.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/mixed_precision_config_generator.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/profiling_config_generator.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/profiling_config_generator.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/pruning_config_generator.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/pruning_config_generator.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/config_generator/quantization_config_generator.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/config_generator/quantization_config_generator.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/configuration_parser.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/configuration_parser.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/get_boundary_nodes.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/get_boundary_nodes.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/get_configuration.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/get_configuration.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/params_feeder.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/params_feeder.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/configuration_wizard/pruning_config_parser.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/configuration_wizard/pruning_config_parser.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/env.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/env.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/644ec953a7dc_pruning_support.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/644ec953a7dc_pruning_support.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/6ece06672ed3_v1_14.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/6ece06672ed3_v1_14.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/6f0d0f71d92e_v1_13.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/6f0d0f71d92e_v1_13.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic/versions/9e89549a08c8_v1_11.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic/versions/9e89549a08c8_v1_11.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/alembic.ini` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/alembic.ini`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_manager.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_manager.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/benchmark.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/benchmark.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/benchmark_result.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/benchmark_result.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/dataset.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/dataset.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/domain.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/domain.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/domain_flavour.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/domain_flavour.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/example.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/example.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/framework.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/framework.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/metric.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/metric.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/optimization.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/optimization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/optimization_type.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/optimization_type.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/precision.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/precision.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/profiling.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/profiling.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/profiling_result.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/profiling_result.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/project.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/project.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/pruning_details.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/pruning_details.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/transform.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/transform.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/tuning_details.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/tuning_details.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_models/tuning_history.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_models/tuning_history.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/benchmark_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/benchmark_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/dataset_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/dataset_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/db_operations.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/db_operations.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/diagnosis_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/diagnosis_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/dictionaries_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/dictionaries_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/examples_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/examples_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/model_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/model_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/optimization_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/optimization_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/profiling_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/profiling_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/db_operations/project_api_interface.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/db_operations/project_api_interface.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/params_interfaces.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/params_interfaces.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/db_manager/utils.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/db_manager/utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/diagnosis.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/diagnosis.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/factory.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/factory.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/onnxrt_diagnosis.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/onnx_diagnosis/onnxrt_diagnosis.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/op_details.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/op_details.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/op_entry.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/op_entry.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/tensorflow_diagnosis.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/diagnosis/tensorflow_diagnosis/tensorflow_diagnosis.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/file_browser/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/file_browser/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/file_browser/file_browser.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/file_browser/file_browser.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/attribute.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/attribute.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/collapser.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/collapser.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/edge.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/edge.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/graph.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/graph.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/graph_reader.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/graph_reader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/node.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/node.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/reader/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/reader/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/reader/onnxrt_reader.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/reader/onnxrt_reader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/graph/reader/tensorflow_reader.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/graph/reader/tensorflow_reader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/jobs_control_queue.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/jobs_control_queue.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/jobs_manager.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/jobs_manager.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/jobs_management/request.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/jobs_management/request.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/manage_workspace.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/manage_workspace.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/domain.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/domain.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/model_type_getter.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/model_type_getter.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/onnxrt/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/onnxrt/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/onnxrt/model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/onnxrt/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/pytorch/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/pytorch/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/pytorch/model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/pytorch/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/repository.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/repository.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/shape.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/shape.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/frozen_pb.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/frozen_pb.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/keras.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/keras.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/meta_graph.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/meta_graph.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/saved_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/saved_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model/tensorflow/utils.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model/tensorflow/utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/download_config.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/download_config.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/download_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/download_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/downloader.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/downloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/model_zoo/list_models.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/model_zoo/list_models.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/names_mapper/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/names_mapper/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/names_mapper/names_mapper.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/names_mapper/names_mapper.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/execute_optimization.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/execute_optimization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/factory.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/factory.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/graph_optimizer/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/graph_optimizer/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/graph_optimizer/graph_optimization.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/graph_optimizer/graph_optimization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/graph_optimizer/optimize_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/graph_optimizer/optimize_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/mixed_precision/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/mixed_precision/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/mixed_precision/mixed_precision.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/mixed_precision/mixed_precision.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/mixed_precision/optimize_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/mixed_precision/optimize_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/neural_coder_optimization/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/neural_coder_optimization/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/neural_coder_optimization/optimize_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/neural_coder_optimization/optimize_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/optimization.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/optimization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/pruning/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/pruning/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/pruning/optimize_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/pruning/optimize_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/pruning/pruning.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/pruning/pruning.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tune/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tune/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tune/tune_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tune/tune_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tune/tuning.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tune/tuning.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/optimization/tuning_history.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/optimization/tuning_history.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/execute_profiling.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/execute_profiling.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/factory.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/factory.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/profile_model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/profile_model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/profiler.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/profiler.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/profiling.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/profiling.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/factory.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/factory.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/profiler.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/profiler.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/components/profiling/tensorflow_profiler/utils.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/components/profiling/tensorflow_profiler/utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/inc_bench.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/inc_bench.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/dataloaders.json` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/dataloaders.json`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/metrics.json` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/metrics.json`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/model_wise_params.json` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/model_wise_params.json`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/models.json` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/models.json`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/image_recognition.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/image_recognition.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/nlp.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/nlp.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/object_detection.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/onnxrt_qlinearops/object_detection.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/pruning.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/pruning.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/default.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/default.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/image_recognition.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/pytorch/image_recognition.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/image_recognition.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/image_recognition.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/nlp.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/nlp.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/object_detection.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/object_detection.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/object_detection_ssd.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/object_detection_ssd.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/recommendation.yaml` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/predefined_configs/tensorflow/recommendation.yaml`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/pruning_details.json` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/pruning_details.json`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/transforms.json` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/transforms.json`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/configs/transforms_filter.json` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/configs/transforms_filter.json`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/consts.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/consts.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/environment.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/environment.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/exceptions.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/exceptions.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/executor.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/executor.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/expiring_dict.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/expiring_dict.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/github_info.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/github_info.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/hw_info.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/hw_info.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/json_serializer.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/json_serializer.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/logger.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/logger.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/parser.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/parser.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/proc.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/proc.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/processes.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/processes.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/singleton.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/singleton.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/status_updates.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/status_updates.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/templates/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/templates/dataloader_and_metric_template.txt` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/dataloader_and_metric_template.txt`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/templates/dataloader_template.txt` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/dataloader_template.txt`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/templates/metric.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/metric.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/templates/metric_template.txt` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/metric_template.txt`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/templates/workdir.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/templates/workdir.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/utils.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/config.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/config.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/dataloader.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/dataloader.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/evaluation.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/evaluation.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/graph_optimization.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/graph_optimization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/mixed_precision.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/mixed_precision.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/pruning.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/pruning.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/quantization.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/quantization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/workload/tuning.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/workload/tuning.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/utils/yaml_utils.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/utils/yaml_utils.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/communication.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/communication.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/configuration.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/configuration.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/exceptions.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/exceptions.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/router.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/router.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/server.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/server.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/__init__.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/__init__.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/benchmark.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/benchmark.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/history_snapshot_parser.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/history_snapshot_parser.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/model.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/model.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/optimization.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/optimization.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/profiling.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/profiling.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/request_data_processor.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/request_data_processor.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/response_generator.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/response_generator.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/service/workload.py` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/service/workload.py`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/3rdpartylicenses.txt` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/3rdpartylicenses.txt`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/004a-information-solid-gray.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/004a-information-solid-gray.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/004a-information-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/004a-information-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/005a-help-solid-blue.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/005a-help-solid-blue.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/005a-help-solid-gray.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/005a-help-solid-gray.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/005a-help-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/005a-help-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/006a-alert-solid-orange.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/006a-alert-solid-orange.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/006a-alert-solid-red.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/006a-alert-solid-red.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/007a-minus-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/007a-minus-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/008a-plus-solid-black.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/008a-plus-solid-black.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/008a-plus-solid-blue.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/008a-plus-solid-blue.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/008a-plus-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/008a-plus-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/009a-close-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/009a-close-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/010a-passed-completed-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/010a-passed-completed-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/016-edit-blue.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/016-edit-blue.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/016-edit-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/016-edit-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/016-edit.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/016-edit.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/043-organize-disabled.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/043-organize-disabled.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/043-organize.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/043-organize.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/050a-folder-solid-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/050a-folder-solid-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/050a-folder-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/050a-folder-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/052a-browse-preview-solid-gray.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/052a-browse-preview-solid-gray.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/052a-browse-preview-solid-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/052a-browse-preview-solid-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/056a-save-solid-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/056a-save-solid-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/057b-trash-outlined-gray.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/057b-trash-outlined-gray.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/057b-trash-outlined.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/057b-trash-outlined.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/073-menu.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/073-menu.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/074-rewind-reverse.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/074-rewind-reverse.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/077-arrow-up.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/077-arrow-up.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/083-arrow-forward-right.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/083-arrow-forward-right.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/088a-start-solid-gray.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/088a-start-solid-gray.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/088a-start-solid-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/088a-start-solid-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/088a-start-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/088a-start-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/145b-document-outlined-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/145b-document-outlined-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/145b-document-outlined.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/145b-document-outlined.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/146a-copy-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/146a-copy-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/160a-download-solid-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/160a-download-solid-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/160a-download-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/160a-download-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/174-gauge.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/174-gauge.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/221a-sunny-day-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/221a-sunny-day-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/222-night.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/222-night.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/234a-database-solid-disable.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/234a-database-solid-disable.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/234a-database-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/234a-database-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/289a-checklist-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/289a-checklist-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/291b-line-chart-outlined.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/291b-line-chart-outlined.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/292-growth-increase.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/292-growth-increase.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/298a-workflow-process-solid-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/298a-workflow-process-solid-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/298a-workflow-process-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/298a-workflow-process-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/307-org-chart-disabled.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/307-org-chart-disabled.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/307-org-chart-white.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/307-org-chart-white.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/307-org-chart.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/307-org-chart.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/383-general-support.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/383-general-support.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/create-new.png` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/create-new.png`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/005a-help-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/005a-help-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/043-organize-disabled.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/043-organize-disabled.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/043-organize.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/043-organize.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/174-gauge.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/174-gauge.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/234a-database-solid-disable.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/234a-database-solid-disable.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/234a-database-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/234a-database-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/298a-workflow-process-solid.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/298a-workflow-process-solid.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/307-org-chart-disabled.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/307-org-chart-disabled.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/dark/307-org-chart.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/dark/307-org-chart.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Bd.ttf` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Bd.ttf`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Lt.ttf` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Lt.ttf`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Rg.ttf` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/IntelClear_Rg.ttf`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-bold.ttf` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-bold.ttf`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-light.ttf` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-light.ttf`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-regular.ttf` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/fonts/intelone-display-regular.ttf`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/logo-energyblue-72px.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/logo-energyblue-72px.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/model-file.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/model-file.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/model-folder.svg` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/model-folder.svg`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/nn.png` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/nn.png`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/assets/performance.png` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/assets/performance.png`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/index.html` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/index.html`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/main.15f64b4092974083.js` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/main.15f64b4092974083.js`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/main.8f02ed35744647d6.js` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/main.8f02ed35744647d6.js`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/main.b1d2e7ec4704abc2.js` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/main.b1d2e7ec4704abc2.js`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/polyfills.05e532f1e1f2503a.js` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/polyfills.05e532f1e1f2503a.js`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/polyfills.20acf87fa4379d4f.js` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/polyfills.20acf87fa4379d4f.js`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/runtime.842b7f3162f7690e.js` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/runtime.842b7f3162f7690e.js`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/styles.00d3de8fab67a2a5.css` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/styles.00d3de8fab67a2a5.css`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/styles.3c84233102d6c6b4.css` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/styles.3c84233102d6c6b4.css`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/ux/web/static/styles.a563d0a77a1990e6.css` & `neural_compressor_full-2.1.1/neural_compressor/ux/web/static/styles.a563d0a77a1990e6.css`

 * *Files identical despite different names*

### Comparing `neural_compressor_full-2.1/neural_compressor/version.py` & `neural_compressor_full-2.1.1/neural_compressor/version.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,8 +12,8 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Intel® Neural Compressor: An open-source Python library supporting popular model compression techniques."""
-__version__ = "2.1"
+__version__ = "2.1.1"
```

### Comparing `neural_compressor_full-2.1/neural_compressor_full.egg-info/PKG-INFO` & `neural_compressor_full-2.1.1/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
-Name: neural-compressor-full
-Version: 2.1
+Name: neural_compressor_full
+Version: 2.1.1
 Summary: Repository of Intel® Neural Compressor
 Home-page: https://github.com/intel/neural-compressor
 Author: Intel AIA Team
 Author-email: feng.tian@intel.com, haihao.shen@intel.com, suyue.chen@intel.com
 License: Apache 2.0
 Keywords: quantization,auto-tuning,post-training static quantization,post-training dynamic quantization,quantization-aware training,tuning strategy
 Classifier: Intended Audience :: Science/Research
@@ -35,15 +35,15 @@
 
 Intel® Neural Compressor aims to provide popular model compression techniques such as quantization, pruning (sparsity), distillation, and neural architecture search on mainstream frameworks such as [TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), [ONNX Runtime](https://onnxruntime.ai/), and [MXNet](https://mxnet.apache.org/),
 as well as Intel extensions such as [Intel Extension for TensorFlow](https://github.com/intel/intel-extension-for-tensorflow) and [Intel Extension for PyTorch](https://github.com/intel/intel-extension-for-pytorch).
 In particular, the tool provides the key features, typical examples, and open collaborations as below:
 
 * Support a wide range of Intel hardware such as [Intel Xeon Scalable processor](https://www.intel.com/content/www/us/en/products/details/processors/xeon/scalable.html), [Intel Xeon CPU Max Series](https://www.intel.com/content/www/us/en/products/details/processors/xeon/max-series.html), [Intel Data Center GPU Flex Series](https://www.intel.com/content/www/us/en/products/details/discrete-gpus/data-center-gpu/flex-series.html), and [Intel Data Center GPU Max Series](https://www.intel.com/content/www/us/en/products/details/discrete-gpus/data-center-gpu/max-series.html) with extensive testing; support AMD CPU, ARM CPU, and NVidia GPU through ONNX Runtime with limited testing
 
-* Validate more than 10,000 models such as [Bloom-176B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [OPT-30B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [Stable Diffusion](/examples/pytorch/nlp/huggingface_models/text-to-image/quantization), [GPT-J](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/fx), [BERT-Large](/examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx), and [ResNet50](/examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx) from popular model hubs such as [Hugging Face](https://huggingface.co/), [Torch Vision](https://pytorch.org/vision/stable/index.html), and [ONNX Model Zoo](https://github.com/onnx/models#models), by leveraging zero-code optimization solution [Neural Coder](/neural_coder#what-do-we-offer) and automatic [accuracy-driven](/docs/source/design.md#workflow) quantization strategies
+* Validate more than 10,000 models such as [Bloom-176B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [OPT-6.7B](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/ipex/smooth_quant), [Stable Diffusion](/examples/pytorch/nlp/huggingface_models/text-to-image/quantization), [GPT-J](/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/fx), [BERT-Large](/examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx), and [ResNet50](/examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx) from popular model hubs such as [Hugging Face](https://huggingface.co/), [Torch Vision](https://pytorch.org/vision/stable/index.html), and [ONNX Model Zoo](https://github.com/onnx/models#models), by leveraging zero-code optimization solution [Neural Coder](/neural_coder#what-do-we-offer) and automatic [accuracy-driven](/docs/source/design.md#workflow) quantization strategies
 
 * Collaborate with cloud marketplace such as [Google Cloud Platform](https://console.cloud.google.com/marketplace/product/bitnami-launchpad/inc-tensorflow-intel?project=verdant-sensor-286207), [Amazon Web Services](https://aws.amazon.com/marketplace/pp/prodview-yjyh2xmggbmga#pdp-support), and [Azure](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/bitnami.inc-tensorflow-intel), software platforms such as [Alibaba Cloud](https://www.intel.com/content/www/us/en/developer/articles/technical/quantize-ai-by-oneapi-analytics-on-alibaba-cloud.html) and [Tencent TACO](https://new.qq.com/rain/a/20221202A00B9S00), and open AI ecosystem such as [Hugging Face](https://huggingface.co/blog/intel), [PyTorch](https://pytorch.org/tutorials/recipes/intel_neural_compressor_for_pytorch.html), [ONNX](https://github.com/onnx/models#models), and [Lightning AI](https://github.com/Lightning-AI/lightning/blob/master/docs/source-pytorch/advanced/post_training_quantization.rst)
 
 ## Installation
 
 ### Install from pypi
 ```Shell
@@ -79,82 +79,82 @@
 > More quick samples can be found in [Get Started Page](./docs/source/get_started.md).
 
 ## Documentation
 
 <table class="docutils">
   <thead>
   <tr>
-    <th colspan="9">Overview</th>
+    <th colspan="8">Overview</th>
   </tr>
   </thead>
   <tbody>
     <tr>
-      <td colspan="3" align="center"><a href="./docs/source/design.md#architecture">Architecture</a></td>
+      <td colspan="2" align="center"><a href="./docs/source/design.md#architecture">Architecture</a></td>
       <td colspan="2" align="center"><a href="./docs/source/design.md#workflow">Workflow</a></td>
       <td colspan="2" align="center"><a href="https://intel.github.io/neural-compressor/latest/docs/source/api-doc/apis.html">APIs</a></td>
       <td colspan="2" align="center"><a href="./docs/source/bench.md">GUI</a></td>
     </tr>
     <tr>
       <td colspan="2" align="center"><a href="examples/README.md#notebook-examples">Notebook</a></td>
       <td colspan="2" align="center"><a href="examples/README.md">Examples</a></td>
-      <td colspan="5" align="center"><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit</a></td>
+      <td colspan="4" align="center"><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit</a></td>
     </tr>
   </tbody>
   <thead>
     <tr>
-      <th colspan="9">Python-based APIs</th>
+      <th colspan="8">Python-based APIs</th>
     </tr>
   </thead>
   <tbody>
     <tr>
         <td colspan="2" align="center"><a href="./docs/source/quantization.md">Quantization</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/mixed_precision.md">Advanced Mixed Precision</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/mixed_precision.md">Advanced Mixed Precision</a></td>
         <td colspan="2" align="center"><a href="./docs/source/pruning.md">Pruning (Sparsity)</a></td> 
         <td colspan="2" align="center"><a href="./docs/source/distillation.md">Distillation</a></td>
     </tr>
     <tr>
         <td colspan="2" align="center"><a href="./docs/source/orchestration.md">Orchestration</a></td>        
         <td colspan="2" align="center"><a href="./docs/source/benchmark.md">Benchmarking</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/distributed.md">Distributed Compression</a></td>
-        <td colspan="3" align="center"><a href="./docs/source/export.md">Model Export</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/distributed.md">Distributed Compression</a></td>
+        <td colspan="2" align="center"><a href="./docs/source/export.md">Model Export</a></td>
     </tr>
   </tbody>
   <thead>
     <tr>
-      <th colspan="9">Neural Coder (Zero-code Optimization)</th>
+      <th colspan="8">Neural Coder (Zero-code Optimization)</th>
     </tr>
   </thead>
   <tbody>
     <tr>
-        <td colspan="1" align="center"><a href="./neural_coder/docs/PythonLauncher.md">Launcher</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/docs/PythonLauncher.md">Launcher</a></td>
         <td colspan="2" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_lab/README.md">JupyterLab Extension</a></td>
-        <td colspan="3" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_vscode/README.md">Visual Studio Code Extension</a></td>
-        <td colspan="3" align="center"><a href="./neural_coder/docs/SupportMatrix.md">Supported Matrix</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/extensions/neural_compressor_ext_vscode/README.md">Visual Studio Code Extension</a></td>
+        <td colspan="2" align="center"><a href="./neural_coder/docs/SupportMatrix.md">Supported Matrix</a></td>
     </tr>    
   </tbody>
   <thead>
       <tr>
-        <th colspan="9">Advanced Topics</th>
+        <th colspan="8">Advanced Topics</th>
       </tr>
   </thead>
   <tbody>
       <tr>
-          <td colspan="1" align="center"><a href="./docs/source/adaptor.md">Adaptor</a></td>
+          <td colspan="2" align="center"><a href="./docs/source/adaptor.md">Adaptor</a></td>
           <td colspan="2" align="center"><a href="./docs/source/tuning_strategies.md">Strategy</a></td>
-          <td colspan="3" align="center"><a href="./docs/source/distillation_quantization.md">Distillation for Quantization</a></td>
-          <td colspan="3" align="center"><a href="./docs/source/smooth_quant.md">SmoothQuant</td>
+          <td colspan="2" align="center"><a href="./docs/source/distillation_quantization.md">Distillation for Quantization</a></td>
+          <td colspan="2" align="center"><a href="./docs/source/smooth_quant.md">SmoothQuant</td>
       </tr>
   </tbody>
 </table>
 
 ## Selected Publications/Events
+* Blog on Medium: [Effective Post-training Quantization for Large Language Models with Enhanced SmoothQuant Approach](https://medium.com/@NeuralCompressor/effective-post-training-quantization-for-large-language-models-with-enhanced-smoothquant-approach-93e9d104fb98) (Apr 2023)
+* Blog by Intel: [Intel® Xeon® Processors Are Still the Only CPU With MLPerf Results, Raising the Bar By 5x](https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Xeon-Processors-Are-Still-the-Only-CPU-With-MLPerf-Results/post/1472750) (Apr 2023)
 * Post on Social Media: [Adopt with Tencent TACO: Heterogeneous optimization is also key to improving AI computing power](https://mp.weixin.qq.com/s/I-FQqOuW7HTnwXegLGNAtw) (Mar 2023)
 * Post on Social Media: [Training and Inference for Stable Diffusion | Intel Business](https://www.youtube.com/watch?v=emCgSTlJaAg) (Jan 2023)
-* Blog by Intel: [Intel® AMX Enhances AI Inference Performance](https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/advanced-matrix-extensions/alibaba-solution-brief.html) (Jan 2023)
-* Blog by TensorFlow: [Optimizing TensorFlow for 4th Gen Intel Xeon Processors](https://blog.tensorflow.org/2023/01/optimizing-tensorflow-for-4th-gen-intel-xeon-processors.html) (Jan 2023)
 * NeurIPS'2022: [Fast Distilbert on CPUs](https://arxiv.org/abs/2211.07715) (Oct 2022)
 * NeurIPS'2022: [QuaLA-MiniLM: a Quantized Length Adaptive MiniLM](https://arxiv.org/abs/2210.17114) (Oct 2022)
 
 > View our [Full Publication List](./docs/source/publication_list.md).
 
 ## Additional Content
```

### Comparing `neural_compressor_full-2.1/neural_compressor_full.egg-info/SOURCES.txt` & `neural_compressor_full-2.1.1/neural_compressor_full.egg-info/SOURCES.txt`

 * *Files 0% similar despite different names*

```diff
@@ -250,14 +250,15 @@
 neural_compressor/adaptor/tf_utils/transform_graph/bias_correction.py
 neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base.py
 neural_compressor/adaptor/tf_utils/transform_graph/insert_logging.py
 neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat.py
 neural_compressor/adaptor/torch_utils/__init__.py
 neural_compressor/adaptor/torch_utils/bf16_convert.py
 neural_compressor/adaptor/torch_utils/hawq_metric.py
+neural_compressor/adaptor/torch_utils/model_wrapper.py
 neural_compressor/adaptor/torch_utils/smooth_quant.py
 neural_compressor/adaptor/torch_utils/symbolic_trace.py
 neural_compressor/adaptor/torch_utils/util.py
 neural_compressor/algorithm/__init__.py
 neural_compressor/algorithm/algorithm.py
 neural_compressor/algorithm/fast_bias_correction.py
 neural_compressor/algorithm/smooth_quant.py
```

### Comparing `neural_compressor_full-2.1/setup.py` & `neural_compressor_full-2.1.1/setup.py`

 * *Files identical despite different names*

